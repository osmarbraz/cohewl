{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPMg5evR7fOzO321614Xjox"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"78HE8FLsKN9Q"},"source":["# Ajuste fino do conjunto de dados do CohQuAD Init pt-br usando BERT Transformers by HuggingFace e Lotes Inteligentes e Validação Holdout por N(5) vezes\n","\n","Realiza o ajuste fino do modelo BERT pré-treinado com o conjunto de dados para discriminar documentos originais e modificados e avalia utilizando validação holdout 30%/70%.\n","\n","Classes:\n","- 1 - Documento original\n","- 0 - Documento modificado\n","\n","Características:\n","- Realiza o ajuste fino nos dados N(5) vezes.\n","- Realiza o ajuste fino utilizando documentos originais e modificados em pares.\n","- O treinamento do modelo utiliza o conjunto de dados com  com 70% dos dados.\n","- A avaliação do modelo utiliza o conjunto de dados de teste com 30% dos dados.\n","- Utiliza Lotes Inteligentes para otimizar o tempo de execução de treinamento.\n","- Opcionalmente salva o modelo ajustado para reaproveitamento.\n","\n","- A seção 2 - parametrização define os argumentos da execução.\n","\n","O ajuste fino utiliza os arquivos:\n","- `original.zip`\n","- `originalpos.zip`\n","- `perturbado_pX_kY.zip`\n","- `perturbadopos_pX_kY.zip`\n","\n","Nos nomes dos arquivos `perturbado_pX_kY.zip`,`perturbadopos_pX_kY.zip`, X é o número de documentos modificados e Y o valor de top K predições. (Somente P=1 e K=1 para o manual)\n","\n","\n","----------------------------\n","\n","**Link biblioteca Transformers:**\n","https://github.com/huggingface/transformers\n","\n","**Artigo original BERT:**\n","https://arxiv.org/pdf/1506.06724.pdf\n","\n","**Artigo padding dinâmico:**\n","https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P3G9t8llcrKz"},"source":["# 1 Preparação do ambiente\n","Preparação do ambiente para execução do notebook."]},{"cell_type":"markdown","metadata":{"id":"cW_5CN8En7zl"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcTEKloUn-VK"},"outputs":[],"source":["import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOHCMMDsiyZg"},"outputs":[],"source":["print(\"  Tempo de início de processamento:  {:} (h:mm:ss)\".format(inicio_processamento))"]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj5TaAH_5-nB"},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================  \n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.    \n","    \"\"\"\n","    \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):  \n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","    \n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B1mvfAU5jZf"},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"    \n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","    \n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.      \n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.      \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","    \n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download    \n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]  \n","\n","    # Define o nome e caminho do arquivo temporário    \n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","    \n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","    \n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:        \n","        tamanho_conteudo = data.headers.get(\"Content-Length\")        \n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)                \n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):        \n","            if chunk:                \n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","    \n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","    \n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qwKjGvyLG4v"},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","    \n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jirIzIstLea0"},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.  \n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC9Xppq-_R0w"},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.   \n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    sentencas = []\n","    for linha in arquivo:        \n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkVk5LQT_G3f"},"outputs":[],"source":["def salvar(nome_arquivo,texto):                       \n","    \"\"\"\n","      Salva um texto em arquivo.\n","     \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.     \n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"1q7fizBnsZFQ"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Guy6B4whsZFR"},"outputs":[],"source":["import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    '''\n","    Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    '''\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","    \n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))"]},{"cell_type":"markdown","metadata":{"id":"nFoXtrnnMisv"},"source":["Calcula a média de uma lista tempo string no formato hh:mm:ss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PqS6-M1fqb9V"},"outputs":[],"source":["# Import das bibliotecas.\n","from cmath import rect, phase\n","from math import radians, degrees\n","  \n","def mediaAngulo(deg):\n","    return degrees(phase(sum(rect(1, radians(d)) for d in deg)/len(deg)))\n"," \n","def mediaTempo(tempos):\n","    '''\n","    Calcula a média de uma lista de tempo string no formato hh:mm:ss\n","    '''\n","    t = (tempo.split(':') for tempo in tempos)\n","    # Converte para segundos\n","    segundos = ((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)\n","    # Verifica se deu algum dia\n","    dia = 24 * 60 * 60\n","    # Converte para angulos\n","    para_angulos = [s * 360. / dia for s in segundos]\n","    # Calcula a média dos angulos\n","    media_como_angulo = mediaAngulo(para_angulos)\n","    media_segundos = media_como_angulo * dia / 360.\n","    if media_segundos < 0:\n","        media_segundos += dia\n","    # Recupera as horas e os minutos  \n","    h, m = divmod(media_segundos, 3600)\n","    # Recupera os minutos e os segundos\n","    m, s = divmod(m, 60)    \n","    return '{:02d}:{:02d}:{:02d}'.format(int(h), int(m), int(s))"]},{"cell_type":"markdown","metadata":{"id":"Mw8KyNOJJLwf"},"source":["Calcula a soma de uma lista de tempo string no formato hh:mm:ss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4gekVLwJIcD"},"outputs":[],"source":["def somaTempo(tempos):\n","    '''\n","    Calcula a soma de uma lista de tempo string no formato hh:mm:ss\n","    '''\n","    t = (tempo.split(':') for tempo in tempos)\n","    # Converte para segundos\n","    segundos = ((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)\n","    # Soma os segundos\n","    soma_segundos = sum([s * 1. for s in segundos])\n","    # Recupera as horas e os minutos   \n","    h, m = divmod(soma_segundos, 3600)\n","    # Recupera os minutos e os segundos\n","    m, s = divmod(m, 60)    \n","    return '{:02d}:{:02d}:{:02d}'.format(int(h), int(m), int(s))"]},{"cell_type":"markdown","metadata":{"id":"nszM7hA_IoKP"},"source":["Em muitos dos meus loops for (de longa duração), imprimirei atualizações periódicas de progresso. Normalmente, eu escolho o intervalo de atualização manualmente, mas para este Notebook, defini uma função auxiliar para fazer essa escolha para mim :)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTrHp0_FgOSg"},"outputs":[],"source":["def obterIntervaloAtualizacao(total_iteracoes, numero_atualizacoes):\n","    '''\n","     Esta função tentará escolher um intervalo de atualização de progresso inteligente\n","     com base na magnitude das iterações totais.\n","\n","     Parâmetros:\n","       `total_iteracoes` - O número de iterações no loop for.\n","       `numero_atualizacoes` - Quantas vezes queremos ver uma atualização sobre o\n","                               curso do loop for.\n","     '''\n","    \n","    # Divida o total de iterações pelo número desejado de atualizações. Provavelmente\n","    # este será um número feio.\n","    intervalo_exato = total_iteracoes / numero_atualizacoes\n","\n","    # A função `arredondar` tem a capacidade de arredondar um número para, por exemplo, o\n","    # milésimo mais próximo: round (intervalo_exato, -3)\n","    #\n","    # Para determinar a magnitude para arredondar, encontre a magnitude do total,\n","    # e então vá uma magnitude abaixo disso.\n","    \n","    # Obtenha a ordem de magnitude do total.\n","    ordem_magnitude = len(str(total_iteracoes)) - 1\n","    \n","    # Nosso intervalo de atualização deve ser arredondado para uma ordem de magnitude menor.\n","    magnitude_arrendonda = ordem_magnitude - 1\n","\n","    # Arredonde para baixo e lance para um int.\n","    intervalo_atualizacao = int(round(intervalo_exato, -magnitude_arrendonda))\n","\n","    # Não permita que o intervalo seja zero!\n","    if intervalo_atualizacao == 0:\n","        intervalo_atualizacao = 1\n","\n","    return intervalo_atualizacao"]},{"cell_type":"markdown","metadata":{"id":"b9OAqrHMjfhJ"},"source":["Classe(ModeloArgumentosMedida) de definição dos parâmetros do modelo para medida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgmN6RqDRDZS"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )    \n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )"]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModeloArgumentosClassificacao) de definição dos parâmetros do modelo para classificação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhYOQI-JbuFc"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosClassificacao:\n","    '''\n","    Classe(ModeloArgumentosClassificacao) de definição dos parâmetros do modelo BERT para a classificação de coerência.\n","    '''\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )\n","    num_labels: int = field(\n","        default=2,\n","        metadata={\"help\": \"número de rótulos a serem classificados.\"},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    optimizer: str = field(\n","        default=\"AdamW\",\n","        metadata={\"help\": \"otimizador do modelo.\"},\n","    )\n","    use_wandb : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o uso do wandb.\"},\n","    )\n","    salvar_modelo_wandb : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o salvamento do modelo no wandb.\"},\n","    )\n","    salvar_modelo : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o salvamento do modelo.\"},\n","    )\n","    salvar_avaliacao : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o salvamento do resultado da avaliação.\"},\n","    )     \n","    salvar_classificacao : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o salvamento da classificação.\"},\n","    )\n","    usar_mcl_ajustado: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o carragamento de mcl ajustado.'},\n","    ) \n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos perturbados comparados com o seu original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de previsões de palavras recuperadas mais próximas da máscara.\"},\n","    ) \n","    epoca: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Época a ser avaliada.\"},\n","    )    \n","    vezes_treinamento: int = field(\n","        default=\"5\",\n","        metadata={\"help\": \"Log da vez de execução do treinamento avaliado.\"},\n","    )   "]},{"cell_type":"markdown","metadata":{"id":"rceIwWa7UmFZ"},"source":["Biblioteca de limpeza de tela"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXTEvmuhUmjO"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"-DnPWIRHfq7V"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54St2CZf5lWv"},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMiH0E3OnRa1"},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"yuHoA4Dx6K1M"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"0zhAltEP6K1M"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"IxAlgXv66K1M"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cmva6ltA6K1M"},"outputs":[],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"XrC2SG3x6K1M"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOnQUkWZ6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def getDeviceGPU():\n","    \"\"\"\n","    Retorna um dispositivo de GPU se disponível ou CPU.\n","    \n","    Retorno:\n","    `device` - Um device de GPU ou CPU.       \n","    \"\"\"\n","        \n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        \n","        # Diz ao PyTorch para usar GPU.    \n","        device = torch.device(\"cuda\")\n","        \n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:        \n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","        \n","    return device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WcMhNxsE6K1N"},"outputs":[],"source":["device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"kkdlEouHftcJ"},"source":["Conecta o modelo ao device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-znVDGyfsVx"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def conectaGPU(model, device):\n","    \"\"\"\n","      Conecta um modelo BERT a GPU.\n","\n","      Parâmetros:\n","        `model` - Um modelo BERT carregado.       \n","        `device` - Um device de GPU.     \n","    \n","      Retorno:\n","        `model` - Um objeto model BERT conectado a GPU.     \n","    \"\"\"\n","    # Associa a GPU ao modelo.\n","    model.to(device)\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():    \n","        # Diga ao pytorch para rodar este modelo na GPU.\n","        logging.info(\"Pytorch rodando o modelo na GPU.\")\n","        model.cuda()\n","        \n","    else:\n","        logging.info(\"Pytorch rodando sem GPU.\")\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"CRdtvR_J6K1N"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSmGz55H6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"LJzK1XjCnZak"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dz3RRgR-nZan"},"outputs":[],"source":["# Monta o Google Drive para esta instância de notebook.\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejzpgGrFM0-j"},"outputs":[],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"6c7JaP-LM2bW"},"source":["Login via linha de comando"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOvp48GnMuvM"},"outputs":[],"source":["!wandb login aded3bc0ea651fff536cc08ba69caf8ac4141cfd"]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.8 Instalação BERT da Hugging Face"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XeR8Sbz0B5x"},"outputs":[],"source":["!pip install -U transformers==4.5.1"]},{"cell_type":"markdown","metadata":{"id":"giOsAS5v61go"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpYGLOkkHEKY"},"outputs":[],"source":["# Prefixo do nome do arquivo usado nas saídas projeto C = Cris, SB = SmartBatch, HT = Holdout\n","NOME_BASE_SAIDA = \"AjusteFinoCohQuADInitptbr_C_SB_HT_v1\"\n","\n","# Definição dos parâmetros a serem avaliados\n","\n","######## Parâmetros Individuais ########\n","\n","# Quantidade de documentos a serem perturbados a partir do original.    \n","DOCUMENTOS_PERTURBADOS = 1 # Somente 1 para o Cohebert manual\n","\n","# Quantidade de palavras a serem recuperadas mais próximas da máscara. \n","TOP_K_PREDICAO = 1 # Somente 1 para o Cohebert manual\n","\n","# Tamanho dos lotes de treino e avaliação. Usar 16 ou 32\n","TAMANHO_LOTE = 32\n","\n","######## Parâmetros de conjunto ########\n","# Taxas de aprendizagem a serem avaliados\n","TAXAS_DE_APRENDIZAGEM = [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]\n","\n","# MCL a serem avaliados\n","#NOMES_MODELO = ['https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip',\n","#                'https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip',\n","#                'bert-base-multilingual-cased']\n","\n","NOMES_MODELO = [\"neuralmind/bert-large-portuguese-cased\"]\n","\n","######## Parâmetros de intervalo ########\n","# Número de épocas a serem avaliadas\n","# Todas as épocas são avaliadas e os resultados da classificação são salvos de 0 até 4.\n","# A época 0 avalia o modelo sem realizar ajuste fino.\n","EPOCAS = 4\n","\n","# Determina o intervalo de repetições a ser executado. De 1 até 5\n","# Usado para quando o processamento é interrompido.\n","inicio_repeticao = 1\n","fim_repeticao = 5"]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"uOioMDitx4EB"},"source":["Parâmetros de treinamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZM7GWMh3hXqw"},"outputs":[],"source":["# Importando as bibliotecas.\n","from transformers import TrainingArguments\n","\n","# Definição dos parâmetros de Treinamento\n","training_args = TrainingArguments(\n","    # NOME_BASE_SAIDA = Nome base do arquivo de saída   \n","    # P = documentos perturbados\n","    # K = previsões palavras \n","    # E = número total de épocas de treinamento\n","    # e = número da época executada\n","    # lr = taxa de aprendizagem\n","    # b = lotes de treino e avaliação    \n","    # n = número da repetição\n","    output_dir = NOME_BASE_SAIDA + \"K_1_P_1_E_4_e_1_lr_5_b_8_4_n\", # É utilizado somente para logs de arquivo e wandb   \n","    save_steps = 0,    \n","    seed = 42,\n","    num_train_epochs = EPOCAS, # Intervalo de valores: 2, 3, 4. É utilizado somente para logs.\n","    learning_rate = 5e-5, # Intervalo de valores: 1e-5, 2e-5, 3e-5, 4e-5, 5e-5. É utilizado somente para logs.\n","    gradient_accumulation_steps = 1,\n","    per_device_train_batch_size = TAMANHO_LOTE, \n","    per_device_eval_batch_size = TAMANHO_LOTE,              \n","    evaluation_strategy = 'epoch',    \n",")"]},{"cell_type":"markdown","metadata":{"id":"Zd5X9PeGx8oW"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4AW1hTYhHq-"},"outputs":[],"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosClassificacao(     \n","    max_seq_len = 512,\n","    pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",    \n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",   \n","    \n","    do_lower_case = False,   # default True\n","    num_labels = 2,\n","    output_attentions = False,    # default False\n","    output_hidden_states = False, # default False \n","    optimizer = 'AdamW',\n","    use_wandb = True, # Ativa a gravação de logs no wandb\n","    salvar_modelo_wandb = False, # Ativa o salvamento do MCL no wandb\n","    salvar_modelo = False, # Ativa o salvamento do MCL no googledrive\n","    salvar_avaliacao = True, # Salva o resultado classificações\n","    salvar_classificacao = True, # Salva o resultado da avaliação das classificações\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path.    \n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.    \n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100, 500 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara. \n","    vezes_treinamento = fim_repeticao # Intervalo de valores: 1 a 5, É utilizado somente para logs. Use as variáveis do bloco a seguir para definir um intervalo de repetições.\n",")"]},{"cell_type":"markdown","metadata":{"id":"_R_RPq2MIu_E"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0SS8IskIu_E"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_INIT_PTBR\""]},{"cell_type":"markdown","metadata":{"id":"cmx5rzAsIaaw"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQyz8gjrIaax"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"tDgJTbPOZ8SW"},"source":["## Inicialização diretórios"]},{"cell_type":"markdown","metadata":{"id":"qpSERA9TC4WU"},"source":["Diretório base local"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edg7eW2cDflg"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","def criaDiretorioLocal():\n","\n","  # Cria o diretório para receber os arquivos Originais e Permutados\n","  # Diretório a ser criado\n","  dirbase = DIRETORIO_LOCAL[:-1]\n","\n","  if not os.path.exists(dirbase):  \n","      # Cria o diretório\n","      os.makedirs(dirbase)    \n","      logging.info(\"Diretório criado: {}.\".format(dirbase))\n","  else:    \n","      logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xge0ar9MJoKy"},"outputs":[],"source":["criaDiretorioLocal()"]},{"cell_type":"markdown","metadata":{"id":"4FmT9nhbaE3D"},"source":["Diretório para conter as os resultados das classificações"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zO76uzj_C3zQ"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioClassificacao():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"/validacao_classificacao_palavra\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1Ot2h_bJuxy"},"outputs":[],"source":["criaDiretorioClassificacao()"]},{"cell_type":"markdown","metadata":{"id":"vIkT6ksqaQs3"},"source":["Diretório para conter os arquivos da avaliação Holdout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIV4xj6zDnb8"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioClassificacaoHoldout():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/holdout\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiOVjJ5BJzE1"},"outputs":[],"source":["criaDiretorioClassificacaoHoldout()"]},{"cell_type":"markdown","metadata":{"id":"cjP6v878aWR7"},"source":["Diretório para conter os arquivos de classificação da avaliação Holdout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qf6UWAZYDsgm"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioClassificacaoHoldoutClassificacao():\n","\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/holdout/Classificacao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IBBfHFuPJ3NM"},"outputs":[],"source":["criaDiretorioClassificacaoHoldoutClassificacao()"]},{"cell_type":"markdown","metadata":{"id":"x_G30UWEaeoN"},"source":["Diretório para conter os arquivos de resultado da avaliação Holdout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VxxKCPTRD3bh"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioClassificacaoHoldoutAvaliacao():\n","\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/holdout/Avaliacao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D691HF9TJ7av"},"outputs":[],"source":["criaDiretorioClassificacaoHoldoutAvaliacao()"]},{"cell_type":"markdown","metadata":{"id":"IBY7q_uH8JSE"},"source":["# 3 BERT"]},{"cell_type":"markdown","metadata":{"id":"MBGTMy8Ic7GK"},"source":["## 3.1 Modelo Pré-treinado BERT"]},{"cell_type":"markdown","metadata":{"id":"uiuxdXe9t1BX"},"source":["### Funções Auxiliares"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Huw0x5kt1Le"},"outputs":[],"source":["def getNomeModeloBERT(model_args):\n","    '''    \n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","    \n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"        \n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","        else:\n","            if 'bert' in model_args.pretrained_model_name_or_path:\n","                MODELO_BERT = \"_BERT\"  \n","            \n","    return MODELO_BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYJB4ik7t5xe"},"outputs":[],"source":["def getTamanhoBERT(model_args):\n","    '''    \n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","    \n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","    \n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","        \n","    return TAMANHO_BERT  "]},{"cell_type":"markdown","metadata":{"id":"rHt4e5pAcEMd"},"source":["### Função download Modelo Pre-treinado BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peDUrV2ccEXA"},"outputs":[],"source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\" \n","    \n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","        \n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","        \n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo.\")\n","            # Apaga o diretório e os arquivos existentes                     \n","            shutil.rmtree(DIRETORIO_MODELO)\n","        \n","        # Realiza o download do arquivo do modelo        \n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.                \n","        arquivo_zip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivo_zip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.        \n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","        \n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta.\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada.\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"V74WUpHqcfoI"},"source":["### Copia o modelo do BERT ajustado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQMpf9yycf8f"},"outputs":[],"source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\" \n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO) \n","   \n","    logging.info(\"Modelo BERT ajustado copiado!\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"]},{"cell_type":"markdown","metadata":{"id":"eaneOhAKcO-3"},"source":["### Verifica de onde utilizar o modelo do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTy1TXz3cPKS"},"outputs":[],"source":["def verificaModelo(model_args):\n","    \"\"\" \n","    Verifica de onde utilizar o modelo.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","    \n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\" \n","\n","    DIRETORIO_MODELO = None\n","    \n","    if model_args.usar_mcl_ajustado == True:        \n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","        \n","        logging.info(\"Usando modelo BERT ajustado.\")\n","        \n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")        \n","        \n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"6tKcaIfReqdy"},"source":["## 3.2 Tokenizador BERT"]},{"cell_type":"markdown","metadata":{"id":"e8n7Z5s-QZF8"},"source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzAuptkwQZR3"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","    \n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","    \n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"]},{"cell_type":"markdown","metadata":{"id":"GYRV9KfHQE6v"},"source":["## 3.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**\n","\n","A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL."]},{"cell_type":"markdown","metadata":{"id":"-pZZrUKRhR3e"},"source":["### Função carrega modelo BERT medida\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zj0G_cbZRCV"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertModel # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","    \n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","        `model_args` - Objeto com os argumentos do modelo.   \n","    \n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:        \n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertModel.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","        \n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertModel.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"rvhXRGskk9yD"},"source":["### Função carrega modelo BERT classificação\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JUEyjCChUQh"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertForSequenceClassification # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloClassifica(DIRETORIO_MODELO, model_args):\n","    ''' \n","    Carrega o modelo e retorna o modelo.\n","    \n","    Parâmetros:\n","    `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","    `model_args` - Objeto com os argumentos do modelo.\n","    \n","    Retorno:\n","    `model` - Um objeto do modelo BERT carregado.\n","    ''' \n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if 'http' in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:\n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para classificação.\".format(DIRETORIO_MODELO))\n","\n","        model = BertForSequenceClassification.from_pretrained(DIRETORIO_MODELO, \n","                                                              num_labels=model_args.num_labels,\n","                                                              output_attentions=model_args.output_attentions,\n","                                                              output_hidden_states=model_args.output_hidden_states)\n","            \n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para classificação.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertForSequenceClassification.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                                              num_labels=model_args.num_labels,\n","                                                              output_attentions=model_args.output_attentions,\n","                                                              output_hidden_states=model_args.output_hidden_states)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"-uFDhRTZe2Js"},"source":["### Função carrega o BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVtAUbUBe2iS"},"outputs":[],"source":["def carregaBERT(model_args):\n","    \"\"\" \n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:    \n","        `model` - Um objeto do modelo BERT carregado.       \n","        `tokenizer` - Um objeto tokenizador BERT carregado.       \n","    \"\"\"\n","            \n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","    \n","    # Variável para conter o modelo\n","    model = None\n","    \n","    # Verifica o tipo do modelo em model_args    \n","    if type(model_args) == ModeloArgumentosMedida:\n","        # Carrega o modelo para cálculo da medida\n","        model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","        \n","    else:\n","        # Carrega o modelo para classificação\n","        model = carregaModeloClassifica(DIRETORIO_MODELO, model_args)\n","        \n","        # Recupera o dispositivo da GPU \n","        device = getDeviceGPU()\n","    \n","        # Conecta o modelo a GPU\n","        model = conectaGPU(model, device)\n","                       \n","    # Carrega o tokenizador. \n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","    \n","    return model, tokenizer"]},{"cell_type":"markdown","metadata":{"id":"x5NTxBRKfAcT"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6sPjTQnuQV2"},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"wJdbTzeejhOE"},"source":["# 4 Treino"]},{"cell_type":"markdown","metadata":{"id":"IrKMXRNm7OI6"},"source":["## 4.1 Wandb\n","\n","https://wandb.ai/osmar-braz/AjusteFinoCohebert_v1_C_SB_HT/table?workspace=user-osmar-braz\n","\n","https://wandb.ai/osmar-braz/AjusteFinoCohebert_v2_C_SB_HT/table?workspace=user-osmar-braz\n"]},{"cell_type":"markdown","metadata":{"id":"ezk8hklEvPYq"},"source":["### Função de inicialização wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdsn_fhsvPwO"},"outputs":[],"source":["def inicializacaoWandb():\n","\n","  if model_args.use_wandb:\n","\n","    # Importando a biblioteca.\n","    import wandb\n","\n","    #Login via linha de comando\n","    !wandb login aded3bc0ea651fff536cc08ba69caf8ac4141cfd\n","\n","     # Inicializando o registro do experimento.\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    # O projeto no wandb recebe o nome base mais o número da repetição.\n","    wandb.init(project=NOME_BASE_SAIDA, name=training_args.output_dir + str(model_args.vezes_treinamento))\n","    \n","    # Atualiza os parâmetros do modelo no wandb.\n","    wandb.config.update(model_args)\n","    # Atualiza os parâmetros de treinamento no wandb.\n","    wandb.config.update(training_args)\n","    wandb.config.dataset = DIRETORIO_COHEBERT\n","    wandb.config.batch_size = training_args.per_device_train_batch_size\n","    \n","    # Registra os parämetros não literais do model_args.    \n","    wandb.log({\"max_seq_len\": model_args.max_seq_len})\n","    wandb.log({\"do_lower_case\": model_args.do_lower_case})\n","    wandb.log({\"output_hidden_states\": model_args.output_hidden_states})\n","\n","    return wandb"]},{"cell_type":"markdown","metadata":{"id":"OimJrCug6f_-"},"source":["## 4.2 Carregamento dos arquivos de dados holdout"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["### Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNgwJRC2uGJb"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"-H337CrisLso"},"source":["### Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nivYSXBssLsp"},"outputs":[],"source":["def copiaArquivoDados():\n","  # Se estiver executando no Google Colaboratory\n","  if IN_COLAB:\n","\n","    !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","    !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","    !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","    !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  \n","    logging.info(\"Terminei a cópia!\")"]},{"cell_type":"code","source":["copiaArquivoDados()"],"metadata":{"id":"p8LEWftFA27l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JUJuCpBJsLsq"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iz6W1ImRsLsq"},"outputs":[],"source":["def descompactaArquivoDados():\n","  # Se estiver executando no Google Colaboratory\n","  if IN_COLAB:\n","    !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","    !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","    !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","    !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","    logging.info(\"Terminei a descompactação!\")"]},{"cell_type":"code","source":["descompactaArquivoDados()"],"metadata":{"id":"nGukjmb3A65r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IjrkbEHWsLsr"},"source":["### Carregamento das lista com os dados dos arquivos originais"]},{"cell_type":"markdown","metadata":{"id":"N4dyl6mXsLsr"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4ajX0vksLss"},"outputs":[],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","def carregamentoDocumentosOriginais():\n","\n","  # Abre o arquivo e retorna o DataFrame\n","  lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","  lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","  logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","  logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))\n","\n","  return lista_documentos_originais, lista_documentos_originais_pos"]},{"cell_type":"code","source":["lista_documentos_originais, lista_documentos_originais_pos = carregamentoDocumentosOriginais()"],"metadata":{"id":"wvbrSaqEBEqw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZF5NhF6sLst"},"outputs":[],"source":["lista_documentos_originais.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYlg3f7psLst"},"outputs":[],"source":["lista_documentos_originais_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"-hfUpvKqXoqe"},"source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lj9sJVavMccj"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","def corrigirTipoDadosColunasOriginais(lista_documentos_originais, lista_documentos_originais_pos):\n","\n","  # Verifica se o tipo da coluna não é list e converte\n","  lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","  lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","  logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","  logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))\n","\n","  return lista_documentos_originais, lista_documentos_originais_pos"]},{"cell_type":"code","source":["lista_documentos_originais, lista_documentos_originais_pos = corrigirTipoDadosColunasOriginais(lista_documentos_originais, lista_documentos_originais_pos)"],"metadata":{"id":"46xLgxMDBM0v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Criando dados indexados originais"],"metadata":{"id":"8yyRt4jnYxsU"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"],"metadata":{"id":"B9INo4nBS8aQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"],"metadata":{"id":"j70x_r30T_bx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJXcpioo7Bhn"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gB500dmd7Bho"},"outputs":[],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","def carregamentoDocumentosPerturbados():\n","\n","  # Abre o arquivo e retorna o DataFrame\n","  lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","  lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","  logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","  logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))\n","\n","  return lista_documentos_perturbados, lista_documentos_perturbados_pos"]},{"cell_type":"code","source":["lista_documentos_perturbados, lista_documentos_perturbados_pos = carregamentoDocumentosPerturbados()"],"metadata":{"id":"VRc55CDiBsbN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pXGee7H7Bhp"},"outputs":[],"source":["lista_documentos_perturbados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IE1xJdZWkc5I"},"outputs":[],"source":["lista_documentos_perturbados_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"VrfZzjjpsUOU"},"source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHf-7dgSsUOU"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","def corrigirTipoDadosColunasPerturbados(lista_documentos_perturbados, lista_documentos_perturbados_pos):\n","\n","  # Verifica se o tipo da coluna não é list e converte\n","  lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","  lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","  lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","  logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","  logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))\n","\n","  return lista_documentos_perturbados, lista_documentos_perturbados_pos"]},{"cell_type":"code","source":[" lista_documentos_perturbados, lista_documentos_perturbados_pos = corrigirTipoDadosColunasPerturbados(lista_documentos_perturbados, lista_documentos_perturbados_pos)"],"metadata":{"id":"SxUYuWmpCA9s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Criando dados indexados perturbados"],"metadata":{"id":"Ix-Q5fZXY3HR"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"],"metadata":{"id":"FqRQnYUtSxzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados_pos.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"],"metadata":{"id":"s0aDUbeZT1M8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kq0-NGaC76jP"},"source":["### Agrupar os dados originais e perturbados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWUvKfGZ8DMP"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","lista_documentos_agrupados = []\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_originais_bar: \n","  #if i < 2:\n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]     \n","    #print(\"id_documento:\",id_documento)     \n"," \n","    # Carrega a lista das sentenças do documento\n","    lista_sentenca_documento = linha_documento[1]    \n","    #print(\"\\nlista_sentenca_documento:\",lista_sentenca_documento)\n","    #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento)) \n","\n","    # Adiciona o original a lista dos dados agrupados, considerando como coerente(1)\n","    lista_documentos_agrupados.append([id_documento, lista_sentenca_documento, linha_documento[2], 1])\n","  \n","    # Percorre os documentos perturbados apartir do original\n","    for j in range(0,  model_args.documentos_perturbados):\n","\n","      # Id do documento perturbado\n","      id_perturbado = str(id_documento) + \"_pert_\" + str(j)\n","\n","      # localiza o documento perturbado \n","      documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","      # Recupera a sentença do documento perturbado\n","      lista_perturbado = documento_perturbado[0]\n","          \n","      # Adiciona o perturbado a lista dos dados agrupados considerando como incoerente(0)\n","      lista_documentos_agrupados.append([id_perturbado, lista_perturbado, documento_perturbado[1], 0])    \n","\n","logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"]},{"cell_type":"markdown","metadata":{"id":"THHBPK6Ov8WV"},"source":["Converte em um dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWz4b8Fpv8ki"},"outputs":[],"source":["# Cria o dataframe da lista\n","lista_documentos_agrupados = pd.DataFrame(lista_documentos_agrupados, columns = [\"id\",\"sentencas\",\"documento\",\"classe\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsbAU3pnAjYQ"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str, \"sentencas\": object, \"documento\": str, \"classe\": int}\n","\n","lista_documentos_agrupados = lista_documentos_agrupados.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3qemxYGwHL7"},"outputs":[],"source":["lista_documentos_agrupados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_TJbwpcYtsN3"},"outputs":[],"source":["# Importa das bibliotecas\n","import pandas as pd\n","\n","# Concatena as listas de documentos originais e perturbados\n","lista_documentos_agrupados_pos = pd.concat([lista_documentos_originais_pos, lista_documentos_perturbados_pos])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO POS: {}.\".format(len(lista_documentos_agrupados_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvDXTxtRuvrX"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_agrupados_pos = lista_documentos_agrupados_pos.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDW4pj8vuh2I"},"outputs":[],"source":["lista_documentos_agrupados_pos.sample(5)"]},{"cell_type":"markdown","source":["#### Criar dados indexados"],"metadata":{"id":"viicg1E7mXLK"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_indexado = lista_documentos_agrupados.set_index([\"id\"])\n","lista_documentos_agrupados_indexado.head()"],"metadata":{"id":"0YBdkvoPm2vO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_pos_indexado = lista_documentos_agrupados_pos.set_index([\"id\"])\n","lista_documentos_agrupados_pos_indexado.head()"],"metadata":{"id":"NQjlOJzOmbsp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZ2cXvEBsLs0"},"source":["### Renomeia o dataframe dos dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHpmDgCysLs0"},"outputs":[],"source":["dfdados = lista_documentos_agrupados"]},{"cell_type":"markdown","metadata":{"id":"ZDxezT4zsLs1"},"source":["Apaga as colunas desnecessárias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lsFZzKhvsLs1"},"outputs":[],"source":["dfdados = dfdados.drop(columns=[\"sentencas\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzXJVsg-sLs1"},"outputs":[],"source":["dfdados.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"wdkkxzscF4Yi"},"source":["### Função de carregamento dos dados holdout"]},{"cell_type":"markdown","metadata":{"id":"TQpcvM7DHuGT"},"source":["Divide aleatóriamente mantendo a proporção de classes para cada conjunto em 70% para treinamento e 30% para validação."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ghqvczsy6LTj"},"outputs":[],"source":["# Import das bibliotecas.\n","from sklearn.model_selection import train_test_split\n","\n","def carregamentoDadosHoldout(dfdados):\n","  \n","  # 30% de teste %70% de avaliação\n","  test_qtde = int(0.3*dfdados.shape[0])\n","\n","  # Realiza a divisão\n","  dfdados_train, dfdados_test = train_test_split(dfdados, test_size=test_qtde, stratify=dfdados['classe'])\n","\n","  logging.info(\"Quantidade de dados de treinamento: {}.\".format(len(dfdados_train)))\n","  logging.info(\"Quantidade de dados de validação  : {}.\".format(len(dfdados_test)))\n","\n","  return dfdados_train, dfdados_test"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 4.3 Análise"]},{"cell_type":"markdown","metadata":{"id":"N2wEm3z-2Lld"},"source":["### Função descarte documentos muito grandes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nPeajX8C2QX-"},"outputs":[],"source":["def descarteDocumentosGrandes(tokenizer, tamanho_maximo_token, dfdados_train, dfdados_test):\n","\n","  logging.info(\"Descartando documentos grandes dos conjuntos de dados.\")\n","\n","  # Define o tamanho máximo para os tokens.\n","  tamanho_maximo = tamanho_maximo_token\n","\n","  # Tokenize a codifica as setenças para o BERT.     \n","  dfdados_train[\"input_ids\"] = dfdados_train[\"documento\"].apply(lambda tokens: tokenizer.encode(tokens, add_special_tokens=True))\n","        \n","  dfdados_train = dfdados_train[dfdados_train[\"input_ids\"].apply(len)<tamanho_maximo]\n","\n","  # Remove as colunas desnecessárias.\n","  dfdados_train = dfdados_train.drop(columns=[\"input_ids\"])\n","\n","  # Tokenize a codifica as setenças para o BERT.     \n","  dfdados_test[\"input_ids\"] = dfdados_test[\"documento\"].apply(lambda tokens: tokenizer.encode(tokens, add_special_tokens=True))\n","\n","  # Corta os inputs para o tamanho máximo 512.\n","  dfdados_test = dfdados_test[dfdados_test[\"input_ids\"].apply(len)<tamanho_maximo]\n","\n","  #logging.info(\"Tamanho do conjunto de dados: {} / Treino: {} / Teste: {}.\".format((len(dfdados_train)+len(dfdados_test)),len(dfdados_train), len(dfdados_test)))\n","    \n","  # Remove as colunas desnecessárias.\n","  dfdados_test = dfdados_test.drop(columns=[\"input_ids\"])\n","\n","  del tokenizer\n","  del tamanho_maximo\n","\n","  return dfdados_train, dfdados_test"]},{"cell_type":"markdown","metadata":{"id":"8bwa6Rts-02-"},"source":["## 4.4 Treinando o modelo de classificação"]},{"cell_type":"markdown","metadata":{"id":"qRWT-D4U_Pvx"},"source":["### Otimizador e Agendador de Taxas de Aprendizado/Optimizer & Learning Rate Scheduler\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8o-VEBobKwHk"},"source":["Agora que temos nosso modelo carregado, precisamos pegar os hiperparâmetros de treinamento no modelo armazenado.\n","\n","Para fins de ajuste fino, os autores recomendam escolher entre os seguintes valores (no Apêndice A.3 do [artigo BERT](https://arxiv.org/pdf/1810.04805.pdf)):\n","\n","> - **Tamanho do lote(Batch size):** 16, 32\n","- **Taxa de aprendizado (Adam):** 5e-5, 3e-5, 2e-5\n","- **Número de épocas:** 2, 3, 4\n","\n","O parâmetro epsilon `eps = 1e-6` é\" um número muito pequeno para impedir qualquer divisão por zero na implementação \"(a partir de [aqui](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n","\n","Você pode encontrar a criação do otimizador do AdamW em `run_glue.py` [aqui](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."]},{"cell_type":"markdown","metadata":{"id":"MKecsl5K3LR9"},"source":["### Função carrega otimizador\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajnrdhF63N-r"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import AdamW\n","\n","def carregaOtimizador(training_args, model):\n","  '''\n","    Esta função carrega o otimizador utilizado no agendador de aprendizado.\n","  '''\n","\n","  # Nota: AdamW é uma classe da biblioteca huggingface (ao contrário de pytorch).\n","  # Eu acredito que o 'W' significa 'Correção de redução de peso \"\n","  optimizer = AdamW(model.parameters(),\n","                  lr = training_args.learning_rate, # (ou alfa) A taxa de aprendizado a ser usada. - default é 3e-5\n","                  # betas = (0.9, 0.999), # (beta1, beta2) - default é (0.9, 0.999)\n","                    # beta1 é taxa de decaimento exponencial para as estimativas do primeiro momento. \n","                    # beta2 é taxa de decaimento exponencial para as estimativas do segundo momento. Este valor deve ser definido próximo a 1,0 em problemas com gradiente esparso (por exemplo, PNL e problemas de visão de computacional)\n","                  # eps = 1e-6, #  É um número muito pequeno para evitar qualquer divisão por zero na implementação - default é 1e-6.\n","                  # weight_decay = 0.0, # Correção de redução de peso. - default é 0.0\n","                    # A redução da taxa de aprendizagem também pode ser usada com Adam. A taxa de decaimento é atualizada a cada época para a demonstração da regressão logística.\n","                  # correct_bias = True #  Se não deve corrigir o viés(bias) no Adam mudar para False.- default é True\n","                )\n","  \n","  return optimizer"]},{"cell_type":"markdown","metadata":{"id":"N-Aqb27R3cci"},"source":["### Função carrega agendador"]},{"cell_type":"markdown","metadata":{"id":"W2MT7UK84srM"},"source":["A função **get_linear_schedule_with_warmup** cria um agendador com uma taxa de aprendizado que diminua linearmente da taxa de aprendizagem inicial definido no otimizador até 0, após um período de aquecimento durante o qual ele aumenta linearmente de 0 para a taxa de aprendizagem inicial definido no otimizador.\n","\n","Se `num_warmup_steps=0` e `weight_decay=0`(otimizador) não ocorre a etapa de aquecimento."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMCaS1VqNr5y"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import get_linear_schedule_with_warmup\n","\n","def carregaAgendador(training_args, optimizer, numero_etapas):\n","  '''\n","    Esta função carrega o agendador com um taxa de aprendizado que diminua linearmente até 0.\n","  '''\n","\n","  # O número total de etapas de ajuste fino é [número de lotes] x [número de épocas].\n","  # (Observe que este não é o mesmo que o número de amostras de ajuste fino).\n","  total_etapas = numero_etapas * training_args.num_train_epochs\n","\n","  #Cria o agendador de taxa de aprendizagem.\n","  scheduler = get_linear_schedule_with_warmup(optimizer, # O otimizador para o qual agendar a taxa de aprendizado.\n","                                            num_warmup_steps = 0, # O número de etapas para a fase de aquecimento. Valor default value em run_glue.py\n","                                            num_training_steps = total_etapas) # O número total de etapas de treinamento.\n","\n","\n","  logging.info(\"Total de etapas: {}\".format(total_etapas))\n","\n","  return scheduler"]},{"cell_type":"markdown","metadata":{"id":"O0my3USqpC45"},"source":["### Função cria lotes inteligentes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGpsZgnDolp9"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","import random\n","\n","def criarLotesInteligentes(tokenizer, \n","                           documentos, \n","                           classes, \n","                           id_documentos, \n","                           batch_size):\n","    '''\n","    Esta função combina todos os passos para preparar os lotes.\n","    '''\n","    logging.info(\"Criando Lotes Inteligentes de {:,} amostras com tamanho de lote {:,}...\".format(len(documentos), batch_size))\n","\n","    # ============================\n","    #   Tokenização & Truncamento\n","    # ============================\n","\n","    input_ids_completos = []\n","    \n","    # Tokeniza todas as amostras de treinamento\n","    #logging.info(\"Tokenizando {:,} amostra...\".format(len(classes)))\n","    \n","    # Escolha o intervalo que o progresso será atualizado.\n","    intervalo_atualizacao = obterIntervaloAtualizacao(total_iteracoes=len(classes), numero_atualizacoes=10)\n","    \n","    # Barra de progresso dos documentos\n","    documentos_bar = tqdm_notebook(documentos, desc=f'Documentos ', unit=f'documento', total=len(documentos))\n","\n","    # Para cada amostra de treinamento...\n","    for documento in documentos_bar:\n","    \n","        # Relatório de progresso\n","        #if ((len(input_ids_completos) % intervalo_atualizacao) == 0):\n","        #    logging.info(\"  Tokenizado {:,} amostras.\".format(len(input_ids_completos)))\n","\n","        # Tokeniza a amostra.\n","        input_ids = tokenizer.encode(text=documento,                    # Documento a ser codificado.\n","                                    add_special_tokens=True,            # Adiciona os ttokens especiais.\n","                                    max_length=model_args.max_seq_len,  # Tamanho do truncamento!\n","                                    truncation=True,                    # Faz o truncamento!\n","                                    padding=False)                      # Não preenche.\n","                \n","        # Adicione o resultado tokenizado à nossa lista.\n","        input_ids_completos.append(input_ids)\n","\n","        del input_ids\n","    \n","    del documentos    \n","    \n","    #logging.info(\"{:>10,} amostras tokenizadas.\".format(len(input_ids_completos)))\n","\n","    # =========================\n","    #      Seleciona os Lotes\n","    # =========================    \n","    \n","    # Classifique as duas listas pelo comprimento da sequência de entrada.\n","    amostras = sorted(zip(input_ids_completos, classes, id_documentos), key=lambda x: len(x[0]))\n","\n","    del input_ids_completos\n","    del classes\n","    del id_documentos\n","\n","    #logging.info(\"{:>10,} amostras após classificação.\".format(len(amostras)))\n","\n","    # Lista de lotes que iremos construir.\n","    batch_ordered_documentos = []\n","    batch_ordered_classes = []\n","    batch_ordered_id_documentos = []\n","\n","    logging.info(\"Criando lotes de tamanho {:}...\".format(batch_size))\n","\n","    # Escolha um intervalo no qual imprimir atualizações de progresso.\n","    intervalo_atualizacao = obterIntervaloAtualizacao(total_iteracoes=len(amostras), numero_atualizacoes=10)\n","        \n","    # Faça um loop em todas as amostras de entrada ... \n","    while len(amostras) > 0:\n","        \n","        # Mostra o progresso.\n","        # if ((len(batch_ordered_documentos) % intervalo_atualizacao) == 0 \\          \n","          #  and not len(batch_ordered_documentos) == 0):\n","           #logging.info(\"  Selecionado {:,} lotes.\".format(len(batch_ordered_documentos)))\n","        \n","        # `to_take` é o tamanho real do nosso lote. Será `batch_size` até\n","        # chegamos ao último lote, que pode ser menor.\n","        to_take = min(batch_size, len(amostras))\n","        \n","        # Escolha um índice aleatório na lista de amostras restantes para começar o nosso lote.\n","        select = random.randint(0, len(amostras) - to_take)\n","\n","        # Selecione um lote contíguo de amostras começando em `select`.\n","        #print (\"Selecionando lote de {:} a {:}\".format(select, select+to_take))\n","        batch = amostras[select:(select + to_take)]\n","\n","        #print(\"Tamanho do lote:\", len(batch))\n","        \n","        # Cada amostra é uma tupla --divida para criar uma lista separada de\n","        # sequências e uma lista de rótulos para este lote.\n","        batch_ordered_documentos.append([s[0] for s in batch])\n","        batch_ordered_classes.append([s[1] for s in batch])\n","        batch_ordered_id_documentos.append([s[2] for s in batch])\n","        \n","        # Remova a amostra da lista\n","        del amostras[select:select + to_take]\n","\n","    #logging.info(\"  FEITO - Selecionado {:,} lotes.\".format(len(batch_ordered_documentos)))\n","\n","    # =========================\n","    #        Adicionando o preenchimento\n","    # =========================    \n","\n","    #logging.info(\"Preenchendo sequências dentro de cada lote...\")\n","\n","    py_input_ids = []\n","    py_attention_masks = []\n","    py_labels = []\n","    list_id_documentos = []\n","\n","    # Para cada lote...\n","    for (batch_input_ids, batch_labels, batch_id_documentos) in zip(batch_ordered_documentos, batch_ordered_classes, batch_ordered_id_documentos):\n","\n","        # Nova versão do lote, desta vez com sequências preenchidas e agora com\n","        # as máscaras de atenção definidas.\n","        batch_padded_input_ids = []\n","        batch_attention_masks = []\n","                \n","        # Primeiro, encontre a amostra mais longa do lote.\n","        # Observe que as sequências atualmente incluem os tokens especiais!\n","        max_size = max([len(input) for input in batch_input_ids])\n","        \n","        # Para cada entrada neste lote...\n","        for input in batch_input_ids:\n","                        \n","            # Quantos tokens pad precisam ser adicionados\n","            num_pads = max_size - len(input)\n","\n","            # Adiciona `num_pads` do pad token(tokenizer.pad_token_id) até o final da sequência.\n","            padded_input = input + [tokenizer.pad_token_id] * num_pads\n","\n","            # Define a máscara de atenção --é apenas um `1` para cada token real\n","            # e um `0` para cada token de preenchimento(pad).\n","            attention_mask = [1] * len(input) + [0] * num_pads\n","            \n","            # Adiciona o resultado preenchido ao lote.\n","            batch_padded_input_ids.append(padded_input)\n","            batch_attention_masks.append(attention_mask)\n","\n","            del padded_input\n","            del attention_mask\n","        \n","        # Nosso lote foi preenchido, portanto, precisamos salvar este lote atualizado.\n","        # Também precisamos que as entradas sejam tensores PyTorch, então faremos isso aqui.\n","        py_input_ids.append(torch.tensor(batch_padded_input_ids))\n","        py_attention_masks.append(torch.tensor(batch_attention_masks))\n","        py_labels.append(torch.tensor(batch_labels))\n","        list_id_documentos.append(batch_id_documentos)\n","        \n","        del batch_padded_input_ids\n","        del batch_attention_masks\n","\n","    del batch_ordered_documentos\n","    del batch_ordered_classes\n","    del batch_ordered_id_documentos\n","    \n","    del tokenizer    \n","\n","    # Retorna o conjunto de dados em lotes inteligentes!\n","    return (py_input_ids, py_attention_masks, py_labels, list_id_documentos)"]},{"cell_type":"markdown","metadata":{"id":"Thh-qfv5q4tI"},"source":["### Função de Treinamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ox8cl_CZDxc-"},"outputs":[],"source":["# Import das bibliotecas\n","import random\n","import numpy as np\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def realizaTreinamento(model, \n","                       tokenizer, \n","                       optimizer, \n","                       scheduler,  \n","                       documentos_treino, \n","                       classes_treino, \n","                       id_documentos_treino, \n","                       documentos_teste, \n","                       classes_teste, \n","                       id_documentos_teste, \n","                       EPOCAS = 4):\n","  \n","  #logging.info(\"Realizando treinamento e avaliação do repetição: {}\".format(model_args.vezes_treinamento))\n","\n","  # Defina o valor da semente em todos os lugares para torná-lo reproduzível.\n","  seed_val = training_args.seed\n","  random.seed(seed_val)\n","  np.random.seed(seed_val)\n","  torch.manual_seed(seed_val)\n","  torch.cuda.manual_seed_all(seed_val)\n","\n","  # Medida do tempo total de treinamento e avaliação.\n","  treinamento_avaliacao_t0 = time.time()\n","\n","  # Limpa o cache da GPU.\n","  torch.cuda.empty_cache()\n","\n","  # Coloque o modelo em modo de treinamento. \n","  model.train()\n","\n","  # Acumula as perdas do treinamento.\n","  train_losses = []\n","  test_losses = []\n","   \n","  # Barra de progresso da época.\n","  epoca_bar = tqdm_notebook(range(0,training_args.num_train_epochs+1), desc=f'Épocas', unit=f'épocas')\n","  \n","  # Para cada época.\n","  for epoca_i in epoca_bar:\n","  \n","    # ========================================\n","    #               Inicialização\n","    # ========================================\n","\n","    # Atualiza a época corrente      \n","    model_args.epoca = epoca_i\n","\n","    # Atualiza o nome da saída corrente\n","    training_args.output_dir = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args, model_args)\n","\n","    # Inicializa o wandb para registro\n","    # Gera uma entrada para cada todas as epocas, com a taxa de aprendizagem, lote e repetição    \n","    wandb = inicializacaoWandb()\n","    \n","    # Log das métidas com wandb.\n","    if model_args.use_wandb:    \n","      wandb.watch(model)  \n","\n","    # Recupera o lote inteligente\n","    (py_input_ids, py_attention_masks, py_labels, documentoids) = criarLotesInteligentes(tokenizer, \n","                                                                                         documentos_treino, \n","                                                                                         classes_treino, \n","                                                                                         id_documentos_treino, \n","                                                                                         training_args.per_device_train_batch_size)\n","   \n","    # ========================================\n","    #               Avaliação época 0, sem treinamento\n","    # ========================================\n","    if epoca_i == 0:\n","\n","      # Registra o tempo inicial.\n","      avaliacao_epoca_t0 = time.time()\n","      \n","      # Realiza a avaliação do modelo.    \n","      media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao = realizaAvaliacao(epoca_i, \n","                                                                                                                     model, \n","                                                                                                                     tokenizer, \n","                                                                                                                     optimizer, \n","                                                                                                                     scheduler, \n","                                                                                                                     wandb, \n","                                                                                                                     documentos_teste, \n","                                                                                                                     classes_teste, \n","                                                                                                                     id_documentos_teste)            \n","\n","      logging.info(\"   Avaliação loss                            : {:.8f}; Acc: {:.8f}; Rec: {:.8f}; Pre: {:.8f}, F1:{:.8f}, vp: {:3d}; vn: {:3d}; fp: {:3d}; fn: {:3d}\".format(media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s))            \n","      logging.info(\"   Acurácia da repetição {}                  : {:.8f}.\".format(model_args.vezes_treinamento, acc))  \n","      \n","      # Não acura acumula a perda de treinamento da época pois não ocorreu treinamento.\n","      # test_losses.append(media_test_epoca_loss)\n","\n","      # Medida de quanto tempo levou a execução da avaliação.\n","      avaliacao_epoca_total = formataTempo(time.time() - avaliacao_epoca_t0)\n","\n","      logging.info(\"  Média perda(loss) do avaliação da época   : {0:.8f}.\".format(media_test_epoca_loss))\n","      logging.info(\"  Tempo de avaliação da época               : {:}.\".format(avaliacao_epoca_total))    \n","      logging.info(\"  Tempo parcial do processamento            : {:} (h:mm:ss)\".format(formataTempo(time.time()-treinamento_avaliacao_t0)))\n","\n","      ################# Salva a classificação e avaliação para a época\n","\n","      # Salva o resultado da classificação da época\n","      salvaResultadoClassificacao(lista_resultado_avaliacao)\n","\n","      # Salva o resultado da avaliação da épóca\n","      treinamento_avaliacao_total_t0 = format(formataTempo(time.time()-treinamento_avaliacao_t0))\n","      salvaResultadoAvaliacao(media_test_epoca_loss, \n","                              acc, \n","                              rec, \n","                              pre, \n","                              f1, \n","                              vp_s, \n","                              vn_s, \n","                              fp_s, \n","                              fn_s, \n","                              treinamento_avaliacao_total_t0)\n","\n","      # Log das métricas com wandb.\n","      if model_args.use_wandb:    \n","        NOME_EXECUCAO = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args,model_args)\n","        wandb.log({\"nome_execucao\": NOME_EXECUCAO[:-2], # -2 para retirar \"_f\" do fina do nome da execução\n","                  \"acuracia\": acc,\n","                  \"vp\": vp_s , \n","                  \"vn\": vn_s,  \n","                  \"fp\": fp_s,\n","                  \"fn\": fn_s, \n","                  \"media_train_epoca_loss\" : 0,\n","                  \"tempo_train\" : 0,\n","                  \"media_test_epoca_loss\" : media_test_epoca_loss,\n","                  \"tempo_test\" : avaliacao_epoca_total})\n","      \n","    else:\n","      # ========================================\n","      #               Treinamento e Avaliação para as épocas > 0\n","      # ========================================\n","\n","      # Execute uma passada completa sobre o conjunto de treinamento.      \n","      logging.info(\"Realizando treinamento do repeticão {} na época: {}.\".format(model_args.vezes_treinamento, model_args.epoca))\n","\n","      # Medida de quanto tempo leva o período de treinamento.\n","      treinamento_epoca_t0 = time.time()\n","\n","      # Acumula as perdas do treinamento da época.\n","      train_batch_losses = []\n","\n","      # Barras de progresso.    \n","      lote_treino_bar = tqdm_notebook(range(0, len(py_input_ids)), desc=f'Epoca {epoca_i}', unit=f'lotes', total=len(py_input_ids) )\n","\n","      # Para cada lote dos dados de treinamento.\n","      for index in lote_treino_bar:      \n","\n","          # Descompacte este lote de treinamento de nosso dataloader.\n","          #\n","          # À medida que descompactamos o lote, também copiaremos cada tensor para a GPU usando o\n","          # o método `to`\n","          #\n","          # `lote` é uma lista contém três tensores pytorch:\n","          #   [0]: input ids \n","          #   [1]: attention masks\n","          #   [2]: labels \n","\n","          # Recupera os tensores do lote e copia para a GPU usando o método `to` \n","          d_input_ids = py_input_ids[index].to(device)\n","          d_input_mask = py_attention_masks[index].to(device)\n","          d_labels = py_labels[index].to(device)     \n","          \n","          # Sempre limpe quaisquer gradientes calculados anteriormente antes de realizar um\n","          # passe para trás. PyTorch não faz isso automaticamente porque\n","          # acumular os gradientes é \"conveniente durante o treinamento de RNNs\".\n","          # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","          model.zero_grad()\n","\n","          # Execute um passe para frente (avalie o modelo neste lote de treinamento).\n","          # A documentação para esta função `model` está aqui:\n","          # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","          # Ele retorna diferentes números de parâmetros dependendo de quais argumentos\n","          # são fornecidos e quais sinalizadores estão definidos. Para nosso uso aqui, ele retorna\n","          # a perda (porque fornecemos rótulos) e os \"logits\" - o modelo de saídas antes da ativação.     \n","\n","          # last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n","          outputs = model(d_input_ids, \n","                          token_type_ids=None, \n","                          attention_mask=d_input_mask, \n","                          labels=d_labels)\n","          \n","          # A perda(loss) é retornado em outputs[0] porque fornecemos rótulos(labels))                  \n","          loss = outputs[0]\n","\n","          # E outputs[1] os \"logits\" - o modelo de saídas antes da ativação.\n","          # logits possui duas dimensões, a primeira do lote e a segunda do rótulo da predição                        \n","          # A função `.detach().cpu()` retira da gpu.\n","          logits = outputs[1].detach().cpu()\n","    \n","          # Acumule a perda de treinamento em todos os lotes da época para que possamos\n","          # calcular a perda média no final da época. `loss` é um tensor contendo um único valor.   \n","          # A função `.item ()` retorna apenas o valor Python do tensor.\n","          train_batch_losses.append(loss.item())\n","\n","          # Mostra a perda na barra de progresso.\n","          lote_treino_bar.set_postfix(loss=loss.item())\n","\n","          # Log das métricas com wandb.\n","          if model_args.use_wandb:          \n","            wandb.log({\"train_batch_loss\": loss.item()})\n","\n","          # Execute uma passagem para trás para calcular os gradientes.\n","          # Todos os parâmetros do modelo deve ter sido setado para param.requires_grad = False\n","          loss.backward()            \n","\n","          # Corte a norma dos gradientes para 1.0.\n","          # Isso ajuda a evitar o problema de \"gradientes explosivos\".\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        \n","          # Atualize os parâmetros e dê um passo usando o gradiente calculado.\n","          # O otimizador dita a \"regra de atualização\" - como os parâmetros são\n","          # modificados com base em seus gradientes, taxa de aprendizagem, etc.\n","          optimizer.step()\n","                            \n","          # Atualize a taxa de aprendizagem.\n","          scheduler.step()\n","\n","          # Apaga variáveis não utilizadas\n","          del outputs\n","\n","      # Média da perda do treinamento de todos os lotes da época.\n","      media_train_epoca_loss = np.mean(train_batch_losses)\n","\n","      # Acumule a perda de treinamento de todas as épocas para calcular a perda média do treinamento.    \n","      train_losses.append(media_train_epoca_loss)\n","\n","      # Medida de quanto tempo levou o treinamento desta época.\n","      treinamento_epoca_total = formataTempo(time.time() - treinamento_epoca_t0)\n","\n","      logging.info(\"   Média perda(loss) do treinamento da época : {0:.8f}.\".format(media_train_epoca_loss))\n","      logging.info(\"   Tempo de treinamento da época             : {:}.\".format(treinamento_epoca_total))    \n","      logging.info(\"   Tempo parcial processamento               : {:} (h:mm:ss)\".format(formataTempo(time.time()-treinamento_avaliacao_t0)))\n","\n","      ################# Avaliação da época\n","      \n","      # Registra o tempo inicial.\n","      avaliacao_epoca_t0 = time.time()\n","\n","      # Realiza a avaliação do modelo.    \n","      media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao = realizaAvaliacao(epoca_i, model, \n","                                                                                                                     tokenizer, \n","                                                                                                                     optimizer, \n","                                                                                                                     scheduler, \n","                                                                                                                     wandb, \n","                                                                                                                     documentos_teste, \n","                                                                                                                     classes_teste, \n","                                                                                                                     id_documentos_teste)\n","\n","      logging.info(\"   Avaliação loss                            : {:.8f}; Acc: {:.8f}; Rec: {:.8f}; Pre: {:.8f}, F1:{:.8f}, vp: {:3d}; vn: {:3d}; fp: {:3d}; fn: {:3d}\".format(media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s))            \n","      logging.info(\"   Acurácia da repetição {}                  : {:.8f}.\".format(model_args.vezes_treinamento, acc))  \n","      \n","      # Acumule a perda de treinamento da época para calcular a perda média do treinamento.    \n","      test_losses.append(media_test_epoca_loss)\n","\n","      # Medida de quanto tempo levou a execução da avaliação\n","      avaliacao_epoca_total = formataTempo(time.time() - avaliacao_epoca_t0)\n","\n","      logging.info(\"   Média perda(loss) do avaliação da época   : {0:.8f}.\".format(media_test_epoca_loss))\n","      logging.info(\"   Tempo de avaliação da época               : {:}.\".format(avaliacao_epoca_total))    \n","      logging.info(\"   Tempo parcial do processamento            : {:} (h:mm:ss)\".format(formataTempo(time.time()-treinamento_avaliacao_t0)))\n","\n","      ################# Salva a classificação e avaliação para a época\n","\n","      # Salva o resultado da classificação da época\n","      salvaResultadoClassificacao(lista_resultado_avaliacao)\n","\n","      # Salva o resultado da avaliação da épóca\n","      treinamento_avaliacao_total_t0 = format(formataTempo(time.time()-treinamento_avaliacao_t0))\n","      salvaResultadoAvaliacao(media_test_epoca_loss, \n","                              acc, \n","                              rec, \n","                              pre, \n","                              f1, \n","                              vp_s, \n","                              vn_s, \n","                              fp_s, \n","                              fn_s, \n","                              treinamento_avaliacao_total_t0)\n","\n","      ################# Salva o modelo ajustado no wandb\n","      salvaModeloWandb(model, model_args)\n","\n","      ################# Salva o modelo ajustado\n","      salvaModelo(model, tokenizer, model_args)\n","\n","      # Apaga variáveis não utilizadas\n","      del py_input_ids\n","      del py_attention_masks\n","      del py_labels\n","      del train_batch_losses\n","      del lote_treino_bar\n","\n","      # Log das métricas com wandb.\n","      if model_args.use_wandb:    \n","        NOME_EXECUCAO = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args,model_args)\n","        wandb.log({\"nome_execucao\": NOME_EXECUCAO[:-2], # -2 para retirar \"_f\" do fina do nome da execução\n","                  \"acuracia\": acc,\n","                  \"vp\": vp_s , \n","                  \"vn\": vn_s,  \n","                  \"fp\": fp_s,\n","                  \"fn\": fn_s, \n","                  \"media_train_epoca_loss\" : media_train_epoca_loss,\n","                  \"tempo_train\" : treinamento_epoca_total,\n","                  \"media_test_epoca_loss\" : media_test_epoca_loss,\n","                  \"tempo_test\" : avaliacao_epoca_total})\n","              \n","    # Finaliza o wandb\n","    if model_args.use_wandb:\n","      wandb.finish()  \n","     \n","  # Média da perda do treinamento de todas as épocas.\n","  media_train_loss = np.mean(train_losses)\n","  media_test_loss = np.mean(test_losses)\n","\n","  logging.info(\"  Média perda(loss) treinamento : {0:.8f}.\".format(media_train_loss))\n","  logging.info(\"  Média perda(loss) avaliação   : {0:.8f}.\".format(media_test_loss))\n","\n","  # Apaga variáveis não utilizadas\n","  del train_losses\n","  del epoca_bar\n","  \n","  del model\n","  del tokenizer  \n","  del documentos_treino\n","  del classes_treino\n","  del id_documentos_treino\n","  del documentos_teste\n","  del classes_teste\n","  del id_documentos_teste"]},{"cell_type":"markdown","metadata":{"id":"av-_hPByrUCA"},"source":["## 4.5 Avaliação\n","\n","Avaliando o modelo treinado no conjunto de dados de teste."]},{"cell_type":"markdown","metadata":{"id":"teXptLZNjszT"},"source":["### Função de avaliação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R8DIJXnmjw5v"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def realizaAvaliacao(epoca, \n","                     model, \n","                     tokenizer, \n","                     optimizer, \n","                     scheduler, \n","                     wandb,\n","                     documentos_teste, \n","                     classes_teste, \n","                     id_documentos_teste):\n","   \n","  # Armazena o resultado da avaliação executada\n","  lista_resultado_avaliacao = []\n","\n","  logging.info(\"Realizando avaliação da repetição {} na época: {}.\".format(model_args.vezes_treinamento, epoca))  \n","\n","  # Use nossa nova função para preparar completamente nosso conjunto de dados.\n","  (py_input_ids, py_attention_masks, py_labels, id_documentos) = criarLotesInteligentes(tokenizer, documentos_teste, classes_teste, id_documentos_teste, training_args.per_device_eval_batch_size)\n","\n","  # Coloque o modelo em modo de avaliação.\n","  model.eval()\n","\n","  # Acumula as perdas dos testes dos lotes.\n","  test_batch_losses = []\n","\n","  # Acumula os resultados dos testes.\n","  vp = [] # Verdadeiro positivo\n","  vn = [] # Verdadeiro negativo\n","  fp = [] # Falso positivo\n","  fn = [] # Falso negativo\n","\n","  # Barra de progresso dos lotes de teste.\n","  lote_teste_bar = tqdm_notebook(range(0, len(py_input_ids)), desc=f'Lotes ', unit=f'lotes', total=len(py_input_ids))\n","\n","  # Para cada lote dos dados de avaliação(teste).\n","  for index in lote_teste_bar:\n","\n","    # Copia o lote para a GPU.\n","    d_input_ids = py_input_ids[index].to(device)\n","    d_input_mask = py_attention_masks[index].to(device)\n","    d_labels = py_labels[index].to(device)\n","    d_id_documentos = id_documentos[index]\n","\n","    # Diga a pytorch para não se preocupar em construir o gráfico de computação durante\n","    # o passe para frente, já que isso só é necessário para backprop (treinamento).\n","    with torch.no_grad():\n","        # Obtenha a saída de \"logits\" pelo modelo. Os \"logits\" são a saída\n","        # valores antes de aplicar uma função de ativação como o softmax.        \n","        # Retorno de model quando ´last_hidden_state=True´ é setado:    \n","        # last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n","        outputs = model(d_input_ids,\n","                        token_type_ids=None, \n","                        attention_mask=d_input_mask, \n","                        labels=d_labels)\n","        \n","    # A perda(loss) é retornado em outputs[0] porque fornecemos rótulos(labels). \n","    # É útil para comparar com a perda do treinamento, quando é realizado a avaliação entre as épocas de treinamento.\n","    loss = outputs[0]\n","\n","    # E outputs[1] os \"logits\" - o modelo de saídas antes da ativação.\n","    # logits possui duas dimensões, a primeira do lote e a segunda do rótulo da predição                        \n","    logits = outputs[1]\n","        \n","    # Acumule a perda da avaliação em todos os lotes para que possamos\n","    # calcular a perda média no final. `loss` é um tensor contendo um único valor.\n","    # A função '.cpu()' move loss para a cpu.\n","    # A função `.item ()` retorna apenas o valor Python do tensor.         \n","    test_batch_losses.append(loss.cpu().item())\n","\n","    # Log das métricas com wandb.\n","    if model_args.use_wandb:\n","        wandb.log({\"test_batch_loss\": loss.cpu().item()})\n","\n","    # Recupera o índice do melhor resultado, maior valor dos tensores para coluna(1)\n","    _, classificacao = torch.max(logits, 1)\n","\n","    # Verifica a classificação realizada e o rótulo previsto\n","    vp.append(((classificacao==1) & (d_labels==1)).sum().cpu().item())\n","    vn.append(((classificacao==0) & (d_labels==0)).sum().cpu().item())\n","    fp.append(((classificacao==1) & (d_labels==0)).sum().cpu().item())\n","    fn.append(((classificacao==0) & (d_labels==1)).sum().cpu().item())\n","\n","    # Adiciona o documento de teste, o rótulo e a classificação realizada a lista de resultado\n","    for lote in range(len(d_labels)):\n","                \n","        lista_resultado_avaliacao.append([d_id_documentos[lote],\n","                                d_labels[lote].cpu().item(), \n","                                classificacao[lote].cpu().item()])\n","\n","    del outputs\n","    del d_input_ids\n","    del d_input_mask\n","    del d_labels\n","    del d_id_documentos\n","\n","  # Soma as classificações realizadas\n","  vp_s, vn_s, fp_s, fn_s = sum(vp), sum(vn), sum(fp), sum(fn)\n","  \n","  # Acurácia indica uma performance geral do modelo. \n","  # Dentre todas as classificações, quantas o modelo classificou corretamente(vp=1 e vn=0).\n","  if (vp_s+vn_s+fp_s+fn_s) != 0:\n","      acc = (vp_s+vn_s)/(vp_s+vn_s+fp_s+fn_s)\n","  else:\n","      acc = 0\n","\n","  # Recall(Revocação) avalia todas as situações da classe Positivo(vp=1) com o valor esperado e quantas estão corretas.\n","  if (vp_s+fn_s) != 0:\n","      rec = (vp_s)/(vp_s+fn_s)\n","  else:\n","      rec = 0\n","  \n","  # Precisão avalia as classificações da classe positivo(vp=1 e fp=0) que o modelo fez e quantas estão corretas.\n","  if (vp_s+fp_s) != 0:\n","      pre = (vp_s)/(vp_s+fp_s)\n","  else:\n","      pre = 0  \n","\n","  # F1 é a média harmônica entre precisão e recall.\n","  if (pre + rec) != 0:  \n","    f1 = 2 * ((pre * rec)/(pre + rec))\n","  else:\n","    f1 = 0\n","\n","  # Média da perda da avaliação  \n","  media_test_epoca_loss = np.mean(test_batch_losses)\n","\n","  del py_input_ids\n","  del py_attention_masks\n","  del py_labels\n","  del test_batch_losses\n","  del lote_teste_bar\n","  \n","  del model\n","  del tokenizer\n","  del documentos_teste\n","  del classes_teste\n","  del id_documentos_teste\n","\n","  return media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao"]},{"cell_type":"markdown","metadata":{"id":"VtblUQT0EAO5"},"source":["### Função que salva o resultado da classificação"]},{"cell_type":"code","source":["def getNomeDiretorioResultados(training_args, model_args):\n","  \n","  # Monta o nome do arquivo com parâmetros\n","  nome_arquivo = \"\"\n","  nome_arquivo = nome_arquivo + \"P_\" + str(model_args.documentos_perturbados)\n","  nome_arquivo = nome_arquivo + \"_K_\" + str(model_args.top_k_predicao) \n","     \n","  return nome_arquivo"],"metadata":{"id":"kDeNao7l9fPu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vnu6iKHwAaTb"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import datetime\n","\n","def salvaResultadoClassificacao(lista_resultado_avaliacao):\n","\n","  if model_args.salvar_classificacao:\n","\n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","    \n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_CLASSIFICACAO = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args, model_args) + str(model_args.vezes_treinamento) + MODELO_BERT + TAMANHO_BERT \n","  \n","    # Diretório para salvar o arquivo.\n","    DIRETORIO_CLASSIFICACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/Classificacao/\" + getNomeDiretorioResultados(training_args, model_args) + \"/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_CLASSIFICACAO):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_CLASSIFICACAO)\n","      logging.info(\"Diretório criado: {}.\".format(DIRETORIO_CLASSIFICACAO))\n","    else:\n","      logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_CLASSIFICACAO))\n","\n","    # Nome do arquivo a ser aberto.\n","    NOME_ARQUIVO_CLASSIFICACAO_COMPLETO = DIRETORIO_CLASSIFICACAO + NOME_ARQUIVO_CLASSIFICACAO + \".csv\"\n","\n","    # Gera todo o conteúdo a ser salvo no arquivo\n","    novo_conteudo = \"\"        \n","    for resultado in lista_resultado_avaliacao:      \n","      novo_conteudo = novo_conteudo + data_e_hora.strftime(\"%d/%m/%Y %H:%M\") + \";\" + str(resultado[0]) + \";\" + str(resultado[1]) + \";\" + str(resultado[2]) + \"\\n\"\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO):\n","      logging.info(\"Atualizando arquivo classificação: {}.\".format(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novo_conteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)  \n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      del conteudo\n","      del arquivo\n","      del lista_resultado_avaliacao\n","      \n","    else:\n","      logging.info(\"Criando arquivo classificação: {}.\".format(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_COMPLETO,'w')\n","      arquivo.writelines('data;id;classe;predicao\\n' + novo_conteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      del arquivo\n","      del lista_resultado_avaliacao    "]},{"cell_type":"markdown","metadata":{"id":"DloA0HIShFzW"},"source":["### Função que salva o resultado da avaliação\n","\n","Salva o resultado da avaliação do conjunto de dados de teste da repetição especificada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4aiVdm7P_TlV"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import datetime\n","\n","def salvaResultadoAvaliacao(media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, treinamento_total):\n","\n","  if model_args.salvar_avaliacao:\n","    \n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","\n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_AVALIACAO = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args, model_args) + str(model_args.vezes_treinamento) + MODELO_BERT + TAMANHO_BERT \n","\n","    # Diretório para salvar o arquivo.\n","    DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/Avaliacao/\" + getNomeDiretorioResultados(training_args, model_args) + \"/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_AVALIACAO):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_AVALIACAO)\n","      logging.info(\"Diretório criado: {}.\".format(DIRETORIO_AVALIACAO))\n","    else:\n","      logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_AVALIACAO))\n","\n","    # Nome do arquivo a ser aberto.\n","    NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + \".csv\"\n","\n","    # Conteúdo a ser adicionado.\n","    novo_conteudo = NOME_ARQUIVO_AVALIACAO + \";\" +  data_e_hora.strftime(\"%d/%m/%Y %H:%M\") + \";\"  + treinamento_total + \";\"  + str(acc) + \";\"  +  str(vp_s) + \";\"  +  str(vn_s) + \";\" +  str(fp_s) + \";\" +  str(fn_s) + \"\\n\"\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","      logging.info(\"Atualizando arquivo resultado: {}.\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novo_conteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)  \n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      del conteudo\n","      del arquivo\n","\n","    else:\n","      logging.info(\"Criando arquivo resultado: {}.\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      arquivo.writelines('arquivo;data;tempo;acuracia;vp;vn;fp;fn\\n' + novo_conteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      del arquivo"]},{"cell_type":"markdown","metadata":{"id":"bUskOwzJmpDB"},"source":["### Função que carrega e calcula a média da acurácia das repetições\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7e4KBUq5iHF"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import pandas as pd\n","\n","def carregaResultadoAvaliacao(NOME_ARQUIVO_AVALIACAO):\n","\n","  NOME_ARQUIVO_EXECUCAO = NOME_ARQUIVO_AVALIACAO + \"X\" + MODELO_BERT + TAMANHO_BERT\n","\n","  logging.info(\"Média dos arquivos: {}\".format(NOME_ARQUIVO_EXECUCAO))\n","\n","  # Diretório para salvar o arquivo.\n","  DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/Avaliacao/\" + getNomeDiretorioResultados(training_args, model_args) + \"/\"\n","\n","  # Verifica se o diretório dos resultados existem.\n","  if os.path.exists(DIRETORIO_AVALIACAO):\n","    # Acumuladores.\n","    soma_acuracia = 0\n","    lista_tempo = []\n","    conta_repeticoes = 0\n","\n","    # Percorre os arquivos de resultados.\n","    for n in range(5):  \n","      # Nome do arquivo a ser aberto.\n","      NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + str(n+1) + MODELO_BERT + TAMANHO_BERT + \".csv\"    \n","      # Verifica se o arquivo existe.\n","      if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","        \n","        # Carrega os dados do arquivo  \n","        dados = pd.read_csv(NOME_ARQUIVO_AVALIACAO_COMPLETO, sep=';')\n","        # Mostra os dados do teste da repetição.\n","        for index, linha in dados.iterrows():\n","        \n","          # Cálculo das estatísticas\n","          acc = (linha['vp']+linha['vn'])/(linha['vp']+linha['vn']+linha['fp']+linha['fn'])\n","          if (linha['vp']+linha['fn']) != 0:\n","              rec = (linha['vp'])/(linha['vp']+linha['fn'])\n","          else:\n","              rec = 0\n","          if (linha['vp']+linha['fp']) != 0:\n","              pre = (linha['vp'])/(linha['vp']+linha['fp'])\n","          else:  \n","              pre = 0\n","          if (pre + rec) != 0:  \n","              f1 = 2 * ((pre * rec)/(pre + rec))\n","          else:\n","              f1 = 0\n","          qtde_testes = linha['vp']+linha['vn']+linha['fp']+linha['fn']\n","          logging.info(\"Arquivo: {}, Data: {}, Tempo: {}, QtdeTeste: {:3d}, Acc: {:.8f}, Rec: {:.8f}, Pre: {:.8f}, F1:{:.8f}, vp: {:4d}; vn: {:4d}; fp: {:4d}; fn: {:4d}\".format( \n","               linha[\"arquivo\"], linha[\"data\"], linha[\"tempo\"], qtde_testes, acc, rec, pre, f1, linha[\"vp\"], linha[\"vn\"], linha[\"fp\"], linha[\"fn\"]))    \n","           \n","          # Guarda o tempo.\n","          lista_tempo.append(str(linha['tempo']))\n","\n","        # Procura a maior acurácia.\n","        soma_acuracia = soma_acuracia + dados['acuracia'].max()\n","        # Conta o número de repetições.\n","        conta_repeticoes = conta_repeticoes + 1\n","\n","        del dados\n","    \n","    # Mostra a soma da acurácia . \n","    logging.info(\"Total acurácia                                            : {:.8f}.\".format(soma_acuracia))\n","    # Mostra a quantidade de repetições.\n","    logging.info(\"Quantidade de repetições                                  : {}.\".format(conta_repeticoes))  \n","    # Calcula a média.\n","    if conta_repeticoes != 0:\n","      media = soma_acuracia/conta_repeticoes\n","      logging.info(\"A média da acurácia de {:2d} repetições é                    : {:.8f}.\".format(conta_repeticoes, media))\n","      logging.info(\"O tempo gasto na execução do treinamentoa {:2d} repetições é : {}.\".format(conta_repeticoes, somaTempo(lista_tempo)))\n","      logging.info(\"A média de tempo de execução de {:2d} repetições é           : {}.\".format(conta_repeticoes, mediaTempo(lista_tempo)))\n","      # Guarda o resultado da execução\n","      lista_resultado_execucoes.append(NOME_ARQUIVO_EXECUCAO + \";\" + str(media) + \";\" + str(somaTempo(lista_tempo)))\n","  else:\n","    logging.info(\"Diretório com os resultados não encontrado.\")\n","  \n","  del lista_tempo"]},{"cell_type":"markdown","metadata":{"id":"TXHxIz73vcet"},"source":["## 4.6 Salva e copia o modelo ajustado"]},{"cell_type":"markdown","metadata":{"id":"XDvwRckAwXt1"},"source":["### Função que salva o modelo ajustado no wandb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93KTjqixwb_e"},"outputs":[],"source":["def salvaModeloWandb(model, model_args):\n","  \n","  # Salvando o Modelo para o wandb\n","  if model_args.use_wandb and model_args.salvar_modelo_wandb:\n","  \n","    # Salva o modelo para o wandb    \n","    torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model_dict.pt'))\n","\n","    logging.info(\"Modelo salvo no wandb.\")"]},{"cell_type":"markdown","metadata":{"id":"q2079Qyn8Mt8"},"source":["### Função que salva e copia o modelo ajustado\n","\n","Salva e  modelo e o tokenizador no disco e copia para o google drive."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ulTWaOr8QNY"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def salvaModelo(model, tokenizer, model_args):\n","  \n","  if model_args.salvar_modelo:\n","\n","    # Salvando as melhores práticas: se você usar nomes padrão para o modelo, você pode recarregá-lo usando from_pretrained ()\n","\n","    # Diretório de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = '/content/modelo_ajustado/' + model_args.vezes_treinamento\n","\n","    # Cria o diretório de saída se necessário.\n","    if not os.path.exists(DIRETORIO_LOCAL_MODELO_AJUSTADO):\n","      os.makedirs(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    logging.info(\"Salvando o modelo para {}.\".format(DIRETORIO_LOCAL_MODELO_AJUSTADO))\n","\n","    # Salve um modelo treinado, configuração e tokenizer usando `save_pretrained ()`.\n","    # Eles podem então ser recarregados usando `from_pretrained ()`.\n","    model_to_save = model.module if hasattr(model, 'module') else model  # Cuide do treinamento distribuído/paralelo\n","    model_to_save.save_pretrained(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","    tokenizer.save_pretrained(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    # Boa prática: salve seus argumentos de treinamento junto com o modelo treinado.\n","    torch.save(model_args, os.path.join (DIRETORIO_LOCAL_MODELO_AJUSTADO, 'mode_args.bin'))\n","    torch.save(training_args, os.path.join (DIRETORIO_LOCAL_MODELO_AJUSTADO, 'training_args.bin'))\n","\n","    logging.info(\"Modelo salvo.\")\n","\n","    # Para salvar seu modelo nas sessões do Colab Notebook, faça o download no seu computador local ou, idealmente, copie-o no seu Google Drive.\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    !cp -r '$DIRETORIO_LOCAL_MODELO_AJUSTADO'* '$DIRETORIO_REMOTO_MODELO_AJUSTADO'\n","\n","    logging.info(\"Modelo copiado.\")\n"]},{"cell_type":"markdown","metadata":{"id":"MPRD4HkL2Ymp"},"source":["# 5 Execução do treinamento e avaliação "]},{"cell_type":"markdown","source":["Gera o sufixo do nome do arquivo de saída com os parâmetros da execução\n","\n","Exemplo de formado de sufixo.\n","`K_1_P_1_E_4_e_1_lr_5_b_8_4_n`\n","  - P = documentos perturbados\n","  - K = previsões palavras \n","  - E = número total de épocas de treinamento\n","  - e = número da época executada\n","  - lr = taxa de aprendizagem\n","  - b = lotes de treino e avaliação  \n","  - n = número da repetição"],"metadata":{"id":"pWZCWsAQ575L"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"khYfqBd7kgMm"},"outputs":[],"source":["def getSufixoNomeArquivoSaida(training_args, model_args):\n","\n","  # Recupera o número inteiro da taxa de aprendizagem\n","  taxa_inteiro = int(training_args.learning_rate*100000)\n","\n","  # Monta o nome do arquivo com parâmetros\n","  nome_arquivo = \"\"\n","  nome_arquivo = nome_arquivo + \"_P_\" + str(model_args.documentos_perturbados) \n","  nome_arquivo = nome_arquivo + \"_K_\" + str(model_args.top_k_predicao) \n","  nome_arquivo = nome_arquivo + \"_E_\" + str(training_args.num_train_epochs)\n","  nome_arquivo = nome_arquivo + \"_e_\" + str(model_args.epoca)   \n","  nome_arquivo = nome_arquivo + \"_lr_\" + str(taxa_inteiro)  \n","  nome_arquivo = nome_arquivo + \"_b_\" + str(training_args.per_device_train_batch_size) \n","  nome_arquivo = nome_arquivo + \"_\" + str( training_args.per_device_eval_batch_size) \n","  nome_arquivo = nome_arquivo + \"_n\" \n","   \n","  return nome_arquivo"]},{"cell_type":"markdown","metadata":{"id":"rlXjlhoFjUAH"},"source":["## 5.1 Função de treinamento e avaliação de todos as repetições\n","\n","Carrega os dados para serem avaliados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTt9_BAS2adF"},"outputs":[],"source":["# Import das bibliotecas\n","from tqdm.notebook import tqdm as tqdm_notebook\n","import time\n","import datetime\n","import gc\n","\n","def procedimentoTreinamentoAvaliacaoRepeticoes(modelo, taxa_de_aprendizagem):\n"," \n","  # Barra de progresso das repetições\n","  repeticao_bar = tqdm_notebook(range(inicio_repeticao, fim_repeticao+1), desc=f'Repetições ', unit=f'repetição', total=fim_repeticao)\n","\n","  # Percorre todos as repetições do intervalo de inicio_repeticao até fim_repeticao\n","  for repeticao_i in repeticao_bar:\n","\n","    # Seta o parâmetro da repetição\n","    model_args.vezes_treinamento = repeticao_i\n","\n","    logging.info(\"Processamendo da repeticao: {}.\".format(model_args.vezes_treinamento))\n","    logging.info(\"   com o modelo: {}\".format(modelo))\n","    logging.info(\"   até época {} e taxa de aprendizagem {}.\".format(training_args.num_train_epochs, taxa_de_aprendizagem))  \n","    \n","    # Marca o tempo de início do processamento\n","    processamento_repeticao_t0 = time.time()\n","\n","    # Carregando o modelo   \n","    model, tokenizer = carregaBERT(model_args)\n","        \n","    # Conecta o modelo a GPU\n","    model = conectaGPU(model, device)\n","\n","    # Função de carregamento dos dados de uma repetição    \n","    dfdados_train, dfdados_test = carregamentoDadosHoldout(dfdados)\n","\n","    # Descartando documentos muito grandes\n","    dfdados_train, dfdados_test = descarteDocumentosGrandes(tokenizer, model_args.max_seq_len, dfdados_train, dfdados_test)\n","    \n","    # Pega as listas de documentos de treino e seus rótulos.\n","    documentos_treino = dfdados_train.documento.values\n","    classes_treino = dfdados_train.classe.values\n","    id_documentos_treino = dfdados_train.id.values\n","\n","    # Pega as listas de documentos teste e seus rótulos.\n","    documentos_teste = dfdados_test.documento.values\n","    classes_teste = dfdados_test.classe.values\n","    id_documentos_teste = dfdados_test.id.values\n","\n","    del dfdados_train\n","    del dfdados_test\n","\n","    # Mostra o resultado dos dados carregados.\n","    logging.info(\"Tamanho do conjunto de dados : {} / Treino: {} / Teste: {}.\".format(len(documentos_treino) + len(documentos_teste), len(documentos_treino), len(documentos_teste)))\n","    \n","    #################  Treinamento\n","\n","    # Carrega o otimizador\n","    optimizer = carregaOtimizador(training_args, model)\n","\n","    # Carrega o agendador\n","    scheduler = carregaAgendador(training_args, optimizer, numero_etapas=len(documentos_treino))\n","\n","    # Registra o tempo inicial.\n","    treinamento_t0 = time.time()\n","    \n","    # Realiza o treinamento.\n","    realizaTreinamento(model, tokenizer, optimizer, scheduler, \n","                       documentos_treino, classes_treino, id_documentos_treino, \n","                       documentos_teste, classes_teste, id_documentos_teste, training_args.num_train_epochs)\n","    \n","    # Medida de quanto tempo levou a execução do treinamento.\n","    treinamento_f = time.time()\n","    treinamento_total = formataTempo(treinamento_f - treinamento_t0)  \n","    logging.info(\"  Tempo total treinamento       : {:}.\".format(treinamento_total))\n","    \n","    #################  Treinamento\n","\n","    # Apaga os dados\n","    del documentos_treino\n","    del classes_treino\n","    del id_documentos_treino\n","    \n","    del documentos_teste\n","    del classes_teste\n","    del id_documentos_teste\n","\n","    del optimizer\n","    del scheduler\n","    del model\n","    del tokenizer\n","\n","    # Pega o tempo atual menos o tempo do início do processamento.\n","    processamento_repeticao_f = time.time()\n","    processamento_repeticao_total = formataTempo(processamento_repeticao_f - processamento_repeticao_t0)    \n","    logging.info(\"  Tempo processamento repetição: {:} (h:mm:ss)\\n\".format(processamento_repeticao_total))    \n","\n","    # Chama o coletor de lixo para esvaziar a memória\n","    gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"F-VmBiSsc71L"},"source":["## 5.2 Execução o procedimento de treinamento e avaliação para todos os parâmetros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ercO4HqjYLxb"},"outputs":[],"source":["# Import das bibliotecas\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","# Barra de progresso modelos\n","modelo_bar = tqdm_notebook(enumerate(NOMES_MODELO), desc=f'Modelos ', unit=f'modelo', total=len(NOMES_MODELO))\n","\n","# Percorre todos os modelos a serem avaliados\n","for modelo_i, modelo in modelo_bar:\n","\n","  # Seta o parâmetro do modelo\n","  model_args.pretrained_model_name_or_path = modelo\n","\n","  # Barra de progresso das taxas de aprendizagem\n","  taxa_de_aprendizagem_bar = tqdm_notebook(enumerate(TAXAS_DE_APRENDIZAGEM), desc=f'Taxas de aprendizagem ', unit=f'taxa', total=len(TAXAS_DE_APRENDIZAGEM))\n","\n","  # Executa o treinamento e avaliação para diversas taxas de aprendizagem\n","  for taxas_de_aprendizagem_i, taxa_de_aprendizagem in taxa_de_aprendizagem_bar:\n","\n","    # Atualiza a taxa de aprendizagem da avaliação\n","    training_args.learning_rate = taxa_de_aprendizagem\n","\n","    # Marca o tempo de início do processamento das repetições\n","    processamento_todos_repeticao_t0 = time.time()\n","\n","    # Executa o treinamento e avaliacao de todas as repetições para o modelo e taxa de aprendizagem\n","    procedimentoTreinamentoAvaliacaoRepeticoes(modelo, taxa_de_aprendizagem)\n","\n","    # Pega o tempo atual menos o tempo do início do processamento.\n","    processamento_todos_repeticao_f = time.time()\n","    processamento_todos_repeticao_total = formataTempo(processamento_todos_repeticao_f - processamento_todos_repeticao_t0)    \n","    logging.info(\"  Tempo processamento de todos as repetições: {:} (h:mm:ss)\\n\".format(processamento_todos_repeticao_total))    "]},{"cell_type":"markdown","metadata":{"id":"sbE7bMqSO6Uy"},"source":["## 5.3 Carregando a acurácia média das execuções"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9qG17x0Su-0"},"outputs":[],"source":["# Import das bibliotecas\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","TAXAS_DE_APRENDIZAGEM = [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]\n","\n","LISTA_EPOCAS = [*range(0,EPOCAS+1)]\n","\n","# Guarda um resumo das execuções\n","lista_resultado_execucoes = []\n","\n","# Barra de progresso modelos\n","modelo_bar = tqdm_notebook(enumerate(NOMES_MODELO), desc=f'Modelos ', unit=f'modelo', total=len(NOMES_MODELO))\n","\n","# Percorre todos os modelos a serem avaliados\n","for modelo_i, modelo in modelo_bar:\n","\n","  # Barra de progresso das taxas de aprendizagem\n","  taxa_de_aprendizagem_bar = tqdm_notebook(enumerate(TAXAS_DE_APRENDIZAGEM), desc=f'Taxas de aprendizagem ', unit=f'taxa', total=len(TAXAS_DE_APRENDIZAGEM))\n","\n","  # Executa o treinamento e avaliação para diversas taxas de aprendizagem\n","  for taxas_de_aprendizagem_i, taxa_de_aprendizagem in taxa_de_aprendizagem_bar:\n","\n","    # Barra de progresso épocas\n","    epoca_bar = tqdm_notebook(enumerate(LISTA_EPOCAS), desc=f'Épocas ', unit=f'época', total=len(LISTA_EPOCAS))\n","\n","    # Percorre todos as épocas a serem avaliadas\n","    for epoca_i, epoca in epoca_bar:\n","\n","      logging.info(\"\\n\")\n","      logging.info(\"Acurácia do modelo: {}\".format(modelo))\n","      logging.info(\"   com época {} e taxa de treinamento {}.\".format(epoca, taxa_de_aprendizagem))\n","\n","      # Seta o parâmetro do modelo\n","      model_args.pretrained_model_name_or_path = modelo\n","\n","      # Seta o parâmetro do modelo\n","      training_args.learning_rate = taxa_de_aprendizagem\n","\n","      # Seta o parâmetro do modelo\n","      model_args.epoca = epoca\n","\n","      # Monta o nome do arquivo de log\n","      NOME_ARQUIVO_AVALIACAO =  NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args, model_args)\n","      \n","      # Carrega o resultado\n","      carregaResultadoAvaliacao(NOME_ARQUIVO_AVALIACAO)"]},{"cell_type":"markdown","metadata":{"id":"pQxpMBDQz-jp"},"source":["Resumo da execução"]},{"cell_type":"markdown","source":["Acurácia por época."],"metadata":{"id":"n6b1qngkxylP"}},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):  \n","  if \"e_1\" in linha:\n","    print(linha)"],"metadata":{"id":"56KwUc34wdiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_e_2\" in linha:\n","    print(linha)"],"metadata":{"id":"InM8K00Awbkj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_e_3\" in linha:\n","    print(linha)"],"metadata":{"id":"sJSlDXEcwZA1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xCaqrur60Ayt"},"outputs":[],"source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_e_4\" in linha:\n","    print(linha)"]},{"cell_type":"markdown","source":["Acurácia por taxa de aprendizagem."],"metadata":{"id":"s36FN2Cpx5ne"}},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_1\" in linha:\n","    print(linha)"],"metadata":{"id":"ZmokTJQrxpx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_2\" in linha:\n","    print(linha)"],"metadata":{"id":"aPCTc4Mtx9c2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_3\" in linha:\n","    print(linha)"],"metadata":{"id":"yND48p1Cx-tU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_4\" in linha:\n","    print(linha)"],"metadata":{"id":"7cJRaMApyCBX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_5\" in linha:\n","    print(linha)"],"metadata":{"id":"ck0rofyjyDzg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"3EUXuiZNpBtL"},"source":["## 6.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H50_GKJwpDha"},"outputs":[],"source":[" # Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento: {:} (h:mm:ss)\".format(tempo_total_processamento))"]}]}