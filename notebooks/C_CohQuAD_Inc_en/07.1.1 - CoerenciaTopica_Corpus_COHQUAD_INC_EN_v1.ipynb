{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNycA0L7JDqFN6aPz8MJdV3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d37a7d6ab6b548729fe03b064cea1d93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd9871a3334c484db6d5d42ef7b8d49f","IPY_MODEL_59972808d15148008e09dbba8bc431a5","IPY_MODEL_a891e9c48e1b48d3b5ff130f85abeeca"],"layout":"IPY_MODEL_0acc7c6152994847bcf6fc0b0c072482"}},"cd9871a3334c484db6d5d42ef7b8d49f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_565b4284431d464bb6e8c166cc3fe006","placeholder":"​","style":"IPY_MODEL_2dbdd1b58c8e4bd1829a926972754c15","value":"100%"}},"59972808d15148008e09dbba8bc431a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9730dd10d76845b3adbe5cba7d07c4eb","max":777388222,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17f26c9fa3ff48718d088deea933ed83","value":777388222}},"a891e9c48e1b48d3b5ff130f85abeeca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b94f5da6ee9546099559bbceaa45de48","placeholder":"​","style":"IPY_MODEL_4c945d6f5df643cab9b14d77aa5b4740","value":" 777M/777M [00:27&lt;00:00, 49.1MB/s]"}},"0acc7c6152994847bcf6fc0b0c072482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"565b4284431d464bb6e8c166cc3fe006":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dbdd1b58c8e4bd1829a926972754c15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9730dd10d76845b3adbe5cba7d07c4eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17f26c9fa3ff48718d088deea933ed83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b94f5da6ee9546099559bbceaa45de48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c945d6f5df643cab9b14d77aa5b4740":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# Criar Corpus Específico do CohQuAD Inc en\n","\n","Geração do corpus específico para o conjunto de dados.\n","\n","\n","Gera as POS-Tagging dos documentos perturbados do conjunto de dados.\n","- Utiliza dados textos sobre o assunto do conjunto de dados.\n","- Gera o arquivo `corpus_especifico.zip`.\n"," \n"]},{"cell_type":"markdown","metadata":{"id":"OP33KWAtBMWs"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"PKUr9Vk4BNLC"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"JXclHCRQBSF2","executionInfo":{"status":"ok","timestamp":1668552512659,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Fj5TaAH_5-nB","executionInfo":{"status":"ok","timestamp":1668552512659,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================  \n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.    \n","    \"\"\"\n","    \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):  \n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","    \n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5B1mvfAU5jZf","executionInfo":{"status":"ok","timestamp":1668552512659,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","    \n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.      \n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.      \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","    \n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download    \n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]  \n","\n","    # Define o nome e caminho do arquivo temporário    \n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","    \n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","    \n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:        \n","        tamanho_conteudo = data.headers.get(\"Content-Length\")        \n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)                \n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):        \n","            if chunk:                \n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","    \n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","    \n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6qwKjGvyLG4v","executionInfo":{"status":"ok","timestamp":1668552512660,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","    \n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jirIzIstLea0","executionInfo":{"status":"ok","timestamp":1668552512660,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.  \n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EC9Xppq-_R0w","executionInfo":{"status":"ok","timestamp":1668552512660,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.   \n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    sentencas = []\n","    for linha in arquivo:        \n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"fkVk5LQT_G3f","executionInfo":{"status":"ok","timestamp":1668552512661,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def salvar(nome_arquivo,texto):                       \n","    \"\"\"\n","      Salva um texto em arquivo.\n","     \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.     \n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Guy6B4whsZFR","executionInfo":{"status":"ok","timestamp":1668552512661,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","    \n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))    "]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModelArguments) de definição dos parâmetros do modelo"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"zgmN6RqDRDZS","executionInfo":{"status":"ok","timestamp":1668552512661,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )    \n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )    "]},{"cell_type":"markdown","metadata":{"id":"SX6jTGkBMNvV"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"95qYX7uzMNvX","executionInfo":{"status":"ok","timestamp":1668552512662,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"DcopxbGZqDip","executionInfo":{"status":"ok","timestamp":1668552512662,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"YMiH0E3OnRa1","executionInfo":{"status":"ok","timestamp":1668552512663,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4177,"status":"ok","timestamp":1668552516830,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"vtaYZmc3Vbfj","outputId":"c13f8418-a35d-43ac-c2a3-b0a3fe9972d5"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Dispositivo GPU não encontrado\n"]}],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"zrjqDO6nWa8J","executionInfo":{"status":"ok","timestamp":1668552521126,"user_tz":180,"elapsed":4301,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","\n","def getDeviceGPU():\n","    \"\"\"\n","      Retorna um dispositivo de GPU se disponível ou CPU.\n","    \n","      Retorno:\n","        `device` - Um device de GPU ou CPU.       \n","    \"\"\"\n","        \n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        \n","        # Diz ao PyTorch para usar GPU.    \n","        device = torch.device(\"cuda\")\n","        \n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:        \n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","        \n","    return device"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668552521127,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ChDxmtXsKwjf","outputId":"ed80228d-89c6-4c1c-aa23-76c16094c739"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Sem GPU disponível, usando CPU.\n"]}],"source":["# Recupera o device com GPU ou CPU\n","device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"fGf59D0yVNx9"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1668552521128,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"1iC5-pSAVh7_","outputId":"0569dc44-c294-4ee7-e955-7e3f140fe0d6"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}],"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41341,"status":"ok","timestamp":1668552562463,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ysnDDapMQK8K","outputId":"ab2e4ce1-1860-4f92-af6f-5907e60a7d0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"oOd2MbBiDq93"},"source":["## 1.7 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":611},"executionInfo":{"elapsed":13387,"status":"ok","timestamp":1668552575847,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"EaMM4WdxgvQ7","outputId":"0721cb9a-a7e5-496e-bde3-f8e4e0c734c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 46.2 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.38.3)\n","Collecting wheel\n","  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n","Installing collected packages: wheel, setuptools, pip\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.38.3\n","    Uninstalling wheel-0.38.3:\n","      Successfully uninstalled wheel-0.38.3\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n","Successfully installed pip-22.3.1 setuptools-65.5.1 wheel-0.38.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20815,"status":"ok","timestamp":1668552596655,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"w4p3Rz2qDq94","outputId":"6c80534b-0235-4fe2-fe31-e59397b3867e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.5)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.8)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.9)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.5.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.10)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.9)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.2\n","    Uninstalling pydantic-1.10.2:\n","      Successfully uninstalled pydantic-1.10.2\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.5\n","    Uninstalling thinc-8.1.5:\n","      Successfully uninstalled thinc-8.1.5\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.2\n","    Uninstalling spacy-3.4.2:\n","      Successfully uninstalled spacy-3.4.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typing-extensions-3.10.0.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"markdown","metadata":{"id":"ZxFiqbpPQ-CR"},"source":["## 1.8 Instalação do Gensim"]},{"cell_type":"markdown","metadata":{"id":"HdjN6H6t_L08"},"source":["Instalando o gensim no Google Colaboratory.\n","\n","No Jupiter Notebook executar através \"Anaconda Prompt\".\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10898,"status":"ok","timestamp":1668552607549,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"BGFVnIzQGrEH","outputId":"3e31208b-aa5b-40b4-af1b-e969abb1ea92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gensim==4.2.0\n","  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.7.3)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.21.6)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (5.2.1)\n","Installing collected packages: gensim\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed gensim-4.2.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#!pip install -U gensim\n","!pip install -U gensim==4.2.0"]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"5uiH9pNpwI6g","executionInfo":{"status":"ok","timestamp":1668552607550,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"Mhkc9sW21zV7"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"oJ15-ylRRRdD","executionInfo":{"status":"ok","timestamp":1668552607550,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosMedida(     \n","    modelo_spacy = \"en_core_web_lg\",\n","    #modelo_spacy = \"en_core_web_md\",\n","    #modelo_spacy = \"en_core_web_sm\",\n","\n","    versao_modelo_spacy = \"3.2.0\",\n","    \n","    sentenciar_documento = True,\n","    do_lower_case = False, # default True  \n",")"]},{"cell_type":"markdown","metadata":{"id":"ecwtQDArKvZn"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"YtNygH9qKvmp","executionInfo":{"status":"ok","timestamp":1668552607551,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_IN_EN\""]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"-gQpxAO74yxj","executionInfo":{"status":"ok","timestamp":1668552607551,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"DjWGu-9D5URZ","executionInfo":{"status":"ok","timestamp":1668552607551,"user_tz":180,"elapsed":7,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","        \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Dq9PnXO77bPQ","executionInfo":{"status":"ok","timestamp":1668552607551,"user_tz":180,"elapsed":7,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    \n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivo_tar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")    \n","    arquivo_tar.extractall(DIRETORIO_COHEBERT)    \n","    arquivo_tar.close()\n","    \n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):        \n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ePOccj0s8WMg","executionInfo":{"status":"ok","timestamp":1668552609204,"user_tz":180,"elapsed":1659,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","    \n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.           \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","                  \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp "]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["d37a7d6ab6b548729fe03b064cea1d93","cd9871a3334c484db6d5d42ef7b8d49f","59972808d15148008e09dbba8bc431a5","a891e9c48e1b48d3b5ff130f85abeeca","0acc7c6152994847bcf6fc0b0c072482","565b4284431d464bb6e8c166cc3fe006","2dbdd1b58c8e4bd1829a926972754c15","9730dd10d76845b3adbe5cba7d07c4eb","17f26c9fa3ff48718d088deea933ed83","b94f5da6ee9546099559bbceaa45de48","4c945d6f5df643cab9b14d77aa5b4740"]},"id":"nbELnrpgA4T1","executionInfo":{"status":"ok","timestamp":1668552651737,"user_tz":180,"elapsed":42536,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"071681b0-2cad-48a6-ceb3-0ca013290432"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório Cohebert criado: COHQUAD_IN_EN\n","INFO:root:Download do arquivo do modelo do spaCy.\n","INFO:root:Download do arquivo: COHQUAD_IN_EN/en_core_web_lg-3.2.0.tar.gz.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/777M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d37a7d6ab6b548729fe03b064cea1d93"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Descompactando o arquivo do modelo do spaCy.\n","INFO:root:spaCy carregado.\n"]}],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","metadata":{"id":"AEzytjZi5Iw2"},"source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"zKg-_XyWoy8o","executionInfo":{"status":"ok","timestamp":1668552651737,"user_tz":180,"elapsed":17,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","    \n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.           \n","    \"\"\"\n","    \n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords "]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"s1o8jevtoy8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668552651737,"user_tz":180,"elapsed":16,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4e8081bd-1175-4495-91b9-60cc4b5875da"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Quantidade de stopwords: 326.\n"]},{"output_type":"stream","name":"stdout","text":["{'nevertheless', 'part', 'other', 'few', 'former', 'herein', 'used', '‘s', 'indeed', 'whether', 'therefore', 'such', 'thereupon', 'us', 'really', 'as', 'of', 'am', 'and', '‘re', 'whereby', 'sometimes', 'next', 'eleven', 'everyone', 'though', '‘ll', 'all', 'amount', '’m', 'anything', '’ve', 'because', 'my', 'becomes', \"n't\", 'since', 'take', 'whenever', 'elsewhere', 'upon', 'down', 'but', 'otherwise', 'doing', 'somewhere', 'back', 'noone', 'thereby', 'bottom', 'further', 'then', 'ca', 'should', 'nor', 'same', 'go', 'ever', 'thence', 'everything', 'does', 'becoming', 'into', 'every', 'everywhere', \"'ve\", 'never', 'via', 'what', \"'m\", 'your', 'here', 're', '‘ve', 'enough', 'too', 'well', 'where', 'please', 'thru', 'above', 'seem', 'somehow', 'twenty', 'on', 'i', 'formerly', 'at', 'for', 'onto', 'just', 'anywhere', 'with', 'thus', 'empty', 'them', '’re', 'might', 'wherever', 'several', 'something', 'without', 'many', 'often', 'even', 'four', 'whom', 'very', \"'re\", 'under', 'in', 'the', 'she', 'see', 'some', 'due', 'towards', 'not', \"'s\", 'hundred', 'is', 'he', 'around', 'already', 'after', 'yours', 'may', 'seeming', 'yet', 'a', 'twelve', 'below', 'keep', 'someone', '’s', 'did', 'by', 'him', 'besides', 'still', 'latter', 'his', 'would', 'both', 'done', 'against', 'afterwards', 'become', 'there', 'side', 'was', 'else', 'we', 'out', 'also', 'ours', 'why', 'first', 'it', 'so', 'nobody', 'whatever', 'regarding', 'thereafter', 'move', 'myself', 'six', 'hereby', 'beside', 'once', 'anyway', '’d', 'however', 'me', 'whence', 'hers', 'fifty', \"'ll\", 'eight', 'now', 'three', 'itself', 'an', 'hereupon', 'least', 'seemed', 'during', 'say', 'throughout', 'amongst', 'make', 'alone', 'do', 'ten', 'using', \"'d\", 'another', 'cannot', 'has', 'must', 'whereafter', 'became', 'toward', 'mine', 'full', 'whoever', 'quite', 'rather', 'himself', 'up', 'call', 'third', 'from', '‘m', 'while', 'these', 'yourself', 'which', 'although', 'anyhow', 'yourselves', 'had', 'are', 'per', 'whither', 'until', 'others', 'again', 'beyond', 'whereupon', 'nothing', 'beforehand', 'seems', 'ourselves', 'namely', '’ll', 'five', 'except', 'when', 'mostly', 'their', 'being', 'off', 'nine', 'therein', 'most', 'behind', 'last', 'neither', 'fifteen', 'hereafter', 'nowhere', 'meanwhile', 'more', 'one', 'perhaps', 'its', 'sixty', '‘d', 'those', 'were', 'wherein', 'n‘t', 'to', 'any', 'top', 'only', 'n’t', 'can', 'serious', 'who', 'along', 'before', 'whose', 'herself', 'own', 'unless', 'over', 'either', 'through', 'within', 'they', 'than', 'her', 'sometime', 'each', 'front', 'latterly', 'will', 'moreover', 'across', 'have', 'get', 'no', 'or', 'less', 'forty', 'two', 'anyone', 'be', 'give', 'themselves', 'put', 'could', 'between', 'about', 'whole', 'how', 'show', 'whereas', 'you', 'various', 'much', 'together', 'among', 'this', 'almost', 'name', 'if', 'always', 'hence', 'none', 'been', 'that', 'our', 'made'}\n"]}],"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"6hdqVdfxm-_W","executionInfo":{"status":"ok","timestamp":1668552651737,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy   \n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                                  \n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar   \n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ] \n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [               \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                   \n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal       \n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ] \n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}}, \n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar \n","               ] \n","\n","matcherv = Matcher(nlp.vocab)\n","         \n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):    \n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","  \n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","  \n","  return lista2"]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"3j3VF4NOSPbq","executionInfo":{"status":"ok","timestamp":1668552651738,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = dict()\n","  \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"0uPDYU4KBC5q","executionInfo":{"status":"ok","timestamp":1668552651738,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades    \n","  novodic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","    \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"j9SA61kD6sJY","executionInfo":{"status":"ok","timestamp":1668552651738,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"mGduPM6HNx2w","executionInfo":{"status":"ok","timestamp":1668552651738,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","    \n","  # Soma os dicionários da lista\n","  novodic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n"," \n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"gWxyAo54AOHU","executionInfo":{"status":"ok","timestamp":1668552651738,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.text)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"awaqjNIZA3Fk","executionInfo":{"status":"ok","timestamp":1668552651739,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":37,"metadata":{"id":"Gvd99wd_pwmt","executionInfo":{"status":"ok","timestamp":1668552651739,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  listatokens = []\n","  listapos = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:    \n","    listatokens.append(token.text)\n","    listapos.append(token.pos_)\n","    \n","  return listatokens, listapos"]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"NpCUpOs06sJY","executionInfo":{"status":"ok","timestamp":1668552651740,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","  \n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\" \n","  return traduzido"]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","execution_count":39,"metadata":{"id":"rMb0uDWzKZXP","executionInfo":{"status":"ok","timestamp":1668552651740,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","execution_count":40,"metadata":{"id":"zxTCYFzcJZD6","executionInfo":{"status":"ok","timestamp":1668552651741,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getSentencaSalientePOS(sentenca, pos, classe_saliente=[\"NOUN\"]):\n","  \n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especificado\n","    if pos[i] in classe_saliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"s07wG9F-qHOc"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"xkBatgxjqHOc","executionInfo":{"status":"ok","timestamp":1668552651741,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def removeStopWord(documento, stopwords):\n","  \n","  # Remoção das stopwords do documento\n","  documentoSemStopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documentoSemStopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"]},{"cell_type":"markdown","metadata":{"id":"eyEaXKeaLWlq"},"source":["### getTokensSemStopword\n","\n","Retira as stopswords de lista de tokens"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"pbUf_V_1axS2","executionInfo":{"status":"ok","timestamp":1668552651741,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getTokensSemStopword(tokens, spacy_stopwords=getStopwords(nlp)):\n","    \"\"\"\n","      Retira os tokens da lista de tokens tokens que estão na lista de stopword.\n","      A lista de tokens pode ou não estar dentro de uma outra lista.\n","    \n","      Parâmetros:\n","        `tokens` - Uma lista com os tokens ou uma lista de lista de tokens.\n","        `spacy_stopwords` - Uma lista com as stopword. \n","    \"\"\"\n","    \n","    # Verifica se é uma lista de palavras(str) ou ou uma lista de lista\n","    if type(tokens[0]) is str:\n","      lista_tokens = [tokens]\n","    else:\n","      lista_tokens = tokens\n","      \n","    # Lista de retorno\n","    lista_tokens_sem_stopwords = []  \n","\n","    # Percorre a lista de tokens\n","    for texto in lista_tokens:\n","\n","      # Lista dos tokens sem as stopwords\n","      tokens_sem_stopwords = []\n","      \n","      # Percorre os tokens    \n","      for token in texto:\n","        # Verifica se o toke não está na lista de stopwords para adicionar a nova lista\n","        if token not in spacy_stopwords:\n","          tokens_sem_stopwords.append(token)\n","      \n","      # Adiciona a lista de tokens sem stopwords na lista de retorno se tiver uma palavra\n","      if len(tokens_sem_stopwords) != 0:\n","        lista_tokens_sem_stopwords.append(tokens_sem_stopwords)\n","\n","    if type(tokens[0]) is str:      \n","      return lista_tokens_sem_stopwords[0]\n","    else:\n","      return lista_tokens_sem_stopwords"]},{"cell_type":"markdown","metadata":{"id":"O7XoLBuW6woe"},"source":["### getSentencasTexto\n","\n","Retorna a lista de tokens de uma lista de textos."]},{"cell_type":"code","execution_count":43,"metadata":{"id":"iR9Oc6Yf6zMa","executionInfo":{"status":"ok","timestamp":1668552651741,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getSentencasTexto(textos, nlp = nlp):\n","\n","  \"\"\"\n","     Sentencia um texto ou uma lista de textos.\n","    \n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","      `nlp` - Modelo spacy carregado.\n","\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista dos tokens\n","  lista_sentencas = []\n","\n","  for texto in lista_texto:\n","\n","    # Sentencia o documento\n","    doc = nlp(texto)\n","      \n","    # Percorre as sentenças do documento\n","    for sentenca in doc.sents:   \n","\n","        lista_sentencas.append(str(sentenca))\n","      \n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_sentencas[0]\n","  else:\n","    return lista_sentencas"]},{"cell_type":"markdown","metadata":{"id":"5czwzaxKza0y"},"source":["### getSentencasMinusculo\n","\n","Retorna a lista das sentencas do texto em minúsculo."]},{"cell_type":"code","execution_count":44,"metadata":{"id":"MQQAO4Raza0z","executionInfo":{"status":"ok","timestamp":1668552651742,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getSentencasMinusculo(textos):\n","\n","  \"\"\"\n","     Sentencia um texto ou uma lista de textos em minusculo.\n","    \n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista dos tokens\n","  lista_sentencas = []\n","\n","  for texto in lista_texto:\n","\n","    lista_sentencas.append(str(texto).lower())\n","      \n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_sentencas[0]\n","  else:\n","    return lista_sentencas"]},{"cell_type":"markdown","metadata":{"id":"dLOaYNEb7C5J"},"source":["### getTokensTexto\n","\n","Retorna a lista de tokens do texto."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"VJ1hqQCg7C5J","executionInfo":{"status":"ok","timestamp":1668552651742,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getTokensTexto(textos, nlp = nlp):\n","\n","  \"\"\"\n","     Tokeniza um texto ou uma lista de textos.\n","    \n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista de retorno\n","  lista_tokens_texto = []\n","\n","  # Percorre a lista de texto\n","  for texto in lista_texto:\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","    if type(texto) is not spacy.tokens.doc.Doc:\n","        # Realiza o parsing no spacy\n","        doc = nlp(texto)\n","    else:\n","        doc = texto\n","\n","    # Lista dos tokens\n","    lista_tokens = []\n","\n","    # Percorre a sentença adicionando os tokens\n","    for token in doc:    \n","      lista_tokens.append(token.text)\n","    \n","    # Adiciona a lista de tokens na lista de sentenças\n","    lista_tokens_texto.append(lista_tokens)\n","\n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_tokens_texto[0]\n","  else:\n","    return lista_tokens_texto"]},{"cell_type":"markdown","source":["### removerPontuacao\n","\n","Remove pontuação"],"metadata":{"id":"l3VOqrF8h3-y"}},{"cell_type":"code","source":["def removerPontuacao(textos):\n","    \n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","        \n","        doc = nlp(\" \".join(texto)) \n","\n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ not in ['PUNCT']:\n","              sentenca.append(token.text)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"R5P_9zfFh3-y","executionInfo":{"status":"ok","timestamp":1668552651742,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["### relevantes\n","\n","Palavras relevantes"],"metadata":{"id":"2C4s2rvzJ7iu"}},{"cell_type":"code","source":["def relevantes(textos, postags_permitidas=['VER', 'AUX', 'NOUN']):\n","    \n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","        \n","        doc = nlp(\" \".join(texto)) \n","      \n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ in postags_permitidas:\n","              sentenca.append(token.text)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"5F6PEOkZJ7iv","executionInfo":{"status":"ok","timestamp":1668552651742,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["### lematizacao\n","\n","Lematização do texto"],"metadata":{"id":"1WOT9a_X5dkP"}},{"cell_type":"code","source":["def lematizacao(textos, postags_permitidas=['NOUN', 'ADJ', 'VERB', 'ADV']):\n","    \n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","        doc = nlp(\" \".join(texto)) \n","\n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ in postags_permitidas:\n","              sentenca.append(token.lemma_)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"SbnNOPv85d0C","executionInfo":{"status":"ok","timestamp":1668552651742,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["### preparaCorpus"],"metadata":{"id":"b32wPnBG1faQ"}},{"cell_type":"code","source":["# Import das biblitecas\n","import pandas as pd\n","import re\n","import gensim\n","\n","def preparaCorpus(textos,                                     \n","                  sentenciaTexto=False,\n","                  tornaMinusculo=False,\n","                  removePontuacao=False, \n","                  removeStopwords=False, \n","                  bigramas=False, \n","                  trigramas=False,\n","                  somenteRelevante=False,\n","                  postag_relevante=['VERB', 'AUX', 'NOUN'],\n","                  lematizar=False,                  \n","                  postag_lema=['NOUN', 'ADJ', 'VERB', 'ADV']):\n","\n","    # Verifica se é um textos é str ou uma lista de texto\n","    if type(textos) is str:\n","      # Sentencia o texto\n","      lista_sentencas = [textos]\n","    else:\n","      lista_sentencas = textos\n","    \n","    # Converte o texto em uma lista de sentencas\n","    if sentenciaTexto==True:\n","      lista_sentencas = getSentencasTexto(lista_sentencas)\n","\n","    # Converte o texto em minúsuclo\n","    if tornaMinusculo==True:\n","      lista_sentencas = getSentencasMinusculo(lista_sentencas)\n","    \n","    # tokeniza o texto\n","    lista_sentencas_palavras = getTokensTexto(lista_sentencas)\n","\n","    # Remove a pontuação \n","    if removePontuacao==True:\n","        lista_sentencas_palavras = removerPontuacao(lista_sentencas_palavras)        \n","\n","    # Remove as stop words\n","    if removeStopwords==True:\n","      lista_sentencas_palavras = getTokensSemStopword(lista_sentencas_palavras)\n","\n","    # Criar bigramas ou trigramas\n","    if bigramas==True:\n","      # Construa os modelos de bigramas\n","      bigram = gensim.models.Phrases(lista_sentencas_palavras, min_count=5, threshold=100) # max_topicse mais alto menos frases.\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama\n","      bigram_mod = gensim.models.phrases.Phraser(bigram)\n","      lista_sentencas_palavras = [bigram_mod[doc] for doc in lista_sentencas_palavras]\n","    \n","    if trigramas==True:      \n","      # Construa os modelos de bigramas\n","      bigram = gensim.models.Phrases(lista_sentencas_palavras, min_count=5, threshold=100) # max_topicse mais alto menos frases.\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama\n","      bigram_mod = gensim.models.phrases.Phraser(bigram)\n","      # Construa os modelos de trigramas\n","      trigram = gensim.models.Phrases(bigram[lista_sentencas_palavras], threshold=100)\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama    \n","      trigram_mod = gensim.models.phrases.Phraser(trigram)   \n","      lista_sentencas_palavras = [trigram_mod[bigram_mod[doc]] for doc in lista_sentencas_palavras]   \n","    \n","    # Somente palavras relevantes\n","    if somenteRelevante==True:      \n","      lista_sentencas_palavras = relevantes(lista_sentencas_palavras, postags_permitidas=postag_relevante)\n","    \n","    # Faça a lematização mantendo apenas para noun, adj, vb, adv\n","    if lematizar==True:      \n","      lista_sentencas_palavras = lematizacao(lista_sentencas_palavras, postags_permitidas=postag_lema)\n","\n","    return lista_sentencas_palavras"],"metadata":{"id":"rSW4ign41h1L","executionInfo":{"status":"ok","timestamp":1668552652303,"user_tz":180,"elapsed":573,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JS7qzOSkcc-L","executionInfo":{"status":"ok","timestamp":1668552652304,"user_tz":180,"elapsed":20,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"guw6ZNtaswKc"},"source":["# 4 Corpus Específico"]},{"cell_type":"markdown","metadata":{"id":"NsBImnwiGFVE"},"source":["## 4.1 Especifica os nomes dos arquivos do corpus"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"-gSzrHQRGJpW","executionInfo":{"status":"ok","timestamp":1668552652305,"user_tz":180,"elapsed":20,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_CORPUS = \"corpus_especifico.csv\"\n","NOME_ARQUIVO_CORPUS_COMPACTADO = \"corpus_especifico.zip\""]},{"cell_type":"markdown","metadata":{"id":"HvkGO02lmaY-"},"source":["## 4.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFYIHcIHE985","executionInfo":{"status":"ok","timestamp":1668552652306,"user_tz":180,"elapsed":20,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"dfdeff4b-4fa3-4a01-b081-5a4c46f729c2"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_IN_EN.\n"]}],"source":["# Biblioteca para acessar o sistema de arquivos\n","import os\n","\n","#Cria o diretório para receber os arquivos Originais e Perturbados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"MOBo4YH-QCfN"},"source":["## 4.3 Conteúdo do Arquivo do Corpus"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhFhSYsc6Q5T","executionInfo":{"status":"ok","timestamp":1668552652306,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"6fbe6bb6-5831-4cd8-ac0e-27548d9e58fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Quantidade de documentos: 106\n"]}],"source":["documentos = [\n","# Pilhas https://en.wikipedia.org/wiki/Stack_(abstract_data_type)\n","['pilha','wikipedia','For the use of the term LIFO in accounting, see LIFO (accounting).'],\n","['pilha','wikipedia','For the use of the term pushdown in strength training, see Pushdown (exercise).'],\n","['pilha','wikipedia','For other uses, see Stack (disambiguation).'],\n","['pilha','wikipedia','Similar to a stack of plates, adding or removing is only possible at the top.'],\n","['pilha','wikipedia','Simple representation of a stack runtime with push and pop operations.'],\n","['pilha','wikipedia','In computer science, a stack is an abstract data type that serves as a collection of elements, with two main operations:'],\n","['pilha','wikipedia','Push, which adds an element to the collection, and Pop, which removes the most recently added element that was not yet removed.'],\n","['pilha','wikipedia','Additionally, a peek operation can, without modifying the stack, return the value of the last element added.'],\n","['pilha','wikipedia','Calling this structure a stack is by analogy to a set of physical items stacked one atop another, such as a stack of plates.'],\n","['pilha','wikipedia','The order in which an element added to or removed from a stack is described as last in, first out, referred to by the acronym LIFO.[nb 1] As with a stack of physical objects, this structure makes it easy to take an item off the top of the stack, but accessing a datum deeper in the stack may require taking off multiple other items first.'],\n","['pilha','wikipedia','Considered as a linear data structure, or more abstractly a sequential collection, the push and pop operations occur only at one end of the structure, referred to as the top of the stack.'],\n","['pilha','wikipedia','This data structure makes it possible to implement a stack as a singly linked list and as a pointer to the top element.'],\n","['pilha','wikipedia','A stack may be implemented to have a bounded capacity.'],\n","['pilha','wikipedia','If the stack is full and does not contain enough space to accept another element, the stack is in a state of stack overflow.'],\n","['pilha','wikipedia','A stack is needed to implement depth-first search.'],\n","\n","# Pilha Thomas Cormen\n","['pilha','Thomas Cormen','Stacks and queues are dynamic sets in which the element removed from the set by the DELETE operation is prespecified.'],\n","['pilha','Thomas Cormen','In a stack, the element deleted from the set is the one most recently inserted: the stack implements a last-in, first-out, or LIFO, policy.'],\n","['pilha','Thomas Cormen','Similarly, in a queue, the element deleted is always the one that has been in the set for the longest time: the queue implements a first-in, first-out, or FIFO, policy.'],\n","['pilha','Thomas Cormen','There are several efficient ways to implement stacks and queues on a computer.'],\n","['pilha','Thomas Cormen','In this section we show how to use a simple array to implement each.'],\n","['pilha','Thomas Cormen','The INSERT operation on a stack is often called PUSH, and the DELETE operation, which does not take an element argument, is often called POP.'],\n","['pilha','Thomas Cormen','These names are allusions to physical stacks, such as the spring-loaded stacks of plates used in cafeterias.'],\n","['pilha','Thomas Cormen','The order in which plates are popped from the stack is the reverse of the order in which they were pushed onto the stack, since only the top plate is accessible.'],\n","['pilha','Thomas Cormen','As Figure 10.1 shows, we can implement a stack of at most n elements with an array S[1..n].'],\n","['pilha','Thomas Cormen','The array has an attribute S:top that indexes the most recently inserted element.'],\n","['pilha','Thomas Cormen','The stack consists of elements S[1..S.top], where S[1] is the element at the bottom of the stack and S[S.top] is the element at the top.'],\n","['pilha','Thomas Cormen','When S.top = 0, the stack contains no elements and is empty.'],\n","['pilha','Thomas Cormen','We can test to see whether the stack is empty by query operation STACK-EMPTY.'],\n","['pilha','Thomas Cormen','If we attempt to pop an empty stack, we say the stack underflows, which is normally an error.'],\n","['pilha','Thomas Cormen','If S.top exceeds n, the stack overflows.'],\n","['pilha','Thomas Cormen','(In our pseudocode implementation, we don’t worry about stack overflow.)'],\n","['pilha','Thomas Cormen','We can implement each of the stack operations with just a few lines of code:'],\n","['pilha','Thomas Cormen','STACK-EMPTY(S)'],\n","['pilha','Thomas Cormen','1 if S.top == 0'],\n","['pilha','Thomas Cormen','2 return TRUE'],\n","['pilha','Thomas Cormen','3 else return FALSE'],\n","['pilha','Thomas Cormen','PUSH(S,x)'],\n","['pilha','Thomas Cormen','1 S.top= S.top + 1'],\n","['pilha','Thomas Cormen','2 S[S.top] = x'],\n","['pilha','Thomas Cormen','POP(S)'],\n","['pilha','Thomas Cormen','1 if STACK-EMPTY(S)'],\n","['pilha','Thomas Cormen','2 error \\“underflow\\”'],\n","['pilha','Thomas Cormen','3 else S.top = S.top -1'],\n","['pilha','Thomas Cormen','4 return S[S.top + 1]'],\n","['pilha','Thomas Cormen','Figure 10.1 shows the effects of the modifying operations PUSH and POP.'],\n","['pilha','Thomas Cormen','Each of the three stack operations takes O(1) time.'],\n","['pilha','Thomas Cormen','Figure 10.2 A queue implemented using an array Q[1..12] Queue elements appear only in the lightly shaded positions.'],\n","['pilha','Thomas Cormen','(a) The queue has 5 elements, in locations Q[7..11].'],\n","['pilha','Thomas Cormen','(b) The configuration of the queue after the calls ENQUEUE(Q,17), ENQUEUE(Q,3), and ENQUEUE(Q,5).'],\n","['pilha','Thomas Cormen','(c) The configuration of the queue after the call DEQUEUE(Q) returns the key value 15 formerly at the head of the queue.'],\n","['pilha','Thomas Cormen','The new head has key 6.'],\n","\n","\n","# Fila https://en.wikipedia.org/wiki/Queue_(abstract_data_type)\n","['pilha','wikipedia','In computer science, a queue is a collection of entities that are maintained in a sequence and can be modified by the addition of entities at one end of the sequence and the removal of entities from the other end of the sequence.'],\n","['pilha','wikipedia','By convention, the end of the sequence at which elements are added is called the back, tail, or rear of the queue, and the end at which elements are removed is called the head or front of the queue, analogously to the words used when people line up to wait for goods or services.'],\n","['pilha','wikipedia','The operation of adding an element to the rear of the queue is known as enqueue, and the operation of removing an element from the front is known as dequeue.'],\n","['pilha','wikipedia','Other operations may also be allowed, often including a peek or front operation that returns the value of the next element to be dequeued without dequeuing it.'],\n","['pilha','wikipedia','The operations of a queue make it a first-in-first-out (FIFO) data structure.'],\n","['pilha','wikipedia','In a FIFO data structure, the first element added to the queue will be the first one to be removed.'],\n","['pilha','wikipedia','This is equivalent to the requirement that once a new element is added, all elements that were added before have to be removed before the new element can be removed.'],\n","['pilha','wikipedia','A queue is an example of a linear data structure, or more abstractly a sequential collection.'],\n","['pilha','wikipedia','Queues are common in computer programs, where they are implemented as data structures coupled with access routines, as an abstract data structure or in object-oriented languages as classes.'],\n","['pilha','wikipedia','Common implementations are circular buffers and linked lists.'],\n","['pilha','wikipedia','Queues provide services in computer science, transport, and operations research where various entities such as data, objects, persons, or events are stored and held to be processed later.'],\n","['pilha','wikipedia','In these contexts, the queue performs the function of a buffer.'],\n","['pilha','wikipedia','Another usage of queues is in the implementation of breadth-first search.'],\n","['pilha','wikipedia','Theoretically, one characteristic of a queue is that it does not have a specific capacity.'],\n","['pilha','wikipedia','Regardless of how many elements are already contained, a new element can always be added.'],\n","['pilha','wikipedia','It can also be empty, at which point removing an element will be impossible until a new element has been added again.'],\n","['pilha','wikipedia','Fixed-length arrays are limited in capacity, but it is not true that items need to be copied towards the head of the queue.'],\n","['pilha','wikipedia','The simple trick of turning the array into a closed circle and letting the head and tail drift around endlessly in that circle makes it unnecessary to ever move items stored in the array.'],\n","['pilha','wikipedia','If n is the size of the array, then computing indices modulo n will turn the array into a circle.'],\n","['pilha','wikipedia','This is still the conceptually simplest way to construct a queue in a high-level language, but it does admittedly slow things down a little, because the array indices must be compared to zero and the array size, which is comparable to the time taken to check whether an array index is out of bounds, which some languages do, but this will certainly be the method of choice for a quick and dirty implementation, or for any high-level language that does not have pointer syntax.'],\n","['pilha','wikipedia','The array size must be declared ahead of time, but some implementations simply double the declared array size when overflow occurs.'],\n","['pilha','wikipedia','Most modern languages with objects or pointers can implement or come with libraries for dynamic lists.'],\n","['pilha','wikipedia','Such data structures may have not specified a fixed capacity limit besides memory constraints.'],\n","['pilha','wikipedia','Queue overflow results from trying to add an element onto a full queue and queue underflow happens when trying to remove an element from an empty queue.'],\n","['pilha','wikipedia','A bounded queue is a queue limited to a fixed number of items.'],\n","\n","# Pilha Thomas Cormen\n","['fila','Thomas Cormen','We call the INSERT operation on a queue ENQUEUE, and we call the DELETE operation DEQUEUE; like the stack operation POP, DEQUEUE takes no element argument.'],\n","['fila','Thomas Cormen','The FIFO property of a queue causes it to operate like a line of customers waiting to pay a cashier.'],\n","['fila','Thomas Cormen','The queue has a head and a tail.'],\n","['fila','Thomas Cormen','When an element is enqueued, it takes its place at the tail of the queue, just as a newly arriving customer takes a place at the end of the line.'],\n","['fila','Thomas Cormen','The element dequeued is always the one at the head of the queue, like the customer at the head of the line who has waited the longest.'],\n","['fila','Thomas Cormen','Figure 10.2 shows one way to implement a queue of at most n-1 elements using an array Q[1..n].'],\n","['fila','Thomas Cormen','The queue has an attribute Q:head that indexes, or points to, its head.'],\n","['fila','Thomas Cormen','The attribute Q:tail indexes the next location at which a newly arriving element will be inserted into the queue.'],\n","['fila','Thomas Cormen','The elements in the queue reside in locations Q.head;Q.head + 1;...;Q.tail - 1, where we “wrap around” in the sense that location 1 immediately follows location n in a circular order.'],\n","['fila','Thomas Cormen','When Q:head D Q:tail, the queue is empty.'],\n","['fila','Thomas Cormen','Initially, we have Q:head D Q:tail D 1.'],\n","['fila','Thomas Cormen','If we attempt to dequeue an element from an empty queue, the queue underflows.'],\n","['fila','Thomas Cormen','When Q.head = Q.tail + 1, the queue is full, and if we attempt to enqueue an element, then the queue overflows.'],\n","['fila','Thomas Cormen','In our procedures ENQUEUE and DEQUEUE, we have omitted the error checking for underflow and overflow.'],\n","['fila','Thomas Cormen','(Exercise 10.1-4 asks you to supply code that checks for these two error conditions.)'],\n","['fila','Thomas Cormen','The pseudocode assumes that n D Q:length.'],\n","['fila','Thomas Cormen','ENQUEUE(Q,x)'],\n","['fila','Thomas Cormen','1 Q[Q.tail] = x'],\n","['fila','Thomas Cormen','2 if Q.tail'],\n","['fila','Thomas Cormen','== Q.length'],\n","['fila','Thomas Cormen','3 Q.tail = 1'],\n","['fila','Thomas Cormen','4 else Q.tail = Q.tail + 1'],\n","['fila','Thomas Cormen','DEQUEUE(Q)'],\n","['fila','Thomas Cormen','1 x D Q[Q.head]'],\n","['fila','Thomas Cormen','2 if Q.head == Q.length'],\n","['fila','Thomas Cormen','3 Q.head = 1'],\n","['fila','Thomas Cormen','4 else Q.head D Q.head + 1'],\n","['fila','Thomas Cormen','5 return x'],\n","['fila','Thomas Cormen','Figure 10.2 shows the effects of the ENQUEUE and DEQUEUE operations.'],\n","['fila','Thomas Cormen','Each operation takes O.1/ time.']\n","]\n","\n","print(\"Quantidade de documentos:\", len(documentos))"]},{"cell_type":"markdown","metadata":{"id":"06mEPdqu9rsI"},"source":["## 4.5 Cria o arquivo do corpus"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"_Z69mLAT9tq4","executionInfo":{"status":"ok","timestamp":1668552652307,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Cria o dataframe da lista\n","df_lista_sentencas = pd.DataFrame(documentos, columns = [\"topico\",\"fonte\",\"sentenca\"])\n"," \n","df_lista_sentencas.to_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_CORPUS, sep=\";\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"WqzXU_Icqiqg"},"source":["## 4.6 Compacta e copia o arquivo perturbado para uma pasta do GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"37e0qS7Dkwou"},"source":["Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1668552652713,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"4f2VhAHXkwow","outputId":"3a197014-6556-4e04-8e75-eb8477b17620"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei compactação.\n"]}],"source":["!zip -o -q -j \"$DIRETORIO_LOCAL$NOME_ARQUIVO_CORPUS_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_CORPUS\"\n","\n","logging.info(\"Terminei compactação.\")"]},{"cell_type":"markdown","metadata":{"id":"JJH7kEhiWmi9"},"source":["Copia o arquivo compactado e os arquivos individuais para o GoogleDrive"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1480,"status":"ok","timestamp":1668552654190,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"URD2iAO3qiqg","outputId":"6ca526f3-3cda-4c9e-f919-2a5a846ea540"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}],"source":["# Import das bibliotecas.\n","import os\n","import datetime\n","\n","# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","     \n","    # Copia o arquivo perturbado\n","    !cp \"$DIRETORIO_LOCAL$NOME_ARQUIVO_CORPUS_COMPACTADO\" \"$DIRETORIO_DRIVE\"\n","    \n","    logging.info(\"Terminei a cópia.\")"]},{"cell_type":"markdown","metadata":{"id":"TkncKDN1i7kq"},"source":["## 4.7 Carrega os dados"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1668552654190,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"jWf1pJbyBbUz","outputId":"5b7c1279-7cdc-4782-89b6-1d5d21e36b9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["106\n"]}],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","df_corpus = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_CORPUS, sep=\";\", encoding=\"UTF-8\")\n","\n","print(len(df_corpus))"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1668552654191,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"UDO7gHyiBbU5","outputId":"79a38d6c-cfb6-45d7-ee7d-89e9695ad9d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    topico          fonte                                           sentenca\n","1    pilha      wikipedia  For the use of the term pushdown in strength t...\n","31   pilha  Thomas Cormen  We can implement each of the stack operations ...\n","52   pilha      wikipedia  By convention, the end of the sequence at whic...\n","105   fila  Thomas Cormen                    Each operation takes O.1/ time.\n","32   pilha  Thomas Cormen                                     STACK-EMPTY(S)"],"text/html":["\n","  <div id=\"df-81fcb7b8-5571-4a6d-b3f0-b6d0693dbd0c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topico</th>\n","      <th>fonte</th>\n","      <th>sentenca</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>pilha</td>\n","      <td>wikipedia</td>\n","      <td>For the use of the term pushdown in strength t...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>We can implement each of the stack operations ...</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>pilha</td>\n","      <td>wikipedia</td>\n","      <td>By convention, the end of the sequence at whic...</td>\n","    </tr>\n","    <tr>\n","      <th>105</th>\n","      <td>fila</td>\n","      <td>Thomas Cormen</td>\n","      <td>Each operation takes O.1/ time.</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>STACK-EMPTY(S)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81fcb7b8-5571-4a6d-b3f0-b6d0693dbd0c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-81fcb7b8-5571-4a6d-b3f0-b6d0693dbd0c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-81fcb7b8-5571-4a6d-b3f0-b6d0693dbd0c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":57}],"source":["df_corpus.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 5 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Bcjt085lZGUr"},"source":["## 5.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1668552654191,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"H50_GKJwpDha","outputId":"20672869-149e-462c-a16b-f06b10e02583"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento:  0:02:21 (h:mm:ss)\n"]}],"source":["# Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempo_total_processamento))"]}]}