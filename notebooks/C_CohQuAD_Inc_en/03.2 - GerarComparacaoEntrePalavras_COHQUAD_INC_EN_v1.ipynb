{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c44d2408d77499fbb60e163d0da3304":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2416aa248bc454c81d7242c4491df05","IPY_MODEL_1cb59e8ff5c642dc8c3a7c0eb224ad97","IPY_MODEL_6937e6e8d2754658ae130d1a0028d4a0"],"layout":"IPY_MODEL_c9ac487972354ff28ca34775bc254724"}},"c2416aa248bc454c81d7242c4491df05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75616565f6654614a28d1a9147e00d61","placeholder":"​","style":"IPY_MODEL_88e579b5e5b44deebc97786e8662d44f","value":"Documentos: 100%"}},"1cb59e8ff5c642dc8c3a7c0eb224ad97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8556b4cda2554c72a7d3930f09d291a5","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cf9b86a29244be682a294066745b580","value":20}},"6937e6e8d2754658ae130d1a0028d4a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22eb3efaafda454bb5c1de8008b03db8","placeholder":"​","style":"IPY_MODEL_856838d96a75411e8491830ca7a38b1d","value":" 20/20 [00:00&lt;00:00, 70.51 documento/s]"}},"c9ac487972354ff28ca34775bc254724":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75616565f6654614a28d1a9147e00d61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88e579b5e5b44deebc97786e8662d44f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8556b4cda2554c72a7d3930f09d291a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cf9b86a29244be682a294066745b580":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22eb3efaafda454bb5c1de8008b03db8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"856838d96a75411e8491830ca7a38b1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46fad172b3ad469abb0189a057ea053e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_284548b212ba4406965e699479e269d4","IPY_MODEL_08487e8029bd44cbbc1fa796db6c5342","IPY_MODEL_396e3531144e4b58997e6033bc6d4e46"],"layout":"IPY_MODEL_8051cd9b7464410f96dee741bf06f48f"}},"284548b212ba4406965e699479e269d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0132d01ee69940c9a6c93ee8eb5478f8","placeholder":"​","style":"IPY_MODEL_a717bba8bef24638804fa967b03ec670","value":"Documentos: 100%"}},"08487e8029bd44cbbc1fa796db6c5342":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a281f106ac5e4ffd8011d88bd7f78a1c","max":2020,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3598429721f14f69aed01a34b5bf64a3","value":2020}},"396e3531144e4b58997e6033bc6d4e46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_572689f32d2b4adab8b0b417845cb614","placeholder":"​","style":"IPY_MODEL_26e044e72e3a46c79d51ac308d725104","value":" 2020/2020 [12:22&lt;00:00,  2.18 documento/s]"}},"8051cd9b7464410f96dee741bf06f48f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0132d01ee69940c9a6c93ee8eb5478f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a717bba8bef24638804fa967b03ec670":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a281f106ac5e4ffd8011d88bd7f78a1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3598429721f14f69aed01a34b5bf64a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"572689f32d2b4adab8b0b417845cb614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26e044e72e3a46c79d51ac308d725104":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# Gerar comparação entre palavras das sentenças dos documentos originais e perturbados do CohQuAD In en\n","\n","Gera a comparação entre as palavras das sentenças dos documentos do conjunto de dados utilizando os arquivos:\n","- `original.zip`\n","- `originalpos.zip`\n","- `perturbado_pX_kY.zip`\n","- `perturbadopos_pX_kY.zip`\n","\n","Nos nomes dos arquivos `perturbado_pX_kY.zip`,`perturbadopos_pX_kY.zip`, X é o número de documentos perturbados e Y o valor de top K predições.\n","\n","Cria o arquivo `comparacao_palavra_pX_kY.zip` com as comparações entre as palavras do documento, onde X é o número de documentos perturbados e Y o valor de top K predições.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OP33KWAtBMWs"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"PKUr9Vk4BNLC"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","metadata":{"id":"JXclHCRQBSF2"},"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"],"metadata":{"id":"OPRnA-mk5-c4"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================\n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.\n","    \"\"\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):\n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","\n","    return DIRETORIO_COHEBERT"],"metadata":{"id":"Fj5TaAH_5-nB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Realiza o download e um arquivo"],"metadata":{"id":"yDCOeh2y5jOH"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","\n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.\n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","\n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download\n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]\n","\n","    # Define o nome e caminho do arquivo temporário\n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","\n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","\n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:\n","        tamanho_conteudo = data.headers.get(\"Content-Length\")\n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)\n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):\n","            if chunk:\n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","\n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","\n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"],"metadata":{"id":"5B1mvfAU5jZf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","metadata":{"id":"6qwKjGvyLG4v"},"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","\n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","metadata":{"id":"jirIzIstLea0"},"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    sentencas = []\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas"],"metadata":{"id":"EC9Xppq-_R0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def salvar(nome_arquivo,texto):\n","    \"\"\"\n","      Salva um texto em arquivo.\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.\n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"],"metadata":{"id":"fkVk5LQT_G3f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","metadata":{"id":"Guy6B4whsZFR"},"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempoArredondado = int(round((tempo)))\n","\n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempoArredondado))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModelArguments) de definição dos parâmetros do modelo"]},{"cell_type":"code","metadata":{"id":"zgmN6RqDRDZS"},"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )\n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HIN413rj50EI"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","metadata":{"id":"bxV4-3Yg50EI"},"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","metadata":{"id":"DcopxbGZqDip"},"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","metadata":{"id":"YMiH0E3OnRa1"},"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yuHoA4Dx6K1M"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"0zhAltEP6K1M"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"IxAlgXv66K1M"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","metadata":{"id":"Cmva6ltA6K1M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423643562,"user_tz":180,"elapsed":3294,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"deeff12e-c265-4f41-f2ef-acae57651446"},"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Dispositivo GPU não encontrado\n"]}]},{"cell_type":"markdown","metadata":{"id":"XrC2SG3x6K1M"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOnQUkWZ6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def getDeviceGPU():\n","    \"\"\"\n","    Retorna um dispositivo de GPU se disponível ou CPU.\n","\n","    Retorno:\n","    `device` - Um device de GPU ou CPU.\n","    \"\"\"\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","\n","        # Diz ao PyTorch para usar GPU.\n","        device = torch.device(\"cuda\")\n","\n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:\n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","\n","    return device"]},{"cell_type":"code","source":["device = getDeviceGPU()"],"metadata":{"id":"WcMhNxsE6K1N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423646405,"user_tz":180,"elapsed":32,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"f78b2eca-b899-49e1-c742-4e852d6acad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Sem GPU disponível, usando CPU.\n"]}]},{"cell_type":"markdown","source":["Conecta o modelo ao device"],"metadata":{"id":"kkdlEouHftcJ"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def conectaGPU(model, device):\n","    \"\"\"\n","      Conecta um modelo BERT a GPU.\n","\n","      Parâmetros:\n","        `model` - Um modelo BERT carregado.\n","        `device` - Um device de GPU.\n","\n","      Retorno:\n","        `model` - Um objeto model BERT conectado a GPU.\n","    \"\"\"\n","    # Associa a GPU ao modelo.\n","    model.to(device)\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        # Diga ao pytorch para rodar este modelo na GPU.\n","        logging.info(\"Pytorch rodando o modelo na GPU.\")\n","        model.cuda()\n","\n","    else:\n","        logging.info(\"Pytorch rodando sem GPU.\")\n","\n","    return model"],"metadata":{"id":"a-znVDGyfsVx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRdtvR_J6K1N"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","metadata":{"id":"hSmGz55H6K1N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423646406,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"df7f2a89-c575-45f1-f946-8249b46df9c1"},"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","metadata":{"id":"ysnDDapMQK8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423665403,"user_tz":180,"elapsed":18595,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"65125210-d685-40cd-ec77-bc772b8429fb"},"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","metadata":{"id":"ejzpgGrFM0-j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423675519,"user_tz":180,"elapsed":10122,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"8e083e3f-3748-4796-918f-399dabf73210"},"source":["!pip install --upgrade wandb"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 56.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 42.6 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 58.4 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 53.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 45.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 57.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 58.2 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 59.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 57.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 68.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 65.9 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=26b38251156ab5deb449d880ba73b2b96d6691c1b99fc41336fac5ceb8523938\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"J0LeiOTx0Dlk"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","metadata":{"id":"EaMM4WdxgvQ7","colab":{"base_uri":"https://localhost:8080/","height":524},"executionInfo":{"status":"ok","timestamp":1664423690830,"user_tz":180,"elapsed":15317,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"12af98ce-f589-49d1-b34c-cf34b8aae56f"},"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.4.0-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","numba 0.56.2 requires setuptools<60, but you have setuptools 65.4.0 which is incompatible.\u001b[0m\n","Successfully installed pip-22.2.2 setuptools-65.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"w4p3Rz2qDq94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423709066,"user_tz":180,"elapsed":18240,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"da1b67f1-30e1-47a8-9b82-b015553e2b3a"},"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.6)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.4.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.8)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.10)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.9.2\n","    Uninstalling pydantic-1.9.2:\n","      Successfully uninstalled pydantic-1.9.2\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.0\n","    Uninstalling thinc-8.1.0:\n","      Successfully uninstalled thinc-8.1.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.1\n","    Uninstalling spacy-3.4.1:\n","      Successfully uninstalled spacy-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typing-extensions-3.10.0.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.9 Instalação do BERT"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face.\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"code","metadata":{"id":"1RfUN_KolV-f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423724183,"user_tz":180,"elapsed":15142,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"dca3087c-eaf7-4f49-92e1-8b5095000610"},"source":["!pip install -U transformers==4.5.1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=307b0768ded0b5fbb60399b829b6adb7c707b5c9a35d78d4225c6ea65dcc82c1\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","source":["## Gerais"],"metadata":{"id":"ifrYNTwGwKal"}},{"cell_type":"code","source":["# Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 1\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 1"],"metadata":{"id":"5uiH9pNpwI6g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Específicos"],"metadata":{"id":"mhByVujAwNAU"}},{"cell_type":"markdown","source":["Parâmetros do modelo"],"metadata":{"id":"Mhkc9sW21zV7"}},{"cell_type":"code","metadata":{"id":"oJ15-ylRRRdD"},"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosMedida(\n","    max_seq_len = 512,\n","\n","    pretrained_model_name_or_path = \"bert-large-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-cased\"\n","    #pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","\n","    modelo_spacy = \"en_core_web_lg\",\n","    #modelo_spacy = \"en_core_web_md\",\n","    #modelo_spacy = \"en_core_web_sm\",\n","    #modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","\n","    versao_modelo_spacy = \"3.2.0\",\n","    sentenciar_documento = False,\n","    do_lower_case = False, # default True\n","    output_attentions = False, # default False\n","    output_hidden_states = True, # default False, se True retorna todas as camadas do modelo para as operações de soma e concatenação\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path.\n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 20 e 100. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Nome do diretório dos arquivos de dados"],"metadata":{"id":"WlF4PKP6Iopi"}},{"cell_type":"code","source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_IN_EN\""],"metadata":{"id":"55PNP2s6Iopi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","source":["### Função download modelo spaCy"],"metadata":{"id":"PWd_9X0nOYnF"}},{"cell_type":"code","source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"],"metadata":{"id":"DjWGu-9D5URZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","source":["### Função descompacta modelo spaCy"],"metadata":{"id":"XAc1tSwvOc4d"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","\n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivo_tar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")\n","    arquivo_tar.extractall(DIRETORIO_COHEBERT)\n","    arquivo_tar.close()\n","\n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):\n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"],"metadata":{"id":"Dq9PnXO77bPQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","source":["### Função carrega modelo spaCy"],"metadata":{"id":"3iFBoyWMOgKz"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","\n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp"],"metadata":{"id":"ePOccj0s8WMg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Carrega o modelo spaCy\n"],"metadata":{"id":"cAk5hHx7OnHn"}},{"cell_type":"code","metadata":{"id":"nbELnrpgA4T1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424341292,"user_tz":180,"elapsed":3306,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"3caddcae-f648-4339-97a7-3d4fa9bd3a63"},"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:spaCy carregado.\n"]}]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"],"metadata":{"id":"AEzytjZi5Iw2"}},{"cell_type":"code","metadata":{"id":"zKg-_XyWoy8o"},"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","\n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.\n","    \"\"\"\n","\n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","metadata":{"id":"s1o8jevtoy8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424341293,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"3462d0a6-87c7-4d66-f7b7-92b47839d10f"},"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Quantidade de stopwords: 326.\n"]},{"output_type":"stream","name":"stdout","text":["{'else', 'from', 'another', 'ourselves', '’s', 'being', 'seem', 'least', 'he', 'too', \"n't\", 'as', 'part', 'and', 'side', 'thereupon', 'nowhere', 'whereafter', 'yourselves', 'she', 'whatever', 'hence', 'amount', 'becomes', 'others', 'herein', 'six', 'thus', 'twenty', 'whom', 'with', 'much', 'beyond', 'latter', 'many', \"'s\", '‘ve', 'always', 'same', 'name', 'via', \"'re\", 'back', 'because', 'seeming', 'towards', 'had', 'see', 'none', 'my', 'behind', 'will', 'nobody', '‘re', 'sometimes', 'whenever', 'say', 'besides', 'for', 'often', 're', 'until', 'am', 'except', 'could', 'either', '‘ll', 'herself', 'alone', 'although', 'move', 'beside', 'whole', 'nine', 'few', 'into', 'becoming', 'we', 'i', 'last', \"'d\", 'us', 'everywhere', 'full', \"'ll\", 'nevertheless', 'to', 'made', 'the', 'never', 'become', 'there', 'hundred', 'anyhow', 'meanwhile', 'up', 'on', 'well', 'whence', 'onto', 'doing', 'after', 'empty', 'how', 'what', 'it', 'around', 'less', 'eight', 'within', 'amongst', 'get', 'everything', 'elsewhere', 'seems', 'anywhere', 'somehow', 'without', 'a', 'keep', 'be', 'an', 'mostly', 'done', 'however', 'therein', '’d', 'please', 'therefore', 'them', 'they', 'anything', 'who', 'using', 'above', 'hereupon', 'did', 'whereupon', 'across', 'per', 'thence', 'whereby', 'these', 'such', 'otherwise', 'wherever', 'than', 'afterwards', 'cannot', 'call', 'against', 'does', 'at', 'top', 'but', 'out', 'formerly', 'sometime', 'that', 'through', 'bottom', 'make', 'are', 'most', 'under', 'since', 'together', 'might', 'eleven', 'wherein', 'by', 'anyone', 'go', 'themselves', \"'ve\", 'hers', 'fifteen', 'its', 'along', 'any', 'do', 'n’t', 'also', 'nor', 'really', 'five', 'both', 'due', 'ever', 'about', 'during', 'of', 'may', \"'m\", 'give', 'one', 'off', 'his', 'him', 'below', 'whereas', 'when', 'should', 'take', 'indeed', 'enough', 'two', 'yours', 'namely', 'me', 'used', 'various', 'this', 'put', 'sixty', 'among', '’ve', 'upon', 'where', '’re', 'seemed', 'your', 'yourself', 'other', 'all', 'would', 'anyway', 'again', 'third', 'twelve', 'further', 'only', 'himself', 'once', '‘m', 'latterly', 'every', 'were', 'very', 'someone', 'ca', 'though', 'have', 'or', 'front', 'hereby', 'still', 'became', 'just', 'several', 'regarding', 'her', 'can', 'before', 'each', 'itself', 'here', 'has', 'fifty', 'why', 'thereby', '’m', 'you', 'their', 'rather', 'throughout', 'whoever', 'was', 'in', 'which', 'thru', 'show', 'quite', 'been', 'serious', 'neither', 'forty', 'perhaps', 'noone', 'something', 'everyone', '‘d', 'so', 'first', 'now', 'beforehand', 'must', 'ten', 'then', 'toward', 'is', 'myself', 'some', 'even', 'not', 'whose', 'ours', 'four', 'former', '‘s', 'n‘t', 'between', 'while', 'hereafter', 'our', 'yet', 'nothing', 'over', 'down', 'thereafter', 'whether', 'more', 'next', 'unless', 'already', 'if', 'mine', 'three', 'moreover', 'own', 'somewhere', 'those', 'almost', '’ll', 'whither', 'no'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","metadata":{"id":"6hdqVdfxm-_W"},"source":["# Import das bibliotecas.\n","import spacy\n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ]\n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal\n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ]\n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},\n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar\n","               ]\n","\n","matcherv = Matcher(nlp.vocab)\n","\n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):\n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","\n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","\n","  return lista2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novo_dic = dict()\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novo_dic[classe_gramatical] = qtde\n","\n","  return novo_dic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novo_dic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novo_dic[classe_gramatical] = qtde\n","\n","  return novo_dic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","metadata":{"id":"j9SA61kD6sJY"},"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","\n","  # Soma os dicionários da lista\n","  novo_dic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n","\n","  return novo_dic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","metadata":{"id":"gWxyAo54AOHU"},"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.text)\n","\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","metadata":{"id":"Gvd99wd_pwmt"},"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista_tokens = []\n","  lista_post = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:\n","    lista_tokens.append(token.text)\n","    lista_post.append(token.pos_)\n","\n","  return lista_tokens, lista_post"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","metadata":{"id":"NpCUpOs06sJY"},"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","\n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\"\n","  return traduzido"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","metadata":{"id":"rMb0uDWzKZXP"},"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","metadata":{"id":"zxTCYFzcJZD6"},"source":["def getSentencaSalientePOS(sentenca, pos, tipoSaliente=\"NOUN\"):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especeficado\n","    if pos[i] == tipoSaliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xaeX0oTVQ5t"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","metadata":{"id":"NIaQ9bzBVQ5t"},"source":["def removeStopWord(documento, stopwords):\n","\n","  # Remoção das stopwords do documento\n","  documento_sem_stopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documento_sem_stopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7NAe8ogCf1y"},"source":["### retornaRelevante\n","\n","Retorna somente os palavras do documento ou sentença do tipo especificado."]},{"cell_type":"code","metadata":{"id":"UNNfykypChn-"},"source":["def retornaRelevante(documento, classe_relevante=\"NOUN\"):\n","\n","  # Corrigir!\n","  # Utilizar o documento já tokenizado pelo spacy!!!!\n","  # Existe uma lista com o documento e a sentença tokenizada pelo spacy\n","\n","  # Realiza o parsing no spacy\n","  doc = nlp(documento)\n","\n","  # Retorna a lista das palavras relevantes\n","  documento_com_substantivos = []\n","  for token in doc:\n","    #print(\"token:\", token.pos_)\n","    if token.pos_ == classe_relevante:\n","      documento_com_substantivos.append(token.text)\n","\n","  # Concatena o documento com os substantivos\n","  documento_concatenado = \" \".join(documento_com_substantivos)\n","\n","  # Retorna o documento\n","  return documento_concatenado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IBY7q_uH8JSE"},"source":["# 4 BERT"]},{"cell_type":"markdown","source":["## 4.1 Modelo Pré-treinado BERT"],"metadata":{"id":"MBGTMy8Ic7GK"}},{"cell_type":"markdown","source":["### Funções Auxiliares"],"metadata":{"id":"uiuxdXe9t1BX"}},{"cell_type":"code","source":["def getNomeModeloBERT(model_args):\n","    '''\n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","\n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"\n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","        else:\n","            if 'bert' in model_args.pretrained_model_name_or_path:\n","                MODELO_BERT = \"_BERT\"\n","\n","    return MODELO_BERT"],"metadata":{"id":"9Huw0x5kt1Le"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getTamanhoBERT(model_args):\n","    '''\n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","\n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","\n","    return TAMANHO_BERT"],"metadata":{"id":"jYJB4ik7t5xe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Função download Modelo Pre-treinado BERT"],"metadata":{"id":"rHt4e5pAcEMd"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","\n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","\n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo!\")\n","            # Apaga o diretório e os arquivos existentes\n","            shutil.rmtree(DIRETORIO_MODELO)\n","\n","        # Realiza o download do arquivo do modelo\n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.\n","        arquivo_zip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivo_zip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.\n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","\n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta!\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada!\")\n","\n","    return DIRETORIO_MODELO"],"metadata":{"id":"peDUrV2ccEXA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Copia o modelo do BERT ajustado"],"metadata":{"id":"V74WUpHqcfoI"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\"\n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    logging.info(\"Modelo BERT ajustado copiado!\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"],"metadata":{"id":"iQMpf9yycf8f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Verifica de onde utilizar o modelo do BERT"],"metadata":{"id":"eaneOhAKcO-3"}},{"cell_type":"code","source":["def verificaModelo(model_args):\n","    \"\"\"\n","    Verifica de onde utilizar o modelo.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    DIRETORIO_MODELO = None\n","\n","    if model_args.usar_mcl_ajustado == True:\n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","\n","        logging.info(\"Usando modelo BERT ajustado.\")\n","\n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")\n","\n","    return DIRETORIO_MODELO"],"metadata":{"id":"TTy1TXz3cPKS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Tokenizador BERT"],"metadata":{"id":"6tKcaIfReqdy"}},{"cell_type":"markdown","source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf)."],"metadata":{"id":"e8n7Z5s-QZF8"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","\n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"],"metadata":{"id":"mzAuptkwQZR3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"],"metadata":{"id":"GYRV9KfHQE6v"}},{"cell_type":"markdown","source":["### Função carrega modelo BERT medida"],"metadata":{"id":"-pZZrUKRhR3e"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","from transformers import BertModel # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:\n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertModel.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertModel.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"],"metadata":{"id":"1JUEyjCChUQh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Função carrega o BERT"],"metadata":{"id":"-uFDhRTZe2Js"}},{"cell_type":"code","source":["def carregaBERT(model_args):\n","    \"\"\"\n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","        `tokenizer` - Um objeto tokenizador BERT carregado.\n","    \"\"\"\n","\n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","\n","    # Variável para conter o modelo\n","    model = None\n","\n","    # Carrega o modelo para cálculo da medida\n","    model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","\n","    # Carrega o tokenizador.\n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","\n","    return model, tokenizer"],"metadata":{"id":"QVtAUbUBe2iS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Carrega o BERT"],"metadata":{"id":"x5NTxBRKfAcT"}},{"cell_type":"code","source":["# Carrega o modelo e tokenizador do BERT\n","model, tokenizer = carregaBERT(model_args)"],"metadata":{"id":"ZYMLJJYSQHY3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424350238,"user_tz":180,"elapsed":8372,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"987bfcc1-5894-45a8-cba5-4c369c0190a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Variável URL_MODELO não setada!\n","INFO:root:Usando modelo BERT pré-treinado.\n","INFO:root:Carregando o modelo BERT da comunidade bert-large-cased para cálculo de medidas.\n","INFO:root:Carregando o tokenizador BERT do diretório bert-large-cased.\n"]}]},{"cell_type":"markdown","metadata":{"id":"d7KprWqyZBQZ"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6sPjTQnuQV2"},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"khTFfBVbnsx9"},"source":["## 4.4 Funções auxiliares do BERT"]},{"cell_type":"markdown","source":["### concatenaListas"],"metadata":{"id":"lCJzsw8T0I-5"}},{"cell_type":"code","source":["def concatenaListas(lista, pos=1):\n","  lista_concat = []\n","\n","  for x in lista:\n","      lista_concat = lista_concat + x[pos]\n","\n","  return lista_concat"],"metadata":{"id":"IpmDZ1mI0JHR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s42mgtmSZ8MR"},"source":["### getEmbeddingsCamadas\n","\n","Funções que recuperam os embeddings das camadas:\n","- Primeira camada;\n","- Penúltima camada;\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"sgo3EBTRZ9-3"},"source":["def getEmbeddingPrimeiraCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][0]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingPenultimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-2]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingUltimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-1]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingSoma4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][-4:]\n","  # Saída: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado\n","\n","def getEmbeddingConcat4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Cria uma lista com os tensores a serem concatenados\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Lista com os tensores a serem concatenados\n","  lista_concat = []\n","\n","  # Percorre os 4 últimos\n","  for i in [-1,-2,-3,-4]:\n","      # Concatena da lista\n","      lista_concat.append(output[2][i])\n","\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Realiza a concatenação dos embeddings de todos as camadas\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  resultado = torch.cat(lista_concat, dim=-1)\n","\n","  # Saída: Entrada: (<1(lote)> x <qtde_tokens> x <3072 ou 4096>)\n","  return resultado\n","\n","def getEmbeddingSomaTodasAsCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas as camadas descontando a primeira(0)\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][1:]\n","  # Saída: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q7nx_eZ8hSlr"},"source":["### getEmbeddingsVisual\n","\n","Função para gerar as coordenadas de plotagem a partir das sentenças de embeddings.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"pLdbOT8-g43V"},"source":["def getEmbeddingsVisualUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAf9lJJ2hZbt"},"source":["def getEmbeddingsVisualSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XpwSN1ghpnz"},"source":["def getEmbeddingsVisualConcat4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3KU1EFrnSPK"},"source":["def getEmbeddingsVisualSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8MjE0utzlZT"},"source":["### getEmbeddings\n","\n","Função para gerar os embeddings de sentenças.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"2QcqOuwS067Q"},"source":["def getEmbeddingsUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BK1wDGBl067Y"},"source":["def getEmbeddingsSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hym19Hxr067Y"},"source":["def getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer):\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-PLZiUR067Z"},"source":["def getEmbeddingsSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingsDocumento\n","\n","Recupera os embeddings e tokens do documento sem buffer."],"metadata":{"id":"Pyra3_pECsoJ"}},{"cell_type":"code","source":["def getEmbeddingsDocumento(documento, modelo, tokenizer):\n","\n","    return getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer)"],"metadata":{"id":"XdDBSRDcCxHp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingsDocumentoBuffer\n","\n","Recupera os embeddings e tokens do documento com buffer."],"metadata":{"id":"-rLcMuDHC-F5"}},{"cell_type":"code","source":["buffer_token_embeddings = {}\n","\n","def getEmbeddingsDocumentoBuffer(documento, modelo, tokenizer):\n","\n","    # Se documento está no dicionário retorna o embedding e os tokens\n","    if documento in buffer_token_embeddings:\n","        registro_buffer = buffer_token_embeddings.get(documento)\n","        return registro_buffer[0], registro_buffer[1]\n","    else:\n","        # Gera o embedding\n","        token_embeddings, documento_tokenizado = getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer)\n","        buffer_token_embeddings.update({documento: [token_embeddings, documento_tokenizado]})\n","\n","        return  token_embeddings, documento_tokenizado"],"metadata":{"id":"OogUm0kuC7wK"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTRcghhuet76"},"source":["def limpaBufferEmbedding():\n","    buffer_token_embeddings.clear()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zFd1rse11DpZ"},"source":["### getDocumentoTokenizado\n","\n","Retorna o documento tokenizado"]},{"cell_type":"code","metadata":{"id":"gvWIBFTLJ7z9"},"source":["def getDocumentoTokenizado(documento, tokenizer):\n","    \"\"\"\n","      Retorna o documento tokenizado pelo BERT.\n","\n","      Parâmetros:\n","      `documento` - Documento a ser tokenizado.\n","      `tokenizer` - Tokenizador do BERT.\n","    \"\"\"\n","\n","    # Adiciona os tokens especiais.\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Documento tokenizado\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    del tokenizer\n","\n","    return documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3wvgXwN81RCz"},"source":["### encontrarIndiceSubLista\n","\n","Retorna os índices de início e fim da sublista na lista"]},{"cell_type":"code","metadata":{"id":"abS44M4yvFxf"},"source":["# Localiza os índices de início e fim de uma sublista em uma lista\n","def encontrarIndiceSubLista(lista, sublista):\n","\n","    \"\"\"\n","      Localiza os índices de início e fim de uma sublista em uma lista.\n","\n","      Parâmetros:\n","      `lista` - Uma lista.\n","      `sublista` - Uma sublista a ser localizada na lista.\n","    \"\"\"\n","    # https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n","\n","    # Recupera o tamanho da lista\n","    h = len(lista)\n","    # Recupera o tamanho da sublista\n","    n = len(sublista)\n","    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n","    i = n - 1\n","    while i < h:\n","      for j in range(n):\n","        if lista[i - j] != sublista[-j - 1]:\n","            i += skip.get(lista[i], n)\n","            break\n","        else:\n","            indice_inicio = i - n + 1\n","            indice_fim = indice_inicio + len(sublista)-1\n","\n","            return indice_inicio, indice_fim\n","\n","    # Não encontrou a sublista na lista\n","    return -1, -1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGL37G6XFcwp"},"source":["### getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras\n","\n","A partir dos embeddings do documento, localiza o indíce de início e fim de uma sentença no documento e retorna os embeddings da sentença."]},{"cell_type":"code","metadata":{"id":"uI07Y_M8__HG"},"source":["# Import das bibliotecas.\n","import numpy as np\n","\n","def getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                           token_BERT_documento,\n","                                                           sentenca,\n","                                                           tokenizer):\n","\n","  # Tokeniza a sentença\n","  sentenca_tokenizada_BERT = getDocumentoTokenizado(sentenca, tokenizer)\n","  #print(sentenca_tokenizada_BERT)\n","\n","  # Remove os tokens de início e fim da sentença\n","  sentenca_tokenizada_BERT.remove(\"[CLS]\")\n","  sentenca_tokenizada_BERT.remove(\"[SEP]\")\n","  #print(len(sentenca_tokenizada_BERT))\n","\n","  # Localiza os índices dos tokens da sentença no documento\n","  inicio, fim = encontrarIndiceSubLista(token_BERT_documento, sentenca_tokenizada_BERT)\n","  #print(inicio,fim)\n","\n","  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do documento\n","  embeddingSentenca = embedding_documento[inicio:fim+1]\n","  #print(\"embeddingSentenca=\", embeddingSentenca.shape)\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del sentenca\n","  del tokenizer\n","\n","  # Retorna o embedding da sentença no documento\n","  return embeddingSentenca, sentenca_tokenizada_BERT"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"THFhXGGmIO_r"},"source":["### getEmbeddingDocumentoComTodasPalavrasMean"]},{"cell_type":"code","metadata":{"id":"IhW_OiEsIPJI"},"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento excluindo os tokens\n","    especiais [CLS] do início e [SEP] do fim.\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embedding do documento.\n","  \"\"\"\n","\n","\n","  # Calcula a média dos embeddings para os tokens de embedding_documento, removendo a primeira dimensão.\n","  # Entrada: <qtde_tokens> x <768 ou 1024>\n","  #print(\"embedding_documento1=\", embedding_documento.shape)\n","  media_embedding_documento = torch.mean(embedding_documento[1:-1], dim=0)\n","  # Saída: <768 ou 1024>\n","\n","  del embedding_documento\n","\n","  return media_embedding_documento"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingDocumentoRelevanteMean"],"metadata":{"id":"1Ko_of60YuNd"}},{"cell_type":"code","source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                       index_sentenca,\n","                                       embedding_documento,\n","                                       token_BERT_documento,\n","                                       documento,\n","                                       tokenizer,\n","                                       token_documento,\n","                                       pos_documento,\n","                                       filtro):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento considerando tokens do tipo\n","    especificado no filtro\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","\n","  \"\"\"\n","\n","  # Recupera a lista de tokens do documento, a lista dos postagging e a lista dos seus embeddings com um mesmo tamanho\n","  lista_tokens, lista_postagging, lista_embeddings = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                    index_sentenca,\n","                                                                                    embedding_documento,\n","                                                                                    token_BERT_documento,\n","                                                                                    documento,\n","                                                                                    tokenizer,\n","                                                                                    token_documento,\n","                                                                                    pos_documento)\n","\n","  #print(\"len(token_BERT_documento):\", len(token_BERT_documento))\n","  #print(\"token_BERT_documento:\", token_BERT_documento)\n","  #print(\"len(pos_documento):\", len(pos_documento))\n","  #print(\"pos_documento:\", pos_documento)\n","  #print(\"filtro:\", filtro)\n","  #print()\n","\n","  # Lista com os tensores selecionados\n","  lista_tokens_selecionados = []\n","  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word no documento\n","  for i, token_documento in enumerate(lista_tokens):\n","      if (lista_postagging[i] in filtro):\n","          #print(\"Adicionando palavra do embedding:\", lista_tokens[i])\n","          lista_tokens_selecionados.append(lista_embeddings[i])\n","\n","  if  len(lista_tokens_selecionados) != 0:\n","      # Empila os embeddings da lista pela dimensão 0\n","      embedding_relevante = torch.stack(lista_tokens_selecionados, dim=0)\n","      #print(\"embedding_relevante.shape:\",embedding_relevante.shape)\n","\n","      # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n","      # Entrada: <qtde_tokens> x <768 ou 1024>\n","      media_embedding_relevante = torch.mean(embedding_relevante, dim=0)\n","      # Saída: <768 ou 1024>\n","      #print(\"media_embedding_relevante.shape:\", media_embedding_relevante.shape)\n","  else:\n","      media_embedding_relevante = None\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del documento\n","  del tokenizer\n","  del token_documento\n","  del pos_documento\n","\n","  return media_embedding_relevante"],"metadata":{"id":"wDokSSODY0Sf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingDocumentoMean\n","\n","Filtros:\n","- ALL - Sentença com todas as palavras\n","- NOUN - Sentença somente com substantivos\n","- VERB - Sentença somente com verbos\n","- VERB,NOUN - Sentença somente com verbos e substantivos"],"metadata":{"id":"L_vknrk7YSpF"}},{"cell_type":"code","source":["def getEmbeddingDocumentoMean(id_documento,\n","                              index_sentenca,\n","                              embedding_documento,\n","                              token_BERT_documento,\n","                              documento,\n","                              tokenizer,\n","                              token_documento,\n","                              pos_documento,\n","                              filtro=[\"ALL\"]):\n","  \"\"\"\n","    Rediciona o cálculo da média dos embeddings de acordo com o filtro especificado.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","  \"\"\"\n","\n","  if \"ALL\" in filtro:\n","    return getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento)\n","  else:\n","    return getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                              index_sentenca,\n","                                              embedding_documento,\n","                                              token_BERT_documento,\n","                                              documento,\n","                                              tokenizer,\n","                                              token_documento,\n","                                              pos_documento,\n","                                              filtro)"],"metadata":{"id":"Pd8B76YyYS02"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7W-7V3QFbpR"},"source":["# 5 Comparar Palavras"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 5.1 Carregamento dos arquivos de dados originais e perturbados"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["#### 5.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","metadata":{"id":"bNgwJRC2uGJb"},"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.1.2 Cria o diretório local para receber os dados"],"metadata":{"id":"CGF4D4B1JY9P"}},{"cell_type":"code","metadata":{"id":"gFYIHcIHE985","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424351491,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"9d5a973c-0838-450d-f1c8-451b897c4422"},"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):\n","    # Cria o diretório\n","    os.makedirs(dirbase)\n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:\n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_IN_EN.\n"]}]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","metadata":{"id":"pviuxToMCxQw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424352636,"user_tz":180,"elapsed":1150,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"5beeef09-c5e1-41b4-c90c-359ade3e9585"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a cópia.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens\n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","metadata":{"id":"dbHl3d88mouc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424354072,"user_tz":180,"elapsed":1441,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"a0cd6061-2ea0-4047-825f-c92ca09f9e76"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a descompactação.\n"]}]},{"cell_type":"markdown","metadata":{"id":"qzhYJNWJm1z4"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais e pertubados"]},{"cell_type":"markdown","metadata":{"id":"Usr1uRzQeJSb"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","metadata":{"id":"QRHlixdHEDTb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424354073,"user_tz":180,"elapsed":65,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"f1253c2f-dd68-4635-e358-21f3a74cf22c"},"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO ORIGINAIS: 20.\n","INFO:root:TERMINADO ORIGINAIS POS: 20.\n"]}]},{"cell_type":"code","metadata":{"id":"jJ5STBZPLlie","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1664424354073,"user_tz":180,"elapsed":57,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7135628c-1579-41da-8c3c-496d6be0f6a9"},"source":["lista_documentos_originais.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id                                          sentencas  \\\n","6    7p0              ['How to pop elements from a queue?']   \n","7    8p0  ['How to pop elements in a queue data structur...   \n","11  12p0  ['What is a queue and how to pop an element fr...   \n","15  16p0  ['What is a stack and how to enqueue and deque...   \n","5    6p0  ['How to push and pop elements in a queue data...   \n","\n","                                            documento  \n","6                   How to pop elements from a queue?  \n","7      How to pop elements in a queue data structure?  \n","11  What is a queue and how to pop an element from...  \n","15  What is a stack and how to enqueue and dequeue...  \n","5   How to push and pop elements in a queue data s...  "],"text/html":["\n","  <div id=\"df-5747b417-7866-4e7a-8745-49c36cf93676\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>7p0</td>\n","      <td>['How to pop elements from a queue?']</td>\n","      <td>How to pop elements from a queue?</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8p0</td>\n","      <td>['How to pop elements in a queue data structur...</td>\n","      <td>How to pop elements in a queue data structure?</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12p0</td>\n","      <td>['What is a queue and how to pop an element fr...</td>\n","      <td>What is a queue and how to pop an element from...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16p0</td>\n","      <td>['What is a stack and how to enqueue and deque...</td>\n","      <td>What is a stack and how to enqueue and dequeue...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6p0</td>\n","      <td>['How to push and pop elements in a queue data...</td>\n","      <td>How to push and pop elements in a queue data s...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5747b417-7866-4e7a-8745-49c36cf93676')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5747b417-7866-4e7a-8745-49c36cf93676 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5747b417-7866-4e7a-8745-49c36cf93676');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":285}]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais = lista_documentos_originais.astype(tipos)"],"metadata":{"id":"BYddg8UODmdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbaWPXE2jK26","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1664424354074,"user_tz":180,"elapsed":55,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"5256f76a-ea3a-4019-9471-2a0a4ee7e9bf"},"source":["lista_documentos_originais_pos.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id                                      pos_documento\n","15  16p0  [[['What', 'is', 'a', 'stack', 'and', 'how', '...\n","10  11p0  [[['What', 'is', 'a', 'stack', 'and', 'how', '...\n","8    9p0  [[['What', 'is', 'a', 'queue', 'and', 'how', '...\n","4    5p0  [[['How', 'to', 'push', 'elements', 'in', 'a',...\n","17  18p0  [[['How', 'are', 'the', 'operations', 'to', 'e..."],"text/html":["\n","  <div id=\"df-7162752a-56e2-4f02-b973-0b99d508d572\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15</th>\n","      <td>16p0</td>\n","      <td>[[['What', 'is', 'a', 'stack', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11p0</td>\n","      <td>[[['What', 'is', 'a', 'stack', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9p0</td>\n","      <td>[[['What', 'is', 'a', 'queue', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5p0</td>\n","      <td>[[['How', 'to', 'push', 'elements', 'in', 'a',...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18p0</td>\n","      <td>[[['How', 'are', 'the', 'operations', 'to', 'e...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7162752a-56e2-4f02-b973-0b99d508d572')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7162752a-56e2-4f02-b973-0b99d508d572 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7162752a-56e2-4f02-b973-0b99d508d572');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":287}]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais_pos = lista_documentos_originais_pos.astype(tipos)"],"metadata":{"id":"d96IZl9nDfHf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"-hfUpvKqXoqe"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"metadata":{"id":"lj9sJVavMccj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424354075,"user_tz":180,"elapsed":54,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"a5e7069c-4406-41a9-eada-4ed65b221f46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO ORIGINAIS: 20.\n","INFO:root:TERMINADO CORREÇÃO ORIGINAIS POS: 20.\n"]}]},{"cell_type":"markdown","source":["#### Criando dados indexados originais"],"metadata":{"id":"8yyRt4jnYxsU"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"B9INo4nBS8aQ","executionInfo":{"status":"ok","timestamp":1664424354720,"user_tz":180,"elapsed":695,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"0cd10241-40f1-4802-e0cc-52d7c974e7dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             sentencas  \\\n","id                                                       \n","1p0              [How to dequeue elements in a stack?]   \n","2p0              [How to dequeue elements in a stack?]   \n","3p0                 [How to push elements in a queue?]   \n","4p0         [How to push and pop elements in a queue?]   \n","5p0  [How to push elements in a queue data structure?]   \n","\n","                                           documento  \n","id                                                    \n","1p0              How to dequeue elements in a stack?  \n","2p0              How to dequeue elements in a stack?  \n","3p0                 How to push elements in a queue?  \n","4p0         How to push and pop elements in a queue?  \n","5p0  How to push elements in a queue data structure?  "],"text/html":["\n","  <div id=\"df-58aefc46-4c79-4785-94b0-d4a6ea066d3e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0</th>\n","      <td>[How to dequeue elements in a stack?]</td>\n","      <td>How to dequeue elements in a stack?</td>\n","    </tr>\n","    <tr>\n","      <th>2p0</th>\n","      <td>[How to dequeue elements in a stack?]</td>\n","      <td>How to dequeue elements in a stack?</td>\n","    </tr>\n","    <tr>\n","      <th>3p0</th>\n","      <td>[How to push elements in a queue?]</td>\n","      <td>How to push elements in a queue?</td>\n","    </tr>\n","    <tr>\n","      <th>4p0</th>\n","      <td>[How to push and pop elements in a queue?]</td>\n","      <td>How to push and pop elements in a queue?</td>\n","    </tr>\n","    <tr>\n","      <th>5p0</th>\n","      <td>[How to push elements in a queue data structure?]</td>\n","      <td>How to push elements in a queue data structure?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58aefc46-4c79-4785-94b0-d4a6ea066d3e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-58aefc46-4c79-4785-94b0-d4a6ea066d3e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-58aefc46-4c79-4785-94b0-d4a6ea066d3e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":290}]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"j70x_r30T_bx","executionInfo":{"status":"ok","timestamp":1664424354721,"user_tz":180,"elapsed":90,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"c0c08439-4f15-4078-e7ef-093df4e015ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         pos_documento\n","id                                                    \n","1p0  [[[How, to, dequeue, elements, in, a, stack, ?...\n","2p0  [[[How, to, dequeue, elements, in, a, stack, ?...\n","3p0  [[[How, to, push, elements, in, a, queue, ?], ...\n","4p0  [[[How, to, push, and, pop, elements, in, a, q...\n","5p0  [[[How, to, push, elements, in, a, queue, data..."],"text/html":["\n","  <div id=\"df-612bd610-eecc-4bcf-a6c7-8417b33455a7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0</th>\n","      <td>[[[How, to, dequeue, elements, in, a, stack, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>2p0</th>\n","      <td>[[[How, to, dequeue, elements, in, a, stack, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>3p0</th>\n","      <td>[[[How, to, push, elements, in, a, queue, ?], ...</td>\n","    </tr>\n","    <tr>\n","      <th>4p0</th>\n","      <td>[[[How, to, push, and, pop, elements, in, a, q...</td>\n","    </tr>\n","    <tr>\n","      <th>5p0</th>\n","      <td>[[[How, to, push, elements, in, a, queue, data...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-612bd610-eecc-4bcf-a6c7-8417b33455a7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-612bd610-eecc-4bcf-a6c7-8417b33455a7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-612bd610-eecc-4bcf-a6c7-8417b33455a7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":291}]},{"cell_type":"markdown","metadata":{"id":"zJXcpioo7Bhn"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","metadata":{"id":"gB500dmd7Bho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664424354722,"user_tz":180,"elapsed":85,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"37640259-b63d-4c95-c692-15edb4b24174"},"source":["# Abre o arquivo e retorna o DataFrame\n","lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO PERTURBADOS: 2000.\n","INFO:root:TERMINADO PERTURBADOS POS: 2000.\n"]}]},{"cell_type":"markdown","source":["Alguns csv estão com o nome da coluna errado."],"metadata":{"id":"jfZEITKEHHWW"}},{"cell_type":"code","source":["lista_documentos_perturbados = lista_documentos_perturbados.rename(columns={'documentoPerturbado':'documento_perturbado'})"],"metadata":{"id":"quf5o1KkHLkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ9cgAz47Bhp","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1664424354723,"user_tz":180,"elapsed":73,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"8bfc1833-72dd-4199-f385-5710d286ad0b"},"source":["lista_documentos_perturbados.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                id                                         perturbado  \\\n","1869  19p0_pert_69  ['In a stack does the enqueue operation govern...   \n","1066  11p0_pert_66  ['What is a stack and how to perform an elemen...   \n","483    5p0_pert_83  ['How to track elements in a queue data struct...   \n","346    4p0_pert_46   ['How to compose and pop elements in a queue ?']   \n","1834  19p0_pert_34  ['In a stack does the enqueue operation termin...   \n","\n","                                   documento_perturbado  \\\n","1869  In a stack does the enqueue operation govern a...   \n","1066  What is a stack and how to perform an element ...   \n","483   How to track elements in a queue data structure ?   \n","346        How to compose and pop elements in a queue ?   \n","1834  In a stack does the enqueue operation terminat...   \n","\n","                                              sentencas  \n","1869  [['In a stack does the enqueue operation [MASK...  \n","1066  [['What is a stack and how to [MASK] an elemen...  \n","483   [['How to [MASK] elements in a queue data stru...  \n","346   [['How to [MASK] and pop elements in a queue ?...  \n","1834  [['In a stack does the enqueue operation [MASK...  "],"text/html":["\n","  <div id=\"df-00036eb4-75c2-4fa8-a0bf-9c65a76385be\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1869</th>\n","      <td>19p0_pert_69</td>\n","      <td>['In a stack does the enqueue operation govern...</td>\n","      <td>In a stack does the enqueue operation govern a...</td>\n","      <td>[['In a stack does the enqueue operation [MASK...</td>\n","    </tr>\n","    <tr>\n","      <th>1066</th>\n","      <td>11p0_pert_66</td>\n","      <td>['What is a stack and how to perform an elemen...</td>\n","      <td>What is a stack and how to perform an element ...</td>\n","      <td>[['What is a stack and how to [MASK] an elemen...</td>\n","    </tr>\n","    <tr>\n","      <th>483</th>\n","      <td>5p0_pert_83</td>\n","      <td>['How to track elements in a queue data struct...</td>\n","      <td>How to track elements in a queue data structure ?</td>\n","      <td>[['How to [MASK] elements in a queue data stru...</td>\n","    </tr>\n","    <tr>\n","      <th>346</th>\n","      <td>4p0_pert_46</td>\n","      <td>['How to compose and pop elements in a queue ?']</td>\n","      <td>How to compose and pop elements in a queue ?</td>\n","      <td>[['How to [MASK] and pop elements in a queue ?...</td>\n","    </tr>\n","    <tr>\n","      <th>1834</th>\n","      <td>19p0_pert_34</td>\n","      <td>['In a stack does the enqueue operation termin...</td>\n","      <td>In a stack does the enqueue operation terminat...</td>\n","      <td>[['In a stack does the enqueue operation [MASK...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00036eb4-75c2-4fa8-a0bf-9c65a76385be')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-00036eb4-75c2-4fa8-a0bf-9c65a76385be button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-00036eb4-75c2-4fa8-a0bf-9c65a76385be');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":294}]},{"cell_type":"code","metadata":{"id":"3pXGee7H7Bhp","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1664424354724,"user_tz":180,"elapsed":66,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"82d35547-6c46-4422-9958-df369c6e3d56"},"source":["lista_documentos_perturbados.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                id                                         perturbado  \\\n","448    5p0_pert_48  ['How to set elements in a queue data structur...   \n","616    7p0_pert_16             ['How to use elements from a queue ?']   \n","1973  20p0_pert_73  ['In a queue does the push operation communica...   \n","764    8p0_pert_64  ['How to bind elements in a queue data structu...   \n","1030  11p0_pert_30  ['What is a stack and how to be an element in ...   \n","\n","                                   documento_perturbado  \\\n","448     How to set elements in a queue data structure ?   \n","616                  How to use elements from a queue ?   \n","1973  In a queue does the push operation communicate...   \n","764    How to bind elements in a queue data structure ?   \n","1030   What is a stack and how to be an element in it ?   \n","\n","                                              sentencas  \n","448   [['How to [MASK] elements in a queue data stru...  \n","616   [['How to [MASK] elements from a queue ?', 'po...  \n","1973  [['In a queue does the push operation [MASK] a...  \n","764   [['How to [MASK] elements in a queue data stru...  \n","1030  [['What is a stack and how to [MASK] an elemen...  "],"text/html":["\n","  <div id=\"df-f6029bac-2c66-47a0-b820-5b0d66f3d7b4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>448</th>\n","      <td>5p0_pert_48</td>\n","      <td>['How to set elements in a queue data structur...</td>\n","      <td>How to set elements in a queue data structure ?</td>\n","      <td>[['How to [MASK] elements in a queue data stru...</td>\n","    </tr>\n","    <tr>\n","      <th>616</th>\n","      <td>7p0_pert_16</td>\n","      <td>['How to use elements from a queue ?']</td>\n","      <td>How to use elements from a queue ?</td>\n","      <td>[['How to [MASK] elements from a queue ?', 'po...</td>\n","    </tr>\n","    <tr>\n","      <th>1973</th>\n","      <td>20p0_pert_73</td>\n","      <td>['In a queue does the push operation communica...</td>\n","      <td>In a queue does the push operation communicate...</td>\n","      <td>[['In a queue does the push operation [MASK] a...</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>8p0_pert_64</td>\n","      <td>['How to bind elements in a queue data structu...</td>\n","      <td>How to bind elements in a queue data structure ?</td>\n","      <td>[['How to [MASK] elements in a queue data stru...</td>\n","    </tr>\n","    <tr>\n","      <th>1030</th>\n","      <td>11p0_pert_30</td>\n","      <td>['What is a stack and how to be an element in ...</td>\n","      <td>What is a stack and how to be an element in it ?</td>\n","      <td>[['What is a stack and how to [MASK] an elemen...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6029bac-2c66-47a0-b820-5b0d66f3d7b4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f6029bac-2c66-47a0-b820-5b0d66f3d7b4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f6029bac-2c66-47a0-b820-5b0d66f3d7b4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":295}]},{"cell_type":"code","source":["lista_documentos_perturbados_pos.sample(5)"],"metadata":{"id":"IE1xJdZWkc5I","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1664424354725,"user_tz":180,"elapsed":65,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"12ef9f26-5e92-4d48-b2fd-c4a6e0ee1c6e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                id                                      pos_documento\n","1022  11p0_pert_22  [[['What', 'is', 'a', 'stack', 'and', 'how', '...\n","421    5p0_pert_21  [[['How', 'to', 'view', 'elements', 'in', 'a',...\n","1691  17p0_pert_91  [[['How', 'are', 'the', 'operations', 'to', 'r...\n","50     1p0_pert_50  [[['How', 'to', 'keep', 'elements', 'in', 'a',...\n","885    9p0_pert_85  [[['What', 'is', 'a', 'queue', 'and', 'how', '..."],"text/html":["\n","  <div id=\"df-28b343cc-2e9a-4f02-824f-56a51e9a3085\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1022</th>\n","      <td>11p0_pert_22</td>\n","      <td>[[['What', 'is', 'a', 'stack', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>421</th>\n","      <td>5p0_pert_21</td>\n","      <td>[[['How', 'to', 'view', 'elements', 'in', 'a',...</td>\n","    </tr>\n","    <tr>\n","      <th>1691</th>\n","      <td>17p0_pert_91</td>\n","      <td>[[['How', 'are', 'the', 'operations', 'to', 'r...</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>1p0_pert_50</td>\n","      <td>[[['How', 'to', 'keep', 'elements', 'in', 'a',...</td>\n","    </tr>\n","    <tr>\n","      <th>885</th>\n","      <td>9p0_pert_85</td>\n","      <td>[[['What', 'is', 'a', 'queue', 'and', 'how', '...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28b343cc-2e9a-4f02-824f-56a51e9a3085')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-28b343cc-2e9a-4f02-824f-56a51e9a3085 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-28b343cc-2e9a-4f02-824f-56a51e9a3085');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":296}]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"VrfZzjjpsUOU"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHf-7dgSsUOU","executionInfo":{"status":"ok","timestamp":1664424354725,"user_tz":180,"elapsed":63,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"758344cc-c81a-4a29-bce1-fd2a78ad56fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO PERTURBADO: 2000.\n","INFO:root:TERMINADO CORREÇÃO PERTURBADO POS: 2000.\n"]}]},{"cell_type":"markdown","source":["#### Criando dados indexados perturbados"],"metadata":{"id":"Ix-Q5fZXY3HR"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"FqRQnYUtSxzB","executionInfo":{"status":"ok","timestamp":1664424354726,"user_tz":180,"elapsed":53,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"e2722a69-ca4d-494f-96ef-785fdb1b412f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         perturbado  \\\n","id                                                    \n","1p0_pert_0   [How to arrange elements in a stack ?]   \n","1p0_pert_1  [How to organize elements in a stack ?]   \n","1p0_pert_2     [How to store elements in a stack ?]   \n","1p0_pert_3       [How to put elements in a stack ?]   \n","1p0_pert_4    [How to manage elements in a stack ?]   \n","\n","                             documento_perturbado  \\\n","id                                                  \n","1p0_pert_0   How to arrange elements in a stack ?   \n","1p0_pert_1  How to organize elements in a stack ?   \n","1p0_pert_2     How to store elements in a stack ?   \n","1p0_pert_3       How to put elements in a stack ?   \n","1p0_pert_4    How to manage elements in a stack ?   \n","\n","                                                    sentencas  \n","id                                                             \n","1p0_pert_0  [[How to [MASK] elements in a stack ?, dequeue...  \n","1p0_pert_1  [[How to [MASK] elements in a stack ?, dequeue...  \n","1p0_pert_2  [[How to [MASK] elements in a stack ?, dequeue...  \n","1p0_pert_3  [[How to [MASK] elements in a stack ?, dequeue...  \n","1p0_pert_4  [[How to [MASK] elements in a stack ?, dequeue...  "],"text/html":["\n","  <div id=\"df-1e624b66-808c-473b-b3b6-7e05f77c4e2c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0_pert_0</th>\n","      <td>[How to arrange elements in a stack ?]</td>\n","      <td>How to arrange elements in a stack ?</td>\n","      <td>[[How to [MASK] elements in a stack ?, dequeue...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_1</th>\n","      <td>[How to organize elements in a stack ?]</td>\n","      <td>How to organize elements in a stack ?</td>\n","      <td>[[How to [MASK] elements in a stack ?, dequeue...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_2</th>\n","      <td>[How to store elements in a stack ?]</td>\n","      <td>How to store elements in a stack ?</td>\n","      <td>[[How to [MASK] elements in a stack ?, dequeue...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_3</th>\n","      <td>[How to put elements in a stack ?]</td>\n","      <td>How to put elements in a stack ?</td>\n","      <td>[[How to [MASK] elements in a stack ?, dequeue...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_4</th>\n","      <td>[How to manage elements in a stack ?]</td>\n","      <td>How to manage elements in a stack ?</td>\n","      <td>[[How to [MASK] elements in a stack ?, dequeue...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e624b66-808c-473b-b3b6-7e05f77c4e2c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1e624b66-808c-473b-b3b6-7e05f77c4e2c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1e624b66-808c-473b-b3b6-7e05f77c4e2c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":298}]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados_pos.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"s0aDUbeZT1M8","executionInfo":{"status":"ok","timestamp":1664424354727,"user_tz":180,"elapsed":52,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"1eabea47-3789-4564-e67c-571f927e5e70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                pos_documento\n","id                                                           \n","1p0_pert_0  [[[How, to, arrange, elements, in, a, stack, ?...\n","1p0_pert_1  [[[How, to, organize, elements, in, a, stack, ...\n","1p0_pert_2  [[[How, to, store, elements, in, a, stack, ?],...\n","1p0_pert_3  [[[How, to, put, elements, in, a, stack, ?], [...\n","1p0_pert_4  [[[How, to, manage, elements, in, a, stack, ?]..."],"text/html":["\n","  <div id=\"df-4e2de20b-2d15-4979-b928-5292af961323\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0_pert_0</th>\n","      <td>[[[How, to, arrange, elements, in, a, stack, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_1</th>\n","      <td>[[[How, to, organize, elements, in, a, stack, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_2</th>\n","      <td>[[[How, to, store, elements, in, a, stack, ?],...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_3</th>\n","      <td>[[[How, to, put, elements, in, a, stack, ?], [...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_4</th>\n","      <td>[[[How, to, manage, elements, in, a, stack, ?]...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e2de20b-2d15-4979-b928-5292af961323')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4e2de20b-2d15-4979-b928-5292af961323 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4e2de20b-2d15-4979-b928-5292af961323');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":299}]},{"cell_type":"markdown","source":["### 5.1.5 Agrupar os dados originais e perturbados"],"metadata":{"id":"kq0-NGaC76jP"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","lista_documentos_agrupados = []\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_originais_bar:\n","  #if i < 2:\n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    #print(\"id_documento:\",id_documento)\n","\n","    # Carrega a lista das sentenças do documento\n","    lista_sentenca_documento = linha_documento[1]\n","    #print(\"\\nlista_sentenca_documento:\",lista_sentenca_documento)\n","    #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","\n","    # Adiciona o original a lista dos dados agrupados, considerando como coerente(1)\n","    lista_documentos_agrupados.append([id_documento, lista_sentenca_documento, linha_documento[2], 1])\n","\n","    # Percorre os documentos perturbados apartir do original\n","    for j in range(0, model_args.documentos_perturbados):\n","\n","      # Id do documento perturbado\n","      id_perturbado = str(id_documento) + \"_pert_\" + str(j)\n","\n","      # localiza o documento perturbado\n","      documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","      # print(\"documento_perturbado:\", documento_perturbado)\n","      # print(\"len(documento_perturbado):\", len(documento_perturbado))\n","      # Recupera a sentença do documento perturbado\n","      lista_perturbado = documento_perturbado[0]\n","\n","      # Adiciona o perturbado a lista dos dados agrupados considerando como incoerente(0)\n","      lista_documentos_agrupados.append([id_perturbado, lista_perturbado, documento_perturbado[1], 0])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["2c44d2408d77499fbb60e163d0da3304","c2416aa248bc454c81d7242c4491df05","1cb59e8ff5c642dc8c3a7c0eb224ad97","6937e6e8d2754658ae130d1a0028d4a0","c9ac487972354ff28ca34775bc254724","75616565f6654614a28d1a9147e00d61","88e579b5e5b44deebc97786e8662d44f","8556b4cda2554c72a7d3930f09d291a5","7cf9b86a29244be682a294066745b580","22eb3efaafda454bb5c1de8008b03db8","856838d96a75411e8491830ca7a38b1d"]},"id":"t_HVTlvaxqoM","executionInfo":{"status":"ok","timestamp":1664424355143,"user_tz":180,"elapsed":466,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ba7858bc-f7ed-430f-c526-20faeda0abff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processando 20 documentos originais\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/20 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c44d2408d77499fbb60e163d0da3304"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO AGRUPAMENTO: 2020.\n"]}]},{"cell_type":"markdown","source":["Converte em um dataframe"],"metadata":{"id":"THHBPK6Ov8WV"}},{"cell_type":"code","source":["# Cria o dataframe da lista\n","lista_documentos_agrupados = pd.DataFrame(lista_documentos_agrupados, columns = [\"id\",\"sentencas\",\"documento\",\"classe\"])"],"metadata":{"id":"sWz4b8Fpv8ki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str, \"sentencas\": object, \"documento\": str, \"classe\": int}\n","\n","lista_documentos_agrupados = lista_documentos_agrupados.astype(tipos)"],"metadata":{"id":"AsbAU3pnAjYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lista_documentos_agrupados.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"LExAiKee0nhm","executionInfo":{"status":"ok","timestamp":1664424355146,"user_tz":180,"elapsed":74,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"d7230340-21e3-4650-bdcd-21f32575181d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                id                                          sentencas  \\\n","1097  11p0_pert_86  [What is a stack and how to run an element in ...   \n","750    8p0_pert_42  [How to generate elements in a queue data stru...   \n","245    3p0_pert_42              [How to insert elements in a queue ?]   \n","1495  15p0_pert_80  [What is a queue and how to set and pop its el...   \n","584    6p0_pert_78  [How to bust and pop elements in a queue data ...   \n","332    4p0_pert_28         [How to say and pop elements in a queue ?]   \n","988   10p0_pert_78  [What is a stack and how to function its eleme...   \n","405     5p0_pert_0  [How to manage elements in a queue data struct...   \n","760    8p0_pert_52  [How to save elements in a queue data structur...   \n","1599  16p0_pert_83  [What is a stack and how to enqueue and partit...   \n","\n","                                              documento  classe  \n","1097  What is a stack and how to run an element in it ?       0  \n","750   How to generate elements in a queue data struc...       0  \n","245                 How to insert elements in a queue ?       0  \n","1495  What is a queue and how to set and pop its ele...       0  \n","584   How to bust and pop elements in a queue data s...       0  \n","332            How to say and pop elements in a queue ?       0  \n","988   What is a stack and how to function its element ?       0  \n","405   How to manage elements in a queue data structu...       0  \n","760    How to save elements in a queue data structure ?       0  \n","1599  What is a stack and how to enqueue and partiti...       0  "],"text/html":["\n","  <div id=\"df-19054b57-56ed-4c96-b875-3108ed8d6a65\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1097</th>\n","      <td>11p0_pert_86</td>\n","      <td>[What is a stack and how to run an element in ...</td>\n","      <td>What is a stack and how to run an element in it ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>750</th>\n","      <td>8p0_pert_42</td>\n","      <td>[How to generate elements in a queue data stru...</td>\n","      <td>How to generate elements in a queue data struc...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>3p0_pert_42</td>\n","      <td>[How to insert elements in a queue ?]</td>\n","      <td>How to insert elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1495</th>\n","      <td>15p0_pert_80</td>\n","      <td>[What is a queue and how to set and pop its el...</td>\n","      <td>What is a queue and how to set and pop its ele...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>584</th>\n","      <td>6p0_pert_78</td>\n","      <td>[How to bust and pop elements in a queue data ...</td>\n","      <td>How to bust and pop elements in a queue data s...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>4p0_pert_28</td>\n","      <td>[How to say and pop elements in a queue ?]</td>\n","      <td>How to say and pop elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>988</th>\n","      <td>10p0_pert_78</td>\n","      <td>[What is a stack and how to function its eleme...</td>\n","      <td>What is a stack and how to function its element ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>5p0_pert_0</td>\n","      <td>[How to manage elements in a queue data struct...</td>\n","      <td>How to manage elements in a queue data structu...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>760</th>\n","      <td>8p0_pert_52</td>\n","      <td>[How to save elements in a queue data structur...</td>\n","      <td>How to save elements in a queue data structure ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1599</th>\n","      <td>16p0_pert_83</td>\n","      <td>[What is a stack and how to enqueue and partit...</td>\n","      <td>What is a stack and how to enqueue and partiti...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19054b57-56ed-4c96-b875-3108ed8d6a65')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-19054b57-56ed-4c96-b875-3108ed8d6a65 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-19054b57-56ed-4c96-b875-3108ed8d6a65');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":303}]},{"cell_type":"code","source":["lista_documentos_agrupados.sample(10)"],"metadata":{"id":"P3qemxYGwHL7","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1664424355147,"user_tz":180,"elapsed":72,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"0ab8e633-9195-40ee-b968-781117e52164"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                id                                          sentencas  \\\n","1365  14p0_pert_51  [What is a queue and how to call an element on...   \n","613     7p0_pert_6              [How to draw elements from a queue ?]   \n","1391  14p0_pert_77  [What is a queue and how to hide an element on...   \n","1652  17p0_pert_35  [How are the operations to squash and pop elem...   \n","1516   16p0_pert_0  [What is a stack and how to enqueue and organi...   \n","1431  15p0_pert_16  [What is a queue and how to define and pop its...   \n","44     1p0_pert_43                [How to bind elements in a stack ?]   \n","1059  11p0_pert_48  [What is a stack and how to insert an element ...   \n","219    3p0_pert_16                [How to move elements in a queue ?]   \n","236    3p0_pert_33              [How to divide elements in a queue ?]   \n","\n","                                              documento  classe  \n","1365  What is a queue and how to call an element on ...       0  \n","613                 How to draw elements from a queue ?       0  \n","1391  What is a queue and how to hide an element on ...       0  \n","1652  How are the operations to squash and pop eleme...       0  \n","1516  What is a stack and how to enqueue and organiz...       0  \n","1431  What is a queue and how to define and pop its ...       0  \n","44                    How to bind elements in a stack ?       0  \n","1059  What is a stack and how to insert an element i...       0  \n","219                   How to move elements in a queue ?       0  \n","236                 How to divide elements in a queue ?       0  "],"text/html":["\n","  <div id=\"df-b59af2ac-1e8f-4bcd-850d-be490a9e406f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1365</th>\n","      <td>14p0_pert_51</td>\n","      <td>[What is a queue and how to call an element on...</td>\n","      <td>What is a queue and how to call an element on ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>613</th>\n","      <td>7p0_pert_6</td>\n","      <td>[How to draw elements from a queue ?]</td>\n","      <td>How to draw elements from a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1391</th>\n","      <td>14p0_pert_77</td>\n","      <td>[What is a queue and how to hide an element on...</td>\n","      <td>What is a queue and how to hide an element on ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1652</th>\n","      <td>17p0_pert_35</td>\n","      <td>[How are the operations to squash and pop elem...</td>\n","      <td>How are the operations to squash and pop eleme...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>16p0_pert_0</td>\n","      <td>[What is a stack and how to enqueue and organi...</td>\n","      <td>What is a stack and how to enqueue and organiz...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1431</th>\n","      <td>15p0_pert_16</td>\n","      <td>[What is a queue and how to define and pop its...</td>\n","      <td>What is a queue and how to define and pop its ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>1p0_pert_43</td>\n","      <td>[How to bind elements in a stack ?]</td>\n","      <td>How to bind elements in a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1059</th>\n","      <td>11p0_pert_48</td>\n","      <td>[What is a stack and how to insert an element ...</td>\n","      <td>What is a stack and how to insert an element i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>219</th>\n","      <td>3p0_pert_16</td>\n","      <td>[How to move elements in a queue ?]</td>\n","      <td>How to move elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>236</th>\n","      <td>3p0_pert_33</td>\n","      <td>[How to divide elements in a queue ?]</td>\n","      <td>How to divide elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b59af2ac-1e8f-4bcd-850d-be490a9e406f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b59af2ac-1e8f-4bcd-850d-be490a9e406f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b59af2ac-1e8f-4bcd-850d-be490a9e406f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":304}]},{"cell_type":"code","source":["# Importa das bibliotecas\n","import pandas as pd\n","\n","# Concatena as listas de documentos originais e perturbados\n","lista_documentos_agrupados_pos = pd.concat([lista_documentos_originais_pos, lista_documentos_perturbados_pos])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO POS: {}.\".format(len(lista_documentos_agrupados_pos)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TJbwpcYtsN3","executionInfo":{"status":"ok","timestamp":1664424355147,"user_tz":180,"elapsed":70,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7c4521ad-7a14-4153-dd45-d9a3257216f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO AGRUPAMENTO POS: 2020.\n"]}]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_agrupados_pos = lista_documentos_agrupados_pos.astype(tipos)"],"metadata":{"id":"JvDXTxtRuvrX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lista_documentos_agrupados_pos.sample(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"dDW4pj8vuh2I","executionInfo":{"status":"ok","timestamp":1664424355150,"user_tz":180,"elapsed":64,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7b5a0f1d-5c2c-4bc1-9351-486aa5de3407"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                id                                      pos_documento\n","216    3p0_pert_16  [[[How, to, move, elements, in, a, queue, ?], ...\n","1967  20p0_pert_67  [[[In, a, queue, does, the, push, operation, t...\n","524    6p0_pert_24  [[[How, to, mix, and, pop, elements, in, a, qu...\n","1360  14p0_pert_60  [[[What, is, a, queue, and, how, to, maintain,...\n","347    4p0_pert_47  [[[How, to, band, and, pop, elements, in, a, q..."],"text/html":["\n","  <div id=\"df-bbf353a6-f029-4d05-b635-8f2b6f051c59\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>216</th>\n","      <td>3p0_pert_16</td>\n","      <td>[[[How, to, move, elements, in, a, queue, ?], ...</td>\n","    </tr>\n","    <tr>\n","      <th>1967</th>\n","      <td>20p0_pert_67</td>\n","      <td>[[[In, a, queue, does, the, push, operation, t...</td>\n","    </tr>\n","    <tr>\n","      <th>524</th>\n","      <td>6p0_pert_24</td>\n","      <td>[[[How, to, mix, and, pop, elements, in, a, qu...</td>\n","    </tr>\n","    <tr>\n","      <th>1360</th>\n","      <td>14p0_pert_60</td>\n","      <td>[[[What, is, a, queue, and, how, to, maintain,...</td>\n","    </tr>\n","    <tr>\n","      <th>347</th>\n","      <td>4p0_pert_47</td>\n","      <td>[[[How, to, band, and, pop, elements, in, a, q...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbf353a6-f029-4d05-b635-8f2b6f051c59')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bbf353a6-f029-4d05-b635-8f2b6f051c59 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bbf353a6-f029-4d05-b635-8f2b6f051c59');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":307}]},{"cell_type":"markdown","source":["#### Criar dados indexados"],"metadata":{"id":"viicg1E7mXLK"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_indexado = lista_documentos_agrupados.set_index([\"id\"])\n","lista_documentos_agrupados_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"0YBdkvoPm2vO","executionInfo":{"status":"ok","timestamp":1664424355151,"user_tz":180,"elapsed":62,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"515417b5-7a50-4e05-e4e9-1ec3d196b005"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          sentencas  \\\n","id                                                    \n","1p0           [How to dequeue elements in a stack?]   \n","1p0_pert_0   [How to arrange elements in a stack ?]   \n","1p0_pert_1  [How to organize elements in a stack ?]   \n","1p0_pert_2     [How to store elements in a stack ?]   \n","1p0_pert_3       [How to put elements in a stack ?]   \n","\n","                                        documento  classe  \n","id                                                         \n","1p0           How to dequeue elements in a stack?       1  \n","1p0_pert_0   How to arrange elements in a stack ?       0  \n","1p0_pert_1  How to organize elements in a stack ?       0  \n","1p0_pert_2     How to store elements in a stack ?       0  \n","1p0_pert_3       How to put elements in a stack ?       0  "],"text/html":["\n","  <div id=\"df-04e8f14a-3445-4d87-ab03-9461c5c017bc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0</th>\n","      <td>[How to dequeue elements in a stack?]</td>\n","      <td>How to dequeue elements in a stack?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_0</th>\n","      <td>[How to arrange elements in a stack ?]</td>\n","      <td>How to arrange elements in a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_1</th>\n","      <td>[How to organize elements in a stack ?]</td>\n","      <td>How to organize elements in a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_2</th>\n","      <td>[How to store elements in a stack ?]</td>\n","      <td>How to store elements in a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_3</th>\n","      <td>[How to put elements in a stack ?]</td>\n","      <td>How to put elements in a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04e8f14a-3445-4d87-ab03-9461c5c017bc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-04e8f14a-3445-4d87-ab03-9461c5c017bc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-04e8f14a-3445-4d87-ab03-9461c5c017bc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":308}]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_pos_indexado = lista_documentos_agrupados_pos.set_index([\"id\"])\n","lista_documentos_agrupados_pos_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"NQjlOJzOmbsp","executionInfo":{"status":"ok","timestamp":1664424355151,"user_tz":180,"elapsed":60,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"05100498-3a41-4867-fc97-5673fd877c35"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         pos_documento\n","id                                                    \n","1p0  [[[How, to, dequeue, elements, in, a, stack, ?...\n","2p0  [[[How, to, dequeue, elements, in, a, stack, ?...\n","3p0  [[[How, to, push, elements, in, a, queue, ?], ...\n","4p0  [[[How, to, push, and, pop, elements, in, a, q...\n","5p0  [[[How, to, push, elements, in, a, queue, data..."],"text/html":["\n","  <div id=\"df-b4148974-1529-41be-b42d-8937c6f92261\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0</th>\n","      <td>[[[How, to, dequeue, elements, in, a, stack, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>2p0</th>\n","      <td>[[[How, to, dequeue, elements, in, a, stack, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>3p0</th>\n","      <td>[[[How, to, push, elements, in, a, queue, ?], ...</td>\n","    </tr>\n","    <tr>\n","      <th>4p0</th>\n","      <td>[[[How, to, push, and, pop, elements, in, a, q...</td>\n","    </tr>\n","    <tr>\n","      <th>5p0</th>\n","      <td>[[[How, to, push, elements, in, a, queue, data...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4148974-1529-41be-b42d-8937c6f92261')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b4148974-1529-41be-b42d-8937c6f92261 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b4148974-1529-41be-b42d-8937c6f92261');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":309}]},{"cell_type":"markdown","metadata":{"id":"d1yGaGzzyEiy"},"source":["## 5.2 Gerando as comparações\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xKaqQPs8VQ5u"},"source":["### 5.2.1 Medidas de similaridade\n"]},{"cell_type":"markdown","metadata":{"id":"jt06PTN5idrg"},"source":["Similaridade do cosseno entre os embeddings.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n","\n","A função spatial.distance.cosine do módulo scipy calcula a distância em vez da similaridade do cosseno, mas para conseguir isso, podemos subtrair o valor da distância de 1.\n","\n","Intervalo de [-1,1]\n","\n","Vetores iguais a distância é igual 1.\n","\n","Vetores diferentes medida próxima de -1."]},{"cell_type":"code","metadata":{"id":"6vbXj-brOlMF"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cosine\n","\n","def similaridadeCosseno(embeddings1, embeddings2):\n","    \"\"\"\n","      Similaridade do cosseno dos embeddings dos textos.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    similaridade = 1 - cosine(embeddings1, embeddings2)\n","\n","    return similaridade"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fazAuLMUr_c0"},"source":["### 5.2.2 Medidas de distância"]},{"cell_type":"markdown","metadata":{"id":"_IcrjAbhwake"},"source":["Distância euclidiana entre os embeddings.\n","\n","Possui outros nomes como distância L2 ou norma L2.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean"]},{"cell_type":"code","metadata":{"id":"mIrTId9jwakh"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import euclidean\n","\n","def distanciaEuclidiana(embeddings1, embeddings2):\n","    \"\"\"\n","      Distância euclidiana entre os embeddings dos textos.\n","      Possui outros nomes como distância L2 ou norma L2.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    distancia = euclidean(embeddings1, embeddings2)\n","\n","    return distancia"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-uJlqYCSXdVk"},"source":["Distância Manhattan entre os embeddings.\n","\n","Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cityblock.html#scipy.spatial.distance.cityblock"]},{"cell_type":"code","metadata":{"id":"jFG5UT_SXdVn"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cityblock\n","\n","def distanciaManhattan(embeddings1, embeddings2):\n","    \"\"\"\n","      Distância Manhattan entre os embeddings dos textos\n","      Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    distancia = cityblock(embeddings1, embeddings2)\n","\n","    return distancia"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6A6-Xwg8GJw"},"source":["### 5.2.3 Retorna todas as medidas dos embeddings"]},{"cell_type":"code","metadata":{"id":"qHzQ98zg8GWJ"},"source":["def getMedidasEmbedding(embedding_wi, embedding_wj):\n","\n","  \"\"\"\n","    Retorna as medidas de similaridade do cosseno(cos), distância Euclidiana(euc) e\n","    distância de Manhattan(man) entre os embeddings.\n","\n","    Parâmetros:\n","    `embeddings_wi` - Um embedding de uma palavra a ser medido.\n","    `embeddings_wj` - Um embedding de uma palavra a ser medido.\n","  \"\"\"\n","\n","  #print(\"embedding_wi=\", embedding_wi.shape)\n","  #print(\"embedding_wj=\", embedding_wj.shape)\n","\n","  # Similaridade do cosseno entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  cos = similaridadeCosseno(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  # Distância euclidiana entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  euc = distanciaEuclidiana(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  # Distância de manhattan entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  man = distanciaManhattan(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  del embedding_wi\n","  del embedding_wj\n","\n","  # Retorno das medidas das sentenças\n","  return cos, euc, man"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KEtmDaKqAL-9"},"source":["### 5.2.4 getTokensEmbeddingsPOSSentenca\n","Gera os tokens, POS e embeddings de cada sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXPWq5JyIoQf"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar mais tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera mais tokens que a tokenização das palavras do spaCy\n","dic_excecao_maior = {\"\":-1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89oBywgbIxzV"},"outputs":[],"source":["def getExcecaoDicMaior(id, token, dic_excecao_maior):\n","\n","  valor = dic_excecao_maior.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPODj-AWfhxW"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar menos tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera menos tokens que a tokenização das palavras do spaCy\n","dic_excecao_menor = {\"1°\":1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xy2bzLBWfeqi"},"outputs":[],"source":["def getExcecaoDicMenor(id, token, dic_excecao_menor):\n","\n","  valor = dic_excecao_menor.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"markdown","source":["Função que retorna os embeddings, tokens e POS da sentença com um mesmo tamamnho."],"metadata":{"id":"LLRdNsbo0qxA"}},{"cell_type":"code","metadata":{"id":"OykQrpVsILpM"},"source":["# Importa a biblioteca\n","import torch\n","\n","def getTokensEmbeddingsPOSSentenca(id_documento,\n","                                   index_sentenca,\n","                                   embedding_documento,\n","                                   token_BERT_documento,\n","                                   sentenca,\n","                                   tokenizer,\n","                                   sentenca_token = None,\n","                                   sentenca_postagging = None,\n","                                   estrategia_medida = 0):\n","    \"\"\"\n","      Retorna os tokens, as POS-Tagging e os embeddings dos tokens igualando a quantidade de tokens do spaCy com a tokenização do BERT de acordo com a estratégia de pooling para palavras fora do vocabulário do BERT.\n","      Usa a estratégia MEAN para calcular a média dos embeddings dos tokens que formam uma palavra fora do vocabulário do BERT.\n","      Usa a estratégia MAX para calcular o valor máximo dos embeddings dos tokens que formam uma palavra fora do vocabulário do BERT.\n","    \"\"\"\n","\n","    #Guarda os tokens e embeddings\n","    lista_tokens = []\n","    lista_embeddings_mean = []\n","    lista_embeddings_max = []\n","\n","    # Se a sentença não for tokenizada\n","    if sentenca_token == None:\n","      # Gera a tokenização e POS-Tagging da sentença\n","      sentenca_token, sentenca_postagging = getListaTokensPOSSentenca(sentenca)\n","\n","    #print(\"\\nsentenca                :\",sentenca)\n","    #print(\"id_documento                :\",id_documento)\n","    #print(\"index_sentenca              :\",index_sentenca)\n","    #print(\"sentenca_token              :\",sentenca_token)\n","    #print(\"len(sentenca_token)         :\",len(sentenca_token))\n","    #print(\"sentenca_postagging         :\",sentenca_postagging)\n","    #print(\"len(sentenca_postagging)    :\",len(sentenca_postagging))\n","\n","    # Recupera os embeddings da sentença dos embeddings dentro dos embeddings do documento\n","    embedding_sentenca, sentenca_tokenizada_BERT = getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                                                                       token_BERT_documento,\n","                                                                                                       sentenca,\n","                                                                                                       tokenizer)\n","\n","    # embedding <qtde_tokens x 4096>\n","    #print(\"embedding_sentenca          :\",embedding_sentenca.shape)\n","    #print(\"sentenca_tokenizada_BERT     :\",sentenca_tokenizada_BERT)\n","    #print(\"len(sentenca_tokenizada_BERT):\",len(sentenca_tokenizada_BERT))\n","\n","    # Seleciona os pares de palavra a serem avaliadas\n","    pos_wi = 0 # Posição do token da palavra gerado pelo spaCy\n","    pos_wj = pos_wi # Posição do token da palavra gerado pelo BERT\n","    pos2 = -1\n","\n","    # Enquanto o indíce da palavra pos_wj(2a palavra) não chegou ao final da quantidade de tokens do BERT\n","    while pos_wj < len(sentenca_tokenizada_BERT):\n","\n","      # Seleciona os tokens da sentença\n","      wi = sentenca_token[pos_wi] # Recupera o token da palavra gerado pelo spaCy\n","      wi1 = \"\"\n","      pos2 = -1\n","      if pos_wi+1 < len(sentenca_token):\n","        wi1 = sentenca_token[pos_wi+1] # Recupera o próximo token da palavra gerado pelo spaCy\n","\n","        # Localiza o deslocamento da exceção\n","        pos2 = getExcecaoDicMenor(id_documento, wi+wi1, dic_excecao_menor)\n","        #print(\"Exceção pos2:\", pos2)\n","\n","      wj = sentenca_tokenizada_BERT[pos_wj] # Recupera o token da palavra gerado pelo BERT\n","      #print(\"wi[\",pos_wi,\"]=\", wi)\n","      #print(\"wj[\",pos_wj,\"]=\", wj)\n","\n","      # Tratando exceções\n","      # Localiza o deslocamento da exceção\n","      pos = getExcecaoDicMaior(id_documento, wi, dic_excecao_maior)\n","      #print(\"Exceção pos:\", pos)\n","\n","      if pos != -1 or pos2 != -1:\n","        if pos != -1:\n","          #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","          lista_tokens.append(wi)\n","          # Verifica se tem mais de um token\n","          if pos != 1:\n","            indice_token = pos_wj + pos\n","            #print(\"Calcula a média de :\", pos_wj , \"até\", indice_token)\n","            embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","            #print(\"embeddings_tokens_palavra:\",embeddings_tokens_palavra.shape)\n","            # calcular a média dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_mean = torch.mean(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_mean:\",embedding_estrategia_mean.shape)\n","            lista_embeddings_mean.append(embedding_estrategia_mean)\n","\n","            # calcular o máximo dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_max, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_max:\",embedding_estrategia_max.shape)\n","            lista_embeddings_max.append(embedding_estrategia_max)\n","          else:\n","            # Adiciona o embedding do token a lista de embeddings\n","            lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","            lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + pos\n","          #print(\"Proxima:\")\n","          #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","          #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","        else:\n","          if pos2 != -1:\n","            #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","            lista_tokens.append(wi+wi1)\n","            # Verifica se tem mais de um token\n","            if pos2 == 1:\n","              # Adiciona o embedding do token a lista de embeddings\n","              lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","              lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","\n","            # Avança para a próxima palavra e token do BERT\n","            pos_wi = pos_wi + 2\n","            pos_wj = pos_wj + pos2\n","            #print(\"Proxima:\")\n","            #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","            #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","      else:\n","        # Tokens iguais adiciona a lista, o token não possui subtoken\n","        if (wi == wj or wj==\"[UNK]\"):\n","          # Adiciona o token a lista de tokens\n","          #print(\"Adiciona 2 wi==wj or wj==[UNK]:\", wi )\n","          lista_tokens.append(wi)\n","          # Adiciona o embedding do token a lista de embeddings\n","          lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","          lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","          #print(\"embedding1[pos_wj]:\", embedding_sentenca[pos_wj].shape)\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + 1\n","\n","        else:\n","          # A palavra foi tokenizada pelo Wordpice com ## ou diferente do spaCy ou desconhecida\n","          # Inicializa a palavra a ser montada\n","          palavra_postagging = wj\n","          indice_token = pos_wj + 1\n","          while  ((palavra_postagging != wi) and indice_token < len(sentenca_tokenizada_BERT)):\n","              if \"##\" in sentenca_tokenizada_BERT[indice_token]:\n","                # Remove os caracteres \"##\" do token\n","                parte = sentenca_tokenizada_BERT[indice_token][2:]\n","              else:\n","                parte = sentenca_tokenizada_BERT[indice_token]\n","\n","              palavra_postagging = palavra_postagging + parte\n","              #print(\"palavra_postagging:\",palavra_postagging)\n","              # Avança para o próximo token do BERT\n","              indice_token = indice_token + 1\n","\n","          #print(\"\\nMontei palavra:\",palavra_postagging)\n","          if (palavra_postagging == wi or palavra_postagging == \"[UNK]\"):\n","              # Adiciona o token a lista\n","              #print(\"Adiciona 3 palavra == wi or palavra_postagging = [UNK]:\",wi)\n","              lista_tokens.append(wi)\n","              # Calcula a média dos tokens da palavra\n","              #print(\"Calcula o máximo :\", pos_wj , \"até\", indice_token)\n","              embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra)\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra.shape)\n","\n","              # calcular a média dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_mean = torch.mean(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_mean:\",embedding_estrategia_mean)\n","              #print(\"embedding_estrategia_mean.shape:\",embedding_estrategia_mean.shape)\n","              lista_embeddings_mean.append(embedding_estrategia_mean)\n","\n","              # calcular o valor máximo dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_max, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_max:\",embedding_estrategia_max)\n","              #print(\"embedding_estrategia_max.shape:\",embedding_estrategia_max.shape)\n","              lista_embeddings_max.append(embedding_estrategia_max)\n","\n","          # Avança para o próximo token do spaCy\n","          pos_wi = pos_wi + 1\n","          # Pula para o próximo token do BERT\n","          pos_wj = indice_token\n","\n","    # Verificação se as listas estão com o mesmo tamanho\n","    #if (len(lista_tokens) != len(sentenca_token)) or (len(lista_embeddings_mean) != len(sentenca_token)):\n","    if (len(lista_tokens) !=  len(lista_embeddings_mean)):\n","       print(\"\\nsentenca                  :\",sentenca)\n","       print(\"id_documento              :\",id_documento)\n","       print(\"index_sentenca            :\",index_sentenca)\n","       print(\"sentenca_postagging       :\",sentenca_postagging)\n","       print(\"sentenca_token            :\",sentenca_token)\n","       print(\"sentenca_tokenizada_BERT  :\",sentenca_tokenizada_BERT)\n","       print(\"lista_tokens              :\",lista_tokens)\n","       print(\"len(lista_tokens)         :\",len(lista_tokens))\n","       print(\"lista_embeddings_mean     :\",lista_embeddings_mean)\n","       print(\"len(lista_embeddings_mean):\",len(lista_embeddings_mean))\n","       print(\"lista_embeddings_max      :\",lista_embeddings_max)\n","       print(\"len(lista_embeddings_max) :\",len(lista_embeddings_max))\n","\n","    del embedding_sentenca\n","    del token_BERT_documento\n","    del tokenizer\n","    del sentenca_tokenizada_BERT\n","    del sentenca_token\n","\n","    return lista_tokens, sentenca_postagging, lista_embeddings_mean, lista_embeddings_max"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kw0qQ6zoQhkq"},"source":["### 5.2.5 comparaPalavrasSentencaTodas"]},{"cell_type":"code","metadata":{"id":"Of3EOJwpQg-B"},"source":["def comparaPalavrasSentencaTodas(id_documento,\n","                                 index_documento,\n","                                 index_sentenca,\n","                                 embedding_documento,\n","                                 token_BERT_documento,\n","                                 sentenca,\n","                                 tokenizer,\n","                                 sentenca_token = None,\n","                                 sentenca_postagging = None):\n","\n","  lista_tokens, lista_postagging, lista_embeddings_mean, lista_embeddings_max = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                                  index_sentenca,\n","                                                                                                  embedding_documento,\n","                                                                                                  token_BERT_documento,\n","                                                                                                  sentenca,\n","                                                                                                  tokenizer,\n","                                                                                                  sentenca_token,\n","                                                                                                  sentenca_postagging)\n","  #print(\"\\nSentença   :\",lista_tokens)\n","  #print(\"POS Tagging:\",lista_postagging)\n","  #print(\"Quantidade de palavras:\",len(lista_tokens))\n","\n","  # Quantidade de palavras no documento\n","  n = len(lista_tokens)\n","\n","  # Guarda a comparação da sentença\n","  lista_comparacao = []\n","\n","  # Realiza o combinação das palavras C(n,p)=(n!/(p!(n-p)!))\n","  # n = Número de elementos e p as combinações\n","  # C(5,2) = 10\n","\n","  # Percorre as palavras da sentença\n","  for i in range(0,n-1):\n","\n","    # Seleciona a palavra i da sentença\n","    wi = lista_tokens[i]\n","    pos_i = lista_postagging[i]\n","    #print(\"i:\",i)\n","\n","    # Percorre as palavras da sentença a partir de i + 1\n","    # Para não comparar a palavra com ela mesma\n","    for j in range(i+1,n):\n","\n","        # Seleciona a palavra j da sentença\n","        wj = lista_tokens[j]\n","        pos_j = lista_postagging[j]\n","\n","        # Recupera as medidas dos embeddings das palavras usando as estratégias MEAN\n","        cos_mean, euc_mean, man_mean = getMedidasEmbedding(lista_embeddings_mean[i], lista_embeddings_mean[j])\n","        # Recupera as medidas dos embeddings das palavras usando as estratégias MAX\n","        cos_max, euc_max, man_max = getMedidasEmbedding(lista_embeddings_max[i], lista_embeddings_max[j])\n","\n","        # Agrupa as medidas\n","        comparacao = [id_documento,   #Id do documento\n","                      index_documento,#Índice do documento no conjunto de dados\n","                      index_sentenca, #[Indice da sentença no documento\n","                      i,              #Índice da palavra i na sentença\n","                      str(wi),        #Palavra i da sentença\n","                      pos_i,          #POS-Tagging da palavra i\n","                      j,              #Índice da palavra j na sentença\n","                      str(wj),        #Palavra j da sentença\n","                      pos_j,          #POS-Tagging da palavra j\n","                      cos_mean,       #Cos de wi e wj usando a média dos embeddings das subpalavras\n","                      euc_mean,       #Euc de wi e wj usando a média dos embeddings das subpalavras\n","                      man_mean,       #Man de wi e wj usando a média dos embeddings das subpalavras\n","                      cos_max,        #Cos de wi e wj usando o máximo dos embeddings das subpalavras\n","                      euc_max,        #Euc de wi e wj usando o máximo dos embeddings das subpalavras\n","                      man_max]        #Man de wi e wj usando o máximo dos embeddings das subpalavras\n","\n","        # Guardas as medidas da comparação na lista\n","        lista_comparacao.append(comparacao)\n","\n","        #print(comparacao)\n","        #print(\"Compara :\", i, \" com \", j)\n","        #print(\"Compara :\", wi, \" com \", wj)\n","        # print(\"     cos_mean:\", cos_mean)\n","        # print(\"     euc_mean:\", euc_mean)\n","        # print(\"     man_mean:\", man_mean)\n","        # print(\"     cos_max:\", cos_max)\n","        # print(\"     euc_max:\", euc_max)\n","        # print(\"     man_max:\", man_max)\n","\n","  del lista_tokens\n","  del lista_postagging\n","  del lista_embeddings_mean\n","  del lista_embeddings_max\n","\n","  return lista_comparacao"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXNhBApgbULb"},"source":["### 5.2.6 Realiza a comparação de todas as palavras"]},{"cell_type":"code","metadata":{"id":"CfGFsRaPDBMt","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["46fad172b3ad469abb0189a057ea053e","284548b212ba4406965e699479e269d4","08487e8029bd44cbbc1fa796db6c5342","396e3531144e4b58997e6033bc6d4e46","8051cd9b7464410f96dee741bf06f48f","0132d01ee69940c9a6c93ee8eb5478f8","a717bba8bef24638804fa967b03ec670","a281f106ac5e4ffd8011d88bd7f78a1c","3598429721f14f69aed01a34b5bf64a3","572689f32d2b4adab8b0b417845cb614","26e044e72e3a46c79d51ac308d725104"],"height":66},"executionInfo":{"status":"ok","timestamp":1664425097801,"user_tz":180,"elapsed":742697,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7312f0b6-b7ad-409a-affe-f3156612089e"},"source":["# Import das bibliotecas\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","logging.info(\"Processando {} documentos originais e perturbados.\".format(len(lista_documentos_agrupados)))\n","\n","# Guarda a comparacação das sentenças\n","resultado_comparacao = []\n","\n","# Conta sentenças comparadas e não comparadas\n","conta_sentenca = 0\n","\n","# Limpa o buffer antes de realizar a comparação\n","limpaBufferEmbedding()\n","\n","# Barra de progresso dos documentos\n","lista_documentos_bar = tqdm_notebook(lista_documentos_agrupados.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_agrupados))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_bar:\n","    # if i < 2:\n","    # print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    # print(\"id_documento:\",id_documento)\n","\n","    # Recupera as sentenças do documento\n","    lista_sentenca_documento = linha_documento[1]\n","    # print(\"lista_sentenca_documento:\",lista_sentenca_documento)\n","    # print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","\n","    # Recupera o documento\n","    documento = linha_documento[2]\n","    #print(\"documento:\",documento)\n","    # Recupera a classe documento (1-original 0-perturbado)\n","    #classe = linha_documento[3]\n","    #print(\"classe:\",classe)\n","\n","    # Localiza a POSTagging do documento agrupado\n","    lista_pos_documento = lista_documentos_agrupados_pos_indexado.loc[id_documento][0]\n","    # print(\"lista_pos_documento:\",lista_pos_documento)\n","    # print(\"len(lista_pos_documento):\",len(lista_pos_documento))\n","\n","    # Troca o documento por uma versão da concatenação das palavras geradas pelo spaCy\n","    # Percorre a lista_pos concatenando a posição 0 dos tokens\n","    documento_concatenado = \" \".join(concatenaListas(lista_pos_documento, pos=0))\n","    # print(\"documento_concatenado:\", documento_concatenado)\n","    documento = documento_concatenado\n","\n","    # Gera os embeddings do documento utiliza a concatenação das 4 últimas camadas\n","    # Somente para os documentos originais\n","    if \"_pert_\" not in id_documento:\n","      embedding_documento, token_BERT_documento = getEmbeddingsDocumentoBuffer(documento, model, tokenizer)\n","    else:\n","      embedding_documento, token_BERT_documento = getEmbeddingsDocumento(documento, model, tokenizer)\n","    # embedding <qtde_tokens x 4096>\n","    # print(\"embedding_documento:\",embedding_documento.shape)\n","    # print(\"token_BERT_documento:\",token_BERT_documento)\n","    # print(\"len(token_BERT_documento):\",len(token_BERT_documento))\n","\n","    # Percorre as sentenças do documento\n","    for j, sentenca in enumerate(lista_sentenca_documento):\n","      #print(\"id_documento:\",id_documento)\n","      #print(\"sentenca:\",sentenca)\n","\n","      sentenca_token = lista_pos_documento[j][0]\n","      sentenca_postagging = lista_pos_documento[j][1]\n","      #sentenca_verbos = lista_pos_documento[j][2]\n","\n","      #print(\"sentenca_token:\",sentenca_token)\n","      #print(\"len(sentenca_token):\",len(sentenca_token))\n","\n","      #print(\"sentenca_postagging:\",sentenca_postagging)\n","      #print(\"len(sentenca_postagging):\",len(sentenca_postagging))\n","\n","      #print(\"sentenca_verbos:\",sentenca_verbos)\n","      #print(\"len(sentenca_verbos):\",len(sentenca_verbos))\n","\n","      # Conta o número de sentenças com palavras comparadas\n","      conta_sentenca = conta_sentenca + 1\n","\n","      # Realiza uma contenação dos tokens da sentença\n","      sentenca_concatenada = \" \".join(sentenca_token)\n","      # print(\"sentenca_concatenada:\", sentenca_concatenada)\n","\n","      # Recupera as maiores e menores medidas entre as palavras\n","      lista_comparacao = comparaPalavrasSentencaTodas(id_documento,\n","                                                      i,\n","                                                      j,\n","                                                      embedding_documento,\n","                                                      token_BERT_documento,\n","                                                      sentenca_concatenada,\n","                                                      tokenizer,\n","                                                      sentenca_token,\n","                                                      sentenca_postagging)\n","      #print(len(lista_comparacao))\n","      #print(lista_comparacao)\n","\n","      # Guarda o resultado da comparação\n","      resultado_comparacao = resultado_comparacao + lista_comparacao"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Processando 2020 documentos originais e perturbados.\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/2020 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46fad172b3ad469abb0189a057ea053e"}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"ugwTe8C3ebjy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664425097802,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"faa650d0-cee3-488f-f452-fb1f43e6d02c"},"source":["logging.info(\"Número de sentenças com palavras comparadas: {}.\".format(conta_sentenca))\n","logging.info(\"Número de comparações                      : {}.\".format(len(resultado_comparacao)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Número de sentenças com palavras comparadas: 2020.\n","INFO:root:Número de comparações                      : 121705.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rMg19DZzYjHB"},"source":["## 5.3 Gera arquivo das comparações"]},{"cell_type":"markdown","metadata":{"id":"waF8KYDlYEH2"},"source":["### 5.3.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","metadata":{"id":"kahGlJdWdP8f"},"source":["# Nome do arquivo\n","NOME_ARQUIVO_COMPARACAO_PALAVRA = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"midCJ2AYes2x"},"source":["### 5.3.2 Gera arquivo comparação"]},{"cell_type":"code","metadata":{"id":"vdHTuPLDYjHB"},"source":["# Cria o dataframe da lista\n","resultado_comparacao = pd.DataFrame(resultado_comparacao, columns = [\"id\",\n","                                                                       \"index_documento\",\n","                                                                       \"index_sentenca\",\n","                                                                       \"index_wi\",\n","                                                                       \"wi\",\n","                                                                       \"pos_i\",\n","                                                                       \"index_wj\",\n","                                                                       \"wj\",\n","                                                                       \"pos_j\",\n","                                                                       \"cos_mean\",\n","                                                                       \"euc_mean\",\n","                                                                       \"man_mean\",\n","                                                                       \"cos_max\",\n","                                                                       \"euc_max\",\n","                                                                       \"man_max\"])\n","\n","# Nome do arquivo original\n","nome_arquivo = DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_PALAVRA\n","\n","# Salva o arquivo original\n","resultado_comparacao.to_csv(nome_arquivo,  sep=\";\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9JSH-_lYjHB"},"source":["### 5.3.3 Carrega os dados\n","\n","Carrega os dados das sentencas a partir dos arquivos.\n"]},{"cell_type":"code","metadata":{"id":"9ob-mUkjYjHC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664425101705,"user_tz":180,"elapsed":639,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"dc01baa9-fb93-4278-e462-7cd7f582b7e8"},"source":["# Importa das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_comparacao_palavra = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_PALAVRA, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"Quantidade de comparações: {}.\".format(len(lista_comparacao_palavra)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Quantidade de comparações: 121705.\n"]}]},{"cell_type":"code","metadata":{"id":"vNCI53tPYjHC","colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"status":"ok","timestamp":1664425101705,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"a3b632c0-baaf-402c-db5d-308288a43a8c"},"source":["lista_comparacao_palavra.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  id  index_documento  index_sentenca  index_wi   wi pos_i  \\\n","59096    13p0_pert_6             1219               0         8   an   DET   \n","23490    6p0_pert_88              594               0         4  pop  VERB   \n","115251   20p0_pert_2             1922               0         1    a   DET   \n","106788  18p0_pert_82             1800               0         4   to  PART   \n","7679     3p0_pert_71              274               0         1   to  PART   \n","\n","        index_wj            wj  pos_j  cos_mean   euc_mean   man_mean  \\\n","59096         12             ?  PUNCT  0.510159  44.803951  2256.9893   \n","23490          9          data   NOUN  0.514392  43.493401  2199.9707   \n","115251         5          push   NOUN  0.528880  43.049652  2142.1968   \n","106788        12  standardized   VERB  0.507371  44.876427  2255.3186   \n","7679           2     integrate   VERB  0.692403  34.013920  1725.4788   \n","\n","         cos_max    euc_max    man_max  \n","59096   0.510159  44.803951  2256.9893  \n","23490   0.514392  43.493401  2199.9707  \n","115251  0.528880  43.049652  2142.1968  \n","106788  0.507371  44.876427  2255.3186  \n","7679    0.692403  34.013920  1725.4788  "],"text/html":["\n","  <div id=\"df-02bc73d4-e775-445d-aa35-636032328343\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>index_documento</th>\n","      <th>index_sentenca</th>\n","      <th>index_wi</th>\n","      <th>wi</th>\n","      <th>pos_i</th>\n","      <th>index_wj</th>\n","      <th>wj</th>\n","      <th>pos_j</th>\n","      <th>cos_mean</th>\n","      <th>euc_mean</th>\n","      <th>man_mean</th>\n","      <th>cos_max</th>\n","      <th>euc_max</th>\n","      <th>man_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>59096</th>\n","      <td>13p0_pert_6</td>\n","      <td>1219</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>an</td>\n","      <td>DET</td>\n","      <td>12</td>\n","      <td>?</td>\n","      <td>PUNCT</td>\n","      <td>0.510159</td>\n","      <td>44.803951</td>\n","      <td>2256.9893</td>\n","      <td>0.510159</td>\n","      <td>44.803951</td>\n","      <td>2256.9893</td>\n","    </tr>\n","    <tr>\n","      <th>23490</th>\n","      <td>6p0_pert_88</td>\n","      <td>594</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>pop</td>\n","      <td>VERB</td>\n","      <td>9</td>\n","      <td>data</td>\n","      <td>NOUN</td>\n","      <td>0.514392</td>\n","      <td>43.493401</td>\n","      <td>2199.9707</td>\n","      <td>0.514392</td>\n","      <td>43.493401</td>\n","      <td>2199.9707</td>\n","    </tr>\n","    <tr>\n","      <th>115251</th>\n","      <td>20p0_pert_2</td>\n","      <td>1922</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>DET</td>\n","      <td>5</td>\n","      <td>push</td>\n","      <td>NOUN</td>\n","      <td>0.528880</td>\n","      <td>43.049652</td>\n","      <td>2142.1968</td>\n","      <td>0.528880</td>\n","      <td>43.049652</td>\n","      <td>2142.1968</td>\n","    </tr>\n","    <tr>\n","      <th>106788</th>\n","      <td>18p0_pert_82</td>\n","      <td>1800</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>to</td>\n","      <td>PART</td>\n","      <td>12</td>\n","      <td>standardized</td>\n","      <td>VERB</td>\n","      <td>0.507371</td>\n","      <td>44.876427</td>\n","      <td>2255.3186</td>\n","      <td>0.507371</td>\n","      <td>44.876427</td>\n","      <td>2255.3186</td>\n","    </tr>\n","    <tr>\n","      <th>7679</th>\n","      <td>3p0_pert_71</td>\n","      <td>274</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>to</td>\n","      <td>PART</td>\n","      <td>2</td>\n","      <td>integrate</td>\n","      <td>VERB</td>\n","      <td>0.692403</td>\n","      <td>34.013920</td>\n","      <td>1725.4788</td>\n","      <td>0.692403</td>\n","      <td>34.013920</td>\n","      <td>1725.4788</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02bc73d4-e775-445d-aa35-636032328343')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-02bc73d4-e775-445d-aa35-636032328343 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-02bc73d4-e775-445d-aa35-636032328343');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":325}]},{"cell_type":"markdown","metadata":{"id":"DFMUo8Oo2CJp"},"source":["### 5.4.4 Compacta e copia o arquivo para uma pasta do GoogleDrive\n","\n","Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"7eb_zukpuHq3"},"source":["Compacta o arquivo.\n","\n","Usa o zip para compactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens"]},{"cell_type":"code","metadata":{"id":"NunMOJWR2O8H"},"source":["!zip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"49_9c2P2nrOx"},"source":["Copia o arquivo  para o GoogleDrive"]},{"cell_type":"code","metadata":{"id":"LqDBH5pUnrOx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664425103155,"user_tz":180,"elapsed":26,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ece91a46-428a-41ac-d411-ca06e9f5fc7d"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","    # Copia o arquivo das comparações para o google drive\n","    !cp \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" \"$DIRETORIO_DRIVE\"\n","\n","    logging.info(\"Terminei a cópia do arquivo.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia do arquivo.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Bcjt085lZGUr"},"source":["## 6.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","metadata":{"id":"H50_GKJwpDha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664425103156,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"efb8cf87-c11a-485b-f6dd-f198534611a4"},"source":["# Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempo_total_processamento))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento:  0:24:23 (h:mm:ss)\n"]}]}]}