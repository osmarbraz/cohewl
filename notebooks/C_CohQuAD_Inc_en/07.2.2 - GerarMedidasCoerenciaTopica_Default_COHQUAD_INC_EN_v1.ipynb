{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["GuO7V9YuhRtT","SG_X_FwShRtU","kw0qQ6zoQhkq","PDHaHnU-5yXx","TXNhBApgbULb","-Tdv2JGeohRH","LBs_KgMz1UW1","3oghc7L7ohRH","VNquK8k3ohRE"],"toc_visible":true,"authorship_tag":"ABX9TyM5vrYNCMhx92RPfSFNrZ4n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7b1b78992a3d445bb502e4c527df8e30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eff1dbf113584376b71591480fb1838a","IPY_MODEL_1894a9e490eb4ace9df0085e8e8dae17","IPY_MODEL_9d5507e57fea4112b77068b4227195b4"],"layout":"IPY_MODEL_88ff50637a894c4d89fb9fb49cc34f57"}},"eff1dbf113584376b71591480fb1838a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f738a3e83b7940bc8e293c10ccaa2042","placeholder":"​","style":"IPY_MODEL_6a7074428c8c4bec8477660ea83910d1","value":"Documentos: 100%"}},"1894a9e490eb4ace9df0085e8e8dae17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8249e4a20cb4205be145e6f7222a643","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_031dd09fd588414fa4974e9d4f7332f3","value":20}},"9d5507e57fea4112b77068b4227195b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a85e96b3245846e38483ce055f25c5da","placeholder":"​","style":"IPY_MODEL_5729ecae62b7447daa390b85bbabfafa","value":" 20/20 [00:00&lt;00:00, 290.18 documento/s]"}},"88ff50637a894c4d89fb9fb49cc34f57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f738a3e83b7940bc8e293c10ccaa2042":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a7074428c8c4bec8477660ea83910d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8249e4a20cb4205be145e6f7222a643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"031dd09fd588414fa4974e9d4f7332f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a85e96b3245846e38483ce055f25c5da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5729ecae62b7447daa390b85bbabfafa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"78HE8FLsKN9Q"},"source":["# Geração de Medidas Coerência Tópica do conjunto de dados CohQuAD In en usando BERT tópicos\n","\n","Este notebook, realiza testes de medidas de (in)coerência entre pares de documentos do conjunto de dados utilizando tópico.\n","\n","A medida de um documento(D) é realizada pela coerência tópica do documento. Todo o documento é submetido e as medidas recuperadas. Cada documento é analisado pelas medidas **Cc_uci**, **Cc_npmi**, **Cc_v** e **Cu_mass**. Estas medidas de coerência utilizando a coerência tópica utilizando as palavras dos documentos.\n","\n","As seguintes medidas foram calculadas entre os embeddings das sentenças **Si** e **Sj**:\n","\n","A medida **c_uci** é baseada em uma janela deslizante e nas informações mútuas pontuais (PMI) de todos os pares de palavras das principais palavras fornecidas\n","\n","**c_npmi** é uma versão aprimorada da coerência C_uci usando a informação mútua pontual normalizada (NPMI)\n","\n","**c_v** é baseada em uma janela deslizante, segmentação de um conjunto das principais palavras e uma medida de confirmação indireta que usa informações mútuas pontuais normalizadas (NPMI) e a semelhança de cosseno\n","\n","**c_umass** é baseado em contagens de coocorrência de documentos, uma segmentação de um precedente e uma probabilidade condicional logarítmica como medida de confirmação\n","\n","\n","Utiliza os arquivos para gerar as medidas:\n","- `original.zip`\n","- `originalpos.zip`\n","- `perturbado_pX_kY.zip`\n","- `perturbadopos_pX_kY.zip`\n","- `corpus_especifico.zip`\n","\n","Nos nomes dos arquivos, `X` é o número de documentos perturbados e `Y` o valor de top `K` predições.\n","\n","\n","----------------------------\n","\n","**Link biblioteca Transformers:**\n","https://github.com/huggingface/transformers\n","\n","\n","**Artigo original BERT:**\n","https://arxiv.org/pdf/1506.06724.pdf"]},{"cell_type":"markdown","metadata":{"id":"xyxb5Px3p1-e"},"source":["# 1 Preparação do ambiente\n","Preparação do ambiente para execução do exemplo."]},{"cell_type":"markdown","metadata":{"id":"cW_5CN8En7zl"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcTEKloUn-VK"},"outputs":[],"source":["# Import das bibliotecas\n","import time\n","import datetime\n","\n","#marca o tempo de início do processamento.\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj5TaAH_5-nB"},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================\n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.\n","    \"\"\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):\n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","\n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B1mvfAU5jZf"},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","\n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.\n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","\n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download\n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]\n","\n","    # Define o nome e caminho do arquivo temporário\n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","\n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","\n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:\n","        tamanho_conteudo = data.headers.get(\"Content-Length\")\n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)\n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):\n","            if chunk:\n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","\n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","\n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qwKjGvyLG4v"},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","\n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jirIzIstLea0"},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC9Xppq-_R0w"},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    sentencas = []\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkVk5LQT_G3f"},"outputs":[],"source":["def salvar(nome_arquivo,texto):\n","    \"\"\"\n","      Salva um texto em arquivo.\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.\n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Guy6B4whsZFR"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","\n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))"]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModeloArgumentosMedida) de definição dos parâmetros do modelo para medida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgmN6RqDRDZS"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={'help': 'max seq len'},\n","    )\n","    pretrained_model_name_or_path: str = field(\n","        default='neuralmind/bert-base-portuguese-cased',\n","        metadata={'help': 'nome do modelo pré-treinado do BERT.'},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={'help': 'define se o texto do modelo deve ser todo em minúsculo.'},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita se o modelo retorna os pesos de atenção.'},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita gerar as camadas ocultas do modelo.'},\n","    )\n","    use_wandb : bool = field(\n","        default=True,\n","        metadata={'help': 'habilita o uso do wandb.'},\n","    )\n","    salvar_avaliacao : bool = field(\n","        default=True,\n","        metadata={'help': 'habilita o salvamento do resultado da avaliação.'},\n","    )\n","    salvar_medicao : bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o salvamento da medicao.'},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o carragamento de mcl ajustado.'},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )\n","    estrategia_medida: int = field(\n","        default=0, # 0 - MEAN estratégia média / 1 - MAX  estratégia maior\n","        metadata={'help': 'Estratégia de cálculo da médida dos embeddings.'},\n","    )\n","    equacao_medida: int = field(\n","        default=0, # 0 - ADJACENTE / 1 - COMBINAÇÃO TODAS / 2 - CONTEXTO\n","        metadata={'help': 'Equação de cálculo da coerência.'},\n","    )\n","    filtro_palavra: int = field(\n","        default=0, # 0 - Considera todas as palavras das sentenças / 1 - Desconsidera as stopwords / 2 - Considera somente as palavras substantivas\n","        metadata={'help': 'Define o filtro de palavras das sentenças para gerar os embeddings.'},\n","    )"]},{"cell_type":"markdown","metadata":{"id":"HIN413rj50EI"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxV4-3Yg50EI"},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcopxbGZqDip"},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4  Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMiH0E3OnRa1"},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3831,"status":"ok","timestamp":1668446999882,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"vtaYZmc3Vbfj","outputId":"90368853-bee1-40c2-a7d0-671f8c962f6f"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Dispositivo GPU não encontrado\n"]}],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrjqDO6nWa8J"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","\n","def getDeviceGPU():\n","    \"\"\"\n","      Retorna um dispositivo de GPU se disponível ou CPU.\n","\n","      Retorno:\n","        `device` - Um device de GPU ou CPU.\n","    \"\"\"\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","\n","        # Diz ao PyTorch para usar GPU.\n","        device = torch.device(\"cuda\")\n","\n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:\n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","\n","    return device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1668447001122,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ChDxmtXsKwjf","outputId":"4cda1682-5acb-47d4-8ca9-9239845228d6"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Sem GPU disponível, usando CPU.\n"]}],"source":["# Recupera o device com GPU ou CPU\n","device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"fGf59D0yVNx9"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1668447001122,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"1iC5-pSAVh7_","outputId":"c3f01b93-cd28-4f3e-e93c-5a65b2713c7c"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}],"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2738,"status":"ok","timestamp":1668447003855,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ysnDDapMQK8K","outputId":"218c5b54-6435-4425-ff30-79f831d2654e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9363,"status":"ok","timestamp":1668447013214,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ejzpgGrFM0-j","outputId":"0c338452-1d80-4e22-e4dc-be73e46449fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.5)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (65.5.1)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.29)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.19.6)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.11)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"oOd2MbBiDq93"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6670,"status":"ok","timestamp":1668447019879,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"EaMM4WdxgvQ7","outputId":"0426f587-3680-4fe6-c0b0-c403148a0e63"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.3.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (65.5.1)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.38.4)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4912,"status":"ok","timestamp":1668447024787,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"w4p3Rz2qDq94","outputId":"9994eeef-854b-4df8-9290-bfce6055b019"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy==3.2.0 in /usr/local/lib/python3.7/dist-packages (3.2.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.10)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.5)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (8.0.17)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.8)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.8.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.9)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.5.1)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.10.0.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"markdown","metadata":{"id":"ZxFiqbpPQ-CR"},"source":["## 1.9 Instalação do Gensim"]},{"cell_type":"markdown","metadata":{"id":"HdjN6H6t_L08"},"source":["Instalando o gensim no Google Colaboratory.\n","\n","No Jupiter Notebook executar através \"Anaconda Prompt\".\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5205,"status":"ok","timestamp":1668447029987,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"BGFVnIzQGrEH","outputId":"705773d9-195c-4b97-fc1e-70fdf0643212"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim==4.2.0 in /usr/local/lib/python3.7/dist-packages (4.2.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.7.3)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.21.6)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (5.2.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#!pip install -U gensim\n","!pip install -U gensim==4.2.0"]},{"cell_type":"markdown","metadata":{"id":"giOsAS5v61go"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uiH9pNpwI6g"},"outputs":[],"source":["# Nome base das saidas do projeto\n","NOME_BASE_SAIDA = \"MedidaTopico_DefaultCohQuADInen_v1\"\n","\n","# Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 1\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 1\n","\n","# Filtro de palavras das sentenças[0,1,2,3,4,5] 'TAP,SSW,SVS'\n","FILTRO_PALAVRAS_STR = [\"TODAS_AS_PALAVRAS\",\n","                       \"SEM_STOPWORDS\",\n","                       \"SOMENTE_VERBOS_SUBSTANTIVOS\",\n","                       \"SEM_PONTUACAO_ALL\",\n","                       \"SEM_PONTUACAO_SEM_STOPWORDS\",\n","                       \"SEM_PONTUACAO_SOMENTE_VERBOS_SUBSTANTIVOS\",\n","                       ]\n","\n","# FILTRO_PALAVRAS_STR_ABREV = [\"TAP\",\"SSW\",\"SVS\",\"SP_TAP\",\"SP_SSW\",\"SP_SVS\"]\n","# FILTRO_PALAVRAS = [0, 1, 2, 3, 4, 5]\n","\n","FILTRO_PALAVRAS_STR_ABREV = [\"SP_SSW\",\"SP_SVS\"]\n","FILTRO_PALAVRAS = [3, 4, 5]"]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"3V_ORR8Qyu1p"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Definição dos parâmetros do Modelo\n","model_args = ModeloArgumentosMedida(\n","    modelo_spacy = \"en_core_web_lg\",\n","    #modelo_spacy = \"en_core_web_md\",\n","    #modelo_spacy = \"en_core_web_sm\",\n","    versao_modelo_spacy = \"3.2.0\",\n","    do_lower_case = True,  # default True\n","    use_wandb = True,\n","    salvar_medicao = True, #Salva o resultado da medição\n","    salvar_avaliacao = True, # Salva o resultado da avaliação das medições\n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100, 500 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","    equacao_medida = 0, # Atributo usado para os logs do wandb. 0 - Palavras adjacentes / 1 - Todas as palavras / 2 - Palavra e contexto\n","    filtro_palavra = 0 # # Atributo usado para os logs do wandb. 0 - Considera todas as palavras das sentenças / 1 - Desconsidera as stopwords / 2 - Considera somente as palavras substantivas\n",")"]},{"cell_type":"markdown","metadata":{"id":"WlF4PKP6Iopi"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55PNP2s6Iopi"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_IN_EN\""]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"tDgJTbPOZ8SW"},"source":["## Inicialização diretórios"]},{"cell_type":"markdown","metadata":{"id":"qpSERA9TC4WU"},"source":["Diretório base local"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edg7eW2cDflg"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","def criaDiretorioLocal():\n","\n","  # Cria o diretório para receber os arquivos Originais e Permutados\n","  # Diretório a ser criado\n","  dirbase = DIRETORIO_LOCAL[:-1]\n","\n","  if not os.path.exists(dirbase):\n","      # Cria o diretório\n","      os.makedirs(dirbase)\n","      logging.info(\"Diretório criado: {}.\".format(dirbase))\n","  else:\n","      logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1668447029990,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"xge0ar9MJoKy","outputId":"bf96055a-0322-4194-e4dc-c131eff2e9dd"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_INIT_EN.\n"]}],"source":["criaDiretorioLocal()"]},{"cell_type":"markdown","metadata":{"id":"4FmT9nhbaE3D"},"source":["Diretório para conter as os resultados das medidas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zO76uzj_C3zQ"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioMedidacao():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_medicao_topico_palavra\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):\n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1668447029990,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"T1Ot2h_bJuxy","outputId":"8a6704e0-b7a2-45fe-9336-8575dddab199"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_EN/validacao_medicao_topico_palavra.\n"]}],"source":["criaDiretorioMedidacao()"]},{"cell_type":"markdown","metadata":{"id":"vIkT6ksqaQs3"},"source":["Diretório para conter os arquivos da avaliação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIV4xj6zDnb8"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioAvaliacao():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_medicao_topico_palavra/Avaliacao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):\n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1668447029991,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"IiOVjJ5BJzE1","outputId":"fb12200e-3f02-4137-c499-415ee35e18ed"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_EN/validacao_medicao_topico_palavra/Avaliacao.\n"]}],"source":["criaDiretorioAvaliacao()"]},{"cell_type":"markdown","metadata":{"id":"cjP6v878aWR7"},"source":["Diretório para conter os arquivos das medidas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qf6UWAZYDsgm"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioMedicao():\n","\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_medicao_topico_palavra/Medicao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):\n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1668447029991,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"IBBfHFuPJ3NM","outputId":"35935827-40e2-4e06-b0dc-0516474e8cac"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_EN/validacao_medicao_topico_palavra/Medicao.\n"]}],"source":["criaDiretorioMedicao()"]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjWGu-9D5URZ"},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dq9PnXO77bPQ"},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","\n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivoTar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")\n","    arquivoTar.extractall(DIRETORIO_COHEBERT)\n","    arquivoTar.close()\n","\n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):\n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePOccj0s8WMg"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","\n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp"]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbELnrpgA4T1","executionInfo":{"status":"ok","timestamp":1668447032754,"user_tz":180,"elapsed":2373,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"5bbe2479-e092-44f0-ff19-351b617ff26d"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:spaCy carregado.\n"]}],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","metadata":{"id":"AEzytjZi5Iw2"},"source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKg-_XyWoy8o"},"outputs":[],"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","\n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.\n","    \"\"\"\n","\n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords"]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1o8jevtoy8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447033880,"user_tz":180,"elapsed":23,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"90095d43-5f95-448d-ed7b-746c1ee73d2d"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Quantidade de stopwords: 326.\n"]},{"output_type":"stream","name":"stdout","text":["{'for', 'nowhere', 'sixty', 'least', 'go', 'using', 'twelve', 'rather', 'almost', 'each', 'whereas', 'toward', 'somewhere', 'amongst', 'an', 'not', \"'m\", 'at', 'is', 'anyhow', 'also', 'first', 'however', 'alone', 'hereafter', 'may', \"'ve\", 'might', 'until', 'though', 'being', 'only', 'n‘t', 'of', '‘re', 'none', 'ours', 'herein', 'where', 'own', 'it', '‘ve', 'formerly', 'while', 'beyond', 'another', 'give', 'again', 'five', 'therein', 'nine', '‘d', 'mostly', 'this', 'behind', 'thence', 'really', 'namely', 'just', 'per', 'whereupon', 'wherein', 'upon', 'most', 'my', 'doing', 'together', 'something', 'done', 'about', 'take', 'below', 'hereupon', 'never', 'elsewhere', 'up', 'every', 'before', \"'d\", 'him', 'very', 'over', 'amount', 'but', \"'ll\", 'became', 'his', 'side', 'get', 'her', 'other', 'yourselves', 'ten', 'he', 'much', 'these', 'too', 'since', 'see', 'yourself', 'indeed', 'would', 'when', 'fifty', 'meanwhile', 'them', 'keep', 'full', 'whereby', 'bottom', 'because', 'between', 'few', 'forty', 'themselves', 'empty', 'above', 'yours', 'seeming', 'into', 'no', 'neither', 'yet', 'back', 'one', '‘s', 'nor', 'sometimes', 'what', 'both', 'move', 'hers', 'was', 'top', 'myself', 'thereby', 'all', 'sometime', 'itself', 'why', 'whence', 'on', 'down', 'mine', 'have', 'via', 'which', 'two', 'hundred', 'beside', 'make', 'less', 'often', 'those', 'others', 'part', '’re', 'anyone', 'therefore', 'such', 'thus', 'beforehand', \"n't\", 'due', 'thereafter', 'now', 'be', 'us', 'quite', 'seems', 'anything', 'even', 'to', 'seem', 'by', 'are', 'whole', 'eleven', 'once', 'with', 'noone', 'twenty', 'will', 'a', 're', 'can', 'besides', 'becoming', 'himself', 'regarding', 'more', 'everything', 'someone', 'there', 'its', 'herself', 'throughout', 'used', 'whither', 'same', 'moreover', 'else', 'although', 'six', 'you', '’ll', 'our', 'towards', 'along', 'am', 'in', '‘ll', 'becomes', 'fifteen', 'last', 'either', 'should', 'call', 'nobody', 'me', 'wherever', 'put', 'various', 'that', 'anyway', '’m', 'does', 'whatever', 'without', 'after', 'thereupon', 'well', 'any', \"'s\", 'if', 'several', '‘m', '’s', 'who', 'latter', 'they', 'could', 'third', 'name', 'from', 'made', '’d', 'whether', 'former', 'out', 'afterwards', 'four', 'except', 'otherwise', 'ca', 'whom', 'must', 'hereby', 'here', 'i', 'nevertheless', \"'re\", 'serious', 'ever', 'among', 'had', 'further', 'seemed', 'always', 'show', 'hence', 'across', 'whereafter', 'perhaps', 'did', 'so', 'onto', 'three', 'front', 'ourselves', 'your', 'whose', 'many', 'or', 'whenever', 'please', 'thru', 'do', 'the', 'everyone', 'within', 'next', 'we', 'then', 'unless', 'were', 'as', 'eight', 'everywhere', 'against', 'than', 'some', 'say', 'somehow', 'enough', 'has', 'their', 'latterly', 'under', 'and', 'been', 'already', 'cannot', 'nothing', 'still', 'anywhere', 'around', 'how', 'she', 'during', 'off', 'whoever', 'through', 'n’t', 'become', '’ve'}\n"]}],"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hdqVdfxm-_W"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy\n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ]\n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal\n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ]\n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},\n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar\n","               ]\n","\n","matcherv = Matcher(nlp.vocab)\n","\n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):\n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","\n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","\n","  return lista2"]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = dict()\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9SA61kD6sJY"},"outputs":[],"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","\n","  # Soma os dicionários da lista\n","  novodic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWxyAo54AOHU"},"outputs":[],"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.text)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gvd99wd_pwmt"},"outputs":[],"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  listatokens = []\n","  listapos = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:\n","    listatokens.append(token.text)\n","    listapos.append(token.pos_)\n","\n","  return listatokens, listapos"]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpCUpOs06sJY"},"outputs":[],"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","\n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\"\n","  return traduzido"]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMb0uDWzKZXP"},"outputs":[],"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxTCYFzcJZD6"},"outputs":[],"source":["def getSentencaSalientePOS(sentenca, pos, classe_saliente=[\"NOUN\"]):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especificado\n","    if pos[i] in classe_saliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"s07wG9F-qHOc"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkBatgxjqHOc"},"outputs":[],"source":["def removeStopWord(documento, stopwords):\n","\n","  # Remoção das stopwords do documento\n","  documentoSemStopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documentoSemStopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"]},{"cell_type":"markdown","metadata":{"id":"eyEaXKeaLWlq"},"source":["### getTokensSemStopword\n","\n","Retira as stopswords de lista de tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbUf_V_1axS2"},"outputs":[],"source":["def getTokensSemStopword(tokens, spacy_stopwords=getStopwords(nlp)):\n","    \"\"\"\n","      Retira os tokens da lista de tokens tokens que estão na lista de stopword.\n","      A lista de tokens pode ou não estar dentro de uma outra lista.\n","\n","      Parâmetros:\n","        `tokens` - Uma lista com os tokens ou uma lista de lista de tokens.\n","        `spacy_stopwords` - Uma lista com as stopword.\n","    \"\"\"\n","\n","    # Verifica se é uma lista de palavras(str) ou ou uma lista de lista\n","    if type(tokens[0]) is str:\n","      lista_tokens = [tokens]\n","    else:\n","      lista_tokens = tokens\n","\n","    # Lista de retorno\n","    lista_tokens_sem_stopwords = []\n","\n","    # Percorre a lista de tokens\n","    for texto in lista_tokens:\n","\n","      # Lista dos tokens sem as stopwords\n","      tokens_sem_stopwords = []\n","\n","      # Percorre os tokens\n","      for token in texto:\n","        # Verifica se o toke não está na lista de stopwords para adicionar a nova lista\n","        if token not in spacy_stopwords:\n","          tokens_sem_stopwords.append(token)\n","\n","      # Adiciona a lista de tokens sem stopwords na lista de retorno se tiver uma palavra\n","      if len(tokens_sem_stopwords) != 0:\n","        lista_tokens_sem_stopwords.append(tokens_sem_stopwords)\n","\n","    if type(tokens[0]) is str:\n","      return lista_tokens_sem_stopwords[0]\n","    else:\n","      return lista_tokens_sem_stopwords"]},{"cell_type":"markdown","metadata":{"id":"O7XoLBuW6woe"},"source":["### getSentencasTexto\n","\n","Retorna a lista de tokens de uma lista de textos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iR9Oc6Yf6zMa"},"outputs":[],"source":["def getSentencasTexto(textos, nlp = nlp):\n","\n","  \"\"\"\n","     Sentencia um texto ou uma lista de textos.\n","\n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","      `nlp` - Modelo spacy carregado.\n","\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista dos tokens\n","  lista_sentencas = []\n","\n","  for texto in lista_texto:\n","\n","    # Sentencia o documento\n","    doc = nlp(texto)\n","\n","    # Percorre as sentenças do documento\n","    for sentenca in doc.sents:\n","\n","        lista_sentencas.append(str(sentenca))\n","\n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_sentencas[0]\n","  else:\n","    return lista_sentencas"]},{"cell_type":"markdown","metadata":{"id":"5czwzaxKza0y"},"source":["### getSentencasMinusculo\n","\n","Retorna a lista das sentencas do texto em minúsculo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQQAO4Raza0z"},"outputs":[],"source":["def getSentencasMinusculo(textos):\n","\n","  \"\"\"\n","     Sentencia um texto ou uma lista de textos em minusculo.\n","\n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista dos tokens\n","  lista_sentencas = []\n","\n","  for texto in lista_texto:\n","\n","    lista_sentencas.append(str(texto).lower())\n","\n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_sentencas[0]\n","  else:\n","    return lista_sentencas"]},{"cell_type":"markdown","metadata":{"id":"dLOaYNEb7C5J"},"source":["### getTokensTexto\n","\n","Retorna a lista de tokens do texto."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJ1hqQCg7C5J"},"outputs":[],"source":["def getTokensTexto(textos, nlp = nlp):\n","\n","  \"\"\"\n","     Tokeniza um texto ou uma lista de textos.\n","\n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista de retorno\n","  lista_tokens_texto = []\n","\n","  # Percorre a lista de texto\n","  for texto in lista_texto:\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","    if type(texto) is not spacy.tokens.doc.Doc:\n","        # Realiza o parsing no spacy\n","        doc = nlp(texto)\n","    else:\n","        doc = texto\n","\n","    # Lista dos tokens\n","    lista_tokens = []\n","\n","    # Percorre a sentença adicionando os tokens\n","    for token in doc:\n","      lista_tokens.append(token.text)\n","\n","    # Adiciona a lista de tokens na lista de sentenças\n","    lista_tokens_texto.append(lista_tokens)\n","\n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_tokens_texto[0]\n","  else:\n","    return lista_tokens_texto"]},{"cell_type":"markdown","source":["### removerPontuacao\n","\n","Remove pontuação"],"metadata":{"id":"l3VOqrF8h3-y"}},{"cell_type":"code","source":["def removerPontuacao(textos):\n","\n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","\n","        doc = nlp(\" \".join(texto))\n","\n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ not in ['PUNCT']:\n","              sentenca.append(token.text)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"R5P_9zfFh3-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### relevantes\n","\n","Palavras relevantes"],"metadata":{"id":"2C4s2rvzJ7iu"}},{"cell_type":"code","source":["def relevantes(textos, postags_permitidas=['VER', 'AUX', 'NOUN']):\n","\n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","\n","        doc = nlp(\" \".join(texto))\n","\n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ in postags_permitidas:\n","              sentenca.append(token.text)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"5F6PEOkZJ7iv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### lematizacao\n","\n","Lematização do texto"],"metadata":{"id":"1WOT9a_X5dkP"}},{"cell_type":"code","source":["def lematizacao(textos, postags_permitidas=['NOUN', 'ADJ', 'VERB', 'ADV']):\n","\n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","        doc = nlp(\" \".join(texto))\n","\n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ in postags_permitidas:\n","              sentenca.append(token.lemma_)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"SbnNOPv85d0C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### preparaCorpus"],"metadata":{"id":"b32wPnBG1faQ"}},{"cell_type":"code","source":["# Import das biblitecas\n","import pandas as pd\n","import re\n","import gensim\n","\n","def preparaCorpus(textos,\n","                  sentenciaTexto=False,\n","                  tornaMinusculo=False,\n","                  removePontuacao=False,\n","                  removeStopwords=False,\n","                  bigramas=False,\n","                  trigramas=False,\n","                  somenteRelevante=False,\n","                  postag_relevante=['VERB', 'AUX', 'NOUN'],\n","                  lematizar=False,\n","                  postag_lema=['NOUN', 'ADJ', 'VERB', 'ADV']):\n","\n","    # Verifica se é um textos é str ou uma lista de texto\n","    if type(textos) is str:\n","      # Sentencia o texto\n","      lista_sentencas = [textos]\n","    else:\n","      lista_sentencas = textos\n","\n","    # Converte o texto em uma lista de sentencas\n","    if sentenciaTexto==True:\n","      lista_sentencas = getSentencasTexto(lista_sentencas)\n","\n","    # Converte o texto em minúsuclo\n","    if tornaMinusculo==True:\n","      lista_sentencas = getSentencasMinusculo(lista_sentencas)\n","\n","    # tokeniza o texto\n","    lista_sentencas_palavras = getTokensTexto(lista_sentencas)\n","\n","    # Remove a pontuação\n","    if removePontuacao==True:\n","        lista_sentencas_palavras = removerPontuacao(lista_sentencas_palavras)\n","\n","    # Remove as stop words\n","    if removeStopwords==True:\n","      lista_sentencas_palavras = getTokensSemStopword(lista_sentencas_palavras)\n","\n","    # Criar bigramas ou trigramas\n","    if bigramas==True:\n","      # Construa os modelos de bigramas\n","      bigram = gensim.models.Phrases(lista_sentencas_palavras, min_count=5, threshold=100) # max_topicse mais alto menos frases.\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama\n","      bigram_mod = gensim.models.phrases.Phraser(bigram)\n","      lista_sentencas_palavras = [bigram_mod[doc] for doc in lista_sentencas_palavras]\n","\n","    if trigramas==True:\n","      # Construa os modelos de bigramas\n","      bigram = gensim.models.Phrases(lista_sentencas_palavras, min_count=5, threshold=100) # max_topicse mais alto menos frases.\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama\n","      bigram_mod = gensim.models.phrases.Phraser(bigram)\n","      # Construa os modelos de trigramas\n","      trigram = gensim.models.Phrases(bigram[lista_sentencas_palavras], threshold=100)\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama\n","      trigram_mod = gensim.models.phrases.Phraser(trigram)\n","      lista_sentencas_palavras = [trigram_mod[bigram_mod[doc]] for doc in lista_sentencas_palavras]\n","\n","    # Somente palavras relevantes\n","    if somenteRelevante==True:\n","      lista_sentencas_palavras = relevantes(lista_sentencas_palavras, postags_permitidas=postag_relevante)\n","\n","    # Faça a lematização mantendo apenas para noun, adj, vb, adv\n","    if lematizar==True:\n","      lista_sentencas_palavras = lematizacao(lista_sentencas_palavras, postags_permitidas=postag_lema)\n","\n","    return lista_sentencas_palavras"],"metadata":{"id":"rSW4ign41h1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JS7qzOSkcc-L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"khTFfBVbnsx9"},"source":["# 4 Funções auxiliares"]},{"cell_type":"markdown","metadata":{"id":"lCJzsw8T0I-5"},"source":["## concatenaListas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpmDZ1mI0JHR"},"outputs":[],"source":["def concatenaListas(lista, pos=1):\n","  lista_concat = []\n","\n","  for x in lista:\n","      lista_concat = lista_concat + x[pos]\n","\n","  return lista_concat"]},{"cell_type":"markdown","metadata":{"id":"3wvgXwN81RCz"},"source":["## encontrarIndiceSubLista\n","\n","Retorna os índices de início e fim da sublista na lista"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zI_n9hMgqHOi"},"outputs":[],"source":["# Localiza os índices de início e fim de uma sublista em uma lista\n","def encontrarIndiceSubLista(lista, sublista):\n","\n","    \"\"\"\n","      Localiza os índices de início e fim de uma sublista em uma lista.\n","\n","      Parâmetros:\n","      `lista` - Uma lista.\n","      `sublista` - Uma sublista a ser localizada na lista.\n","    \"\"\"\n","    # https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n","\n","    # Recupera o tamanho da lista\n","    h = len(lista)\n","    # Recupera o tamanho da sublista\n","    n = len(sublista)\n","    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n","    i = n - 1\n","    while i < h:\n","      for j in range(n):\n","        if lista[i - j] != sublista[-j - 1]:\n","            i += skip.get(lista[i], n)\n","            break\n","        else:\n","            indice_inicio = i - n + 1\n","            indice_fim = indice_inicio + len(sublista)-1\n","\n","            return indice_inicio, indice_fim\n","\n","    # Não encontrou a sublista na lista\n","    return -1, -1"]},{"cell_type":"markdown","metadata":{"id":"qlZRwLGTq_r_"},"source":["# 5 Comparar documentos\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 5.1 Carregamento dos arquivos de dados originais e perturbados"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["#### 5.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","metadata":{"id":"bNgwJRC2uGJb"},"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.1.2 Cria o diretório local para receber os dados"],"metadata":{"id":"CGF4D4B1JY9P"}},{"cell_type":"code","metadata":{"id":"gFYIHcIHE985","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447033889,"user_tz":180,"elapsed":24,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"c09a2e04-457f-405b-9f56-9f7352337957"},"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):\n","    # Cria o diretório\n","    os.makedirs(dirbase)\n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:\n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_INIT_EN.\n"]}]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","metadata":{"id":"pviuxToMCxQw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447034431,"user_tz":180,"elapsed":561,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"8964e627-efbb-4464-b297-c47d4c4de624"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a cópia.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens\n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","metadata":{"id":"dbHl3d88mouc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447034892,"user_tz":180,"elapsed":463,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"98d00675-e1a7-4d0f-a0ff-b77021ecefe9"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a descompactação.\n"]}]},{"cell_type":"markdown","metadata":{"id":"qzhYJNWJm1z4"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais e pertubados"]},{"cell_type":"markdown","metadata":{"id":"Usr1uRzQeJSb"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","metadata":{"id":"QRHlixdHEDTb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447034893,"user_tz":180,"elapsed":21,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4fe37cfa-286b-4f9f-c2d6-da5f22f83462"},"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO ORIGINAIS: 20.\n","INFO:root:TERMINADO ORIGINAIS POS: 20.\n"]}]},{"cell_type":"code","metadata":{"id":"jJ5STBZPLlie","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1668447034893,"user_tz":180,"elapsed":17,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"a6de14da-eaef-4812-f299-9288a44c676d"},"source":["lista_documentos_originais.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    id                                          sentencas  \\\n","1    2            ['How to dequeue elements in a queue?']   \n","11  12  ['What is a stack and how to pop an element fr...   \n","7    8  ['How to pop elements in a stack data structur...   \n","17  18  ['How are the operations to enqueue and dequeu...   \n","6    7              ['How to pop elements from a stack?']   \n","\n","                                            documento  \n","1                 How to dequeue elements in a queue?  \n","11  What is a stack and how to pop an element from...  \n","7      How to pop elements in a stack data structure?  \n","17  How are the operations to enqueue and dequeue ...  \n","6                   How to pop elements from a stack?  "],"text/html":["\n","  <div id=\"df-aa383870-daeb-4511-bb59-2cd05b7234c4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>['How to dequeue elements in a queue?']</td>\n","      <td>How to dequeue elements in a queue?</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>['What is a stack and how to pop an element fr...</td>\n","      <td>What is a stack and how to pop an element from...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>['How to pop elements in a stack data structur...</td>\n","      <td>How to pop elements in a stack data structure?</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>['How are the operations to enqueue and dequeu...</td>\n","      <td>How are the operations to enqueue and dequeue ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>['How to pop elements from a stack?']</td>\n","      <td>How to pop elements from a stack?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa383870-daeb-4511-bb59-2cd05b7234c4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aa383870-daeb-4511-bb59-2cd05b7234c4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aa383870-daeb-4511-bb59-2cd05b7234c4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais = lista_documentos_originais.astype(tipos)"],"metadata":{"id":"BYddg8UODmdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbaWPXE2jK26","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1668447034894,"user_tz":180,"elapsed":15,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"3c39d074-77ac-4dd7-b180-51af3e940012"},"source":["lista_documentos_originais_pos.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    id                                      pos_documento\n","5    6  [[['How', 'to', 'push', 'and', 'pop', 'element...\n","12  13  [[['What', 'is', 'a', 'queue', 'and', 'how', '...\n","17  18  [[['How', 'are', 'the', 'operations', 'to', 'e...\n","13  14  [[['What', 'is', 'a', 'stack', 'and', 'how', '...\n","3    4  [[['How', 'to', 'push', 'and', 'pop', 'element..."],"text/html":["\n","  <div id=\"df-b76c2973-a16e-482f-be10-a375fbf99329\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>[[['How', 'to', 'push', 'and', 'pop', 'element...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>[[['What', 'is', 'a', 'queue', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>[[['How', 'are', 'the', 'operations', 'to', 'e...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>[[['What', 'is', 'a', 'stack', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>[[['How', 'to', 'push', 'and', 'pop', 'element...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b76c2973-a16e-482f-be10-a375fbf99329')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b76c2973-a16e-482f-be10-a375fbf99329 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b76c2973-a16e-482f-be10-a375fbf99329');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais_pos = lista_documentos_originais_pos.astype(tipos)"],"metadata":{"id":"d96IZl9nDfHf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"-hfUpvKqXoqe"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"metadata":{"id":"lj9sJVavMccj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447034894,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"3257fa24-54f5-4d64-93e0-8d1177cffb63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO ORIGINAIS: 20.\n","INFO:root:TERMINADO CORREÇÃO ORIGINAIS POS: 20.\n"]}]},{"cell_type":"markdown","source":["#### Criando dados indexados originais"],"metadata":{"id":"8yyRt4jnYxsU"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"B9INo4nBS8aQ","executionInfo":{"status":"ok","timestamp":1668447034895,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"46641ca6-461f-443e-8276-22d370e67d8d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            sentencas  \\\n","id                                                      \n","1               [How to enqueue elements in a queue?]   \n","2               [How to dequeue elements in a queue?]   \n","3                  [How to push elements in a stack?]   \n","4          [How to push and pop elements in a stack?]   \n","5   [How to push elements in a stack data structure?]   \n","\n","                                          documento  \n","id                                                   \n","1               How to enqueue elements in a queue?  \n","2               How to dequeue elements in a queue?  \n","3                  How to push elements in a stack?  \n","4          How to push and pop elements in a stack?  \n","5   How to push elements in a stack data structure?  "],"text/html":["\n","  <div id=\"df-10549518-6f3d-4838-911f-483b658c1ee1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>[How to enqueue elements in a queue?]</td>\n","      <td>How to enqueue elements in a queue?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[How to dequeue elements in a queue?]</td>\n","      <td>How to dequeue elements in a queue?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[How to push elements in a stack?]</td>\n","      <td>How to push elements in a stack?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[How to push and pop elements in a stack?]</td>\n","      <td>How to push and pop elements in a stack?</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[How to push elements in a stack data structure?]</td>\n","      <td>How to push elements in a stack data structure?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10549518-6f3d-4838-911f-483b658c1ee1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-10549518-6f3d-4838-911f-483b658c1ee1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-10549518-6f3d-4838-911f-483b658c1ee1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"j70x_r30T_bx","executionInfo":{"status":"ok","timestamp":1668447035412,"user_tz":180,"elapsed":526,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7c0bf2fa-caa5-429f-8f8c-796fc8d1e7cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        pos_documento\n","id                                                   \n","1   [[[How, to, enqueue, elements, in, a, queue, ?...\n","2   [[[How, to, dequeue, elements, in, a, queue, ?...\n","3   [[[How, to, push, elements, in, a, stack, ?], ...\n","4   [[[How, to, push, and, pop, elements, in, a, s...\n","5   [[[How, to, push, elements, in, a, stack, data..."],"text/html":["\n","  <div id=\"df-486b3633-52c3-4f01-99ab-a3690c1a58e6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>[[[How, to, enqueue, elements, in, a, queue, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[[[How, to, dequeue, elements, in, a, queue, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[[[How, to, push, elements, in, a, stack, ?], ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[[[How, to, push, and, pop, elements, in, a, s...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[[[How, to, push, elements, in, a, stack, data...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-486b3633-52c3-4f01-99ab-a3690c1a58e6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-486b3633-52c3-4f01-99ab-a3690c1a58e6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-486b3633-52c3-4f01-99ab-a3690c1a58e6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"zJXcpioo7Bhn"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","metadata":{"id":"gB500dmd7Bho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447035413,"user_tz":180,"elapsed":35,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"e2eb49a0-f034-426c-ae87-8794fd713b64"},"source":["# Abre o arquivo e retorna o DataFrame\n","lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO PERTURBADOS: 20.\n","INFO:root:TERMINADO PERTURBADOS POS: 20.\n"]}]},{"cell_type":"markdown","source":["Alguns csv estão com o nome da coluna errado."],"metadata":{"id":"jfZEITKEHHWW"}},{"cell_type":"code","source":["lista_documentos_perturbados = lista_documentos_perturbados.rename(columns={'documentoPerturbado':'documento_perturbado'})"],"metadata":{"id":"quf5o1KkHLkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ9cgAz47Bhp","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1668447035414,"user_tz":180,"elapsed":31,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"0d003158-c8cf-4827-8e77-31ee87cdf60c"},"source":["lista_documentos_perturbados.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           id                                         perturbado  \\\n","1    2_pert_0           ['How to dequeue elements in a stack ?']   \n","6    7_pert_0             ['How to pop elements from a queue ?']   \n","18  19_pert_0  ['In a stack does the enqueue operation occur ...   \n","7    8_pert_0  ['How to pop elements in a queue data structur...   \n","11  12_pert_0  ['What is a queue and how to pop an element fr...   \n","\n","                                 documento_perturbado  \\\n","1               How to dequeue elements in a stack ?'   \n","6                  How to pop elements from a queue ?   \n","18  In a stack does the enqueue operation occur at...   \n","7     How to pop elements in a queue data structure ?   \n","11  What is a queue and how to pop an element from...   \n","\n","                                            sentencas  \n","1   [['How to dequeue elements in a [MASK] ?', 'qu...  \n","6   [['How to pop elements from a [MASK] ?', 'stac...  \n","18  [['In a stack does the [MASK] operation occur ...  \n","7   [['How to pop elements in a [MASK] data struct...  \n","11  [['What is a [MASK] and how to pop an element ...  "],"text/html":["\n","  <div id=\"df-9d7cc43a-e7ef-44be-827d-02f8dcbedc65\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2_pert_0</td>\n","      <td>['How to dequeue elements in a stack ?']</td>\n","      <td>How to dequeue elements in a stack ?'</td>\n","      <td>[['How to dequeue elements in a [MASK] ?', 'qu...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7_pert_0</td>\n","      <td>['How to pop elements from a queue ?']</td>\n","      <td>How to pop elements from a queue ?</td>\n","      <td>[['How to pop elements from a [MASK] ?', 'stac...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19_pert_0</td>\n","      <td>['In a stack does the enqueue operation occur ...</td>\n","      <td>In a stack does the enqueue operation occur at...</td>\n","      <td>[['In a stack does the [MASK] operation occur ...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8_pert_0</td>\n","      <td>['How to pop elements in a queue data structur...</td>\n","      <td>How to pop elements in a queue data structure ?</td>\n","      <td>[['How to pop elements in a [MASK] data struct...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12_pert_0</td>\n","      <td>['What is a queue and how to pop an element fr...</td>\n","      <td>What is a queue and how to pop an element from...</td>\n","      <td>[['What is a [MASK] and how to pop an element ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d7cc43a-e7ef-44be-827d-02f8dcbedc65')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9d7cc43a-e7ef-44be-827d-02f8dcbedc65 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9d7cc43a-e7ef-44be-827d-02f8dcbedc65');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"3pXGee7H7Bhp","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1668447035414,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"63d3500f-0aa4-4a0b-f398-2a4aac3d5d66"},"source":["lista_documentos_perturbados.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           id                                         perturbado  \\\n","19  20_pert_0  ['In a queue does the push operation occur at ...   \n","2    3_pert_0              ['How to push elements in a queue ?']   \n","6    7_pert_0             ['How to pop elements from a queue ?']   \n","4    5_pert_0  ['How to push elements in a queue data structu...   \n","16  17_pert_0  ['How are the operations to push and pop eleme...   \n","\n","                                 documento_perturbado  \\\n","19  In a queue does the push operation occur at wh...   \n","2                   How to push elements in a queue ?   \n","6                  How to pop elements from a queue ?   \n","4    How to push elements in a queue data structure ?   \n","16  How are the operations to push and pop element...   \n","\n","                                            sentencas  \n","19  [['In a queue does the [MASK] operation occur ...  \n","2   [['How to push elements in a [MASK] ?', 'stack...  \n","6   [['How to pop elements from a [MASK] ?', 'stac...  \n","4   [['How to push elements in a [MASK] data struc...  \n","16  [['How are the operations to push and pop elem...  "],"text/html":["\n","  <div id=\"df-968d9c6a-4ec9-4733-bd2a-5959d7f8e074\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>19</th>\n","      <td>20_pert_0</td>\n","      <td>['In a queue does the push operation occur at ...</td>\n","      <td>In a queue does the push operation occur at wh...</td>\n","      <td>[['In a queue does the [MASK] operation occur ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3_pert_0</td>\n","      <td>['How to push elements in a queue ?']</td>\n","      <td>How to push elements in a queue ?</td>\n","      <td>[['How to push elements in a [MASK] ?', 'stack...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7_pert_0</td>\n","      <td>['How to pop elements from a queue ?']</td>\n","      <td>How to pop elements from a queue ?</td>\n","      <td>[['How to pop elements from a [MASK] ?', 'stac...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5_pert_0</td>\n","      <td>['How to push elements in a queue data structu...</td>\n","      <td>How to push elements in a queue data structure ?</td>\n","      <td>[['How to push elements in a [MASK] data struc...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17_pert_0</td>\n","      <td>['How are the operations to push and pop eleme...</td>\n","      <td>How are the operations to push and pop element...</td>\n","      <td>[['How are the operations to push and pop elem...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-968d9c6a-4ec9-4733-bd2a-5959d7f8e074')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-968d9c6a-4ec9-4733-bd2a-5959d7f8e074 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-968d9c6a-4ec9-4733-bd2a-5959d7f8e074');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["lista_documentos_perturbados_pos.sample(5)"],"metadata":{"id":"IE1xJdZWkc5I","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1668447035415,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4668c4f4-6182-4abd-e47e-d71c202ae639"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           id                                      pos_documento\n","5    6_pert_0  [[['How', 'to', 'push', 'and', 'pop', 'element...\n","10  11_pert_0  [[['What', 'is', 'a', 'stack', 'and', 'how', '...\n","12  13_pert_0  [[['What', 'is', 'a', 'stack', 'and', 'how', '...\n","11  12_pert_0  [[['What', 'is', 'a', 'queue', 'and', 'how', '...\n","4    5_pert_0  [[['How', 'to', 'push', 'elements', 'in', 'a',..."],"text/html":["\n","  <div id=\"df-ac49c777-679b-4cc6-af3a-ea3b07e93d0c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>6_pert_0</td>\n","      <td>[[['How', 'to', 'push', 'and', 'pop', 'element...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11_pert_0</td>\n","      <td>[[['What', 'is', 'a', 'stack', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13_pert_0</td>\n","      <td>[[['What', 'is', 'a', 'stack', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12_pert_0</td>\n","      <td>[[['What', 'is', 'a', 'queue', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5_pert_0</td>\n","      <td>[[['How', 'to', 'push', 'elements', 'in', 'a',...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac49c777-679b-4cc6-af3a-ea3b07e93d0c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ac49c777-679b-4cc6-af3a-ea3b07e93d0c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ac49c777-679b-4cc6-af3a-ea3b07e93d0c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":78}]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"VrfZzjjpsUOU"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHf-7dgSsUOU","executionInfo":{"status":"ok","timestamp":1668447035416,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"efc4fbe4-9c0d-4d33-9796-51bf90be1c5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO PERTURBADO: 20.\n","INFO:root:TERMINADO CORREÇÃO PERTURBADO POS: 20.\n"]}]},{"cell_type":"markdown","source":["#### Criando dados indexados perturbados"],"metadata":{"id":"Ix-Q5fZXY3HR"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"FqRQnYUtSxzB","executionInfo":{"status":"ok","timestamp":1668447035417,"user_tz":180,"elapsed":28,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"626846a2-5eef-44d8-890d-a2ffd43454ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 perturbado  \\\n","id                                                            \n","1_pert_0             [How to enqueue elements in a stack ?]   \n","2_pert_0             [How to dequeue elements in a stack ?]   \n","3_pert_0                [How to push elements in a queue ?]   \n","4_pert_0        [How to push and pop elements in a queue ?]   \n","5_pert_0  [How to push elements in a queue data structure?]   \n","\n","                                      documento_perturbado  \\\n","id                                                           \n","1_pert_0             How to enqueue elements in a stack ?'   \n","2_pert_0             How to dequeue elements in a stack ?'   \n","3_pert_0                 How to push elements in a queue ?   \n","4_pert_0         How to push and pop elements in a queue ?   \n","5_pert_0  How to push elements in a queue data structure ?   \n","\n","                                                  sentencas  \n","id                                                           \n","1_pert_0  [[How to enqueue elements in a [MASK] ?, queue...  \n","2_pert_0  [[How to dequeue elements in a [MASK] ?, queue...  \n","3_pert_0  [[How to push elements in a [MASK] ?, stack, q...  \n","4_pert_0  [[How to push and pop elements in a [MASK] ?, ...  \n","5_pert_0  [[How to push elements in a [MASK] data struct...  "],"text/html":["\n","  <div id=\"df-961de534-500f-4125-aa44-30f0273c40f4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1_pert_0</th>\n","      <td>[How to enqueue elements in a stack ?]</td>\n","      <td>How to enqueue elements in a stack ?'</td>\n","      <td>[[How to enqueue elements in a [MASK] ?, queue...</td>\n","    </tr>\n","    <tr>\n","      <th>2_pert_0</th>\n","      <td>[How to dequeue elements in a stack ?]</td>\n","      <td>How to dequeue elements in a stack ?'</td>\n","      <td>[[How to dequeue elements in a [MASK] ?, queue...</td>\n","    </tr>\n","    <tr>\n","      <th>3_pert_0</th>\n","      <td>[How to push elements in a queue ?]</td>\n","      <td>How to push elements in a queue ?</td>\n","      <td>[[How to push elements in a [MASK] ?, stack, q...</td>\n","    </tr>\n","    <tr>\n","      <th>4_pert_0</th>\n","      <td>[How to push and pop elements in a queue ?]</td>\n","      <td>How to push and pop elements in a queue ?</td>\n","      <td>[[How to push and pop elements in a [MASK] ?, ...</td>\n","    </tr>\n","    <tr>\n","      <th>5_pert_0</th>\n","      <td>[How to push elements in a queue data structure?]</td>\n","      <td>How to push elements in a queue data structure ?</td>\n","      <td>[[How to push elements in a [MASK] data struct...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-961de534-500f-4125-aa44-30f0273c40f4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-961de534-500f-4125-aa44-30f0273c40f4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-961de534-500f-4125-aa44-30f0273c40f4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados_pos.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"s0aDUbeZT1M8","executionInfo":{"status":"ok","timestamp":1668447035418,"user_tz":180,"elapsed":29,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"162bab44-57c3-4a65-9cc2-f9a3867a3a71"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              pos_documento\n","id                                                         \n","1_pert_0  [[[How, to, enqueue, elements, in, a, stack, ?...\n","2_pert_0  [[[How, to, dequeue, elements, in, a, stack, ?...\n","3_pert_0  [[[How, to, push, elements, in, a, queue, ?], ...\n","4_pert_0  [[[How, to, push, and, pop, elements, in, a, q...\n","5_pert_0  [[[How, to, push, elements, in, a, queue, data..."],"text/html":["\n","  <div id=\"df-b5a5e42c-8379-4b95-a2ba-7c64148f7e25\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1_pert_0</th>\n","      <td>[[[How, to, enqueue, elements, in, a, stack, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>2_pert_0</th>\n","      <td>[[[How, to, dequeue, elements, in, a, stack, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>3_pert_0</th>\n","      <td>[[[How, to, push, elements, in, a, queue, ?], ...</td>\n","    </tr>\n","    <tr>\n","      <th>4_pert_0</th>\n","      <td>[[[How, to, push, and, pop, elements, in, a, q...</td>\n","    </tr>\n","    <tr>\n","      <th>5_pert_0</th>\n","      <td>[[[How, to, push, elements, in, a, queue, data...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5a5e42c-8379-4b95-a2ba-7c64148f7e25')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b5a5e42c-8379-4b95-a2ba-7c64148f7e25 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b5a5e42c-8379-4b95-a2ba-7c64148f7e25');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","source":["### 5.1.5 Gerando pares de documentos originais e perturbados / Documento Original(1) e Documento Perturbado(0)\n"],"metadata":{"id":"kq0-NGaC76jP"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","lista_documentos_agrupados = []\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_originais_bar:\n","  #if i < 2:\n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento_original = linha_documento[0]\n","    #print(\"id_documento_original:\",id_documento_original)\n","\n","    # Carrega a lista das sentenças do documento\n","    lista_sentencas_original = linha_documento[1]\n","    #print(\"\\lista_sentencas_original:\",lista_sentencas_original)\n","    #print(\"len(lista_sentencas_original):\",len(lista_sentencas_original))\n","\n","    # Carrega o documento original\n","    documento_original = linha_documento[2]\n","    #print(\"\\documento_original:\",documento_original)\n","\n","    # Recupera a POS do documento original\n","    tokens_original = []\n","    tokens_original_pos = []\n","    reg_original_pos = lista_documentos_originais_pos_indexado.loc[id_documento_original]\n","    # print(\"reg_original_pos:\",reg_original_pos)\n","    pos_documento_original = reg_original_pos['pos_documento']\n","    for i, linha2 in enumerate(pos_documento_original):\n","\n","      tokens_original.append(linha2[0])\n","      tokens_original_pos.append(linha2[1])\n","\n","    # Percorre os documentos perturbados apartir do original\n","    for j in range(0, model_args.documentos_perturbados):\n","\n","        # Id do documento perturbado\n","        id_perturbado = str(id_documento_original) + \"_pert_\" + str(j)\n","        #print(\"id_perturbado:\", id_perturbado)\n","\n","        # Recupera o documento perturbado apartir do id original\n","        reg_documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","        # Recupera a sentença do documento perturbado\n","        lista_sentencas_perturbado = reg_documento_perturbado[\"perturbado\"]\n","        #print(\"\\lista_sentencas_perturbado:\",lista_sentencas_perturbado)\n","        #print(\"len(lista_sentencas_perturbado):\",len(lista_sentencas_perturbado))\n","\n","        # Carrega o documento perturbado\n","        documento_perturbado = reg_documento_perturbado[\"documento_perturbado\"]\n","        #print(\"\\documento_perturbado:\",documento_perturbado)\n","\n","        # Recupera a POS do documento perturbado\n","        tokens_perturbado = []\n","        tokens_perturbado_pos = []\n","        reg_perturbado_pos = lista_documentos_perturbados_pos_indexado.loc[id_perturbado]\n","        #print(\"reg_perturbado_pos:\",reg_perturbado_pos)\n","        pos_documento_perturbado = reg_perturbado_pos['pos_documento']\n","        for i, linha2 in enumerate(pos_documento_perturbado):\n","          tokens_perturbado.append(linha2[0])\n","          tokens_perturbado_pos.append(linha2[1])\n","\n","        # Guarda o agrupamento de original e perturbado\n","        lista_documentos_agrupados.append([id_documento_original,\n","                                           lista_sentencas_original,\n","                                           documento_original,\n","                                           tokens_original,\n","                                           tokens_original_pos,\n","                                           id_perturbado,\n","                                           lista_sentencas_perturbado,\n","                                           documento_perturbado,\n","                                           tokens_perturbado,\n","                                           tokens_perturbado_pos])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["7b1b78992a3d445bb502e4c527df8e30","eff1dbf113584376b71591480fb1838a","1894a9e490eb4ace9df0085e8e8dae17","9d5507e57fea4112b77068b4227195b4","88ff50637a894c4d89fb9fb49cc34f57","f738a3e83b7940bc8e293c10ccaa2042","6a7074428c8c4bec8477660ea83910d1","b8249e4a20cb4205be145e6f7222a643","031dd09fd588414fa4974e9d4f7332f3","a85e96b3245846e38483ce055f25c5da","5729ecae62b7447daa390b85bbabfafa"],"height":84},"id":"t_HVTlvaxqoM","executionInfo":{"status":"ok","timestamp":1668447035418,"user_tz":180,"elapsed":28,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"12b1964a-063b-45eb-a9c8-ad1598f5b1d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processando 20 documentos originais\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/20 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b1b78992a3d445bb502e4c527df8e30"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO AGRUPAMENTO: 20.\n"]}]},{"cell_type":"markdown","metadata":{"id":"THHBPK6Ov8WV"},"source":["#### Converte a lista em um dataframe\n","\n","Atributos do dataframe:\n","Atributos do dataframe:\n","0. 'id_original' - Nome do arquivo original\n","1. 'sentencas_originais' - Lista das sentenças do documento original\n","2. 'documento_original' - Documento original\n","3. 'tokens_original' - Tokens do documento original\n","4. 'pos_original' - Postagging do documento original\n","5. 'id_perturbado' - Nome do arquivo perturbado\n","6. 'sentencas_perturbadas' - Lista das sentenças do documento perturbado\n","7. 'documento_perturbado' - Documento perturbado\n","8. 'tokens_perturbado' - Tokens do documento perturbado\n","9. 'pos_perturbado' - Postagging do documento perturbado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWz4b8Fpv8ki","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447035418,"user_tz":180,"elapsed":27,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ce326802-062e-4090-8911-4b68933c57f0"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Total de registros              : 20\n"]}],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Converte a lista em um dataframe.\n","lista_documentos_agrupados = pd.DataFrame.from_records(lista_documentos_agrupados,\n","                                                         columns=['id_original',\n","                                                                  'sentencas_original',\n","                                                                  'documento_original',\n","                                                                  'tokens_original',\n","                                                                  'pos_original',\n","                                                                  'id_perturbado',\n","                                                                  'sentencas_perturbado',\n","                                                                  'documento_perturbado',\n","                                                                  'tokens_perturbado',\n","                                                                  'pos_perturbado'])\n","\n","# Número de linhas carregadas do arquivo.\n","logging.info('Total de registros              : {}'.format(len(lista_documentos_agrupados)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3qemxYGwHL7","colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"status":"ok","timestamp":1668447035419,"user_tz":180,"elapsed":24,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"0346fc29-6830-4a89-f768-52fe5fb467ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id_original                                 sentencas_original  \\\n","19          20  [In a queue does the enqueue operation occur a...   \n","9           10  [What is a queue and how to enqueue its element?]   \n","2            3                 [How to push elements in a stack?]   \n","0            1              [How to enqueue elements in a queue?]   \n","11          12  [What is a stack and how to pop an element fro...   \n","\n","                                   documento_original  \\\n","19  In a queue does the enqueue operation occur at...   \n","9     What is a queue and how to enqueue its element?   \n","2                    How to push elements in a stack?   \n","0                 How to enqueue elements in a queue?   \n","11  What is a stack and how to pop an element from...   \n","\n","                                      tokens_original  \\\n","19  [[In, a, queue, does, the, enqueue, operation,...   \n","9   [[What, is, a, queue, and, how, to, enqueue, i...   \n","2        [[How, to, push, elements, in, a, stack, ?]]   \n","0     [[How, to, enqueue, elements, in, a, queue, ?]]   \n","11  [[What, is, a, stack, and, how, to, pop, an, e...   \n","\n","                                         pos_original id_perturbado  \\\n","19  [[ADP, DET, NOUN, AUX, DET, NOUN, NOUN, VERB, ...     20_pert_0   \n","9   [[PRON, AUX, DET, NOUN, CCONJ, SCONJ, PART, VE...     10_pert_0   \n","2   [[SCONJ, PART, VERB, NOUN, ADP, DET, NOUN, PUN...      3_pert_0   \n","0   [[SCONJ, PART, VERB, NOUN, ADP, DET, NOUN, PUN...      1_pert_0   \n","11  [[PRON, AUX, DET, NOUN, CCONJ, SCONJ, PART, VE...     12_pert_0   \n","\n","                                 sentencas_perturbado  \\\n","19  [In a queue does the push operation occur at w...   \n","9   [What is a stack and how to enqueue its element?]   \n","2                 [How to push elements in a queue ?]   \n","0              [How to enqueue elements in a stack ?]   \n","11  [What is a queue and how to pop an element fro...   \n","\n","                                 documento_perturbado  \\\n","19  In a queue does the push operation occur at wh...   \n","9    What is a stack and how to enqueue its element ?   \n","2                   How to push elements in a queue ?   \n","0               How to enqueue elements in a stack ?'   \n","11  What is a queue and how to pop an element from...   \n","\n","                                    tokens_perturbado  \\\n","19  [[In, a, queue, does, the, push, operation, oc...   \n","9   [[What, is, a, stack, and, how, to, enqueue, i...   \n","2        [[How, to, push, elements, in, a, queue, ?]]   \n","0     [[How, to, enqueue, elements, in, a, stack, ?]]   \n","11  [[What, is, a, queue, and, how, to, pop, an, e...   \n","\n","                                       pos_perturbado  \n","19  [[ADP, DET, NOUN, AUX, DET, NOUN, NOUN, VERB, ...  \n","9   [[PRON, AUX, DET, NOUN, CCONJ, SCONJ, PART, VE...  \n","2   [[SCONJ, PART, VERB, NOUN, ADP, DET, NOUN, PUN...  \n","0   [[SCONJ, PART, VERB, NOUN, ADP, DET, NOUN, PUN...  \n","11  [[PRON, AUX, DET, NOUN, CCONJ, SCONJ, PART, VE...  "],"text/html":["\n","  <div id=\"df-cdafa5ff-1966-45cf-b494-69abaa276b3e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_original</th>\n","      <th>sentencas_original</th>\n","      <th>documento_original</th>\n","      <th>tokens_original</th>\n","      <th>pos_original</th>\n","      <th>id_perturbado</th>\n","      <th>sentencas_perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>tokens_perturbado</th>\n","      <th>pos_perturbado</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>[In a queue does the enqueue operation occur a...</td>\n","      <td>In a queue does the enqueue operation occur at...</td>\n","      <td>[[In, a, queue, does, the, enqueue, operation,...</td>\n","      <td>[[ADP, DET, NOUN, AUX, DET, NOUN, NOUN, VERB, ...</td>\n","      <td>20_pert_0</td>\n","      <td>[In a queue does the push operation occur at w...</td>\n","      <td>In a queue does the push operation occur at wh...</td>\n","      <td>[[In, a, queue, does, the, push, operation, oc...</td>\n","      <td>[[ADP, DET, NOUN, AUX, DET, NOUN, NOUN, VERB, ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>[What is a queue and how to enqueue its element?]</td>\n","      <td>What is a queue and how to enqueue its element?</td>\n","      <td>[[What, is, a, queue, and, how, to, enqueue, i...</td>\n","      <td>[[PRON, AUX, DET, NOUN, CCONJ, SCONJ, PART, VE...</td>\n","      <td>10_pert_0</td>\n","      <td>[What is a stack and how to enqueue its element?]</td>\n","      <td>What is a stack and how to enqueue its element ?</td>\n","      <td>[[What, is, a, stack, and, how, to, enqueue, i...</td>\n","      <td>[[PRON, AUX, DET, NOUN, CCONJ, SCONJ, PART, VE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>[How to push elements in a stack?]</td>\n","      <td>How to push elements in a stack?</td>\n","      <td>[[How, to, push, elements, in, a, stack, ?]]</td>\n","      <td>[[SCONJ, PART, VERB, NOUN, ADP, DET, NOUN, PUN...</td>\n","      <td>3_pert_0</td>\n","      <td>[How to push elements in a queue ?]</td>\n","      <td>How to push elements in a queue ?</td>\n","      <td>[[How, to, push, elements, in, a, queue, ?]]</td>\n","      <td>[[SCONJ, PART, VERB, NOUN, ADP, DET, NOUN, PUN...</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>[How to enqueue elements in a queue?]</td>\n","      <td>How to enqueue elements in a queue?</td>\n","      <td>[[How, to, enqueue, elements, in, a, queue, ?]]</td>\n","      <td>[[SCONJ, PART, VERB, NOUN, ADP, DET, NOUN, PUN...</td>\n","      <td>1_pert_0</td>\n","      <td>[How to enqueue elements in a stack ?]</td>\n","      <td>How to enqueue elements in a stack ?'</td>\n","      <td>[[How, to, enqueue, elements, in, a, stack, ?]]</td>\n","      <td>[[SCONJ, PART, VERB, NOUN, ADP, DET, NOUN, PUN...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>[What is a stack and how to pop an element fro...</td>\n","      <td>What is a stack and how to pop an element from...</td>\n","      <td>[[What, is, a, stack, and, how, to, pop, an, e...</td>\n","      <td>[[PRON, AUX, DET, NOUN, CCONJ, SCONJ, PART, VE...</td>\n","      <td>12_pert_0</td>\n","      <td>[What is a queue and how to pop an element fro...</td>\n","      <td>What is a queue and how to pop an element from...</td>\n","      <td>[[What, is, a, queue, and, how, to, pop, an, e...</td>\n","      <td>[[PRON, AUX, DET, NOUN, CCONJ, SCONJ, PART, VE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdafa5ff-1966-45cf-b494-69abaa276b3e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cdafa5ff-1966-45cf-b494-69abaa276b3e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cdafa5ff-1966-45cf-b494-69abaa276b3e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":84}],"source":["lista_documentos_agrupados.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"ti5-qQCMA9qz"},"source":["Apaga as listas que não serão mais utilizadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQedeKG1A1xZ"},"outputs":[],"source":["del lista_documentos_originais\n","del lista_documentos_originais_pos\n","del lista_documentos_perturbados\n","del lista_documentos_perturbados_pos"]},{"cell_type":"markdown","source":["## 5.2 Carrega os corpus específico"],"metadata":{"id":"NTLml6TrmLij"}},{"cell_type":"markdown","metadata":{"id":"NsBImnwiGFVE"},"source":["### Especifica os nomes dos arquivos do corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gSzrHQRGJpW"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_CORPUS = \"corpus_especifico.csv\"\n","NOME_ARQUIVO_CORPUS_COMPACTADO = \"corpus_especifico.zip\""]},{"cell_type":"markdown","metadata":{"id":"KLbWwQOBmx68"},"source":["### Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447036024,"user_tz":180,"elapsed":628,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"df660462-034c-40be-8588-e6c341ac7862","id":"ADtvU9Zqmx68"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_CORPUS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a cópia.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rg4yATG4mx68"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens\n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447036024,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7ab92cf8-76e2-4d74-e320-4746af481d8a","id":"CSq9Os_gmx68"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_CORPUS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a descompactação.\n"]}]},{"cell_type":"markdown","metadata":{"id":"TkncKDN1i7kq"},"source":["### Carrega os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWf1pJbyBbUz","executionInfo":{"status":"ok","timestamp":1668447036025,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"28b5d9ea-e3b1-4d9d-c18d-dd68df896bd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["106\n"]}],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","df_corpus = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_CORPUS, sep=\";\", encoding=\"UTF-8\")\n","\n","print(len(df_corpus))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"UDO7gHyiBbU5","executionInfo":{"status":"ok","timestamp":1668447036025,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"2341d344-b491-4a76-b559-592e5928dd13"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   topico          fonte                                           sentenca\n","48  pilha  Thomas Cormen  (b) The configuration of the queue after the c...\n","20  pilha  Thomas Cormen  The INSERT operation on a stack is often calle...\n","23  pilha  Thomas Cormen  As Figure 10.1 shows, we can implement a stack...\n","81   fila  Thomas Cormen  Figure 10.2 shows one way to implement a queue...\n","63  pilha      wikipedia  Another usage of queues is in the implementati..."],"text/html":["\n","  <div id=\"df-9feda056-2652-44c1-bcc5-5de7cf314e66\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topico</th>\n","      <th>fonte</th>\n","      <th>sentenca</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>48</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>(b) The configuration of the queue after the c...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>The INSERT operation on a stack is often calle...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>As Figure 10.1 shows, we can implement a stack...</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>fila</td>\n","      <td>Thomas Cormen</td>\n","      <td>Figure 10.2 shows one way to implement a queue...</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>pilha</td>\n","      <td>wikipedia</td>\n","      <td>Another usage of queues is in the implementati...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9feda056-2652-44c1-bcc5-5de7cf314e66')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9feda056-2652-44c1-bcc5-5de7cf314e66 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9feda056-2652-44c1-bcc5-5de7cf314e66');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":90}],"source":["df_corpus.sample(5)"]},{"cell_type":"markdown","source":["## 5.4 Medição"],"metadata":{"id":"QIGBEi-KhLja"}},{"cell_type":"markdown","metadata":{"id":"GuO7V9YuhRtT"},"source":["### 5.4.1 Wandb\n","\n","https://wandb.ai/osmar-braz/MedidaCoerenciaCohebert_v1/table?workspace=user-osmar-braz"]},{"cell_type":"markdown","metadata":{"id":"SG_X_FwShRtU"},"source":["#### Função de inicialização wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d_lIIswhRtU"},"outputs":[],"source":["def inicializacaoWandb():\n","\n","  if model_args.use_wandb:\n","\n","    # Importando a biblioteca.\n","    import wandb\n","\n","    #Login via linha de comando\n","    !wandb login aded3bc0ea651fff536cc08ba69caf8ac4141cfd\n","\n","    # Inicializando o registro do experimento.\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    wandb.init(project=NOME_BASE_SAIDA, name=NOME_BASE_SAIDA)\n","\n","    # Atualiza os parâmetros do modelo no wandb.\n","    wandb.config.update(model_args)\n","\n","    # Registra os parämetros não literais do model_args.\n","    wandb.log({'max_seq_len': model_args.max_seq_len})\n","    wandb.log({'do_lower_case': model_args.do_lower_case})\n","    wandb.log({'output_hidden_states': model_args.output_hidden_states})\n","    wandb.log({\"documentos_perturbados\": model_args.documentos_perturbados})\n","    wandb.log({\"top_k_predicao\": model_args.top_k_predicao})\n","\n","    return wandb"]},{"cell_type":"markdown","metadata":{"id":"kw0qQ6zoQhkq"},"source":["### 5.4.2 Função quer realiza a medição de um documento\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PDHaHnU-5yXx"},"source":["#### getMedidasTopica"]},{"cell_type":"code","source":["# Import das biblitecas\n","import gensim\n","import gensim.corpora as corpora\n","from gensim.models import CoherenceModel\n","\n","def getCoerenciasTopica(textos, dados_palavras, numero_topicos = 2):\n","\n","    # Criando o dicionário com as palavras a serem analisadas do corpus de referência e conjunto de dados\n","    id2word = corpora.Dictionary(textos)\n","\n","    # Criando o corpus\n","    # Ocorrência das palavras a serem analisadas no corpus\n","    # Frequência de termos no documento (Term Document Frequency)\n","    corpus = [id2word.doc2bow(texto) for texto in textos]\n","\n","    # Calcular pontuação de coerência 'c_uci'\n","    coherence_model = CoherenceModel(topics=dados_palavras,\n","                                     texts=textos,\n","                                     corpus=corpus,\n","                                     dictionary=id2word,\n","                                     coherence='c_uci')\n","\n","    coherence_model_valor_u_uci = coherence_model.get_coherence()\n","\n","    # Calcular pontuação de coerência 'c_npmi'\n","    coherence_model = CoherenceModel(topics=dados_palavras,\n","                                     texts=textos,\n","                                     dictionary=id2word,\n","                                     coherence='c_npmi')\n","\n","    coherence_model_valor_c_npmi = coherence_model.get_coherence()\n","\n","        # Calcular pontuação de coerência c_v\n","    coherence_model = CoherenceModel(topics=dados_palavras,\n","                                         texts=textos,\n","                                         corpus=corpus,\n","                                         dictionary=id2word,\n","                                         coherence='c_v')\n","\n","    coherence_model_valor_c_v = coherence_model.get_coherence()\n","\n","    # Calcular pontuação de coerência 'u_mass'\n","    coherence_model = CoherenceModel(topics=dados_palavras,\n","                                     texts=textos,\n","                                     corpus=corpus,\n","                                     dictionary=id2word,\n","                                     coherence='u_mass')\n","\n","    coherence_model_valor_u_mass = coherence_model.get_coherence()\n","\n","    return coherence_model_valor_u_uci, coherence_model_valor_c_npmi, coherence_model_valor_c_v, coherence_model_valor_u_mass"],"metadata":{"id":"xFFG3XgzmC5F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXNhBApgbULb"},"source":["### 5.4.3 Função que realiza a medição de todos os documentos"]},{"cell_type":"code","source":["def dadosTratadoCorpus(texto, filtro_palavra):\n","\n","  sentencia=False\n","\n","  # Todas as palavras com pontuação\n","  if filtro_palavra == 0:\n","    corpus = preparaCorpus(texto,\n","                           sentenciaTexto=sentencia,\n","                           tornaMinusculo=model_args.do_lower_case,\n","                           removePontuacao=False)\n","  else:\n","    # Sem as stopwords com pontuação\n","    if filtro_palavra == 1:\n","      corpus = preparaCorpus(texto,\n","                             sentenciaTexto=sentencia,\n","                             tornaMinusculo=model_args.do_lower_case,\n","                             removePontuacao=False,\n","                             removeStopwords=True)\n","    else:\n","      # Somente palavras relevantes Verbos, Verbos Auxiliares e Substantivos com pontuação\n","      if filtro_palavra == 2:\n","        corpus = preparaCorpus(texto,\n","                               sentenciaTexto=sentencia,\n","                               tornaMinusculo=model_args.do_lower_case,\n","                               removePontuacao=False,\n","                               removeStopwords=False,\n","                               somenteRelevante=True)\n","      else:\n","        # Todas as palavras e sem pontuação\n","        if filtro_palavra == 3:\n","          corpus = preparaCorpus(texto,\n","                                sentenciaTexto=sentencia,\n","                                tornaMinusculo=model_args.do_lower_case,\n","                                removePontuacao=True)\n","        else:\n","          # Sem as stopwords e sem pontuação\n","          if filtro_palavra == 4:\n","            corpus = preparaCorpus(texto,\n","                                  sentenciaTexto=sentencia,\n","                                  tornaMinusculo=model_args.do_lower_case,\n","                                  removePontuacao=True,\n","                                  removeStopwords=True)\n","          else:\n","            # Somente palavras relevantes Verbos, Verbos Auxiliares e Substantivos e sem pontuação\n","            if filtro_palavra == 5:\n","              corpus = preparaCorpus(texto,\n","                                    sentenciaTexto=sentencia,\n","                                    tornaMinusculo=model_args.do_lower_case,\n","                                    removePontuacao=True,\n","                                    removeStopwords=False,\n","                                    somenteRelevante=True)\n","\n","  return corpus"],"metadata":{"id":"s1HskvrwnpZW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XP4eqsBsfzLV"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def calculaMedidasDocumentos(corpus,\n","                             lista_documentos_agrupados,\n","                             wandb,\n","                             filtro_palavra):\n","\n","  '''\n","    Percorre os documentos para calcular as medidas das sentenças\n","  '''\n","\n","  logging.info(\"Processando {} pares de documentos originais e perturbados.\".format(len(lista_documentos_agrupados)))\n","\n","  # Contadores de ocorrência de coerência\n","  conta_coherence_model_valor_u_uci = 0\n","  conta_coherence_model_valor_c_npmi = 0\n","  conta_coherence_model_valor_c_v = 0\n","  conta_coherence_model_valor_c_umass = 0\n","  conta = 0\n","\n","  # Retorna os dados tratados do corpus\n","  corpus_tratado = dadosTratadoCorpus(corpus['sentenca'].values.tolist(),filtro_palavra)\n","  # print(\"corpus_tratado:\",corpus_tratado)\n","\n","  # Lista para o salvamento das medidas\n","  lista_medidas_documentos_salvar = []\n","\n","  # Barra de progresso dos documentos\n","  lista_documentos_agrupados_bar = tqdm_notebook(lista_documentos_agrupados.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_agrupados))\n","\n","  # Percorre os documentos do conjunto de dados\n","  for i, linha_documento in lista_documentos_agrupados_bar:\n","    # if i < 5:\n","\n","      # Conta o número de pares de documentos\n","      conta = conta + 1\n","\n","      #print(\"linha_documento:\",linha_documento)\n","      # Recupera o id do documento Original\n","      id_documento_original = linha_documento[0]\n","      # print(\"id_documento_original:\",id_documento_original)\n","      lista_sentenca_documento_original = linha_documento[1]\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      # Recupera o documento Original\n","      documento_original = linha_documento[2]\n","      # print(\"documento_original:\",documento_original)\n","      # Recupera os tokens do documento original\n","      lista_tokens_documento_original = linha_documento[3]\n","      #print(\"lista_tokens_documento_original:\",lista_tokens_documento_original)\n","      #print(\"len(lista_tokens_documento_original):\",len(lista_tokens_documento_original))\n","      # Recupera o postagging do documento original\n","      lista_pos_documento_original = linha_documento[4]\n","      #print(\"lista_pos_documento_original:\",lista_pos_documento_original)\n","      #print(\"len(lista_pos_documento_original):\",len(lista_pos_documento_original))\n","\n","      # Calcula a coerencia do documento\n","      # Retorna os dados tratados do documento\n","      doc_original_tratado = dadosTratadoCorpus([documento_original],filtro_palavra)\n","\n","      # print(\"doc_original_tratado:\",doc_original_tratado)\n","      coherence_model_valor_u_uci_orig, coherence_model_valor_c_npmi_orig, coherence_model_valor_c_v_orig, coherence_model_valor_c_umass_orig = getCoerenciasTopica(corpus_tratado, doc_original_tratado)\n","\n","      # Recupera o id do documento Perturbado\n","      id_documento_perturbado = linha_documento[5]\n","      # print(\"id_documento_perturbado:\",id_documento_perturbado)\n","      lista_sentenca_documento_perturbado = linha_documento[6]\n","      #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","      #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","      # Recupera o documento Perturbado\n","      documento_perturbado = linha_documento[7]\n","      #print(\"documento_perturbado:\",documento_perturbado)\n","      # Recupera os tokens do documento perturbado\n","      lista_tokens_documento_perturbado = linha_documento[8]\n","      #print(\"lista_tokens_documento_perturbado:\",lista_tokens_documento_perturbado)\n","      #print(\"len(lista_tokens_documento_perturbado):\",len(lista_tokens_documento_perturbado))\n","      # Recupera o postagging do documento original\n","      lista_pos_documento_perturbado = linha_documento[9]\n","      #print(\"lista_pos_documento_perturbado:\",lista_pos_documento_perturbado)\n","      #print(\"len(lista_pos_documento_perturbado):\",len(lista_pos_documento_perturbado))\n","\n","      # Calcula a coerencia do documento\n","      # Retorna os dados tratados do documento\n","      doc_perturbado_tratado = dadosTratadoCorpus([documento_perturbado],filtro_palavra)\n","\n","      # print(\"doc_perturbado_tratado:\",doc_perturbado_tratado)\n","      coherence_model_valor_u_uci_pert, coherence_model_valor_c_npmi_pert, coherence_model_valor_c_v_pert, coherence_model_valor_c_umass_pert = getCoerenciasTopica(corpus_tratado,doc_perturbado_tratado)\n","\n","      # Verifica a medida de coerência u_uci das sentenças do documento original com as sentenças do documento pertubado.\n","      # Quanto menor o valor de Ceuc mais as documentos do documentos são coerentes\n","      if coherence_model_valor_u_uci_orig >= coherence_model_valor_u_uci_pert:\n","          conta_coherence_model_valor_u_uci = conta_coherence_model_valor_u_uci + 1\n","\n","      # Verifica a medida de coerência c_npmi das sentenças do documento original com as sentenças do documento pertubado.\n","      # Quanto menor o valor de Ceuc mais as documentos do documentos são coerentes\n","      if coherence_model_valor_c_npmi_orig >= coherence_model_valor_c_npmi_pert:\n","          conta_coherence_model_valor_c_npmi = conta_coherence_model_valor_c_npmi + 1\n","\n","      # Verifica a medida de coerência c_v das sentenças do documento original com as sentenças do documento pertubado.\n","      # Quanto maior o valor de coherence_model_valor_c_v_orig mais as documentos do documentos são coerentes\n","      if coherence_model_valor_c_v_orig >= coherence_model_valor_c_v_pert:\n","          conta_coherence_model_valor_c_v = conta_coherence_model_valor_c_v + 1\n","\n","      # Verifica a medida de coerência c_umass das sentenças do documento original com as sentenças do documento pertubado.\n","      # Quanto menor o valor de Ceuc mais as documentos do documentos são coerentes\n","      if coherence_model_valor_c_umass_orig >= coherence_model_valor_c_umass_pert:\n","          conta_coherence_model_valor_c_umass = conta_coherence_model_valor_c_umass + 1\n","\n","      # Guarda as medidas em uma lista para salvar em arquivo\n","      # Guarda as medidas dos documentos originais\n","      lista_medidas_documentos_salvar.append([id_documento_original,\n","                                              coherence_model_valor_u_uci_orig,\n","                                              coherence_model_valor_c_npmi_orig,\n","                                              coherence_model_valor_c_v_orig,\n","                                              coherence_model_valor_c_umass_orig])\n","      # Guarda as medidas dos documentos perturbados\n","      lista_medidas_documentos_salvar.append([id_documento_perturbado,\n","                                              coherence_model_valor_u_uci_pert,\n","                                              coherence_model_valor_c_npmi_pert,\n","                                              coherence_model_valor_c_v_pert,\n","                                              coherence_model_valor_c_umass_pert])\n","\n","  logging.info(\"Total de Pares : {}.\".format(str(conta)))\n","\n","  if model_args.use_wandb:\n","       wandb.log({'pares_doc': conta})\n","\n","  logging.info(\"Pares Corretos u_uci {}.\".format(str(conta_coherence_model_valor_u_uci)))\n","  acuracia_u_uci = float(conta_coherence_model_valor_u_uci)/float(conta)\n","  logging.info(\"Acurácia: {}.\".format(str(acuracia_u_uci*100)))\n","\n","  if model_args.use_wandb:\n","    wandb.log({'acuracia_u_uci': acuracia_u_uci})\n","\n","  logging.info(\"Pares Corretos c_npmi {}.\".format(str(conta_coherence_model_valor_c_npmi)))\n","  acuracia_c_npmi = float(conta_coherence_model_valor_c_npmi)/float(conta)\n","  logging.info(\"Acurácia: {}.\".format(str(acuracia_c_npmi*100)))\n","\n","  if model_args.use_wandb:\n","    wandb.log({'acuracia_c_npmi': acuracia_c_npmi})\n","\n","  logging.info(\"Pares Corretos c_v: {}.\".format(str(conta_coherence_model_valor_c_v)))\n","  acuracia_c_v = float(conta_coherence_model_valor_c_v)/float(conta)\n","  logging.info(\"Acurácia: {}.\".format(str(acuracia_c_v*100)))\n","\n","  if model_args.use_wandb:\n","    wandb.log({'acuracia_c_v': acuracia_c_v})\n","\n","  logging.info(\"Pares Corretos u_mass {}.\".format(str(conta_coherence_model_valor_c_umass)))\n","  acuracia_c_umass = float(conta_coherence_model_valor_c_umass)/float(conta)\n","  logging.info(\"Acurácia: {}.\".format(str(acuracia_c_umass*100)))\n","\n","  if model_args.use_wandb:\n","    wandb.log({'acuracia_c_umass': acuracia_c_umass})\n","\n","  logging.info(\"TERMINADO!\")\n","\n","  del lista_documentos_agrupados_bar\n","\n","  return lista_medidas_documentos_salvar, conta, acuracia_c_v, conta_coherence_model_valor_c_v, acuracia_c_umass, conta_coherence_model_valor_c_umass,  acuracia_u_uci, conta_coherence_model_valor_u_uci, acuracia_c_npmi, conta_coherence_model_valor_c_npmi"]},{"cell_type":"markdown","metadata":{"id":"-Tdv2JGeohRH"},"source":["### 5.4.4 Salvando os resultados"]},{"cell_type":"markdown","metadata":{"id":"LBs_KgMz1UW1"},"source":["#### Salvando o resultado da medição"]},{"cell_type":"code","source":["def salvaResultadoMedicao(lista_medidas_documentos_salvar):\n","\n","  if model_args.salvar_medicao:\n","\n","    # Import das bibliotecas.\n","    import os\n","    import datetime\n","\n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","\n","    FILTRO_PALAVRA = '_tap' # Todas as palavras\n","    if model_args.filtro_palavra == 1:\n","      FILTRO_PALAVRA = '_ssw'  # Sem stopwords\n","    else:\n","      if model_args.filtro_palavra == 2:\n","        FILTRO_PALAVRA = '_svs'  # Somente verbos(e auxiliares) e substantivos\n","      else:\n","        if model_args.filtro_palavra == 3:\n","          FILTRO_PALAVRA = '_sp_tap'  # Todas as palavras e sem pontuação\n","        else:\n","          if model_args.filtro_palavra == 4:\n","            FILTRO_PALAVRA = '_sp_ssw'  # Sem stopwords e substantivos e sem pontuação\n","          else:\n","            if model_args.filtro_palavra == 5:\n","              FILTRO_PALAVRA = '_sp_svs'  # Somente verbos(e auxiliares) e substantivos e sem pontuação\n","\n","    # Contatena os parâmetros que forma o nome do arquivo medição\n","    NOME_ARQUIVO_MEDICAO = NOME_BASE_SAIDA + \"_P_\" + str(model_args.documentos_perturbados) + \"_K_\" + str(model_args.top_k_predicao) + FILTRO_PALAVRA\n","\n","    # Diretório do drive do arquivo\n","    DIRETORIO_MEDICAO_DRIVE = DIRETORIO_DRIVE + \"validacao_medicao_topico_palavra/Medicao/\"\n","\n","    # Diretório local para salvar o arquivo\n","    DIRETORIO_MEDICAO_LOCAL = DIRETORIO_LOCAL + \"Medicao/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_MEDICAO_DRIVE):\n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_MEDICAO_DRIVE)\n","      logging.info(\"Diretório criado: {}.\".format(DIRETORIO_MEDICAO_DRIVE))\n","    else:\n","      logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_MEDICAO_DRIVE))\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_MEDICAO_LOCAL):\n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_MEDICAO_LOCAL)\n","      logging.info(\"Diretório criado: {}.\".format(DIRETORIO_MEDICAO_LOCAL))\n","    else:\n","      logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_MEDICAO_LOCAL))\n","\n","    # Caminho completo do arquivo compactado no drive\n","    NOME_ARQUIVO_MEDICAO_DRIVE_COMPACTADO = DIRETORIO_MEDICAO_DRIVE + NOME_ARQUIVO_MEDICAO + \".zip\"\n","    # print(\"NOME_ARQUIVO_MEDICAO_DRIVE_COMPACTADO:\", NOME_ARQUIVO_MEDICAO_DRIVE_COMPACTADO)\n","\n","    # Caminho completo do arquivo compactado no local\n","    NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO = DIRETORIO_MEDICAO_LOCAL + NOME_ARQUIVO_MEDICAO + \".zip\"\n","    # print(\"NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO:\", NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO)\n","\n","    # Caminho completo do arquivo no local\n","    NOME_ARQUIVO_MEDICAO_LOCAL = DIRETORIO_MEDICAO_LOCAL + NOME_ARQUIVO_MEDICAO + \".csv\"\n","    # print(\"NOME_ARQUIVO_MEDICAO_LOCAL:\", NOME_ARQUIVO_MEDICAO_LOCAL)\n","\n","    # Gera todo o conteúdo a ser salvo no arquivo\n","    novo_conteudo = ''\n","    for resultado in lista_medidas_documentos_salvar:\n","      novo_conteudo = novo_conteudo + data_e_hora.strftime('%d/%m/%Y %H:%M') + ';'  + str(resultado[0]) + ';'  + str(resultado[1]) + ';'  + str(resultado[2]) + ';'  + str(resultado[3]) + ';' + str(resultado[4]) + '\\n'\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_MEDICAO_DRIVE_COMPACTADO):\n","      # Copia arquivo da medição compactado do google drive para o drive local\n","      !cp \"$NOME_ARQUIVO_MEDICAO_DRIVE_COMPACTADO\" \"$NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO\"\n","      # Descompacta arquivo da medição compactado no drive local\n","      !unzip -o -j -q \"$NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO\" -d \"$DIRETORIO_MEDICAO_LOCAL\"\n","\n","      logging.info(\"Atualizando arquivo medição: {}.\".format(NOME_ARQUIVO_MEDICAO_LOCAL))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_MEDICAO_LOCAL,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novo_conteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_MEDICAO_LOCAL,'w')\n","      # Escreve o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)\n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      # Compacta o arquivo da medição\n","      !zip -o -q -j \"$NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO\" \"$NOME_ARQUIVO_MEDICAO_LOCAL\"\n","      # Copia o arquivo da medição compactado para o drive\n","      !cp \"$NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO\" \"$NOME_ARQUIVO_MEDICAO_DRIVE_COMPACTADO\"\n","\n","    else:\n","      logging.info(\"Criando arquivo medição: {}.\".format(NOME_ARQUIVO_MEDICAO_LOCAL))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_MEDICAO_LOCAL,'w')\n","      arquivo.writelines('data;arquivo;c_uci;c_npmi;c_v;c_umass\\n' + novo_conteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      # Compacta o arquivo da medição\n","      !zip -o -q -j \"$NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO\" \"$NOME_ARQUIVO_MEDICAO_LOCAL\"\n","      # Copia o arquivo da medição compactado para o drive\n","      !cp \"$NOME_ARQUIVO_MEDICAO_LOCAL_COMPACTADO\" \"$NOME_ARQUIVO_MEDICAO_DRIVE_COMPACTADO\""],"metadata":{"id":"RTAInEL7RZTA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3oghc7L7ohRH"},"source":["#### Salvando o resultado da avaliação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DL3D6GbKohRI"},"outputs":[],"source":["def salvaResultadoAvaliacao(tempo_total_processamento,\n","                            conta,\n","                            acuracia_u_uci,\n","                            conta_coherence_model_valor_u_uci,\n","                            acuracia_c_npmi,\n","                            conta_coherence_model_valor_c_npmi,\n","                            acuracia_c_v,\n","                            conta_coherence_model_valor_c_v,\n","                            acuracia_c_umass,\n","                            conta_coherence_model_valor_c_umass):\n","\n","  if model_args.salvar_avaliacao:\n","\n","    # Import das bibliotecas.\n","    import os\n","\n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","\n","    FILTRO_PALAVRA = '_tap' # Todas as palavras\n","    if model_args.filtro_palavra == 1:\n","      FILTRO_PALAVRA = '_ssw'  # Sem stopwords\n","    else:\n","      if model_args.filtro_palavra == 2:\n","        FILTRO_PALAVRA = '_svs'  # Somente verbos(e auxiliares) e substantivos\n","      else:\n","        if model_args.filtro_palavra == 3:\n","          FILTRO_PALAVRA = '_sp_tap'  # Todas as palavras e sem pontuação\n","        else:\n","          if model_args.filtro_palavra == 4:\n","            FILTRO_PALAVRA = '_sp_ssw'  # Sem stopwords e substantivos e sem pontuação\n","          else:\n","            if model_args.filtro_palavra == 5:\n","              FILTRO_PALAVRA = '_sp_svs'  # Somente verbos(e auxiliares) e substantivos e sem pontuação\n","\n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_AVALIACAO = NOME_BASE_SAIDA + \"_P_\" + str(model_args.documentos_perturbados) + \"_K_\" + str(model_args.top_k_predicao) + FILTRO_PALAVRA\n","\n","    # Diretório para salvar o arquivo de resultado.\n","    DIRETORIO_AVALIACAO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_medicao_topico_palavra/Avaliacao/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_AVALIACAO):\n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_AVALIACAO)\n","      logging.info(\"Diretório criado: {}.\".format(DIRETORIO_AVALIACAO))\n","    else:\n","      logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_AVALIACAO))\n","\n","    # Nome do arquivo a ser aberto.\n","    NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + '.csv'\n","\n","    # Conteúdo a ser adicionado.\n","    novo_conteudo = NOME_ARQUIVO_AVALIACAO + ';' + data_e_hora.strftime('%d/%m/%Y %H:%M') + ';' + tempo_total_processamento + ';'  + str(conta) + ';' + str(acuracia_u_uci) + ';' + str(conta_coherence_model_valor_u_uci) + ';' + str(acuracia_c_npmi) + ';' + str(conta_coherence_model_valor_c_npmi) + ';' + str(acuracia_c_v) + ';' + str(conta_coherence_model_valor_c_v) + ';' + str(acuracia_c_umass) + ';' + str(conta_coherence_model_valor_c_umass) + '\\n'\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","      logging.info(\"Atualizando arquivo resultado avaliação: {}.\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novo_conteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)\n","      # Fecha o arquivo.\n","      arquivo.close()\n","    else:\n","      logging.info(\"Criando arquivo resultado avaliação: {}.\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      arquivo.writelines('arquivo;data;tempo;conta;c_uci;contac_uci;c_npmi;contac_npmi;c_v;contac_v;c_umass;contac_umass\\n' + novo_conteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"VNquK8k3ohRE"},"source":["### 5.4.5 Função de cálculo das medidas dos documentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Iud3NTDvtzG"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","import gc\n","\n","def procedimentoCalculaMedida(filtro_palavra):\n","\n","  # Seta o parâmetro do fitro (ALL,CLEAN,VERNOUN)\n","  model_args.filtro_palavra = filtro_palavra\n","\n","  logging.info(\"Processamento filtro palavra {}.\".format(FILTRO_PALAVRAS_STR[filtro_palavra]))\n","\n","  # Marca o tempo de início do processamento\n","  tempoInicioTeste = time.time()\n","  logging.info(\"Tempo início processamento: {:} (h:mm:ss).\".format(formataTempo(tempoInicioTeste)))\n","\n","  # Inicializa o wandb para registro\n","  wandb = inicializacaoWandb()\n","\n","  # Calcula as medidas dos documentos\n","  resultado_medida, conta, acuracia_u_uci, conta_coherence_model_valor_u_uci, acuracia_c_npmi, conta_coherence_model_valor_c_npmi, acuracia_c_v, conta_coherence_model_valor_c_v, acuracia_c_umass, conta_coherence_model_valor_c_umass = calculaMedidasDocumentos(df_corpus, lista_documentos_agrupados, wandb, filtro_palavra)\n","\n","  # Pega o tempo atual menos o tempo do início do processamento.\n","  tempoFinalTeste = time.time()\n","  tempo_total_processamento = formataTempo(tempoFinalTeste - tempoInicioTeste)\n","\n","  # Salva o resultado da classificação\n","  salvaResultadoMedicao(resultado_medida)\n","\n","  # Salva o resultado da avaliação\n","  salvaResultadoAvaliacao(tempo_total_processamento, conta, acuracia_u_uci, conta_coherence_model_valor_u_uci, acuracia_c_npmi, conta_coherence_model_valor_c_npmi, acuracia_c_v, conta_coherence_model_valor_c_v, acuracia_c_umass, conta_coherence_model_valor_c_umass)\n","\n","  logging.info(\"  Tempo processamento: {:} (h:mm:ss).\\n\".format(tempo_total_processamento))\n","\n","  # Finaliza o wandb\n","  if model_args.use_wandb:\n","     wandb.finish()\n","\n","  # Apaga as variáveis\n","  del resultado_medida\n","  del wandb\n","\n","  # Chama o coletor de lixo para esvaziar a memória\n","  gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"HQBuXxeGrCaY"},"source":["### 5.4.6 Executa o procedimento para todos os parâmetros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQKqYDNrrCrD","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["96f5f02f18a34ad8b7bc2f1acb14d040","e97f1b42d3244846bd9a1072b6b77276","f1060aebf615498fb469a13e1ce455a7","91fedc567d024a7e8ac91924fac6c728","7eb36b49828e4a8d9e111d85712d7be2","178e1cfd393644e1951db5b784b1b9a2","6e2c0904ecdd4ffeb36fd119b0cc8932","f3845078dd044311ab4e1eafb4893211","fe26679890944431bc1d7a2e9018ca83","27a4e8e8e399461ca6d61b949c03b748","ad069a75d9fc4b8fb0a77b3d858f2279","79c598c6104848d4bbd64f244c6255ec","192e4d66ae8b4d86a37b0e1681846222","e83d496d69d14971844b9b3c1dbc4522","f40d21a78cec4b5cb4f509c87c7345d3","520a0cadf50f49d48ad1f047656d59fa","d3f02597113b458bb72af5c4cb5ae1fc","c09542d52e5a4ddc86a538f8c9aa904d","c052ff7e35c54350a20da096408ecdb8","15923202b5cd4f9eb71f4c17b4b00304","5643dc57a29c44a58ef98adc697a1d94","5f5462368b3743ac93eea940e20fec27","b6cd47ffb5f94106a90b21aaf36ea310","9e2abdc8dee84ab5b9ff4f15dff96ea0","1a5ac533461e47f4ac7c924cdfa49974","ecc89b8b2b184778980b50cd07461aa5","2211f899407841c3a18a7bd745a144f1","1f7ce57dd6ba45109f12c999b6a01ba2","ed10a57513284e7baa351b0e7f09d6da","c0908ecd039f4b6ca2329e7faa7e49c3","25d66a7109684017b8aad060891e3c97","6c71c405c68a48408d33948dc21b5523","0ffa5907f42f46ceb9dd4b313fe79ef1","7730bf179f074f6fb277e65e6b6a0357","47a48c45eccb45858f086d62df627251","b73bef897718415a81f22591e74327b7","52f00c75f93041c18703da34c411c1b6","52dccbb780f4483ab6ba8ee79a35e7c0","64b0952497c64971a091f226a5d42ca3","dec30fd978804514bce9e83bac9c95d7","8a09a81f00704ed4b875e0a981fcd667","ad719012cc0c4efc84b3625856bcd3e9","5cc48a7414fe4f708eb059d20c1288f7","c166466bcfae491c8413a47cc86cdf92","548825fa076c4920b2db7bc8def930e5","6e4bceddd1e6457da0d249097af6f95e","9a9fcd60191548cb86549706d34482e4","24fc20f5ada44b69ac10510abb34ac61","dfd00a56b1a44c93a29d1185d9e74668","48572fbc6c91435a83ee8839037f5988","e331137c7fde4841b71b410863ee8728","9a22edbe10644ffd95c8cee36658ce5f"]},"executionInfo":{"status":"ok","timestamp":1668447819065,"user_tz":180,"elapsed":50678,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ea8c9178-c6c8-4ee3-c618-12fb88fd587d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Filtro palavras:   0%|          | 0/3 [00:00<?, ?filtro/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96f5f02f18a34ad8b7bc2f1acb14d040"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Processamento filtro palavra SEM_PONTUACAO_ALL.\n","INFO:root:Tempo início processamento: 19310 days, 17:42:48 (h:mm:ss).\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mosmar-braz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221114_174255-14kompz6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/14kompz6\" target=\"_blank\">MedidaTopico_DefaultCohQuADInitptbr_v1</a></strong> to <a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Processando 20 pares de documentos originais e perturbados.\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/20 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c598c6104848d4bbd64f244c6255ec"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:42:59.122119', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:42:59.242992', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:42:59.357802', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:42:59.487220', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:42:59.606193', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:42:59.716116', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:42:59.822829', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:42:59.941023', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:00.079117', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:00.206551', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:00.335932', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:00.475753', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:00.646253', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:00.762999', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:00.877627', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:01.004228', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:01.151773', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:01.302250', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:01.474157', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:01.643456', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:01.792966', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:01.933052', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:02.074631', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:02.252785', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:02.405821', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:02.565091', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:02.744988', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:02.897496', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:03.055552', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:03.195866', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:03.369770', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:03.524224', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:03.688559', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:03.851063', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:04.011966', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:04.151345', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:04.325199', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:04.464272', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:04.600079', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<565 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 1776 corpus positions)\", 'datetime': '2022-11-14T17:43:04.736763', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.text_analysis:WordOccurrenceAccumulator accumulated stats from 1000 documents\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:root:Total de Pares : 20.\n","INFO:root:Pares Corretos u_uci 16.\n","INFO:root:Acurácia: 80.0.\n","INFO:root:Pares Corretos c_npmi 16.\n","INFO:root:Acurácia: 80.0.\n","INFO:root:Pares Corretos c_v: 12.\n","INFO:root:Acurácia: 60.0.\n","INFO:root:Pares Corretos u_mass 17.\n","INFO:root:Acurácia: 85.0.\n","INFO:root:TERMINADO!\n","INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Medicao/.\n","INFO:root:Diretório criado: /content/COHQUAD_INIT_PTBR/Medicao/.\n","INFO:root:Criando arquivo medição: /content/COHQUAD_INIT_PTBR/Medicao/MedidaTopico_DefaultCohQuADInitptbr_v1_P_1_K_1_sp_tap.csv.\n","INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Avaliacao/.\n","INFO:root:Criando arquivo resultado avaliação: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Avaliacao/MedidaTopico_DefaultCohQuADInitptbr_v1_P_1_K_1_sp_tap.csv.\n","INFO:root:  Tempo processamento: 0:00:17 (h:mm:ss).\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acuracia_c_npmi</td><td>▁</td></tr><tr><td>acuracia_c_umass</td><td>▁</td></tr><tr><td>acuracia_c_v</td><td>▁</td></tr><tr><td>acuracia_u_uci</td><td>▁</td></tr><tr><td>do_lower_case</td><td>▁</td></tr><tr><td>documentos_perturbados</td><td>▁</td></tr><tr><td>output_hidden_states</td><td>▁</td></tr><tr><td>pares_doc</td><td>▁</td></tr><tr><td>top_k_predicao</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acuracia_c_npmi</td><td>0.8</td></tr><tr><td>acuracia_c_umass</td><td>0.85</td></tr><tr><td>acuracia_c_v</td><td>0.6</td></tr><tr><td>acuracia_u_uci</td><td>0.8</td></tr><tr><td>do_lower_case</td><td>True</td></tr><tr><td>documentos_perturbados</td><td>1</td></tr><tr><td>output_hidden_states</td><td>False</td></tr><tr><td>pares_doc</td><td>20</td></tr><tr><td>top_k_predicao</td><td>1</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">MedidaTopico_DefaultCohQuADInitptbr_v1</strong>: <a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/14kompz6\" target=\"_blank\">https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/14kompz6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221114_174255-14kompz6/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Processamento filtro palavra SEM_PONTUACAO_SEM_STOPWORDS.\n","INFO:root:Tempo início processamento: 19310 days, 17:43:08 (h:mm:ss).\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221114_174309-dii3te5u</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/dii3te5u\" target=\"_blank\">MedidaTopico_DefaultCohQuADInitptbr_v1</a></strong> to <a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Processando 20 pares de documentos originais e perturbados.\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/20 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6cd47ffb5f94106a90b21aaf36ea310"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:14.853711', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.118516', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.303932', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.376051', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.450257', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.521489', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.598054', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.670069', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.758306', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.850918', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:15.945887', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.027650', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.116529', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.185964', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.270957', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.372248', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.455868', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.527901', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.621484', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.698431', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.784188', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.850631', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:16.956641', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.037374', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.132044', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.204636', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.295882', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.379041', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.474725', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.554786', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.649362', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.724826', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.810367', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.895627', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:17.984142', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:18.084208', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:18.168470', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:18.239955', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:18.351345', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<446 unique tokens: ['abstrato', 'baseado', 'caracterizando', 'ciência', 'computação']...> from 104 documents (total 917 corpus positions)\", 'datetime': '2022-11-14T17:43:18.438643', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:root:Total de Pares : 20.\n","INFO:root:Pares Corretos u_uci 19.\n","INFO:root:Acurácia: 95.0.\n","INFO:root:Pares Corretos c_npmi 19.\n","INFO:root:Acurácia: 95.0.\n","INFO:root:Pares Corretos c_v: 18.\n","INFO:root:Acurácia: 90.0.\n","INFO:root:Pares Corretos u_mass 19.\n","INFO:root:Acurácia: 95.0.\n","INFO:root:TERMINADO!\n","INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Medicao/.\n","INFO:root:Diretório já existe: /content/COHQUAD_INIT_PTBR/Medicao/.\n","INFO:root:Criando arquivo medição: /content/COHQUAD_INIT_PTBR/Medicao/MedidaTopico_DefaultCohQuADInitptbr_v1_P_1_K_1_sp_ssw.csv.\n","INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Avaliacao/.\n","INFO:root:Criando arquivo resultado avaliação: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Avaliacao/MedidaTopico_DefaultCohQuADInitptbr_v1_P_1_K_1_sp_ssw.csv.\n","INFO:root:  Tempo processamento: 0:00:10 (h:mm:ss).\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7730bf179f074f6fb277e65e6b6a0357"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acuracia_c_npmi</td><td>▁</td></tr><tr><td>acuracia_c_umass</td><td>▁</td></tr><tr><td>acuracia_c_v</td><td>▁</td></tr><tr><td>acuracia_u_uci</td><td>▁</td></tr><tr><td>do_lower_case</td><td>▁</td></tr><tr><td>documentos_perturbados</td><td>▁</td></tr><tr><td>output_hidden_states</td><td>▁</td></tr><tr><td>pares_doc</td><td>▁</td></tr><tr><td>top_k_predicao</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acuracia_c_npmi</td><td>0.95</td></tr><tr><td>acuracia_c_umass</td><td>0.95</td></tr><tr><td>acuracia_c_v</td><td>0.9</td></tr><tr><td>acuracia_u_uci</td><td>0.95</td></tr><tr><td>do_lower_case</td><td>True</td></tr><tr><td>documentos_perturbados</td><td>1</td></tr><tr><td>output_hidden_states</td><td>False</td></tr><tr><td>pares_doc</td><td>20</td></tr><tr><td>top_k_predicao</td><td>1</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">MedidaTopico_DefaultCohQuADInitptbr_v1</strong>: <a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/dii3te5u\" target=\"_blank\">https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/dii3te5u</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221114_174309-dii3te5u/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Processamento filtro palavra SEM_PONTUACAO_SOMENTE_VERBOS_SUBSTANTIVOS.\n","INFO:root:Tempo início processamento: 19310 days, 17:43:24 (h:mm:ss).\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221114_174324-c8em6xpy</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/c8em6xpy\" target=\"_blank\">MedidaTopico_DefaultCohQuADInitptbr_v1</a></strong> to <a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Processando 20 pares de documentos originais e perturbados.\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/20 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad719012cc0c4efc84b3625856bcd3e9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:30.998655', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.092996', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.182246', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.258142', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.357412', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.449841', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.543909', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.621987', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.721322', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.799865', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:31.906362', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.014026', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.114305', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.196321', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.296505', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.380751', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.498190', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.635738', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.737758', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.822857', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:32.921103', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.009291', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.111855', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.208061', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.308561', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.391760', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.506795', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.598578', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.696063', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.803265', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:33.914738', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.042534', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.141503', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.229101', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.368128', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.455429', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.571667', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.659492', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.757648', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n","INFO:gensim.corpora.dictionary:built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\n","INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<343 unique tokens: ['baseado', 'caracterizando', 'ciência', 'computação', 'dado']...> from 95 documents (total 786 corpus positions)\", 'datetime': '2022-11-14T17:43:34.834556', 'gensim': '4.2.0', 'python': '3.7.15 (default, Oct 12 2022, 19:14:55) \\n[GCC 7.5.0]', 'platform': 'Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:gensim.topic_coherence.probability_estimation:using WordOccurrenceAccumulator to estimate probabilities from sliding windows\n","INFO:root:Total de Pares : 20.\n","INFO:root:Pares Corretos u_uci 18.\n","INFO:root:Acurácia: 90.0.\n","INFO:root:Pares Corretos c_npmi 17.\n","INFO:root:Acurácia: 85.0.\n","INFO:root:Pares Corretos c_v: 16.\n","INFO:root:Acurácia: 80.0.\n","INFO:root:Pares Corretos u_mass 18.\n","INFO:root:Acurácia: 90.0.\n","INFO:root:TERMINADO!\n","INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Medicao/.\n","INFO:root:Diretório já existe: /content/COHQUAD_INIT_PTBR/Medicao/.\n","INFO:root:Criando arquivo medição: /content/COHQUAD_INIT_PTBR/Medicao/MedidaTopico_DefaultCohQuADInitptbr_v1_P_1_K_1_sp_svs.csv.\n","INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Avaliacao/.\n","INFO:root:Criando arquivo resultado avaliação: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_INIT_PTBR/validacao_medicao_topico_palavra/Avaliacao/MedidaTopico_DefaultCohQuADInitptbr_v1_P_1_K_1_sp_svs.csv.\n","INFO:root:  Tempo processamento: 0:00:11 (h:mm:ss).\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acuracia_c_npmi</td><td>▁</td></tr><tr><td>acuracia_c_umass</td><td>▁</td></tr><tr><td>acuracia_c_v</td><td>▁</td></tr><tr><td>acuracia_u_uci</td><td>▁</td></tr><tr><td>do_lower_case</td><td>▁</td></tr><tr><td>documentos_perturbados</td><td>▁</td></tr><tr><td>output_hidden_states</td><td>▁</td></tr><tr><td>pares_doc</td><td>▁</td></tr><tr><td>top_k_predicao</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acuracia_c_npmi</td><td>0.85</td></tr><tr><td>acuracia_c_umass</td><td>0.9</td></tr><tr><td>acuracia_c_v</td><td>0.8</td></tr><tr><td>acuracia_u_uci</td><td>0.9</td></tr><tr><td>do_lower_case</td><td>True</td></tr><tr><td>documentos_perturbados</td><td>1</td></tr><tr><td>output_hidden_states</td><td>False</td></tr><tr><td>pares_doc</td><td>20</td></tr><tr><td>top_k_predicao</td><td>1</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">MedidaTopico_DefaultCohQuADInitptbr_v1</strong>: <a href=\"https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/c8em6xpy\" target=\"_blank\">https://wandb.ai/osmar-braz/MedidaTopico_DefaultCohQuADInitptbr_v1/runs/c8em6xpy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221114_174324-c8em6xpy/logs</code>"]},"metadata":{}}],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","# Barra de progresso filtro (0 - ALL, 1 - CLEAN, 2 - VERBNOUN)\n","filtro_palavra_bar = tqdm_notebook(enumerate(FILTRO_PALAVRAS), desc=f'Filtro palavras', unit=f'filtro', total=len(FILTRO_PALAVRAS))\n","\n","# Percorre todos formas de filtro de palavras a serem avaliados\n","for filtro_palavra_i, filtro_palavra in filtro_palavra_bar:\n","\n","  # Passa os parâmetros para o procedimento cálculo das medidas\n","  procedimentoCalculaMedida(filtro_palavra)"]},{"cell_type":"markdown","metadata":{"id":"geCGsyphNfkK"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"3EUXuiZNpBtL"},"source":["## 6.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H50_GKJwpDha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668447095666,"user_tz":180,"elapsed":15,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"350a4494-11d8-4f2e-ac2c-fc8da5b92bce"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento:  0:01:40 (h:mm:ss)\n"]}],"source":[" # Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print('')\n","print('  Tempo processamento:  {:} (h:mm:ss)'.format(tempo_total_processamento))"]}]}