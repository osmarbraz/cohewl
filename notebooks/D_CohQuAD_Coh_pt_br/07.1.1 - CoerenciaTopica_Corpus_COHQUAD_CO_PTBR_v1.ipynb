{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcBk/iJC/YH2FlYRYSpsR4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# Criar Corpus Específico do CohQuAD Coh pt-br\n","\n","Geração do corpus específico para o conjunto de dados.\n","\n","\n","Gera as POS-Tagging dos documentos perturbados do conjunto de dados.\n","- Utiliza dados textos sobre o assunto do conjunto de dados.\n","- Gera o arquivo `corpus_especifico.zip`.\n"," \n"]},{"cell_type":"markdown","metadata":{"id":"OP33KWAtBMWs"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"PKUr9Vk4BNLC"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JXclHCRQBSF2"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj5TaAH_5-nB"},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================  \n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.    \n","    \"\"\"\n","    \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):  \n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","    \n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B1mvfAU5jZf"},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","    \n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.      \n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.      \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","    \n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download    \n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]  \n","\n","    # Define o nome e caminho do arquivo temporário    \n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","    \n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","    \n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:        \n","        tamanho_conteudo = data.headers.get(\"Content-Length\")        \n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)                \n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):        \n","            if chunk:                \n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","    \n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","    \n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qwKjGvyLG4v"},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","    \n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jirIzIstLea0"},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.  \n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC9Xppq-_R0w"},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.   \n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    sentencas = []\n","    for linha in arquivo:        \n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkVk5LQT_G3f"},"outputs":[],"source":["def salvar(nome_arquivo,texto):                       \n","    \"\"\"\n","      Salva um texto em arquivo.\n","     \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.     \n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Guy6B4whsZFR"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","    \n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))    "]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModelArguments) de definição dos parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgmN6RqDRDZS"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )    \n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )    "]},{"cell_type":"markdown","metadata":{"id":"SX6jTGkBMNvV"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95qYX7uzMNvX"},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcopxbGZqDip"},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMiH0E3OnRa1"},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3218,"status":"ok","timestamp":1668610542589,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"vtaYZmc3Vbfj","outputId":"25c9ba03-136c-4bf7-8570-126028d3e121"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Dispositivo GPU não encontrado\n"]}],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrjqDO6nWa8J"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","\n","def getDeviceGPU():\n","    \"\"\"\n","      Retorna um dispositivo de GPU se disponível ou CPU.\n","    \n","      Retorno:\n","        `device` - Um device de GPU ou CPU.       \n","    \"\"\"\n","        \n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        \n","        # Diz ao PyTorch para usar GPU.    \n","        device = torch.device(\"cuda\")\n","        \n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:        \n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","        \n","    return device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1668610545015,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ChDxmtXsKwjf","outputId":"aa0bae3c-376a-4cd1-de0f-56c3c3b9e20d"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Sem GPU disponível, usando CPU.\n"]}],"source":["# Recupera o device com GPU ou CPU\n","device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"fGf59D0yVNx9"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1668610545016,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"1iC5-pSAVh7_","outputId":"e587ba22-593c-4356-a054-3b47194a72cb"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}],"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68040,"status":"ok","timestamp":1668610613051,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ysnDDapMQK8K","outputId":"f67591a7-3322-4190-8f03-14d2b1f1f61f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"oOd2MbBiDq93"},"source":["## 1.7 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":611},"executionInfo":{"elapsed":11287,"status":"ok","timestamp":1668610624333,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"EaMM4WdxgvQ7","outputId":"00a3d6b1-268b-481e-9d42-9a919cf28b17"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 52.4 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.38.3)\n","Collecting wheel\n","  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n","Installing collected packages: wheel, setuptools, pip\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.38.3\n","    Uninstalling wheel-0.38.3:\n","      Successfully uninstalled wheel-0.38.3\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n","Successfully installed pip-22.3.1 setuptools-65.5.1 wheel-0.38.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15952,"status":"ok","timestamp":1668610640277,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"w4p3Rz2qDq94","outputId":"696468ef-752f-4106-98e6-64505ff550ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.1)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.8)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.9)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.9)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.10)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.5.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.9.24)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.2\n","    Uninstalling pydantic-1.10.2:\n","      Successfully uninstalled pydantic-1.10.2\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.5\n","    Uninstalling thinc-8.1.5:\n","      Successfully uninstalled thinc-8.1.5\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.2\n","    Uninstalling spacy-3.4.2:\n","      Successfully uninstalled spacy-3.4.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typing-extensions-3.10.0.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"markdown","metadata":{"id":"ZxFiqbpPQ-CR"},"source":["## 1.8 Instalação do Gensim"]},{"cell_type":"markdown","metadata":{"id":"HdjN6H6t_L08"},"source":["Instalando o gensim no Google Colaboratory.\n","\n","No Jupiter Notebook executar através \"Anaconda Prompt\".\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7301,"status":"ok","timestamp":1668610647574,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"BGFVnIzQGrEH","outputId":"a9401a98-f0a1-4b34-b46a-95ff212660d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gensim==4.2.0\n","  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.21.6)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.7.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (5.2.1)\n","Installing collected packages: gensim\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed gensim-4.2.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#!pip install -U gensim\n","!pip install -U gensim==4.2.0"]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uiH9pNpwI6g"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"Mhkc9sW21zV7"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosMedida(     \n","    modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","\n","    versao_modelo_spacy = \"3.2.0\",\n","    \n","    sentenciar_documento = True,\n","    do_lower_case = False, # default True  \n",")"]},{"cell_type":"markdown","metadata":{"id":"ecwtQDArKvZn"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtNygH9qKvmp"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_CO_PTBR\""]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjWGu-9D5URZ"},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","        \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dq9PnXO77bPQ"},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    \n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivo_tar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")    \n","    arquivo_tar.extractall(DIRETORIO_COHEBERT)    \n","    arquivo_tar.close()\n","    \n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):        \n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePOccj0s8WMg"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","    \n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.           \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","                  \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp "]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["b42eb8e8c56849989ff15bd64a2a6891","4fac9ba9e0354dfb88652c51359b44ac","95653dd21b8d4a58ad2b34e53454a486","35b9af196a1247038cd3f64523d120b2","a33761f081ce4651a4a9277a065d1af3","50646a2a042b455cae440ad8c162800d","3481a6b0e8b149e4ab8c6260e0fd4a76","2229d10dc1384df1a1f1c173285530e1","345c5261056440ab94a939f0c5d2188c","ef12a9d471194fa6b1646cf1eb0d1100","ee02c3bc43124a10bd8d56e280dcba92"]},"id":"nbELnrpgA4T1","executionInfo":{"status":"ok","timestamp":1668610689850,"user_tz":180,"elapsed":41162,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"a7253c23-4471-4a68-bb3c-c8590042dc6d"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório Cohebert criado: COHQUAD_CO_PTBR\n","INFO:root:Download do arquivo do modelo do spaCy.\n","INFO:root:Download do arquivo: COHQUAD_CO_PTBR/pt_core_news_lg-3.2.0.tar.gz.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/577M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b42eb8e8c56849989ff15bd64a2a6891"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:Descompactando o arquivo do modelo do spaCy.\n","INFO:root:spaCy carregado.\n"]}],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","metadata":{"id":"AEzytjZi5Iw2"},"source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKg-_XyWoy8o"},"outputs":[],"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","    \n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.           \n","    \"\"\"\n","    \n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords "]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1o8jevtoy8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668610689851,"user_tz":180,"elapsed":31,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"b5f22e5c-8889-409f-f7fe-cfec9f23f587"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Quantidade de stopwords: 416.\n"]},{"output_type":"stream","name":"stdout","text":["{'menos', 'próxima', 'pois', 'quinze', 'pelas', 'apoia', 'final', 'nove', 'tua', 'desse', 'deverá', 'pouca', 'este', 'esse', 'tais', 'pegar', 'número', 'era', 'só', 'faço', 'pela', 'custa', 'nesta', 'estiveram', 'você', 'após', 'nesse', 'nos', 'neste', 'sou', 'ali', 'te', 'fez', 'nossos', 'meus', 'no', 'vosso', 'foste', 'pôde', 'porquê', 'aquele', 'à', 'pode', 'minha', 'quê', 'vais', 'último', 'tempo', 'seu', 'também', 'máximo', 'tentaram', 'meu', 'conhecido', 'quieta', 'novo', 'quieto', 'entre', 'algo', 'devem', 'fazemos', 'local', 'cá', 'quais', 'diz', 'estão', 'conselho', 'essa', 'os', 'ora', 'temos', 'fim', 'vinda', 'outros', 'deste', 'estas', 'segundo', 'for', 'são', 'maioria', 'pelo', 'por', 'sistema', 'fomos', 'poderá', 'foram', 'grande', 'pouco', 'teve', 'pelos', 'caminho', 'cinco', 'elas', 'sei', 'tentei', 'estivestes', 'ao', 'ou', 'certamente', 'dezassete', 'valor', 'tanto', 'ambas', 'cada', 'numa', 'nosso', 'quanto', 'dizem', 'dos', 'antes', 'isso', 'além', 'todos', 'sempre', 'tudo', 'muitos', 'tiveste', 'quatro', 'seis', 'dezoito', 'ver', 'em', 'podia', 'eu', 'tivestes', 'aí', 'comprido', 'logo', 'usa', 'que', 'dentro', 'depois', 'somente', 'adeus', 'foi', 'menor', 'está', 'qual', 'vezes', 'vens', 'aos', 'com', 'nuns', 'mesmo', 'és', 'mal', 'podem', 'aqui', 'aquela', 'iniciar', 'bom', 'ela', 'minhas', 'na', 'umas', 'tanta', 'todo', 'sexto', 'terceiro', 'desta', 'quarto', 'possível', 'ir', 'apenas', 'quem', 'onze', 'ligado', 'às', 'tão', 'terceira', 'assim', 'puderam', 'ontem', 'sétima', 'oito', 'atrás', 'desde', 'um', 'porém', 'tens', 'dessa', 'me', 'grupo', 'fazer', 'sua', 'talvez', 'posição', 'vai', 'eles', 'lhe', 'catorze', 'é', 'sim', 'daquela', 'sob', 'através', 'geral', 'forma', 'dez', 'tal', 'essas', 'seus', 'posso', 'estes', 'próximo', 'cima', 'dezanove', 'irá', 'somos', 'mil', 'eventual', 'de', 'tente', 'vão', 'dizer', 'novos', 'deve', 'outra', 'tiveram', 'vós', 'outras', 'parece', 'conhecida', 'povo', 'tentar', 'estar', 'isto', 'breve', 'dezasseis', 'portanto', 'direita', 'tarde', 'partir', 'faz', 'favor', 'usar', 'coisa', 'debaixo', 'lado', 'veja', 'suas', 'mês', 'todas', 'num', 'zero', 'nenhuma', 'doze', 'fazia', 'cedo', 'aqueles', 'sois', 'certeza', 'aquilo', 'contra', 'enquanto', 'tive', 'agora', 'corrente', 'vários', 'como', 'baixo', 'três', 'onde', 'estás', 'mas', 'questão', 'meio', 'contudo', 'vêm', 'apontar', 'ter', 'porquanto', 'obrigada', 'vindo', 'poder', 'e', 'fazem', 'sabe', 'daquele', 'teu', 'vos', 'ele', 'grandes', 'uma', 'bem', 'fará', 'muito', 'nossas', 'se', 'põem', 'naquele', 'esta', 'sem', 'vossas', 'estava', 'comprida', 'sexta', 'tenho', 'área', 'da', 'oitavo', 'nossa', 'oitava', 'para', 'têm', 'põe', 'primeiro', 'das', 'treze', 'vocês', 'estivemos', 'esses', 'possivelmente', 'dão', 'nem', 'disso', 'bastante', 'meses', 'estado', 'nunca', 'naquela', 'tu', 'quarta', 'lá', 'então', 'algumas', 'ademais', 'nível', 'duas', 'boa', 'nova', 'já', 'teus', 'vez', 'quinto', 'lugar', 'maiorias', 'fostes', 'quinta', 'esteve', 'pontos', 'momento', 'tipo', 'cujo', 'as', 'segunda', 'saber', 'novas', 'sete', 'do', 'demais', 'acerca', 'nas', 'vinte', 'não', 'uns', 'des', 'sétimo', 'vossa', 'estou', 'alguns', 'dois', 'quando', 'mais', 'embora', 'nada', 'ser', 'inicio', 'estiveste', 'estive', 'dar', 'vem', 'a', 'falta', 'inclusive', 'apoio', 'tendes', 'obrigado', 'sobre', 'nós', 'próprio', 'tem', 'nessa', 'fazeis', 'cuja', 'cento', 'porque', 'quer', 'primeira', 'diante', 'ponto', 'números', 'até', 'longe', 'dá', 'ainda', 'aquelas', 'relação', 'quero', 'exemplo', 'fazes', 'fui', 'tuas', 'vossos', 'parte', 'fora', 'maior', 'tivemos', 'ambos', 'perto', 'toda', 'querem', 'o', 'estará', 'seria', 'qualquer'}\n"]}],"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hdqVdfxm-_W"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy   \n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                                  \n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar   \n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ] \n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [               \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                   \n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal       \n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ] \n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}}, \n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar \n","               ] \n","\n","matcherv = Matcher(nlp.vocab)\n","         \n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):    \n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","  \n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","  \n","  return lista2"]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = dict()\n","  \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades    \n","  novodic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","    \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9SA61kD6sJY"},"outputs":[],"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","    \n","  # Soma os dicionários da lista\n","  novodic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n"," \n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWxyAo54AOHU"},"outputs":[],"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.text)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gvd99wd_pwmt"},"outputs":[],"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  listatokens = []\n","  listapos = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:    \n","    listatokens.append(token.text)\n","    listapos.append(token.pos_)\n","    \n","  return listatokens, listapos"]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpCUpOs06sJY"},"outputs":[],"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","  \n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\" \n","  return traduzido"]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMb0uDWzKZXP"},"outputs":[],"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxTCYFzcJZD6"},"outputs":[],"source":["def getSentencaSalientePOS(sentenca, pos, classe_saliente=[\"NOUN\"]):\n","  \n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especificado\n","    if pos[i] in classe_saliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"s07wG9F-qHOc"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkBatgxjqHOc"},"outputs":[],"source":["def removeStopWord(documento, stopwords):\n","  \n","  # Remoção das stopwords do documento\n","  documentoSemStopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documentoSemStopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"]},{"cell_type":"markdown","metadata":{"id":"eyEaXKeaLWlq"},"source":["### getTokensSemStopword\n","\n","Retira as stopswords de lista de tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbUf_V_1axS2"},"outputs":[],"source":["def getTokensSemStopword(tokens, spacy_stopwords=getStopwords(nlp)):\n","    \"\"\"\n","      Retira os tokens da lista de tokens tokens que estão na lista de stopword.\n","      A lista de tokens pode ou não estar dentro de uma outra lista.\n","    \n","      Parâmetros:\n","        `tokens` - Uma lista com os tokens ou uma lista de lista de tokens.\n","        `spacy_stopwords` - Uma lista com as stopword. \n","    \"\"\"\n","    \n","    # Verifica se é uma lista de palavras(str) ou ou uma lista de lista\n","    if type(tokens[0]) is str:\n","      lista_tokens = [tokens]\n","    else:\n","      lista_tokens = tokens\n","      \n","    # Lista de retorno\n","    lista_tokens_sem_stopwords = []  \n","\n","    # Percorre a lista de tokens\n","    for texto in lista_tokens:\n","\n","      # Lista dos tokens sem as stopwords\n","      tokens_sem_stopwords = []\n","      \n","      # Percorre os tokens    \n","      for token in texto:\n","        # Verifica se o toke não está na lista de stopwords para adicionar a nova lista\n","        if token not in spacy_stopwords:\n","          tokens_sem_stopwords.append(token)\n","      \n","      # Adiciona a lista de tokens sem stopwords na lista de retorno se tiver uma palavra\n","      if len(tokens_sem_stopwords) != 0:\n","        lista_tokens_sem_stopwords.append(tokens_sem_stopwords)\n","\n","    if type(tokens[0]) is str:      \n","      return lista_tokens_sem_stopwords[0]\n","    else:\n","      return lista_tokens_sem_stopwords"]},{"cell_type":"markdown","metadata":{"id":"O7XoLBuW6woe"},"source":["### getSentencasTexto\n","\n","Retorna a lista de tokens de uma lista de textos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iR9Oc6Yf6zMa"},"outputs":[],"source":["def getSentencasTexto(textos, nlp = nlp):\n","\n","  \"\"\"\n","     Sentencia um texto ou uma lista de textos.\n","    \n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","      `nlp` - Modelo spacy carregado.\n","\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista dos tokens\n","  lista_sentencas = []\n","\n","  for texto in lista_texto:\n","\n","    # Sentencia o documento\n","    doc = nlp(texto)\n","      \n","    # Percorre as sentenças do documento\n","    for sentenca in doc.sents:   \n","\n","        lista_sentencas.append(str(sentenca))\n","      \n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_sentencas[0]\n","  else:\n","    return lista_sentencas"]},{"cell_type":"markdown","metadata":{"id":"5czwzaxKza0y"},"source":["### getSentencasMinusculo\n","\n","Retorna a lista das sentencas do texto em minúsculo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQQAO4Raza0z"},"outputs":[],"source":["def getSentencasMinusculo(textos):\n","\n","  \"\"\"\n","     Sentencia um texto ou uma lista de textos em minusculo.\n","    \n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista dos tokens\n","  lista_sentencas = []\n","\n","  for texto in lista_texto:\n","\n","    lista_sentencas.append(str(texto).lower())\n","      \n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_sentencas[0]\n","  else:\n","    return lista_sentencas"]},{"cell_type":"markdown","metadata":{"id":"dLOaYNEb7C5J"},"source":["### getTokensTexto\n","\n","Retorna a lista de tokens do texto."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJ1hqQCg7C5J"},"outputs":[],"source":["def getTokensTexto(textos, nlp = nlp):\n","\n","  \"\"\"\n","     Tokeniza um texto ou uma lista de textos.\n","    \n","     Parâmetros:\n","      `textos` - Um texto(str) ou uma lista de textos.\n","  \"\"\"\n","\n","  # Verifica se é um texto é str ou uma lista de texto\n","  if type(textos) is str:\n","    lista_texto = [textos]\n","  else:\n","    lista_texto = textos\n","\n","  # Lista de retorno\n","  lista_tokens_texto = []\n","\n","  # Percorre a lista de texto\n","  for texto in lista_texto:\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","    if type(texto) is not spacy.tokens.doc.Doc:\n","        # Realiza o parsing no spacy\n","        doc = nlp(texto)\n","    else:\n","        doc = texto\n","\n","    # Lista dos tokens\n","    lista_tokens = []\n","\n","    # Percorre a sentença adicionando os tokens\n","    for token in doc:    \n","      lista_tokens.append(token.text)\n","    \n","    # Adiciona a lista de tokens na lista de sentenças\n","    lista_tokens_texto.append(lista_tokens)\n","\n","  # Verifica o tipo documento para o tipo de retorno\n","  if type(textos) is str:\n","    return lista_tokens_texto[0]\n","  else:\n","    return lista_tokens_texto"]},{"cell_type":"markdown","source":["### removerPontuacao\n","\n","Remove pontuação"],"metadata":{"id":"l3VOqrF8h3-y"}},{"cell_type":"code","source":["def removerPontuacao(textos):\n","    \n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","        \n","        doc = nlp(\" \".join(texto)) \n","\n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ not in ['PUNCT']:\n","              sentenca.append(token.text)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"R5P_9zfFh3-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### relevantes\n","\n","Palavras relevantes"],"metadata":{"id":"2C4s2rvzJ7iu"}},{"cell_type":"code","source":["def relevantes(textos, postags_permitidas=['VER', 'AUX', 'NOUN']):\n","    \n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","        \n","        doc = nlp(\" \".join(texto)) \n","      \n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ in postags_permitidas:\n","              sentenca.append(token.text)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"5F6PEOkZJ7iv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### lematizacao\n","\n","Lematização do texto"],"metadata":{"id":"1WOT9a_X5dkP"}},{"cell_type":"code","source":["def lematizacao(textos, postags_permitidas=['NOUN', 'ADJ', 'VERB', 'ADV']):\n","    \n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","\n","    textos_saida = []\n","\n","    for texto in textos:\n","        doc = nlp(\" \".join(texto)) \n","\n","        sentenca = []\n","        for token in doc:\n","          if token.pos_ in postags_permitidas:\n","              sentenca.append(token.lemma_)\n","\n","        if len(sentenca) != 0:\n","          textos_saida.append(sentenca)\n","\n","    return textos_saida"],"metadata":{"id":"SbnNOPv85d0C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### preparaCorpus"],"metadata":{"id":"b32wPnBG1faQ"}},{"cell_type":"code","source":["# Import das biblitecas\n","import pandas as pd\n","import re\n","import gensim\n","\n","def preparaCorpus(textos,                                     \n","                  sentenciaTexto=False,\n","                  tornaMinusculo=False,\n","                  removePontuacao=False, \n","                  removeStopwords=False, \n","                  bigramas=False, \n","                  trigramas=False,\n","                  somenteRelevante=False,\n","                  postag_relevante=['VERB', 'AUX', 'NOUN'],\n","                  lematizar=False,                  \n","                  postag_lema=['NOUN', 'ADJ', 'VERB', 'ADV']):\n","\n","    # Verifica se é um textos é str ou uma lista de texto\n","    if type(textos) is str:\n","      # Sentencia o texto\n","      lista_sentencas = [textos]\n","    else:\n","      lista_sentencas = textos\n","    \n","    # Converte o texto em uma lista de sentencas\n","    if sentenciaTexto==True:\n","      lista_sentencas = getSentencasTexto(lista_sentencas)\n","\n","    # Converte o texto em minúsuclo\n","    if tornaMinusculo==True:\n","      lista_sentencas = getSentencasMinusculo(lista_sentencas)\n","    \n","    # tokeniza o texto\n","    lista_sentencas_palavras = getTokensTexto(lista_sentencas)\n","\n","    # Remove a pontuação \n","    if removePontuacao==True:\n","        lista_sentencas_palavras = removerPontuacao(lista_sentencas_palavras)        \n","\n","    # Remove as stop words\n","    if removeStopwords==True:\n","      lista_sentencas_palavras = getTokensSemStopword(lista_sentencas_palavras)\n","\n","    # Criar bigramas ou trigramas\n","    if bigramas==True:\n","      # Construa os modelos de bigramas\n","      bigram = gensim.models.Phrases(lista_sentencas_palavras, min_count=5, threshold=100) # max_topicse mais alto menos frases.\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama\n","      bigram_mod = gensim.models.phrases.Phraser(bigram)\n","      lista_sentencas_palavras = [bigram_mod[doc] for doc in lista_sentencas_palavras]\n","    \n","    if trigramas==True:      \n","      # Construa os modelos de bigramas\n","      bigram = gensim.models.Phrases(lista_sentencas_palavras, min_count=5, threshold=100) # max_topicse mais alto menos frases.\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama\n","      bigram_mod = gensim.models.phrases.Phraser(bigram)\n","      # Construa os modelos de trigramas\n","      trigram = gensim.models.Phrases(bigram[lista_sentencas_palavras], threshold=100)\n","      # Maneira mais rápida de obter uma frase batida como um trigrama/bigrama    \n","      trigram_mod = gensim.models.phrases.Phraser(trigram)   \n","      lista_sentencas_palavras = [trigram_mod[bigram_mod[doc]] for doc in lista_sentencas_palavras]   \n","    \n","    # Somente palavras relevantes\n","    if somenteRelevante==True:      \n","      lista_sentencas_palavras = relevantes(lista_sentencas_palavras, postags_permitidas=postag_relevante)\n","    \n","    # Faça a lematização mantendo apenas para noun, adj, vb, adv\n","    if lematizar==True:      \n","      lista_sentencas_palavras = lematizacao(lista_sentencas_palavras, postags_permitidas=postag_lema)\n","\n","    return lista_sentencas_palavras"],"metadata":{"id":"rSW4ign41h1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JS7qzOSkcc-L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"guw6ZNtaswKc"},"source":["# 4 Corpus Específico"]},{"cell_type":"markdown","metadata":{"id":"NsBImnwiGFVE"},"source":["## 4.1 Especifica os nomes dos arquivos do corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gSzrHQRGJpW"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_CORPUS = \"corpus_especifico.csv\"\n","NOME_ARQUIVO_CORPUS_COMPACTADO = \"corpus_especifico.zip\""]},{"cell_type":"markdown","metadata":{"id":"HvkGO02lmaY-"},"source":["## 4.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFYIHcIHE985","executionInfo":{"status":"ok","timestamp":1668610690231,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"b68e662d-b9f7-4e25-ae48-c28ee8fab3c3"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_CO_PTBR.\n"]}],"source":["# Biblioteca para acessar o sistema de arquivos\n","import os\n","\n","#Cria o diretório para receber os arquivos Originais e Perturbados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"MOBo4YH-QCfN"},"source":["## 4.3 Conteúdo do Arquivo do Corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhFhSYsc6Q5T","executionInfo":{"status":"ok","timestamp":1668610690231,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"1690c49a-99bc-49c5-d57c-c47a5b3fe9ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Quantidade de documentos: 104\n"]}],"source":["documentos = [\n","# Pilhas https://pt.wikipedia.org/wiki/Pilha_(inform%C3%A1tica)\n","['pilha','wikipedia','Em ciência da computação, uma pilha (stack em inglês) é um tipo abstrato de dado e estrutura de dados baseado no princípio de Last In First Out (LIFO), ou seja \"o último que entra é o primeiro que sai\" caracterizando um empilhamento de dados.'],\n","['pilha','wikipedia','Pilhas são fundamentalmente compostas por duas operações: push (empilhar) que adiciona um elemento no topo da pilha e pop (desempilhar) que remove o último elemento adicionado.'],\n","['pilha','wikipedia','Pilhas zamba são usadas extensivamente em cada nível de um sistema de computação moderno.'],\n","['pilha','wikipedia','Por exemplo, um PC moderno usa pilhas ao nível de arquitetura, as quais são usadas no design básico de um sistema operacional para manipular interrupções e chamadas de função do sistema operacional.'],\n","['pilha','wikipedia','Entre outros usos, pilhas são usadas para executar uma Máquina virtual java e a própria linguagem Java possui uma classe denominada \"Stack\", as quais podem ser usadas pelos programadores.'],\n","['pilha','wikipedia','A pilha é onipresente.'],\n","['pilha','wikipedia','Um sistema informático baseado em pilha é aquele que armazena a informação temporária basicamente em pilhas, em vez de registradores de hardware da UCP (um sistema baseado em registradores).'],\n","\n","# Pilha Thomas Cormen\n","['pilha','Thomas Cormen','As pilhas e filas são conjuntos dinâmicos nos quais o elemento removido do conjunto pela operação DELETE é especificado previamente.'],\n","['pilha','Thomas Cormen','Em uma pilha, o elemento eliminado do conjunto é o mais recentemente inserido: a pilha implementa uma norma de último a entrar, primeiro a sair, ou LIFO (last-in, first-out).'],\n","['pilha','Thomas Cormen','De modo semelhante, em uma fila, o elemento eliminado é sempre o que esteve no conjunto pelo tempo mais longo: a fila implementa uma norma de prímeiro a entrar, primeiro a sair, ou FIFO (first-in, first-out).'], \n","['pilha','Thomas Cormen','Existem vários modos eficientes de implementar pilhas e filas em um computador.'],\n","['pilha','Thomas Cormen','Nesta seção, mostraremos como usar um arranjo simples para implementar cada uma dessas estruturas.'],\n","['pilha','Thomas Cormen','A operação INSERT sobre uma pilha é chamada com frequência PUSH, e a operação DELETE, que não toma um argumento de elemento, é freqientemente chamada POP.'],\n","['pilha','Thomas Cormen','Esses nomes são alusões a pilhas físicas, como as pilhas de pratos usados em restaurantes.'],\n","['pilha','Thomas Cormen','A ordem em que os pratos são retirados da pilha é o oposto da ordem em que eles são colocados sobre a pilha e, como conseqúência, apenas o prato do topo está acessível.'],\n","['pilha','Thomas Cormen','Como mostra a Figura 10.1, podemos implementar uma pilha de no máximo n elementos com um arranjo S[1.. ].'],\n","['pilha','Thomas Cormen','O arranjo tem um atributo topo[S] que realiza a indexação do elemento inserido mais recentemente.'],\n","['pilha','Thomas Cormen','A pilha consiste nos elementos S[1..topo[S]], onde s[1] é o elemento na parte inferior da pilha e S[topo[S]] é o elemento na parte superior (ou no topo).'],\n","['pilha','Thomas Cormen','Quando topo(S] = O, a pilha não contém nenhum elemento e está vazia.'],\n","['pilha','Thomas Cormen','É possível testar se a pilha está vazia, através da operação de consulta STACK-EMPTY.'],\n","['pilha','Thomas Cormen','Se uma pilha vazia sofre uma Operação de extração, dizemos que a pilha tem um estouro negativo, que é normalmente um erro.'],\n","['pilha','Thomas Cormen','Se topo[S] excede n, a pilha tem um estonuro posítivo.'],\n","['pilha','Thomas Cormen','(Em nossa implementação de pseudocódigo, não nos preocuparemos com o estouro de pilhas.)'], \n","['pilha','Thomas Cormen','FIGURA 10.1 Uma implementação de arranjo de uma pilha S.'], \n","['pilha','Thomas Cormen','Os elementos da pilha só aparecem nas posições levemente sombreadas.'],\n","['pilha','Thomas Cormen','(a) A pilha S tem á elementos.'],\n","['pilha','Thomas Cormen','O elemento do topo é 9.'],\n","['pilha','Thomas Cormen','(b) A pilha S após as chamadas PUSH(S, 17) e PUSH(S, 3).'],\n","['pilha','Thomas Cormen','(c) A pilha S após a chamada POP(S) retornou o elemento 3, que é o e lemento mais recentemente inserido na pilha.'],\n","['pilha','Thomas Cormen','Embora o elemento 3 ainda apareça no arranjo, ele não está mais na pilha; o elemento do topo é o elemento 17.'],\n","['pilha','Thomas Cormen','Cada uma das operações sobre pilhas pode ser implementada com algumas linhas de código.'],\n","['pilha','Thomas Cormen','STACK-EMPTY(S)'],\n","['pilha','Thomas Cormen','1 if topo[s] = O'],\n","['pilha','Thomas Cormen','2  then return TRUE'],\n","['pilha','Thomas Cormen','3  else return FALSE'],\n","['pilha','Thomas Cormen','PUSH(S, x)'],\n","['pilha','Thomas Cormen','1 topo[S] <- topo[S] + 1'],\n","['pilha','Thomas Cormen','2 S[topo[S]] <- x'],\n","['pilha','Thomas Cormen','POP(S)'],\n","['pilha','Thomas Cormen','1 if STACK-EMPTY(S)'],\n","['pilha','Thomas Cormen','2  then error \\“underflow\\\"'],\n","['pilha','Thomas Cormen','3  else topolS] <- topo[S]-1'],\n","['pilha','Thomas Cormen','4    return S[topo[S] + 1)'],\n","['pilha','Thomas Cormen','A Figura 10.1 mostra os feitos das operações de modificação PUSH (EMPILHAR) e POP(DESEMPILHAR).'], \n","['pilha','Thomas Cormen','Cada uma das três operações sobre pilhas demora o tempo O(1).'],\n","\n","# Fila https://pt.wikipedia.org/wiki/FIFO\n","['fila','wikipedia','Em Ciência da Computação, algoritmo de fila simples,FIFO (do inglês: first in, first out, \\\"primeiro a entrar, primeiro a sair\\\", \"PEPS\") ou FCFS (do inglês: first come, first served, \"primeiro a chegar, primeiro a ser servido\") é um algoritmo de escalonamento para estruturas de dados do tipo fila.'],\n","['fila','wikipedia','Apresenta o seguinte critério: o primeiro elemento a ser retirado é o primeiro que tiver sido inserido, é um algoritmo de escalonamento não preemptivo que entrega a CPU os processos pela ordem de chegada.'],\n","['fila','wikipedia','Ele executa o processo como um todo do inicio ao fim não interrompendo o processo executado até ser finalizado, então quando um novo processo chega e existe um ainda em execução ele vai para uma fila de espera.'],\n","['fila','wikipedia','Esta fila de espera nada mais é do que uma fila que organiza os processos que chegam até eles serem atendidos pela CPU.'],\n","['fila','wikipedia','Neste escalonamento todos os processos tendem a serem atendidos (por isso evita o fenômeno do starvation) ao menos que um processo possua um erro ou loop infinito.'],\n","['fila','wikipedia','O loop infinito irá parar a máquina, pois com o FIFO não terá como dar continuidade a execução dos processos que estão aguardando na fila de espera.'],\n","['fila','wikipedia','O algoritmo FIFO não garante um tempo de resposta rápido pois é extremamente sensível a ordem de chegada de cada processo e dos antecessores (se existirem) e se processos que tendem a demorar mais tempo chegarem primeiro o tempo médio de espera e o turnaround acabam sendo aumentados.'],\n","['fila','wikipedia','Pelo critério do primeiro a entrar é o primeiro a ser servido, faz o agendamento de tarefas do sistema operacional dando a cada processo tempo de CPU na ordem em que as demandas são feitas.'],\n","['fila','wikipedia','O oposto de FIFO é LIFO (Last-In, First-Out), que significa \"o último a entrar é o primeiro a sair\", aonde a entrada mais recente, ou o topo da pilha de processos, é processado primeiro.[4].'],\n","['fila','wikipedia','Já uma fila prioritária não é nem FIFO, nem LIFO, mas pode adotar comportamento similar temporariamente, ou mesmo por padrão.'],\n","['fila','wikipedia','As listas são amplamente utilizadas em programação para implementar filas de espera.'],\n","['fila','wikipedia','Em uma fila de tipo FIFO os elementos vão sendo colocados na fila e retirados (ou processados) por ordem de chegada.'],\n","['fila','wikipedia','A ideia fundamental da fila é que só podemos inserir um novo elemento no final da fila e só podemos retirar o elemento do início.'],\n","['fila','wikipedia','É vantajoso por ser o mais simples entre os processos de escalonamento; e todos os processos tendem a serem atendidos.'],\n","['fila','wikipedia','Dentre as desvantagens estão: muito sensível a ordem de chegada; se processos maiores chegarem primeiro aumentarão o tempo médio de espera; nãoo garante um tempo de resposta rápido; não é eficiente em sistemas de tempo compartilhado; e não é eficiente em sistemas em tempo real.'],\n","['fila','wikipedia','FIFO são comumente usados em circuitos eletrônicos de buffer e controle de fluxo, que vai desde o hardware até o software.'],\n","['fila','wikipedia','Na forma de um hardware o FIFO consiste basicamente de um conjunto de ler e escrever ponteiros, armazenamento e lógica de controle.'],\n","['fila','wikipedia','Armazenamento pode ser SRAM, flip-flops, fechos ou qualquer outra forma adequada de armazenamento.'],\n","['fila','wikipedia','Para o FIFO, de tamanho não trivial, uma SRAM de porta dupla geralmente é utilizada quando uma porta é usada para a escrita e a outra para leitura.'],\n","['fila','wikipedia','O FIFO síncrono aonde o mesmo clock é usado para leitura e escrita.'],\n","['fila','wikipedia','Um FIFO assíncrono utiliza diferentes relógios para leitura e escrita.'],\n","['fila','wikipedia','Uma aplicação comum de um FIFO assíncrono utiliza um código de Gray (código binário refletido), ou qualquer unidade de código a distância, para a ler e escrever os ponteiros para garantir a geração de bandeira confiável.'],\n","['fila','wikipedia','Uma nota mais preocupante é que se deve necessariamente usar a aritmética de ponteiro para gerar bandeiras para implementações assíncronas FIFO.'],\n","['fila','wikipedia','Por outro lado, pode-se usar a abordagem de um balde \"de fuga\" ou a aritmética de ponteiro para gerar bandeiras nas implementações síncronas FIFO.'],\n","\n","# Fila Thomas Cormen\n","['fila','Thomas Cormen','Chamamos a operação INSERT sobre uma fila de ENQUEUE (ENFILEIRAR), e também a operação DELETE de DEQUEUE (DESINFILEIRAR); como a operação sobre pilhas POP, DEQUEUE não tem nenhum argumento de elemento.'],\n","['fila','Thomas Cormen','A propriedade FIFO de uma fila faz com que ela opere como uma fileira de pessoas no posto de atendimento da previdência social.'],\n","['fila','Thomas Cormen','A fila tem um início (ou cabeça) e um fim (ou cauda).'],\n","['fila','Thomas Cormen','Quando um elemento é colocado na fila, ele ocupa seu lugar no fim da fila, como um aluno recém-chegado que ocupa um lugar no final da fileira.'],\n","['fila','Thomas Cormen','O elemento retirado da fila é sempre aquele que está no início da fila, como o aluno que se encontra no começo da fileira e que esperou por mais tempo.'],\n","['fila','Thomas Cormen','(Felizmente, não temos de nos preocupar com a possibilidade de elementos computacionais \\“furarem\\” a fila.)'],\n","['fila','Thomas Cormen','A Figura 10.2 mostra um modo de implementar uma fila de no máximo n - 1 elementos usando um arranjo O[1..n].'],\n","['fila','Thomas Cormen','A fila tem um atributo ínício[Q] que indexa ou aponta para seu início.'],\n","['fila','Thomas Cormen','O atributo fím[Q] realiza a indexação da próxima posição na qual um elemento recém chegado será inserido na fila.'],\n","['fila','Thomas Cormen','Os elementos na fila estão nas posições início[Q), início[Q]+1, ... fim[Q]-1, onde “retornamos”, no sentido de que a posição 1 segue imediatamente a posição n em uma ordem circular.'],\n","['fila','Thomas Cormen','Quando início[Q] = fim[Q]), a fila está vazia.'],\n","['fila','Thomas Cormen','Inicialmente, temos início[Q] = fim[Q] = 1.'],\n","['fila','Thomas Cormen','Quando a fila está vazia, uma tentativa de retirar um elemento da fila provoca o estouro negativo da fila.'],\n","['fila','Thomas Cormen','Quando início[Q] = fim[Q] + 1, a fila está cheia, e uma tentativa de colocar um elemento na fila provoca o estouro positivo da fila.'],\n","['fila','Thomas Cormen','FIGURA 10.2 Uma fila implementada com a utilização de um arranjo Q[1..12).'],\n","['fila','Thomas Cormen','Os elementos da fila aparecem apenas nas posições levemente sombreadas.'],\n","['fila','Thomas Cormen','(a) A filatem 5 elementos, nas localizações O[7..11].'], \n","['fila','Thomas Cormen','(b) A configuração da fila depois das chamadas ENQUEUE(Q, 17), ENQUEUE(Q, 3) e ENQUEUE(O, 5).'],\n","['fila','Thomas Cormen','A configuração da fila depois da chamada DEQUEUE(Q) retorna o valor de chave 15 que se encontrava anteriormente no início da fila.'],\n","['fila','Thomas Cormen','O novo início tem a chave 6'],\n","['fila','Thomas Cormen','Em nossos procedimentos ENQUEUE e DEQUEUE, a verificação de erros de estouro negativo (underfiow) € estouro positivo (overflow) foi omitida.'],\n","['fila','Thomas Cormen','O Exercício 10.1-4 lhe pede para fornecer o código que efetua a verificação dessas duas condições de erro.'],\n","['fila','Thomas Cormen','ENQUEUE(Q, x)'],\n","['fila','Thomas Cormen','1 Q[fim[Q] = x'],\n","['fila','Thomas Cormen','2 iffim[Q] = comprimento[Q]'],\n","['fila','Thomas Cormen','3 then fim[Q] = 1'],\n","['fila','Thomas Cormen','4 else fim[Q] = fim[Q]+1'],\n","['fila','Thomas Cormen','DEQUEUE(Q)'],\n","['fila','Thomas Cormen','1 x = OQlinício[Q]]'],\n","['fila','Thomas Cormen','2 if início[Q] == comprimento[Q]'],\n","['fila','Thomas Cormen','3 then início[Q] = 1'],\n","['fila','Thomas Cormen','4  else início[Q] & início[Q] + 1'],\n","['fila','Thomas Cormen','5 return x'],\n","['fila','Thomas Cormen','A Figura 10.2 mostra os efeitos das operações ENQUEUE e DEQUEUE.'],\n","['fila','Thomas Cormen','Cada operação demora o tempo O(1).']\n","]\n","\n","\n","print(\"Quantidade de documentos:\", len(documentos))"]},{"cell_type":"markdown","metadata":{"id":"06mEPdqu9rsI"},"source":["## 4.5 Cria o arquivo do corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Z69mLAT9tq4"},"outputs":[],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Cria o dataframe da lista\n","df_lista_sentencas = pd.DataFrame(documentos, columns = [\"topico\",\"fonte\",\"sentenca\"])\n"," \n","df_lista_sentencas.to_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_CORPUS, sep=\";\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"WqzXU_Icqiqg"},"source":["## 4.6 Compacta e copia o arquivo perturbado para uma pasta do GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"37e0qS7Dkwou"},"source":["Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1668610690483,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"4f2VhAHXkwow","outputId":"3f7c7d2d-df13-46bb-9af3-5dda009fc79e"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei compactação.\n"]}],"source":["!zip -o -q -j \"$DIRETORIO_LOCAL$NOME_ARQUIVO_CORPUS_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_CORPUS\"\n","\n","logging.info(\"Terminei compactação.\")"]},{"cell_type":"markdown","metadata":{"id":"JJH7kEhiWmi9"},"source":["Copia o arquivo compactado e os arquivos individuais para o GoogleDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1338,"status":"ok","timestamp":1668610691818,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"URD2iAO3qiqg","outputId":"cb32ca30-951a-435b-cb8c-f80859474b55"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}],"source":["# Import das bibliotecas.\n","import os\n","import datetime\n","\n","# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","     \n","    # Copia o arquivo perturbado\n","    !cp \"$DIRETORIO_LOCAL$NOME_ARQUIVO_CORPUS_COMPACTADO\" \"$DIRETORIO_DRIVE\"\n","    \n","    logging.info(\"Terminei a cópia.\")"]},{"cell_type":"markdown","metadata":{"id":"TkncKDN1i7kq"},"source":["## 4.7 Carrega os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1668610691819,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"jWf1pJbyBbUz","outputId":"f7f59a02-fcda-4128-c882-ae25bf0ce493"},"outputs":[{"output_type":"stream","name":"stdout","text":["104\n"]}],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","df_corpus = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_CORPUS, sep=\";\", encoding=\"UTF-8\")\n","\n","print(len(df_corpus))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1668610691821,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"UDO7gHyiBbU5","outputId":"fd90271c-bf10-48eb-b91f-ecf5518d2532"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   topico          fonte                                           sentenca\n","74   fila  Thomas Cormen  (Felizmente, não temos de nos preocupar com a ...\n","36  pilha  Thomas Cormen                           1 topo[S] <- topo[S] + 1\n","30  pilha  Thomas Cormen  Cada uma das operações sobre pilhas pode ser i...\n","24  pilha  Thomas Cormen  Os elementos da pilha só aparecem nas posições...\n","17  pilha  Thomas Cormen  A pilha consiste nos elementos S[1..topo[S]], ..."],"text/html":["\n","  <div id=\"df-8d038b02-5805-4ff6-a1a7-19d5b28aa50f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topico</th>\n","      <th>fonte</th>\n","      <th>sentenca</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>74</th>\n","      <td>fila</td>\n","      <td>Thomas Cormen</td>\n","      <td>(Felizmente, não temos de nos preocupar com a ...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>1 topo[S] &lt;- topo[S] + 1</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>Cada uma das operações sobre pilhas pode ser i...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>Os elementos da pilha só aparecem nas posições...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>pilha</td>\n","      <td>Thomas Cormen</td>\n","      <td>A pilha consiste nos elementos S[1..topo[S]], ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d038b02-5805-4ff6-a1a7-19d5b28aa50f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8d038b02-5805-4ff6-a1a7-19d5b28aa50f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8d038b02-5805-4ff6-a1a7-19d5b28aa50f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":57}],"source":["df_corpus.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 5 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Bcjt085lZGUr"},"source":["## 5.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1668610691821,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"H50_GKJwpDha","outputId":"75c1dd7e-e68d-40e5-b4b7-0dbe1ccfc29e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento:  0:02:33 (h:mm:ss)\n"]}],"source":["# Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempo_total_processamento))"]}]}