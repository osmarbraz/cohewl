{"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# Perturbação de sentenças do CohQuAD CoIn pt-br\n","\n","Gera as perturbações de sentenças dos documentos pré-processados do conjunto de dados.\n","\n","- Utiliza os dados pré-processados de `original.zip`.\n","- Gera o arquivo `perturbado_pX_kY.zip` com as o documento com as perturbações.\n"," \n","Gera o arquivo `perturbado_pX_kY.csv`, onde X é o número de documentos perturbados e Y o valor de top K predições. Contêm a compactação do arquivo `perturbado.csv`.\n","\n","Cada linha de `perturbardo.csv` é formado por `[\"id\",\"perturbado\", \"documento_perturbado\", \"sentencas\"]`.\n"," - `\"id\"` é o idenficador da pergunta na base de dados original.\n"," - `\"perturbado\"` é uma lista com as sentenças perturbadas do documento. \n"," - `\"documento_perturbado\"` é um string com as sentenças perturbadas do documento. \n"," - `\"sentencas\"` uma lista com os dados das sentenças do documento perturbado. Cada elemento da lista é formado por:\n","    - `\"sentenca_perturbada\"` A sentença com a perturbação.\n","    - `\"sentenca_mascarada\"` A sentença mascarada.\n","    - `\"palavra_mascarada\"` A palavra da sentença que foi mascarada.\n","    - `\"token_predito\"` O token predito para a palavra mascarada.\n","    - `\"peso_predito\"` O peso do token predito para a palavra mascarada.\n","    - `\"token_predito_marcado\"` A token em sua forma original.\n"]},{"cell_type":"markdown","metadata":{"id":"OP33KWAtBMWs"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"PKUr9Vk4BNLC"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"JXclHCRQBSF2","executionInfo":{"status":"ok","timestamp":1664389235411,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Fj5TaAH_5-nB","executionInfo":{"status":"ok","timestamp":1664389235412,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================  \n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.    \n","    \"\"\"\n","    \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):  \n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","    \n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5B1mvfAU5jZf","executionInfo":{"status":"ok","timestamp":1664389235412,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","    \n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.      \n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.      \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","    \n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download    \n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]  \n","\n","    # Define o nome e caminho do arquivo temporário    \n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","    \n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","    \n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:        \n","        tamanho_conteudo = data.headers.get(\"Content-Length\")        \n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)                \n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):        \n","            if chunk:                \n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","    \n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","    \n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6qwKjGvyLG4v","executionInfo":{"status":"ok","timestamp":1664389235412,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","    \n","    import re\n","\n","    documentoLimpo = re.compile(\"<.*?>\")\n","    return re.sub(documentoLimpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jirIzIstLea0","executionInfo":{"status":"ok","timestamp":1664389235413,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.  \n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EC9Xppq-_R0w","executionInfo":{"status":"ok","timestamp":1664389235413,"user_tz":180,"elapsed":7,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.   \n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    sentencas = []\n","    for linha in arquivo:        \n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"fkVk5LQT_G3f","executionInfo":{"status":"ok","timestamp":1664389235413,"user_tz":180,"elapsed":7,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def salvar(nome_arquivo,texto):                       \n","    \"\"\"\n","      Salva um texto em arquivo.\n","     \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.     \n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Guy6B4whsZFR","executionInfo":{"status":"ok","timestamp":1664389235413,"user_tz":180,"elapsed":6,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","    \n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))    "]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModelArguments) de definição dos parâmetros do modelo"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"zgmN6RqDRDZS","executionInfo":{"status":"ok","timestamp":1664389235414,"user_tz":180,"elapsed":6,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )    \n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )    "]},{"cell_type":"markdown","metadata":{"id":"SX6jTGkBMNvV"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"95qYX7uzMNvX","executionInfo":{"status":"ok","timestamp":1664389235725,"user_tz":180,"elapsed":317,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"DcopxbGZqDip","executionInfo":{"status":"ok","timestamp":1664389235725,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"YMiH0E3OnRa1","executionInfo":{"status":"ok","timestamp":1664389235726,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4558,"status":"ok","timestamp":1664389240272,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"vtaYZmc3Vbfj","outputId":"ecd20902-d669-47ff-f19a-af35bbb073df"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Dispositivo GPU não encontrado\n"]}],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"zrjqDO6nWa8J","executionInfo":{"status":"ok","timestamp":1664389244100,"user_tz":180,"elapsed":3832,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","\n","def getDeviceGPU():\n","    \"\"\"\n","      Retorna um dispositivo de GPU se disponível ou CPU.\n","    \n","      Retorno:\n","        `device` - Um device de GPU ou CPU.       \n","    \"\"\"\n","        \n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        \n","        # Diz ao PyTorch para usar GPU.    \n","        device = torch.device(\"cuda\")\n","        \n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:        \n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","        \n","    return device"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1664389244101,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ChDxmtXsKwjf","outputId":"6a70fd77-c9b8-45eb-f458-c7f985057cec"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Sem GPU disponível, usando CPU.\n"]}],"source":["# Recupera o device com GPU ou CPU\n","device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"fGf59D0yVNx9"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1664389244102,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"1iC5-pSAVh7_","outputId":"ac0b776a-2f9c-4dc4-aea7-a02d186537e0"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}],"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19204,"status":"ok","timestamp":1664389263299,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ysnDDapMQK8K","outputId":"50a833bb-4f2d-440b-b57b-2ab084b4e678"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10870,"status":"ok","timestamp":1664389274162,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ejzpgGrFM0-j","outputId":"9830c932-09cd-43cb-fae5-8a081fdc47d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 5.4 MB/s \n","\u001b[?25hCollecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 53.2 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 53.3 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 46.4 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 47.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 63.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 58.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 61.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 62.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 66.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 63.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 46.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=995d7029f3a7984120e075444738f0f833c3e5c265363e5f6d9ce12f80374f84\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.3\n"]}],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"oOd2MbBiDq93"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"executionInfo":{"elapsed":17824,"status":"ok","timestamp":1664389291977,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"EaMM4WdxgvQ7","outputId":"5a57204d-a028-467b-bffb-58829314e033"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.4.0-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 38.0 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","numba 0.56.2 requires setuptools<60, but you have setuptools 65.4.0 which is incompatible.\u001b[0m\n","Successfully installed pip-22.2.2 setuptools-65.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20669,"status":"ok","timestamp":1664389312632,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"w4p3Rz2qDq94","outputId":"85d68976-a350-4846-b5fd-a66b20e41c98"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.4.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.8)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.6)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.10)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.9.2\n","    Uninstalling pydantic-1.9.2:\n","      Successfully uninstalled pydantic-1.9.2\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.0\n","    Uninstalling thinc-8.1.0:\n","      Successfully uninstalled thinc-8.1.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.1\n","    Uninstalling spacy-3.4.1:\n","      Successfully uninstalled spacy-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typing-extensions-3.10.0.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.9 Instalação do BERT"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face. \n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19232,"status":"ok","timestamp":1664389331859,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"1RfUN_KolV-f","outputId":"368fabd5-a409-4316-e0b1-d3ea12657356"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=f84450b17aaed23ee48b5ab652f918199414234bb27451adcd9badcdaddb47e9\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -U transformers==4.5.1"]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":112,"metadata":{"executionInfo":{"elapsed":324,"status":"ok","timestamp":1664389588296,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"5uiH9pNpwI6g"},"outputs":[],"source":["# Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 1\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 1\n","\n","# Gera a seleção aleatória da palara perturbada entre as topk palavras da predição\n","SELECAO_ALEATORIA_TOP_K = False"]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"Mhkc9sW21zV7"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":113,"metadata":{"executionInfo":{"elapsed":248,"status":"ok","timestamp":1664389588907,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosMedida(     \n","    max_seq_len = 512,\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",\n","    \n","    #pretrained_model_name_or_path = \"bert-large-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-cased\"\n","    pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",    \n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","\n","    #modelo_spacy = \"en_core_web_lg\",\n","    #modelo_spacy = \"en_core_web_md\",\n","    #modelo_spacy = \"en_core_web_sm\",\n","    modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","\n","    versao_modelo_spacy = \"3.2.0\",\n","    sentenciar_documento = True,\n","    do_lower_case = False, # default True  \n","    output_attentions = False, # default False\n","    output_hidden_states = True, # default False, se True retorna todas as camadas do modelo para as operações de soma e concatenação\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path. \n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",")"]},{"cell_type":"markdown","metadata":{"id":"ecwtQDArKvZn"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":114,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1664389588907,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"YtNygH9qKvmp"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_COIN_PTBR\""]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":115,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1664389588907,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":116,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1664389588908,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"DjWGu-9D5URZ"},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","        \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":117,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1664389588908,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"Dq9PnXO77bPQ"},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    \n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivo_tar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")    \n","    arquivo_tar.extractall(DIRETORIO_COHEBERT)    \n","    arquivo_tar.close()\n","    \n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):        \n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":118,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1664389588909,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ePOccj0s8WMg"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","    \n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.           \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","                  \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp "]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7046,"status":"ok","timestamp":1664389595948,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"nbELnrpgA4T1","outputId":"3d7eb612-ad4f-4093-89d8-d8e11cf0a301"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:spaCy carregado.\n"]}],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"Gk9I_DX5coOI"},"source":["# 4 BERT"]},{"cell_type":"markdown","metadata":{"id":"MBGTMy8Ic7GK"},"source":["## 4.1 Modelo Pré-treinado BERT"]},{"cell_type":"markdown","metadata":{"id":"uiuxdXe9t1BX"},"source":["### Funções Auxiliares"]},{"cell_type":"code","execution_count":120,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389595949,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"9Huw0x5kt1Le"},"outputs":[],"source":["def getNomeModeloBERT(model_args):\n","    '''    \n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","    \n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"\n","        \n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","            \n","    return MODELO_BERT"]},{"cell_type":"code","execution_count":121,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389595950,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"jYJB4ik7t5xe"},"outputs":[],"source":["def getTamanhoBERT(model_args):\n","    '''    \n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","    \n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","    \n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","        \n","    return TAMANHO_BERT  "]},{"cell_type":"markdown","metadata":{"id":"rHt4e5pAcEMd"},"source":["### Função download Modelo Pre-treinado BERT"]},{"cell_type":"code","execution_count":122,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389595950,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"peDUrV2ccEXA"},"outputs":[],"source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\" \n","    \n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","        \n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","        \n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo!\")\n","            # Apaga o diretório e os arquivos existentes                     \n","            shutil.rmtree(DIRETORIO_MODELO)\n","        \n","        # Realiza o download do arquivo do modelo        \n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.                \n","        arquivo_zip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivo_zip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.        \n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","        \n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta.\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada.\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"V74WUpHqcfoI"},"source":["### Copia o modelo do BERT ajustado"]},{"cell_type":"code","execution_count":123,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389595951,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"iQMpf9yycf8f"},"outputs":[],"source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\" \n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/CSTNEWS/validacao_classificacao/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO) \n","   \n","    logging.info(\"Modelo BERT ajustado copiado.\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"]},{"cell_type":"markdown","metadata":{"id":"eaneOhAKcO-3"},"source":["### Verifica de onde utilizar o modelo do BERT"]},{"cell_type":"code","execution_count":124,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389595951,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"TTy1TXz3cPKS"},"outputs":[],"source":["def verificaModelo(model_args):\n","    \"\"\" \n","    Verifica de onde utilizar o modelo.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","    \n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\" \n","\n","    DIRETORIO_MODELO = None\n","    \n","    if model_args.usar_mcl_ajustado == True:        \n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","        \n","        logging.info(\"Usando modelo BERT ajustado.\")\n","        \n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")        \n","        \n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"6tKcaIfReqdy"},"source":["## 4.2 Tokenizador BERT"]},{"cell_type":"markdown","metadata":{"id":"e8n7Z5s-QZF8"},"source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf)."]},{"cell_type":"code","execution_count":125,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389595951,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"mzAuptkwQZR3"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí..), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","    \n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","    \n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"]},{"cell_type":"markdown","metadata":{"id":"GYRV9KfHQE6v"},"source":["## 4.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"markdown","metadata":{"id":"-pZZrUKRhR3e"},"source":["### Função carrega modelo BERT medida"]},{"cell_type":"code","execution_count":126,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389595952,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"1JUEyjCChUQh"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertForMaskedLM # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","    \n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","        `model_args` - Objeto com os argumentos do modelo.   \n","    \n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:        \n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertForMaskedLM.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","        \n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertForMaskedLM.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"-uFDhRTZe2Js"},"source":["### Função carrega o BERT"]},{"cell_type":"code","execution_count":127,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389595952,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"QVtAUbUBe2iS"},"outputs":[],"source":["def carregaBERT(model_args):\n","    \"\"\" \n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:    \n","        `model` - Um objeto do modelo BERT carregado.       \n","        `tokenizer` - Um objeto tokenizador BERT carregado.       \n","    \"\"\"\n","            \n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","    \n","    # Variável para conter o modelo\n","    model = None\n","    \n","    # Carrega o modelo para cálculo da medida\n","    model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","                \n","    # Carrega o tokenizador. \n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","    \n","    return model, tokenizer"]},{"cell_type":"markdown","metadata":{"id":"x5NTxBRKfAcT"},"source":["### Carrega o BERT"]},{"cell_type":"code","execution_count":128,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11124,"status":"ok","timestamp":1664389607063,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ZYMLJJYSQHY3","outputId":"7ef90f24-2179-427a-8b2f-9847a5ea8f94"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Variável URL_MODELO não setada.\n","INFO:root:Usando modelo BERT pré-treinado.\n","INFO:root:Carregando o modelo BERT da comunidade neuralmind/bert-large-portuguese-cased para cálculo de medidas.\n","Some weights of the model checkpoint at neuralmind/bert-large-portuguese-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","INFO:root:Carregando o tokenizador BERT do diretório neuralmind/bert-large-portuguese-cased.\n"]}],"source":["# Carrega o modelo e tokenizador do BERT\n","model, tokenizer = carregaBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"d7KprWqyZBQZ"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":129,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1664389607064,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"D6sPjTQnuQV2"},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"guw6ZNtaswKc"},"source":["# 5 Perturbação das sentenças\n"]},{"cell_type":"markdown","metadata":{"id":"7aZJTfpz1mIk"},"source":["## 5.1 Carregamento dos arquivos de dados"]},{"cell_type":"markdown","metadata":{"id":"_wTNIiyE1mIl"},"source":["### 5.1.1 Especifica os nomes dos arquivos de dados originais\n","\n"]},{"cell_type":"code","execution_count":130,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1664389607064,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"_rp3C_XK1mIl"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINALCOMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\""]},{"cell_type":"markdown","metadata":{"id":"HvkGO02lmaY-"},"source":["### 5.1.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":131,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1664389607065,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"gFYIHcIHE985","outputId":"78dd1441-6ed2-40aa-c694-1ee201a7401b"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_COIN_PTBR.\n"]}],"source":["# Biblioteca para acessar o sistema de arquivos\n","import os\n","\n","#Cria o diretório para receber os arquivos Originais e Perturbados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"rGnyGoyu1mIl"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"uuiMbbAfmqcb"},"source":["Copia os arquivos do google drive"]},{"cell_type":"code","execution_count":132,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1664389607746,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"gCl5TpK91mIl","outputId":"0c4042c8-5627-4897-9c78-21f176d05a4c"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINALCOMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINALCOMPACTADO\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\"\n","\n","  logging.info(\"Terminei a cópia.\")"]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos.\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n","\n"]},{"cell_type":"code","execution_count":133,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":655,"status":"ok","timestamp":1664389608399,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"dbHl3d88mouc","outputId":"ba1056cd-d823-45ea-88c5-b1cf595d9cf1"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a descompactação.\n"]}],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINALCOMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"]},{"cell_type":"markdown","metadata":{"id":"WkWm5KWc1mIm"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais"]},{"cell_type":"markdown","metadata":{"id":"Fvoe9l2o1mIm"},"source":["#### Carrega o arquivo dos dados originais e POS\n","\n"]},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1664389608399,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"QRHlixdHEDTb","outputId":"856c75aa-ecfe-4644-a253-632c337bc9cc"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO ORIGINAIS: 40.\n","INFO:root:TERMINADO ORIGINAIS POS: 40.\n"]}],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"code","execution_count":135,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1664389608400,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"jJ5STBZPLlie","outputId":"ed41c2e6-b352-4cd1-f18f-663f280c9e06"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id                                          sentencas  \\\n","1    1p0        ['Como enfileirar elementos em uma pilha?']   \n","16     9  ['O que é uma pilha e como empilhar seu elemen...   \n","39  20p0  ['Em uma fila a operação de empilhar ocorre em...   \n","36    19  ['Em uma pilha a operação de empilhar ocorre e...   \n","5    3p0           ['Como empilhar elementos em uma fila?']   \n","\n","                                            documento  \n","1             Como enfileirar elementos em uma pilha?  \n","16    O que é uma pilha e como empilhar seu elemento?  \n","39  Em uma fila a operação de empilhar ocorre em q...  \n","36  Em uma pilha a operação de empilhar ocorre em ...  \n","5                Como empilhar elementos em uma fila?  "],"text/html":["\n","  <div id=\"df-d7940b42-4be8-494a-8681-52849d8828ec\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1p0</td>\n","      <td>['Como enfileirar elementos em uma pilha?']</td>\n","      <td>Como enfileirar elementos em uma pilha?</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>9</td>\n","      <td>['O que é uma pilha e como empilhar seu elemen...</td>\n","      <td>O que é uma pilha e como empilhar seu elemento?</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>20p0</td>\n","      <td>['Em uma fila a operação de empilhar ocorre em...</td>\n","      <td>Em uma fila a operação de empilhar ocorre em q...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>19</td>\n","      <td>['Em uma pilha a operação de empilhar ocorre e...</td>\n","      <td>Em uma pilha a operação de empilhar ocorre em ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3p0</td>\n","      <td>['Como empilhar elementos em uma fila?']</td>\n","      <td>Como empilhar elementos em uma fila?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7940b42-4be8-494a-8681-52849d8828ec')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d7940b42-4be8-494a-8681-52849d8828ec button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d7940b42-4be8-494a-8681-52849d8828ec');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":135}],"source":["lista_documentos_originais.sample(5)"]},{"cell_type":"code","execution_count":136,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389608401,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"1LDhF8NkFjG5","outputId":"9b06788f-fa4f-4eb8-92ac-7f64b7570a22"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id                                      pos_documento\n","36    19  [[['Em', 'uma', 'pilha', 'a', 'operação', 'de'...\n","34    18  [[['Como', 'são', 'implementadas', 'as', 'oper...\n","19  10p0  [[['O', 'que', 'é', 'uma', 'pilha', 'e', 'como...\n","8      5  [[['Como', 'empilhar', 'elementos', 'em', 'uma...\n","2      2  [[['Como', 'desenfileirar', 'elementos', 'em',..."],"text/html":["\n","  <div id=\"df-60bc6297-60d0-434f-bbbf-c41127b7301d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>36</th>\n","      <td>19</td>\n","      <td>[[['Em', 'uma', 'pilha', 'a', 'operação', 'de'...</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>18</td>\n","      <td>[[['Como', 'são', 'implementadas', 'as', 'oper...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>10p0</td>\n","      <td>[[['O', 'que', 'é', 'uma', 'pilha', 'e', 'como...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5</td>\n","      <td>[[['Como', 'empilhar', 'elementos', 'em', 'uma...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[[['Como', 'desenfileirar', 'elementos', 'em',...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60bc6297-60d0-434f-bbbf-c41127b7301d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-60bc6297-60d0-434f-bbbf-c41127b7301d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-60bc6297-60d0-434f-bbbf-c41127b7301d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":136}],"source":["lista_documentos_originais_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"T5WkUTU-9a5M"},"source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":137,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389608401,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"lj9sJVavMccj","outputId":"a796f4ba-a0ce-475d-8af9-ffdd026b365b"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO ORIGINAIS: 40.\n","INFO:root:TERMINADO CORREÇÃO ORIGINAIS POS: 40.\n"]}],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"markdown","metadata":{"id":"lRNu1gPKuRxd"},"source":["## 5.2 Gerando as perturbações"]},{"cell_type":"markdown","metadata":{"id":"NsBImnwiGFVE"},"source":["### 5.2.1 Especifica os nomes dos arquivos de dados perturbados"]},{"cell_type":"code","execution_count":138,"metadata":{"executionInfo":{"elapsed":444,"status":"ok","timestamp":1664389608837,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"-gSzrHQRGJpW"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"70dvLWiZePmo"},"source":["### 5.2.2 Gerando as perturbações"]},{"cell_type":"markdown","metadata":{"id":"bkPRy5TyVqUG"},"source":["Conta o número de ocorrências do elemento na lista."]},{"cell_type":"code","execution_count":139,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389608838,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"Dp9X6-3VN90o"},"outputs":[],"source":["def contaElemento(lista, elemento):\n","    \"\"\" \n","      Conta o número de ocorrências do elemento na lista.\n","          \n","      Parâmetros:\n","        `lista` - Lista com os elementos.\n","        `elemento` - Elemento a ser contado a ocorrência na lista.\n","\n","      Retorno:    \n","        `cont` - Quantidade de ocorrências de elmento na lista.\n","    \"\"\"\n","    cont = 0\n","    # Percorre a lista\n","    for i, linha in enumerate(lista):      \n","      # Verifica se o elemento existe na lista\n","      if linha in elemento:\n","        # conta o elemento\n","        cont = cont + 1\n","    return cont"]},{"cell_type":"markdown","metadata":{"id":"a7wlD9LWi6Sx"},"source":["#### Gera sentença mascarada aleatória"]},{"cell_type":"markdown","metadata":{"id":"kJyTCimeVubM"},"source":["Gera a sentença mascarada com [MAKS] para usar com MLM do BERT."]},{"cell_type":"code","execution_count":140,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389608838,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"NQBCxLcqBsU8"},"outputs":[],"source":["# Import das bibliotecas.\n","from random import randint # Biblioteca para o sorteio\n","\n","def getSentencaMascarada(sentenca, \n","                         sentenca_token,\n","                         sentenca_pos, \n","                         classe=[\"VERB\",\"NOUN\",\"AUX\"], \n","                         qtde=1):\n","  \"\"\" \n","      Gera a sentença mascarada com [MAKS] para usar com MLM do BERT.\n","      Considera determinadas classes morfossintática das palavras e uma quantidade(qtde) de palavras a serem mascaradas.\n","          \n","      Parâmetros:\n","        `sentenca` - Sentença a ser mascarada.\n","        `sentenca_token` - Lista com os tokens da sentença.\n","        `sentenca_pos` - Lista com as POS dos tokens da sentença.\n","        `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n","        `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n","                 Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n","                 for menor que quantidade de palavras das classes na sentença.\n","\n","      Retorno:    \n","        `sentenca_mascarada` - Sentença mascarada.\n","        `palavra_mascarada` - Lista com as palavras substituidas pela máscara.\n","\n","  \"\"\"\n","  sentenca_mascarada = \"\"\n","  palavra_mascarada = \"\"\n","\n","  # Verifica a quantidade de trocas a ser realizada\n","  if qtde != 0:\n","\n","    # Conta o número de palavras das classes especificadas\n","    if len(classe) > 1:\n","      # Se tem duas classes usa a primeira para contar se existe uma palavra\n","      # Pega o primeiro para realizar a conta\n","      classe_conta = [classe[0]]\n","      conta_mascara = contaElemento(sentenca_pos, classe_conta)\n","      \n","      # Senão encontrar pega a segunda classe\n","      if conta_mascara == 0:\n","        #Pega a segunda classe\n","        classe_conta = [classe[1]]\n","        conta_mascara = contaElemento(sentenca_pos, classe_conta)\n","\n","        # Senão encontrar pega a terceira classe\n","        if conta_mascara == 0:\n","          #Pega a terceira classe\n","          classe_conta = [classe[2]]\n","          conta_mascara = contaElemento(sentenca_pos, classe_conta) \n","      \n","      # Usa a classe para gerar a sentença mascarada\n","      classe = classe_conta\n","    else:\n","      conta_mascara = contaElemento(sentenca_pos, classe)\n","    \n","    # Verifica se existe palavras das classes a serem mascaradas\n","    if conta_mascara != 0:    \n","      # Verifica a quantidade de trocas é menor que a quantidade palavras a serem trocadas encontradas\n","      if qtde < conta_mascara:\n","        # A quantidade de trocas é menor que a quantidade de palavras existentes\n","        # Precisa sortear as posições que serão trocadas pela máscara dentro da quantidade\n","               \n","        roleta = []\n","        # preenche a roleta com o indice das palavras as serem mscaradas\n","        for i in range(conta_mascara):\n","            roleta.append(i)\n","\n","        # Sorteia as posições das trocas\n","        posicao = []\n","        for i in range(qtde):\n","            posicao_sorteio = randint(0, len(roleta)-1)\n","            # Guarda o número sorteado\n","            posicao.append(roleta[posicao_sorteio])\n","            # Remove o elemento sorteado da roleta\n","            del roleta[posicao_sorteio]\n","        \n","        # Conta o número das trocas realizadas\n","        troca = 0\n","\n","        # Substitui o elemento pela máscara\n","        for i, token in enumerate(sentenca_token):            \n","            # Se a classe da palavra é a desejada\n","            if sentenca_pos[i] in classe:\n","                # Verifica se a troca deve ser realizada para a posição\n","                if troca in posicao:      \n","                  # Trocar palavra da classe por [MASK]\n","                  sentenca_mascarada = sentenca_mascarada + \"[MASK]\" + \" \"    \n","                  # Guarda a palavra que foi mascarada\n","                  palavra_mascarada = token                                  \n","                else:                  \n","                  # Adiciona o token\n","                  sentenca_mascarada = sentenca_mascarada + token + \" \"\n","                # Avança para a próxima troca\n","                troca = troca + 1\n","            else:\n","              # Adiciona o token\n","                sentenca_mascarada = sentenca_mascarada + token + \" \"\n","      else:        \n","        # Trocar todas as palavras pela mascará, pois a quantidade\n","        # de trocas é igual a quantidade de mascarás existentes na sentença\n","\n","        # Substitui o elemento da classe pela mascará\n","        for i, token in enumerate(sentenca_token):\n","            #print(token, sentenca_pos[i])        \n","            # Se a classe da palavra é a desejada\n","            if sentenca_pos[i] in classe:\n","                # Trocar palavra da classe por [MASK]\n","                sentenca_mascarada = sentenca_mascarada + \"[MASK]\" + \" \"    \n","                # Guarda a palavra que foi mascarada\n","                palavra_mascarada = token \n","            else:\n","                sentenca_mascarada = sentenca_mascarada + token + \" \"\n","    else:\n","      # Não existe palavras da classe especificada      \n","      print(\"Não existe palavras da classe especificada.\")\n","      print(\"sentenca:\",sentenca)\n","      print(\"sentenca_pos:\",sentenca_pos)\n","      sentenca_mascarada = sentenca    \n","  else:\n","    # Quantidade trocas igual a 0\n","    print(\"Não foi especificado uma quantidade de trocas.\")\n","    sentenca_mascarada = sentenca\n","\n","  # Retira o espaço em branco do início e fim da sentença\n","  sentenca_mascarada = sentenca_mascarada.strip(\" \")\n","\n","  return sentenca_mascarada, palavra_mascarada"]},{"cell_type":"markdown","metadata":{"id":"sVoxgoMaMQU-"},"source":["#### Gerar perturbação palavra aleatória"]},{"cell_type":"markdown","metadata":{"id":"h6sISvtuV9eQ"},"source":["Gera as palavras da perturbação da máscara da sentença. Considera determinadas classes morfossintática das palavras."]},{"cell_type":"code","execution_count":141,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389608839,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"JbOsuSX7BkhU"},"outputs":[],"source":["# Import das bibliotecas\n","import torch\n","from random import randint # Biblioteca para o sorteio\n","\n","def getPerturbacaoPalavraSentencaAleatoria(sentenca, \n","                                           sentenca_token, \n","                                           sentenca_pos, \n","                                           classe=[\"VERB\",\"NOUN\",\"AUX\"], \n","                                           qtde=1, \n","                                           top_k_predicao = 100):\n","    \"\"\" \n","        Gera as palavras da perturbação da máscara da sentença.\n","        Considera determinadas classes morfossintática das palavras.\n","            \n","        Parâmetros:\n","          `sentenca` - Sentença a ser mascarada.\n","          `sentenca_token` - Lista com os tokens da sentença.\n","          `sentenca_pos` - Lista com as POS dos tokens da sentença.\n","          `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n","          `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n","                  Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n","                  for menor que quantidade de palavras das classes na sentença.          \n","          `top_k_predicao` - Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","\n","        Retorno:    \n","          `sentenca_mascarada` - Sentença mascarada.\n","          `palavra_mascarada` - Palavra substituídas pela máscara.\n","          `token_predito` - Palavra prevista para a máscara.\n","          `token_peso` - Peso da palavra prevista.\n","          `posicao_sorteio` - Posição da palavra prevista na lista de previsões.\n","          `token_predito_marcado` - Token previsto marcado(##) para a máscara.\n","          `lista_previsoes` - Lista dos 'top_k_predicao' tokens preditos para a máscara.\n","    \"\"\"\n","\n","    #print(\"Sentença original:\", sentenca)\n","    sentenca_mascarada, palavra_mascarada = getSentencaMascarada(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde=1)\n","    \n","    # Adiciona os tokens especiais ao sentenca\n","    sentenca_marcado = \"[CLS] \" + sentenca_mascarada + \"[SEP]\"\n","    #print(\"sentenca_marcado:\", sentenca_marcado)\n","\n","    # Divide as palavras em tokens\n","    sentenca_tokenizado = tokenizer.tokenize(sentenca_marcado)    \n","    #print(\"sentenca_tokenizado:\", sentenca_tokenizado)\n","\n","    # Retorna o índice da mascara de atenção\n","    mascara_atencao_indice = sentenca_tokenizado.index(\"[MASK]\")\n","    #print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n","\n","    # Mapeia os tokens em seus índices do vocabulário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(sentenca_tokenizado)\n","    #print(\"tokens_indexados:\", tokens_indexados)\n","    \n","    # Converte as entradas de lista para tensores do torch\n","    tokens_tensores = torch.tensor([tokens_indexados])\n","    \n","    # Realiza a predição dos tokens\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = model(tokens_tensores)\n","\n","    # Recupera a predição com os embeddings da última camada oculta    \n","    predicao = outputs[0]\n","    \n","    # Normaliza os pesos das predições nos embeddings e calcula sua probabilidade\n","    probabilidades = torch.nn.functional.softmax(predicao[0, mascara_atencao_indice], dim=-1)    \n","    # Retorna os k maiores elementos de determinado tensor de entrada ao longo de uma determinada dimensão de forma ordenada descrescentemente.\n","    \n","    # Se existe mais de uma top_k_predição    \n","    if top_k_predicao != 1:\n","\n","      # Recupera as top_k_predicao predições em ordem de orobabilidades\n","      top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao, sorted=True)\n","      #print(\"top_k_predicao_pesos:\",top_k_predicao_pesos)\n","      #print(\"top_k_predicao_indices:\",top_k_predicao_indices)\n","      #print(\"len(top_k_predicao_indices):\",len(top_k_predicao_indices))\n","\n","      # Sorteia uma predição do intervalo\n","      posicao_sorteio = randint(0, top_k_predicao-1)    \n","      #print(\"posicao_sorteio:\",posicao_sorteio)\n","\n","      # Recupera as predições    \n","      # Mapeia os índices do vocabulário para os seus tokens\n","      token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao_sorteio]])[0]\n","      # Recupera os pesos da predição\n","      token_peso = top_k_predicao_pesos[posicao_sorteio]\n","      #print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | peso:\", float(token_peso))\n","           \n","      # Se o token predito for igual a palavra que foi substituída pela máscara ou desconhecida ([UNK]) sorteia outra palavra\n","      while (palavra_mascarada.lower() == token_predito.lower()) or (token_predito == \"[UNK]\"):\n","          # Sorteia uma predição do intervalo\n","          posicao_sorteio = randint(0, top_k_predicao-1)    \n","          #print(\"posicao_sorteio:\",posicao_sorteio)\n","\n","          # Recupera as predições    \n","          # Mapeia os índices do vocabulário para os seus tokens\n","          token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao_sorteio]])[0]\n","          # Recupera os pesos da predição\n","          token_peso = top_k_predicao_pesos[posicao_sorteio]\n","          #print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | peso:\", float(token_peso))\n","    \n","    else:\n","      # Se existe somente uma predição, esta não pode ser igual a palavra mascarada,\n","      # portanto é necessário aumentar a quantidade de top_k predições para gerar uma predição diferente \n","      # da palavra mascarada.\n","              \n","      # Recupera as top_k_predicao predições em ordem de orobabilidades\n","      top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao, sorted=True)\n","      #print(\"top_k_predicao_pesos:\",top_k_predicao_pesos)\n","      #print(\"top_k_predicao_indices:\",top_k_predicao_indices)\n","      #print(\"len(top_k_predicao_indices):\",len(top_k_predicao_indices))\n","\n","      # Sorteia uma predição do intervalo\n","      posicao_sorteio = randint(0, top_k_predicao-1)    \n","      #print(\"posicao_sorteio:\",posicao_sorteio)\n","\n","      # Recupera as predições    \n","      # Mapeia os índices do vocabulário para os seus tokens\n","      token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao_sorteio]])[0]\n","      # Recupera os pesos da predição\n","      token_peso = top_k_predicao_pesos[posicao_sorteio]\n","      #print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | peso:\", float(token_peso))\n","\n","      # Se o token predito for igual a palavra que foi substituída pela máscara ou desconhecida ([UNK]) sorteia outra palavra\n","      while (palavra_mascarada.lower() == token_predito.lower()) or (token_predito == \"[UNK]\"):\n","          \n","          # Incrementa a quantidade de predições para pegar uma palavra diferente\n","          top_k_predicao = top_k_predicao + 1\n","\n","          # Recupera as top_k_predicao + 1 predições em ordem de orobabilidades\n","          top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao, sorted=True)\n","          #print(\"top_k_predicao_pesos:\",top_k_predicao_pesos)\n","          #print(\"top_k_predicao_indices:\",top_k_predicao_indices)\n","          #print(\"len(top_k_predicao_indices):\",len(top_k_predicao_indices))\n","\n","          # Sorteia uma predição do intervalo\n","          posicao_sorteio = randint(0, top_k_predicao-1)    \n","          #print(\"posicao_sorteio:\",posicao_sorteio)\n","\n","          # Recupera as predições    \n","          # Mapeia os índices do vocabulário para os seus tokens\n","          token_predito = tokenizer.convert_ids_to_tokens([top_k_predicao_indices[posicao_sorteio]])[0]\n","          # Recupera os pesos da predição\n","          token_peso = top_k_predicao_pesos[posicao_sorteio]\n","          #print((posicao_sorteio+1), \"[MASK]: \", token_predito, \" | peso:\", float(token_peso))\n","\n","    token_predito_marcado = token_predito\n","    if \"##\" in token_predito:      \n","      # Remove \"##\" do token\n","      token_predito = token_predito[2:]\n","\n","    # Lista das predições\n","    lista_predicoes = []\n","    for i, indice_predicao in enumerate(top_k_predicao_indices):\n","        # Mapeia os índices do vocabulário para os seus tokens\n","        token_predito1 = tokenizer.convert_ids_to_tokens([indice_predicao])[0]\n","        token_peso1 = top_k_predicao_pesos[i]\n","        lista_predicoes.append([(i+1), token_predito1, float(token_peso1)])        \n","      \n","    return sentenca_mascarada, palavra_mascarada, token_predito, token_peso, posicao_sorteio, token_predito_marcado, lista_predicoes"]},{"cell_type":"markdown","metadata":{"id":"T4TlEyO8nspd"},"source":["#### Gerar perturbação palavra sequencial"]},{"cell_type":"code","execution_count":142,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389608840,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"RkTpSL8UnwYb"},"outputs":[],"source":["# Import das bibliotecas\n","import torch\n","from random import randint # Biblioteca para o sorteio\n","\n","def getPerturbacaoPalavraSentencaSequencial(sentenca_mascarada, \n","                                            palavra_mascarada,                                            \n","                                            top_k_predicao = 100):\n","  \n","    \"\"\" \n","        Gera as palavras da perturbação da máscara da sentença.\n","        Considera determinadas classes morfossintática das palavras.\n","            \n","        Parâmetros:\n","          `sentenca_mascarada` - Sentença mascarada.\n","          `palavra_mascarada` - Palavra substituídas pela máscara.\n","          `top_k_predicao` - Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","\n","        Retorno:    \n","          `lista_predicoes` - Lista com as top_k_predições da sentença mascarada. Cada registro possui:\n","              `indice` - ìndice predição.\n","              `sentenca_mascarada` - Sentença mascarada.\n","              `palavra_mascarada` - Palavra substituídas pela máscara.\n","              `token_predito` - Palavra prevista para a máscara.\n","              `token_peso` - Peso da palavra prevista.\n","              `posicao_sorteio` - Posição da palavra prevista na lista de previsões.\n","              `token_predito_marcado` - Token previsto marcado(##) para a máscara.          \n","    \"\"\"\n","\n","    # Adiciona os tokens especiais ao sentenca\n","    sentenca_marcado = \"[CLS] \" + sentenca_mascarada + \"[SEP]\"\n","    #print(\"sentenca_marcado:\", sentenca_marcado)\n","\n","    # Divide as palavras em tokens\n","    sentenca_tokenizado = tokenizer.tokenize(sentenca_marcado)    \n","    #print(\"sentenca_tokenizado:\", sentenca_tokenizado)\n","\n","    # Retorna o índice da mascara de atenção\n","    mascara_atencao_indice = sentenca_tokenizado.index(\"[MASK]\")\n","    #print(\"mascara_atencao_indice:\", mascara_atencao_indice)\n","\n","    # Mapeia os tokens em seus índices do vocabulário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(sentenca_tokenizado)\n","    #print(\"tokens_indexados:\", tokens_indexados)\n","    \n","    # Converte as entradas de lista para tensores do torch\n","    tokens_tensores = torch.tensor([tokens_indexados])\n","    \n","    # Realiza a predição dos tokens\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = model(tokens_tensores)\n","\n","    # Recupera a predição com os embeddings da última camada oculta    \n","    predicao = outputs[0]\n","    \n","    # Normaliza os pesos das predições nos embeddings e calcula sua probabilidade\n","    probabilidades = torch.nn.functional.softmax(predicao[0, mascara_atencao_indice], dim=-1)    \n","    \n","    # Retorna os k maiores elementos de determinado tensor de entrada ao longo de uma determinada \n","    # dimensão de forma ordenada descrescentemente.    \n","    # Adiciona 20 elementos em topkpredicao para pular os tokens desconhecidos([UNK])\n","    MARGEM_UNK = 20\n","    top_k_predicao_pesos, top_k_predicao_indices = torch.topk(probabilidades, top_k_predicao + MARGEM_UNK, sorted=True)\n","    #print(\"top_k_predicao_pesos:\",top_k_predicao_pesos)\n","    #print(\"top_k_predicao_indices:\",top_k_predicao_indices)\n","    #print(\"len(top_k_predicao_indices):\",len(top_k_predicao_indices))\n","\n","    # Lista das predições\n","    lista_predicoes = []\n","    indice_token = 0\n","    for i, indice_predicao in enumerate(top_k_predicao_indices):\n","\n","        # Mapeia os índices do vocabulário para os seus tokens\n","        token_predito = tokenizer.convert_ids_to_tokens([indice_predicao])[0]\n","        token_peso = top_k_predicao_pesos[i]\n","\n","        # Pula o token se for desconhecido e existir tokens disponíveis\n","        if token_predito != \"[UNK]\" and indice_token < (top_k_predicao):\n","          \n","          # Guarda o token original        \n","          token_predito_marcado = token_predito\n","          \n","          # Se o token tiver ##\n","          if \"##\" in token_predito:      \n","              # Remove \"##\" do token     \n","              token_predito = token_predito[2:]\n","\n","          # Guarda o token\n","          lista_predicoes.append([indice_token, sentenca_mascarada, palavra_mascarada, token_predito, float(token_peso), token_predito_marcado])\n","\n","          # Incrementa para o próximo token\n","          indice_token = indice_token + 1\n","      \n","    return lista_predicoes"]},{"cell_type":"markdown","metadata":{"id":"R6VUrXR4MVyh"},"source":["#### Gera perturbacao sentença aleatória"]},{"cell_type":"markdown","metadata":{"id":"kGVhA-NSWIYW"},"source":[" Gera a sentença com a perturbação. Considera determinadas classes morfossintática das palavras."]},{"cell_type":"code","execution_count":143,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389608840,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"GgJ2hx5DV99t"},"outputs":[],"source":["def getPerturbacaoSentencaAleatoria(sentenca, \n","                                    sentenca_token, \n","                                    sentenca_pos, \n","                                    classe=[\"VERB\",\"NOUN\",\"AUX\"], \n","                                    qtde=1, \n","                                    top_k_predicao = 100):\n","  \"\"\" \n","      Gera a sentença com a perturbação.\n","      Considera determinadas classes morfossintática das palavras.\n","          \n","      Parâmetros:\n","        `sentenca` - Sentença a ser mascarada.\n","        `sentenca_token` - Lista com os tokens da sentença.\n","        `sentenca_pos` - Lista com as POS dos tokens da sentença.\n","        `classe` - Lista com as classes morfossintática das palavras a serem mascarada com [MASK].\n","        `qtde` - Quantidade de mascarada a serem realizadas nas palavras das sentenças.\n","                Seleciona aleatoriamente a(s) palavra(s) a ser(em) mascarada(s) se a qtde \n","                for menor que quantidade de palavras das classes na sentença.\n","        `top_k_predicao` - Quantidade de palavras a serem recuperadas mais próximas da máscara.                \n","\n","      Retorno:    \n","        `sentenca_perturbada` - Sentença com a perturbação.\n","        `sentenca_mascarada` - Sentença mascarada.\n","        `palavra_mascarada` - Palavra substituídas pela máscara.\n","        `token_predito` - Token previsto para a máscara.\n","        `token_predito_marcado` - Token previsto marcado(##) para a máscara.\n","        `lista_predicoes` - Lista dos tokens preditos para a máscara.\n","        \n","  \"\"\"\n","\n","  # Recupera a sentença mascarada e o token pervisto\n","  sentenca_mascarada, palavra_mascarada, token_predito, token_peso, posicao_sorteio, token_predito_marcado, lista_predicoes = getPerturbacaoPalavraSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe, qtde, top_k_predicao)\n","  \n","  # Se existir o token especial [MASK]\n","  if \"[MASK]\" in sentenca_mascarada:\n","    \n","      # Substituir a mascará pelo token predito\n","      sentenca_perturbada = sentenca_mascarada.replace(\"[MASK]\", token_predito)\n","  \n","  return sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, token_peso, posicao_sorteio, token_predito_marcado, lista_predicoes"]},{"cell_type":"markdown","metadata":{"id":"IGc-CVt6Mmfe"},"source":["#### Gera documentos perturbados aleatória"]},{"cell_type":"markdown","metadata":{"id":"ZBJ5NKjuWMak"},"source":["Gera a perturbação para todas as sentenças dos documentos do conjunto de dados.\n","\n","Todas as perturbações de um documento são diferentes uma das outras."]},{"cell_type":"code","execution_count":144,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389608841,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"iUSm9qvGQ8JB"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","\n","def getDocumentosPerturbadosAleatorio(lista_documentos_originais, \n","                                      model_args):\n","\n","  # Lista para armazenar os documentos perturbados\n","  lista_documentos_perturbados = []\n","\n","  # Barra de progresso dos dados\n","  dados_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Dados\", unit=f\"registro\", total=len(lista_documentos_originais))\n","\n","  # Percorre a lista de documentos\n","  for i, linha_documento in dados_bar:\n","    #if i < 2:     \n","      #print(\"linha_documento:\",linha_documento)\n","      # Recupera o id do documento\n","      id_documento = linha_documento[0]     \n","      #print(\"id_documento:\",id_documento)    \n","      # Recupera o documento \n","      documento = linha_documento[2]\n","      #print(\"documento:\",documento) \n","      \n","      # Recupera as sentenças do documento\n","      lista_sentenca_documento = linha_documento[1]\n","      # Localiza a POSTagging do documento\n","      lista_pos_documento = lista_documentos_originais_pos.iloc[i][1]  \n","\n","      #print(\"lista_sentenca_documento:\",lista_sentenca_documento)\n","      #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","      #print(\"lista_pos_documento:\",lista_pos_documento)\n","      #print(\"len(lista_pos_documento):\",len(lista_pos_documento))\n","\n","      # Gera os documentos perturbados a partir do original\n","      for j in range(0, model_args.documentos_perturbados):\n","\n","        # Guarda os dados das sentenças perturbadas\n","        registro_sentencas_perturbadas = []\n","        # Lista com as sentenças perturbadas do documento\n","        lista_sentenca_documento_perturbado = []\n","        # Concatena o texto do documento perturbado\n","        documento_perturbado = \"\"\n","\n","        # Percorre as sentenças do documento\n","        for k, sentenca in enumerate(lista_sentenca_documento):      \n","          #print(\"sentenca Original:\",sentenca)\n","\n","          # Carrega as POSTagging da sentença\n","          sentenca_token = lista_pos_documento[k][0]\n","          sentenca_pos = lista_pos_documento[k][1]\n","          sentenca_verbos = lista_pos_documento[k][2]\n","        \n","          #print(\"sentenca_token:\",sentenca_token)\n","          #print(\"len(sentenca_token):\",len(sentenca_token))\n","          #print(\"sentenca_pos:\",sentenca_pos)\n","          #print(\"len(sentenca_pos):\",len(sentenca_pos))\n","          #print(\"sentenca_verbos:\",sentenca_verbos)\n","          #print(\"len(sentenca_verbos):\",len(sentenca_verbos))\n","\n","          # Gerar sentença com a perturbação\n","          sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, token_peso, posicao_sorteio, token_predito_marcado, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde = 1, top_k_predicao = model_args.top_k_predicao)      \n","\n","          # Se a sentencaPermutada for igual a alguma já perturbada gera outra\n","          conta_repeticao = 0\n","          while sentenca_perturbada.lower() in lista_sentenca_documento_perturbado and conta_repeticao < 3:\n","              \n","              # Gerar sentença com a perturbação pois é igual a uma já existente.\n","              sentenca_perturbada, sentenca_mascarada, palavra_mascarada, token_predito, token_peso, posicao_sorteio, token_predito_marcado, lista_predicoes = getPerturbacaoSentencaAleatoria(sentenca, sentenca_token, sentenca_pos, classe=[\"VERB\",\"NOUN\",\"AUX\"], qtde = 1, top_k_predicao = model_args.top_k_predicao) \n","\n","              # Tenta gerar uma nova 3 vezes\n","              conta_repeticao = conta_repeticao + 1\n","\n","          #print(\"sentenca Original      :\",sentenca)      \n","          #print(\"     sentenca_perturbada:\",sentenca_perturbada) \n","          #print(\"     conta_repeticao    :\",conta_repeticao) \n","          #print(\"                    => palavra_mascarada:\",palavra_mascarada, \" predito:\", token_predito)\n","          # Cria lista das sentenças mascaradas, palavras mascaradas e os tokens preditos\n","          registro_sentencas_perturbadas.append([sentenca_mascarada, palavra_mascarada, token_predito, token_peso, posicao_sorteio, token_predito_marcado])\n","          # Lista da sentenças perturbadas do documento\n","          lista_sentenca_documento_perturbado.append(sentenca_perturbada)\n","          # Concatena em um texto as sentenças do  documento perturbado\n","          documento_perturbado = documento_perturbado + sentenca_perturbada\n","\n","        # Concatena o id do documento e o id da perturbação\n","        novo_id_documento  = str(id_documento) + \"_pert_\" + str(j)\n","\n","        # Guarda o documento perturbado\n","        lista_documentos_perturbados.append([novo_id_documento, \n","                                             lista_sentenca_documento_perturbado, \n","                                             documento_perturbado, \n","                                             registro_sentencas_perturbadas])\n","              \n","  print(\"TERMINEI PERTURBAÇÃO ALEATÓRIA.\")\n","  return lista_documentos_perturbados"]},{"cell_type":"markdown","metadata":{"id":"ZX6IeZslMwEu"},"source":["#### Gera perturbação documentos sequencial"]},{"cell_type":"code","execution_count":145,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1664389608841,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"1m4yJ6eVj9eA"},"outputs":[],"source":["def gerarPerturbacoesSequencial(id_documento, sentenca_mascarada, palavra_mascarada, model_args):\n","    \n","  registro_sentencas_perturbadas = []\n","\n","  # Recupera as predições para a sentença mascarada\n","  lista_predicoes = getPerturbacaoPalavraSentencaSequencial(sentenca_mascarada,\n","                                                            palavra_mascarada,\n","                                                            top_k_predicao = model_args.top_k_predicao)                                                            \n","  #print(\"lista_predicoes:\", len(lista_predicoes))\n","  \n","  # Percorre a lista de predições e faz a substituicão\n","  for predicao in lista_predicoes:\n","    \n","    #print(\"predicao:\",predicao)\n","\n","    # Se existir o token especial [MASK] na sentença marcada\n","    if \"[MASK]\" in predicao[1]: \n","\n","      # Substituir a mascará pelo token predito\n","      sentenca_perturbada = sentenca_mascarada.replace(\"[MASK]\", predicao[3])\n","\n","      # Concatena o id do documento e o id da perturbação\n","      novo_id_documento  = str(id_documento) + \"_pert_\" + str(predicao[0])\n","\n","      # Guarda o registro da sentença perturbada\n","      registro_sentencas_perturbadas.append([novo_id_documento,    #0\n","                                             sentenca_perturbada,  #1\n","                                             predicao[1],          #2 sentenca_mascarada\n","                                             predicao[2],          #3 palavra_mascarada\n","                                             predicao[3],          #4 token_predito\n","                                             predicao[4],          #5 float(token_peso)\n","                                             predicao[5]])         #6 token_predito_marcado      \n","    else:\n","      print(\"Não existe máscara na sentença:\", sentenca_mascarada)\n","  \n","  return registro_sentencas_perturbadas"]},{"cell_type":"code","execution_count":146,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1664389608842,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"6Rinqy_QL9IF"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","\n","def getDocumentosPerturbadosSequencial(lista_documentos_originais, model_args):\n","\n","  # Lista para armazenar os documentos perturbados\n","  lista_documentos_perturbados = []\n","\n","  # Barra de progresso dos dados\n","  dados_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Dados\", unit=f\"registro\", total=len(lista_documentos_originais))\n","\n","  # Percorre a lista de documentos\n","  for i, linha_documento in dados_bar:\n","    #if i < 3:     \n","      #print(\"linha_documento:\",linha_documento)\n","      # Recupera o id do documento\n","      id_documento = linha_documento[0]     \n","      #print(\"id_documento:\",id_documento)    \n","      # Recupera o documento \n","      documento = linha_documento[2]\n","      #print(\"documento:\",documento) \n","      \n","      # Recupera as sentenças do documento\n","      lista_sentenca_documento = linha_documento[1]\n","      # Localiza a POSTagging do documento\n","      lista_pos_documento = lista_documentos_originais_pos.iloc[i][1]  \n","\n","      #print(\"lista_sentenca_documento:\",lista_sentenca_documento)\n","      #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","      #print(\"lista_pos_documento:\",lista_pos_documento)\n","      #print(\"len(lista_pos_documento):\",len(lista_pos_documento))\n","\n","      # Se o documento possui somente 1 sentença, não precisa selecionar uma aleatória para perturbar \n","      if len(lista_sentenca_documento) == 1:\n","\n","        # Percorre as sentenças do documento (neste caso somente 1 sentença)\n","        # Seleciona uma sentença para gerar a perturbação\n","        for k, sentenca in enumerate(lista_sentenca_documento):      \n","          #print(\"sentenca Original:\",sentenca)\n","\n","          # Carrega as POSTagging da sentença\n","          sentenca_token = lista_pos_documento[k][0]\n","          sentenca_pos = lista_pos_documento[k][1]\n","          sentenca_verbos = lista_pos_documento[k][2]\n","            \n","        #print(\"sentenca_token:\",sentenca_token)\n","        #print(\"len(sentenca_token):\",len(sentenca_token))\n","        #print(\"sentenca_pos:\",sentenca_pos)\n","        #print(\"len(sentenca_pos):\",len(sentenca_pos))\n","        #print(\"sentenca_verbos:\",sentenca_verbos)\n","        #print(\"len(sentenca_verbos):\",len(sentenca_verbos))\n","\n","        # Gerar a sentença mascarada para a sentença\n","        sentenca_mascarada, palavra_mascarada = getSentencaMascarada(sentenca, \n","                                                                     sentenca_token, \n","                                                                     sentenca_pos,\n","                                                                     classe=[\"VERB\",\"NOUN\",\"AUX\"], \n","                                                                     qtde=1)\n","        #print(\"sentenca_mascarada:\", sentenca_mascarada)\n","        #print(\"palavra_mascarada:\", palavra_mascarada)\n","          \n","        # Gerar as sentenças com as perturbações para a sentença mascarada\n","        lista_perturbacoes = gerarPerturbacoesSequencial(id_documento, \n","                                                         sentenca_mascarada, \n","                                                         palavra_mascarada, \n","                                                         model_args)\n","        #print(\"lista_perturbacoes:\", len(lista_perturbacoes))\n","\n","        # Percorre as perturbações\n","        for perturbacao in lista_perturbacoes: \n","          \n","          # Lista com as sentenças perturbadas do documento\n","          lista_sentenca_documento_perturbado = []\n","\n","          # Guarda os dados das sentenças perturbadas\n","          registro_sentencas_perturbadas = []\n","          \n","          # Concatena o texto do documento perturbado\n","          documento_perturbado = \"\"\n","\n","          # Guarda o registro da sentença perturbada\n","          registro_sentencas_perturbadas.append([perturbacao[2],  #0 novoId\n","                                                 perturbacao[3],  #1 sentenca_perturbada\n","                                                 perturbacao[4],  #2 sentenca_mascarada\n","                                                 perturbacao[5],  #3 palavra_mascarada\n","                                                 perturbacao[6]]) #4 token_predito_marcado            \n","        \n","          # Lista da sentenças perturbadas do documento\n","          lista_sentenca_documento_perturbado.append(perturbacao[1])\n","          # Concatena em um texto as sentenças do  documento perturbado\n","          documento_perturbado = documento_perturbado + perturbacao[1]\n","            \n","          # Guarda o documento perturbado\n","          lista_documentos_perturbados.append([perturbacao[0], \n","                                               lista_sentenca_documento_perturbado, \n","                                               documento_perturbado, \n","                                               registro_sentencas_perturbadas])\n","\n","      else:\n","        print(\"Documento com mais de uma sentença\")\n","        # Selecionar aleatoriamente uma sentença para perturbar\n","              \n","  print(\"TERMINEI PERTURBAÇÃO SEQUENCIAL.\")\n","  return lista_documentos_perturbados"]},{"cell_type":"markdown","metadata":{"id":"SQXNmcqrljZF"},"source":["#### Gera a perturbação"]},{"cell_type":"code","execution_count":147,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["9876ffc4bf01485ebe6d54cc037c2e04","8428be1d9f1a4c339ee259b5671d8cad","888181d6205d490284ff9040bbef73f0","a22771792d64437e81a78f569745f0c1","98e5eb085bfa4dac998108d80d460df0","82b6a5b253aa4021bbfbbd0d0078dad5","57929a3188e94d3cb6036d5d0a01ee17","44d209214f9045c8a0f006b58e35a8a6","46986af4631e44a8bc7fc753643720cc","d7ebb06e5ceb4feba9c9e40abe0700f2","cb5b96954da547efb1402b8efe7d529f"]},"executionInfo":{"elapsed":19229,"status":"ok","timestamp":1664389628058,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"QVb4YRzsLnGi","outputId":"05c29307-5b5a-4096-d954-76660bd25b3b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Dados:   0%|          | 0/40 [00:00<?, ?registro/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9876ffc4bf01485ebe6d54cc037c2e04"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["TERMINEI PERTURBAÇÃO SEQUENCIAL.\n"]}],"source":["if SELECAO_ALEATORIA_TOP_K == True:  \n","  lista_documentos_perturbados = getDocumentosPerturbadosAleatorio(lista_documentos_originais, model_args)\n","\n","else:\n","  lista_documentos_perturbados = getDocumentosPerturbadosSequencial(lista_documentos_originais, model_args)"]},{"cell_type":"markdown","metadata":{"id":"2brsc83ReC9W"},"source":["### 5.2.3 Cria o arquivo com as perturbações"]},{"cell_type":"code","execution_count":148,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1664389628059,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"j9hX13wgd63W"},"outputs":[],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Cria o dataframe da lista\n","df_lista_documentos_perturbados = pd.DataFrame(lista_documentos_perturbados, columns = [\"id\", \"perturbado\", \"documento_perturbado\", \"sentencas\"])\n","\n","# Salva o arquivo perturbado\n","df_lista_documentos_perturbados.to_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO,  sep=\";\", index=False)"]},{"cell_type":"code","execution_count":149,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1664389628061,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"VJwgPw9ad-mN","outputId":"30fbb74f-4659-4358-de51-b5de2e28980b"},"outputs":[{"output_type":"stream","name":"stdout","text":["4000\n"]}],"source":["print(len(df_lista_documentos_perturbados))"]},{"cell_type":"code","execution_count":150,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1664389628061,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"NWXOQ2CM6aJV","outputId":"afdd4d19-0eba-41cf-830e-7e9af6ce1404"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                id                                         perturbado  \\\n","2344  12p0_pert_44  [O que é uma esfera e como desempilhar um elem...   \n","1911  10p0_pert_11  [O que é uma pilha e como descobrir seu elemen...   \n","3026    16_pert_26  [O que é uma fila e como fechar e desenfileira...   \n","3153  16p0_pert_53  [O que é uma pilha e como acomodar e desenfile...   \n","3359  17p0_pert_59  [Como são implementadas as operações de recebe...   \n","\n","                                   documento_perturbado  \\\n","2344  O que é uma esfera e como desempilhar um eleme...   \n","1911  O que é uma pilha e como descobrir seu elemento ?   \n","3026  O que é uma fila e como fechar e desenfileirar...   \n","3153  O que é uma pilha e como acomodar e desenfilei...   \n","3359  Como são implementadas as operações de receber...   \n","\n","                                              sentencas  \n","2344  [[O que é uma [MASK] e como desempilhar um ele...  \n","1911  [[O que é uma pilha e como [MASK] seu elemento...  \n","3026  [[O que é uma fila e como [MASK] e desenfileir...  \n","3153  [[O que é uma pilha e como [MASK] e desenfilei...  \n","3359  [[Como são implementadas as operações de [MASK...  "],"text/html":["\n","  <div id=\"df-aa8832bc-1598-4fba-aab8-d9d7b0d775ea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2344</th>\n","      <td>12p0_pert_44</td>\n","      <td>[O que é uma esfera e como desempilhar um elem...</td>\n","      <td>O que é uma esfera e como desempilhar um eleme...</td>\n","      <td>[[O que é uma [MASK] e como desempilhar um ele...</td>\n","    </tr>\n","    <tr>\n","      <th>1911</th>\n","      <td>10p0_pert_11</td>\n","      <td>[O que é uma pilha e como descobrir seu elemen...</td>\n","      <td>O que é uma pilha e como descobrir seu elemento ?</td>\n","      <td>[[O que é uma pilha e como [MASK] seu elemento...</td>\n","    </tr>\n","    <tr>\n","      <th>3026</th>\n","      <td>16_pert_26</td>\n","      <td>[O que é uma fila e como fechar e desenfileira...</td>\n","      <td>O que é uma fila e como fechar e desenfileirar...</td>\n","      <td>[[O que é uma fila e como [MASK] e desenfileir...</td>\n","    </tr>\n","    <tr>\n","      <th>3153</th>\n","      <td>16p0_pert_53</td>\n","      <td>[O que é uma pilha e como acomodar e desenfile...</td>\n","      <td>O que é uma pilha e como acomodar e desenfilei...</td>\n","      <td>[[O que é uma pilha e como [MASK] e desenfilei...</td>\n","    </tr>\n","    <tr>\n","      <th>3359</th>\n","      <td>17p0_pert_59</td>\n","      <td>[Como são implementadas as operações de recebe...</td>\n","      <td>Como são implementadas as operações de receber...</td>\n","      <td>[[Como são implementadas as operações de [MASK...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa8832bc-1598-4fba-aab8-d9d7b0d775ea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aa8832bc-1598-4fba-aab8-d9d7b0d775ea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aa8832bc-1598-4fba-aab8-d9d7b0d775ea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":150}],"source":["df_lista_documentos_perturbados.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"WqzXU_Icqiqg"},"source":["### 5.2.4 Compacta e copia o arquivo perturbado para uma pasta do GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"37e0qS7Dkwou"},"source":["Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"code","execution_count":151,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374,"status":"ok","timestamp":1664389628419,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"4f2VhAHXkwow","outputId":"d56ed676-cbc3-4c84-c7f8-4f41b75870d0"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei compactação.\n"]}],"source":["!zip -o -q -j \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO\"\n","\n","logging.info(\"Terminei compactação.\")"]},{"cell_type":"markdown","metadata":{"id":"JJH7kEhiWmi9"},"source":["Copia o arquivo compactado e os arquivos individuais para o GoogleDrive"]},{"cell_type":"code","execution_count":152,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":761,"status":"ok","timestamp":1664389629179,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"URD2iAO3qiqg","outputId":"d76e5da2-1b9f-44c8-87ec-3917706e58ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_COIN_PTBR/perturbado_p100_k100.zip': No such file or directory\n"]},{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}],"source":["# Import das bibliotecas.\n","import os\n","import datetime\n","\n","# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","    # Recupera a hora do sistema.\n","    data_e_hora_str = datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M\")\n","   \n","    # Copia o arquivo atual para um backup no google drive\n","    !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO$data_e_hora_str\"\n","    \n","    # Copia o arquivo perturbado\n","    !cp \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_DRIVE\"\n","    \n","    logging.info(\"Terminei a cópia.\")"]},{"cell_type":"markdown","metadata":{"id":"TkncKDN1i7kq"},"source":["### 5.2.5 Carrega os dados"]},{"cell_type":"code","execution_count":153,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1664389629180,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"jWf1pJbyBbUz","outputId":"8886dae9-d42b-492e-ca5b-a69cafbb0e34"},"outputs":[{"output_type":"stream","name":"stdout","text":["4000\n"]}],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","df_lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","\n","print(len(df_lista_documentos_perturbados))"]},{"cell_type":"code","execution_count":154,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1664389629181,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"UDO7gHyiBbU5","outputId":"76caaf5d-3cd2-4311-941d-95c3a682b7c0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id                                         perturbado  \\\n","1545  8p0_pert_45  ['Como desempilhar comandos em uma estrutura d...   \n","1866   10_pert_66  ['O que é uma fila e como administrar seu elem...   \n","1077    6_pert_77  ['Como empilhar e procurar elementos em uma es...   \n","1321  7p0_pert_21       ['Como desempilhar elementos em uma obra ?']   \n","361   2p0_pert_61           ['Como montar elementos em uma pilha ?']   \n","\n","                                   documento_perturbado  \\\n","1545  Como desempilhar comandos em uma estrutura de ...   \n","1866  O que é uma fila e como administrar seu elemen...   \n","1077  Como empilhar e procurar elementos em uma estr...   \n","1321           Como desempilhar elementos em uma obra ?   \n","361                Como montar elementos em uma pilha ?   \n","\n","                                              sentencas  \n","1545  [['Como desempilhar [MASK] em uma estrutura de...  \n","1866  [['O que é uma fila e como [MASK] seu elemento...  \n","1077  [['Como empilhar e [MASK] elementos em uma est...  \n","1321  [['Como desempilhar elementos em uma [MASK] ?'...  \n","361   [['Como [MASK] elementos em uma pilha ?', 'des...  "],"text/html":["\n","  <div id=\"df-6005c7ca-3fa7-4d1d-a581-568beff51d31\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1545</th>\n","      <td>8p0_pert_45</td>\n","      <td>['Como desempilhar comandos em uma estrutura d...</td>\n","      <td>Como desempilhar comandos em uma estrutura de ...</td>\n","      <td>[['Como desempilhar [MASK] em uma estrutura de...</td>\n","    </tr>\n","    <tr>\n","      <th>1866</th>\n","      <td>10_pert_66</td>\n","      <td>['O que é uma fila e como administrar seu elem...</td>\n","      <td>O que é uma fila e como administrar seu elemen...</td>\n","      <td>[['O que é uma fila e como [MASK] seu elemento...</td>\n","    </tr>\n","    <tr>\n","      <th>1077</th>\n","      <td>6_pert_77</td>\n","      <td>['Como empilhar e procurar elementos em uma es...</td>\n","      <td>Como empilhar e procurar elementos em uma estr...</td>\n","      <td>[['Como empilhar e [MASK] elementos em uma est...</td>\n","    </tr>\n","    <tr>\n","      <th>1321</th>\n","      <td>7p0_pert_21</td>\n","      <td>['Como desempilhar elementos em uma obra ?']</td>\n","      <td>Como desempilhar elementos em uma obra ?</td>\n","      <td>[['Como desempilhar elementos em uma [MASK] ?'...</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>2p0_pert_61</td>\n","      <td>['Como montar elementos em uma pilha ?']</td>\n","      <td>Como montar elementos em uma pilha ?</td>\n","      <td>[['Como [MASK] elementos em uma pilha ?', 'des...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6005c7ca-3fa7-4d1d-a581-568beff51d31')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6005c7ca-3fa7-4d1d-a581-568beff51d31 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6005c7ca-3fa7-4d1d-a581-568beff51d31');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":154}],"source":["df_lista_documentos_perturbados.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Bcjt085lZGUr"},"source":["## 6.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","execution_count":155,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1664389629182,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"H50_GKJwpDha","outputId":"f16ebeaf-1626-45c7-acf5-3c2eadb3a2b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento:  0:06:34 (h:mm:ss)\n"]}],"source":["# Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempo_total_processamento))"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9876ffc4bf01485ebe6d54cc037c2e04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8428be1d9f1a4c339ee259b5671d8cad","IPY_MODEL_888181d6205d490284ff9040bbef73f0","IPY_MODEL_a22771792d64437e81a78f569745f0c1"],"layout":"IPY_MODEL_98e5eb085bfa4dac998108d80d460df0"}},"8428be1d9f1a4c339ee259b5671d8cad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82b6a5b253aa4021bbfbbd0d0078dad5","placeholder":"​","style":"IPY_MODEL_57929a3188e94d3cb6036d5d0a01ee17","value":"Dados: 100%"}},"888181d6205d490284ff9040bbef73f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44d209214f9045c8a0f006b58e35a8a6","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46986af4631e44a8bc7fc753643720cc","value":40}},"a22771792d64437e81a78f569745f0c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7ebb06e5ceb4feba9c9e40abe0700f2","placeholder":"​","style":"IPY_MODEL_cb5b96954da547efb1402b8efe7d529f","value":" 40/40 [00:19&lt;00:00,  1.97registro/s]"}},"98e5eb085bfa4dac998108d80d460df0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b6a5b253aa4021bbfbbd0d0078dad5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57929a3188e94d3cb6036d5d0a01ee17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44d209214f9045c8a0f006b58e35a8a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46986af4631e44a8bc7fc753643720cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7ebb06e5ceb4feba9c9e40abe0700f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb5b96954da547efb1402b8efe7d529f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}