{"cells":[{"cell_type":"markdown","metadata":{"id":"78HE8FLsKN9Q"},"source":["#Ajuste fino do conjunto de dados do CohQuAD CoIn pt-br usando BERT Transformers by HuggingFace e Lotes Inteligentes e Validação Cruzada para todos os Folds\n","\n","Realiza o ajuste fino do modelo BERT pré-treinado com o conjunto de dados para discriminar documentos originais e modificados e avalia utilizando validação cruzada 10 fold.\n","\n","Classes:\n","- 1 - Documento original\n","- 0 - Documento modificado\n","\n","Características:\n","- Realiza o ajuste fino utilizando documentos originais e modificados em pares.\n","- O Treinamento do modelo utiliza o conjunto de dados com um treinamento para um fold com 90% dos dados.\n","- A avaliação do modelo utiliza o conjunto de dados de teste para um fold com 10% dos dados.\n","- Realiza o ajuste fino em 10 pares de folds de treino e teste.\n","- Utiliza Lotes Inteligentes para otimizar o tempo de execução de treinamento.\n","\n","- A seção 2 - parametrização define os argumentos da execução.\n","\n","Utiliza o arquivo `COHEBERT_KFOLD_10_PX_KY.zip`, X é o número de documentos modificados e Y o valor de top K predições.\n","\n","----------------------------\n","\n","**Link biblioteca Transformers:**\n","https://github.com/huggingface/transformers\n","\n","\n","**Artigo original BERT:**\n","https://arxiv.org/pdf/1506.06724.pdf\n","\n","**Artigo padding dinâmico:**\n","https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e"]},{"cell_type":"markdown","metadata":{"id":"P3G9t8llcrKz"},"source":["# 1 Preparação do ambiente\n","Preparação do ambiente para execução do notebook."]},{"cell_type":"markdown","metadata":{"id":"cW_5CN8En7zl"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rcTEKloUn-VK","executionInfo":{"status":"ok","timestamp":1664487228219,"user_tz":180,"elapsed":1170,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LOHCMMDsiyZg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487230360,"user_tz":180,"elapsed":765,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"5976ce97-bc0d-4590-dafc-a4c2c1103655"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Tempo de início de processamento:  1664487224.1446238 (h:mm:ss)\n"]}],"source":["print(\"  Tempo de início de processamento:  {:} (h:mm:ss)\".format(inicio_processamento))"]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Fj5TaAH_5-nB","executionInfo":{"status":"ok","timestamp":1664487230361,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================  \n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.    \n","    \"\"\"\n","    \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):  \n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","    \n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"5B1mvfAU5jZf","executionInfo":{"status":"ok","timestamp":1664487230362,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"    \n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","    \n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.      \n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.      \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","    \n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download    \n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]  \n","\n","    # Define o nome e caminho do arquivo temporário    \n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","    \n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","    \n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:        \n","        tamanho_conteudo = data.headers.get(\"Content-Length\")        \n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)                \n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):        \n","            if chunk:                \n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","    \n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","    \n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6qwKjGvyLG4v","executionInfo":{"status":"ok","timestamp":1664487230363,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","    \n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jirIzIstLea0","executionInfo":{"status":"ok","timestamp":1664487230363,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.  \n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"EC9Xppq-_R0w","executionInfo":{"status":"ok","timestamp":1664487230364,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.   \n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    sentencas = []\n","    for linha in arquivo:        \n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas "]},{"cell_type":"code","execution_count":8,"metadata":{"id":"fkVk5LQT_G3f","executionInfo":{"status":"ok","timestamp":1664487230364,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def salvar(nome_arquivo,texto):                       \n","    \"\"\"\n","      Salva um texto em arquivo.\n","     \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.     \n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"1q7fizBnsZFQ"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Guy6B4whsZFR","executionInfo":{"status":"ok","timestamp":1664487230365,"user_tz":180,"elapsed":19,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","    \n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))    "]},{"cell_type":"markdown","metadata":{"id":"nFoXtrnnMisv"},"source":["Calcula a média de uma lista tempo string no formato hh:mm:ss."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"PqS6-M1fqb9V","executionInfo":{"status":"ok","timestamp":1664487230365,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from cmath import rect, phase\n","from math import radians, degrees\n","  \n","def mediaAngulo(deg):\n","    return degrees(phase(sum(rect(1, radians(d)) for d in deg)/len(deg)))\n"," \n","def mediaTempo(tempos):\n","    '''\n","    Calcula a média de uma lista de tempo string no formato hh:mm:ss\n","    '''\n","    t = (tempo.split(':') for tempo in tempos)\n","    # Converte para segundos\n","    segundos = ((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)\n","    # Verifica se deu algum dia\n","    dia = 24 * 60 * 60\n","    # Converte para angulos\n","    para_angulos = [s * 360. / dia for s in segundos]\n","    # Calcula a média dos angulos\n","    media_como_angulo = mediaAngulo(para_angulos)\n","    media_segundos = media_como_angulo * dia / 360.\n","    if media_segundos < 0:\n","        media_segundos += dia\n","    # Recupera as horas e os minutos  \n","    h, m = divmod(media_segundos, 3600)\n","    # Recupera os minutos e os segundos\n","    m, s = divmod(m, 60)    \n","    return '{:02d}:{:02d}:{:02d}'.format(int(h), int(m), int(s))"]},{"cell_type":"markdown","metadata":{"id":"Mw8KyNOJJLwf"},"source":["Calcula a soma de uma lista de tempo string no formato hh:mm:ss"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"V4gekVLwJIcD","executionInfo":{"status":"ok","timestamp":1664487230366,"user_tz":180,"elapsed":19,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def somaTempo(tempos):\n","    '''\n","    Calcula a soma de uma lista de tempo string no formato hh:mm:ss\n","    '''\n","    t = (tempo.split(':') for tempo in tempos)\n","    # Converte para segundos\n","    segundos = ((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)\n","    # Soma os segundos\n","    soma_segundos = sum([s * 1. for s in segundos])\n","    # Recupera as horas e os minutos   \n","    h, m = divmod(soma_segundos, 3600)\n","    # Recupera os minutos e os segundos\n","    m, s = divmod(m, 60)    \n","    return '{:02d}:{:02d}:{:02d}'.format(int(h), int(m), int(s))"]},{"cell_type":"markdown","metadata":{"id":"nszM7hA_IoKP"},"source":["Em muitos dos meus loops for (de longa duração), imprimirei atualizações periódicas de progresso. Normalmente, eu escolho o intervalo de atualização manualmente, mas para este Notebook, defini uma função auxiliar para fazer essa escolha para mim :)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"iTrHp0_FgOSg","executionInfo":{"status":"ok","timestamp":1664487230366,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def obterIntervaloAtualizacao(total_iteracoes, numero_atualizacoes):\n","    '''\n","     Esta função tentará escolher um intervalo de atualização de progresso inteligente\n","     com base na magnitude das iterações totais.\n","\n","     Parâmetros:\n","       `total_iteracoes` - O número de iterações no loop for.\n","       `numero_atualizacoes` - Quantas vezes queremos ver uma atualização sobre o\n","                               curso do loop for.\n","     '''\n","    \n","    # Divida o total de iterações pelo número desejado de atualizações. Provavelmente\n","    # este será um número feio.\n","    intervalo_exato = total_iteracoes / numero_atualizacoes\n","\n","    # A função `arredondar` tem a capacidade de arredondar um número para, por exemplo, o\n","    # milésimo mais próximo: round (intervalo_exato, -3)\n","    #\n","    # Para determinar a magnitude para arredondar, encontre a magnitude do total,\n","    # e então vá uma magnitude abaixo disso.\n","    \n","    # Obtenha a ordem de magnitude do total.\n","    ordem_magnitude = len(str(total_iteracoes)) - 1\n","    \n","    # Nosso intervalo de atualização deve ser arredondado para uma ordem de magnitude menor.\n","    magnitude_arrendonda = ordem_magnitude - 1\n","\n","    # Arredonde para baixo e lance para um int.\n","    intervalo_atualizacao = int(round(intervalo_exato, -magnitude_arrendonda))\n","\n","    # Não permita que o intervalo seja zero!\n","    if intervalo_atualizacao == 0:\n","        intervalo_atualizacao = 1\n","\n","    return intervalo_atualizacao"]},{"cell_type":"markdown","metadata":{"id":"b9OAqrHMjfhJ"},"source":["Classe(ModeloArgumentosMedida) de definição dos parâmetros do modelo para medida"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"zgmN6RqDRDZS","executionInfo":{"status":"ok","timestamp":1664487230367,"user_tz":180,"elapsed":19,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )    \n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )"]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModeloArgumentosClassificacao) de definição dos parâmetros do modelo para classificação"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"IhYOQI-JbuFc","executionInfo":{"status":"ok","timestamp":1664487230367,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosClassificacao:\n","    '''\n","    Classe(ModeloArgumentosClassificacao) de definição dos parâmetros do modelo BERT para a classificação de coerência.\n","    '''\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )\n","    num_labels: int = field(\n","        default=2,\n","        metadata={\"help\": \"número de rótulos a serem classificados.\"},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    optimizer: str = field(\n","        default=\"AdamW\",\n","        metadata={\"help\": \"otimizador do modelo.\"},\n","    )\n","    use_wandb : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o uso do wandb.\"},\n","    )\n","    salvar_modelo_wandb : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o salvamento do modelo no wandb.\"},\n","    )\n","    salvar_modelo : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o salvamento do modelo.\"},\n","    )\n","    salvar_avaliacao : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o salvamento do resultado da avaliação.\"},\n","    )     \n","    salvar_classificacao : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o salvamento da classificação.\"},\n","    )\n","    usar_mcl_ajustado: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o carragamento de mcl ajustado.'},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de previsões de palavras recuperadas mais próximas da máscara.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos perturbados comparados com o seu original.\"},\n","    ) \n","    epoca: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Época a ser avaliada.\"},\n","    )    \n","    fold: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Fold a ser avaliado.\"},\n","    )    "]},{"cell_type":"markdown","metadata":{"id":"rceIwWa7UmFZ"},"source":["Biblioteca de limpeza de tela"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"PXTEvmuhUmjO","executionInfo":{"status":"ok","timestamp":1664487230368,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"-DnPWIRHfq7V"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"54St2CZf5lWv","executionInfo":{"status":"ok","timestamp":1664487230368,"user_tz":180,"elapsed":17,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"YMiH0E3OnRa1","executionInfo":{"status":"ok","timestamp":1664487230369,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","import sys\n","\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = 'google.colab' in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"yuHoA4Dx6K1M"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"0zhAltEP6K1M"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"IxAlgXv66K1M"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Cmva6ltA6K1M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487235779,"user_tz":180,"elapsed":5427,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"fabc6a7a-ea36-4ef8-fc7f-454a35c490bb"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Encontrei GPU em: /device:GPU:0\n"]}],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"XrC2SG3x6K1M"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"oOnQUkWZ6K1N","executionInfo":{"status":"ok","timestamp":1664487236384,"user_tz":180,"elapsed":610,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def getDeviceGPU():\n","    \"\"\"\n","    Retorna um dispositivo de GPU se disponível ou CPU.\n","    \n","    Retorno:\n","    `device` - Um device de GPU ou CPU.       \n","    \"\"\"\n","        \n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        \n","        # Diz ao PyTorch para usar GPU.    \n","        device = torch.device(\"cuda\")\n","        \n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:        \n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","        \n","    return device"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"WcMhNxsE6K1N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487238345,"user_tz":180,"elapsed":1965,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"760bad27-c56f-494e-f6c0-df0573a8b184"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Existem 1 GPU(s) disponíveis.\n","INFO:root:Iremos usar a GPU: Tesla P100-PCIE-16GB.\n"]}],"source":["device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"kkdlEouHftcJ"},"source":["Conecta o modelo ao device"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"a-znVDGyfsVx","executionInfo":{"status":"ok","timestamp":1664487238346,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def conectaGPU(model, device):\n","    \"\"\"\n","      Conecta um modelo BERT a GPU.\n","\n","      Parâmetros:\n","        `model` - Um modelo BERT carregado.       \n","        `device` - Um device de GPU.     \n","    \n","      Retorno:\n","        `model` - Um objeto model BERT conectado a GPU.     \n","    \"\"\"\n","    # Associa a GPU ao modelo.\n","    model.to(device)\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():    \n","        # Diga ao pytorch para rodar este modelo na GPU.\n","        logging.info(\"Pytorch rodando o modelo na GPU.\")\n","        model.cuda()\n","        \n","    else:\n","        logging.info(\"Pytorch rodando sem GPU.\")\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"CRdtvR_J6K1N"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"hSmGz55H6K1N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487238347,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"08289995-7a7e-4a7f-f210-6af5059d22f6"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}],"source":["# Import das bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"LJzK1XjCnZak"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados.\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Dz3RRgR-nZan","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487240618,"user_tz":180,"elapsed":2276,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4fd95f57-143b-4ee9-a423-95111191b553"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Monta o Google Drive para esta instância de notebook.\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"ejzpgGrFM0-j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487248937,"user_tz":180,"elapsed":8324,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"c0abacb7-a455-4feb-cb0a-98cf95129fc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.3)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n"]}],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"6c7JaP-LM2bW"},"source":["Login via linha de comando"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"WOvp48GnMuvM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487251455,"user_tz":180,"elapsed":2527,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"036d22b1-098a-45d8-dd01-d410ade66cef"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login aded3bc0ea651fff536cc08ba69caf8ac4141cfd"]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.8 Instalação BERT da Hugging Face"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face. "]},{"cell_type":"code","execution_count":26,"metadata":{"id":"-XeR8Sbz0B5x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487255276,"user_tz":180,"elapsed":3827,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"897899ef-b63b-4c19-8a01-5a66137c5c88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.5.1 in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (0.10.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.8.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (0.0.53)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n"]}],"source":["!pip install -U transformers==4.5.1"]},{"cell_type":"markdown","metadata":{"id":"giOsAS5v61go"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"QGpAaeEtkT6c","executionInfo":{"status":"ok","timestamp":1664487255277,"user_tz":180,"elapsed":37,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Prefixo do nome do arquivo usado nas saídas projeto C = Cris, SB = SmartBatch, KF = KFold\n","NOME_BASE_SAIDA = \"AjusteFinoCohQuADCoInptbr_C_SB_KF_v1\"\n","\n","# Definição dos parâmetros a serem avaliados\n","\n","######## Parâmetros Individuais ########\n","\n","# Quantidade de documentos a serem perturbados a partir do original. Usar valores 1, 20 ou 100.   \n","DOCUMENTOS_PERTURBADOS = 100 \n","\n","# Quantidade de palavras a serem recuperadas mais próximas da máscara. Usar valores 1, 20 ou 100. \n","TOP_K_PREDICAO = 100 \n","\n","# Tamanho dos lotes de treino e avaliação. Usar 16 ou 32\n","TAMANHO_LOTE = 32\n","\n","######## Parâmetros de conjunto ########\n","# Taxas de aprendizagem a serem avaliadas\n","TAXAS_DE_APRENDIZAGEM = [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]\n","\n","# MCLs a serem avaliados\n","#NOMES_MODELO = ['https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip',\n","#                'https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip',\n","#                'bert-base-multilingual-cased']\n","\n","NOMES_MODELO = [\"neuralmind/bert-large-portuguese-cased\"]\n","\n","######## Parâmetros de intervalo ########\n","# Número de épocas a serem avaliadas\n","# Todas as épocas são avaliadas e os resultados da classificação são salvos. De 1 até 4\n","EPOCAS = 4\n","\n","# Determina o intervalo de folds a ser avaliado. De 1 até 10\n","inicio_fold = 1\n","fim_fold = 10"]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"Mhkc9sW21zV7"},"source":["Parâmetros do treinamento"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"ZM7GWMh3hXqw","executionInfo":{"status":"ok","timestamp":1664487255278,"user_tz":180,"elapsed":37,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Importando as bibliotecas.\n","from transformers import TrainingArguments\n","\n","# Definição dos parâmetros de Treinamento\n","training_args = TrainingArguments(    \n","    # NOME_BASE_SAIDA = Nome base do arquivo de saída\n","    # P = documentos perturbados\n","    # K = previsões palavras \n","    # E = número total de épocas de treinamento\n","    # e = número da época executada\n","    # lr = taxa de aprendizagem\n","    # b = lotes de treino e avaliação    \n","    # f = número do fold\n","    output_dir = NOME_BASE_SAIDA + \"K_1_P_1_E_4_e_1_lr_5_b_8_4_f\", # É utilizado somente para logs de arquivo e wandb   \n","    save_steps = 0,    \n","    seed = 42,\n","    num_train_epochs = EPOCAS, # Intervalo de valores: 2, 3, 4. É utilizado somente para logs.\n","    learning_rate = 5e-5, # Intervalo de valores: 1e-5, 2e-5, 3e-5, 4e-5, 5e-5. É utilizado somente para logs.\n","    gradient_accumulation_steps = 1,\n","    per_device_train_batch_size = TAMANHO_LOTE, \n","    per_device_eval_batch_size = TAMANHO_LOTE,        \n","    evaluation_strategy = 'epoch',    \n",")"]},{"cell_type":"markdown","metadata":{"id":"_oOW3RSO8O2q"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"A4AW1hTYhHq-","executionInfo":{"status":"ok","timestamp":1664487255278,"user_tz":180,"elapsed":36,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosClassificacao(     \n","    max_seq_len = 512,\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",\n","    \n","    #pretrained_model_name_or_path = \"bert-large-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-cased\"\n","    pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",    \n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","\n","    do_lower_case = False,   # default True\n","    num_labels = 2,\n","    output_attentions = False,    # default False\n","    output_hidden_states = False, # default False \n","    optimizer = 'AdamW',\n","    use_wandb = True, # Ativa a gravação de logs no wandb\n","    salvar_modelo_wandb = False, # Ativa o salvamento do MCL no wandb\n","    salvar_modelo = False, # Ativa o salvamento do MCL no googledrive\n","    salvar_avaliacao = True, # Salva o resultado classificações\n","    salvar_classificacao = True, # Salva o resultado da avaliação das classificações\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path. \n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.    \n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100, 500 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara. \n","    fold = 1, # Intervalo de valores: 1 a 10, É utilizado somente para logs. Use as variáveis do bloco a seguir para definir um intervalo dos folds\n",")"]},{"cell_type":"markdown","metadata":{"id":"_R_RPq2MIu_E"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"C0SS8IskIu_E","executionInfo":{"status":"ok","timestamp":1664487255279,"user_tz":180,"elapsed":37,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_COIN_PTBR\""]},{"cell_type":"markdown","metadata":{"id":"cmx5rzAsIaaw"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"WQyz8gjrIaax","executionInfo":{"status":"ok","timestamp":1664487255279,"user_tz":180,"elapsed":37,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","source":["## Inicialização diretórios"],"metadata":{"id":"tDgJTbPOZ8SW"}},{"cell_type":"markdown","source":["Diretório base local"],"metadata":{"id":"qpSERA9TC4WU"}},{"cell_type":"code","source":["# Importando as bibliotecas.\n","import os\n","\n","def criaDiretorioLocal():\n","\n","  # Cria o diretório para receber os arquivos Originais e Permutados\n","  # Diretório a ser criado\n","  dirbase = DIRETORIO_LOCAL[:-1]\n","\n","  if not os.path.exists(dirbase):  \n","      # Cria o diretório\n","      os.makedirs(dirbase)    \n","      logging.info(\"Diretório criado: {}.\".format(dirbase))\n","  else:    \n","      logging.info(\"Diretório já existe: {}.\".format(dirbase))"],"metadata":{"id":"edg7eW2cDflg","executionInfo":{"status":"ok","timestamp":1664487255280,"user_tz":180,"elapsed":37,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["criaDiretorioLocal()"],"metadata":{"id":"xge0ar9MJoKy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487255281,"user_tz":180,"elapsed":38,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"1310590d-b2a6-437a-f207-96aa450a6793"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_COIN_PTBR.\n"]}]},{"cell_type":"markdown","source":["Diretório para conter as os resultados das classificações"],"metadata":{"id":"4FmT9nhbaE3D"}},{"cell_type":"code","source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioClassificacao():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"/validacao_classificacao_palavra\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"],"metadata":{"id":"zO76uzj_C3zQ","executionInfo":{"status":"ok","timestamp":1664487255281,"user_tz":180,"elapsed":35,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["criaDiretorioClassificacao()"],"metadata":{"id":"T1Ot2h_bJuxy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487255282,"user_tz":180,"elapsed":35,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"d5982aa2-51ea-4c6c-a68a-bb67daa01f6a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_COIN_PTBR//validacao_classificacao_palavra.\n"]}]},{"cell_type":"markdown","source":["Diretório para conter os arquivos da avaliação kfold"],"metadata":{"id":"vIkT6ksqaQs3"}},{"cell_type":"code","source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioClassificacaoKfold():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/kfold\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"],"metadata":{"id":"NIV4xj6zDnb8","executionInfo":{"status":"ok","timestamp":1664487255282,"user_tz":180,"elapsed":31,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["criaDiretorioClassificacaoKfold()"],"metadata":{"id":"IiOVjJ5BJzE1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487255283,"user_tz":180,"elapsed":31,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"9ab61c9e-9baa-4a70-cf17-fdf007bf73b5"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_COIN_PTBR/validacao_classificacao_palavra/kfold.\n"]}]},{"cell_type":"markdown","source":["Diretório para conter os arquivos de classificação da avaliação kfold"],"metadata":{"id":"cjP6v878aWR7"}},{"cell_type":"code","source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioClassificacaoKfoldClassificacao():\n","\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/kfold/Classificacao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"],"metadata":{"id":"Qf6UWAZYDsgm","executionInfo":{"status":"ok","timestamp":1664487255283,"user_tz":180,"elapsed":28,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["criaDiretorioClassificacaoKfoldClassificacao()"],"metadata":{"id":"IBBfHFuPJ3NM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487255283,"user_tz":180,"elapsed":27,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"42bc234e-516a-4143-c440-39f95c558c68"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_COIN_PTBR/validacao_classificacao_palavra/kfold/Classificacao.\n"]}]},{"cell_type":"markdown","source":["Diretório para conter os arquivos de resultado da avaliação kfold"],"metadata":{"id":"x_G30UWEaeoN"}},{"cell_type":"code","source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioClassificacaoKfoldAvaliacao():\n","\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/kfold/Avaliacao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"],"metadata":{"id":"VxxKCPTRD3bh","executionInfo":{"status":"ok","timestamp":1664487255284,"user_tz":180,"elapsed":25,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["criaDiretorioClassificacaoKfoldAvaliacao()"],"metadata":{"id":"D691HF9TJ7av","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487255284,"user_tz":180,"elapsed":25,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"b7d22437-9401-4d86-b199-a29d593b5f18"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_COIN_PTBR/validacao_classificacao_palavra/kfold/Avaliacao.\n"]}]},{"cell_type":"markdown","metadata":{"id":"IBY7q_uH8JSE"},"source":["# 3 BERT"]},{"cell_type":"markdown","metadata":{"id":"MBGTMy8Ic7GK"},"source":["## 3.1 Modelo Pré-treinado BERT"]},{"cell_type":"markdown","metadata":{"id":"uiuxdXe9t1BX"},"source":["### Funções Auxiliares"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"9Huw0x5kt1Le","executionInfo":{"status":"ok","timestamp":1664487255285,"user_tz":180,"elapsed":23,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getNomeModeloBERT(model_args):\n","    '''    \n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","    \n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"        \n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","        else:\n","            if 'bert' in model_args.pretrained_model_name_or_path:\n","                MODELO_BERT = \"_BERT\"  \n","            \n","    return MODELO_BERT"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"jYJB4ik7t5xe","executionInfo":{"status":"ok","timestamp":1664487255285,"user_tz":180,"elapsed":22,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getTamanhoBERT(model_args):\n","    '''    \n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","    \n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","    \n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","        \n","    return TAMANHO_BERT  "]},{"cell_type":"markdown","metadata":{"id":"rHt4e5pAcEMd"},"source":["### Função download Modelo Pre-treinado BERT"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"peDUrV2ccEXA","executionInfo":{"status":"ok","timestamp":1664487255286,"user_tz":180,"elapsed":22,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\" \n","    \n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","        \n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","        \n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo.\")\n","            # Apaga o diretório e os arquivos existentes                     \n","            shutil.rmtree(DIRETORIO_MODELO)\n","        \n","        # Realiza o download do arquivo do modelo        \n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.                \n","        arquivo_zip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivo_zip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.        \n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","        \n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        del arquivo_zip\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta.\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada.\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"V74WUpHqcfoI"},"source":["### Copia o modelo do BERT ajustado"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"iQMpf9yycf8f","executionInfo":{"status":"ok","timestamp":1664487255286,"user_tz":180,"elapsed":22,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\" \n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO) \n","   \n","    logging.info(\"Modelo BERT ajustado copiado!\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"]},{"cell_type":"markdown","metadata":{"id":"eaneOhAKcO-3"},"source":["### Verifica de onde utilizar o modelo do BERT"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"TTy1TXz3cPKS","executionInfo":{"status":"ok","timestamp":1664487255287,"user_tz":180,"elapsed":22,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def verificaModelo(model_args):\n","    \"\"\" \n","    Verifica de onde utilizar o modelo.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","    \n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\" \n","\n","    DIRETORIO_MODELO = None\n","    \n","    if model_args.usar_mcl_ajustado == True:        \n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","        \n","        logging.info(\"Usando modelo BERT ajustado.\")\n","        \n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")        \n","        \n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"6tKcaIfReqdy"},"source":["## 3.2 Tokenizador BERT"]},{"cell_type":"markdown","metadata":{"id":"e8n7Z5s-QZF8"},"source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"mzAuptkwQZR3","executionInfo":{"status":"ok","timestamp":1664487255287,"user_tz":180,"elapsed":20,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","    \n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","    \n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"]},{"cell_type":"markdown","metadata":{"id":"GYRV9KfHQE6v"},"source":["## 3.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**\n","\n","A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL."]},{"cell_type":"markdown","metadata":{"id":"-pZZrUKRhR3e"},"source":["### Função carrega modelo BERT medida\n","\n","\n"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"5zj0G_cbZRCV","executionInfo":{"status":"ok","timestamp":1664487255850,"user_tz":180,"elapsed":583,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertModel # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","    \n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","        `model_args` - Objeto com os argumentos do modelo.   \n","    \n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:        \n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertModel.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","        \n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertModel.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"rvhXRGskk9yD"},"source":["### Função carrega modelo BERT classificação\n","\n"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"1JUEyjCChUQh","executionInfo":{"status":"ok","timestamp":1664487255851,"user_tz":180,"elapsed":11,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertForSequenceClassification # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloClassifica(DIRETORIO_MODELO, model_args):\n","    ''' \n","    Carrega o modelo e retorna o modelo.\n","    \n","    Parâmetros:\n","    `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","    `model_args` - Objeto com os argumentos do modelo.\n","    \n","    Retorno:\n","    `model` - Um objeto do modelo BERT carregado.\n","    ''' \n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if 'http' in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:\n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para classificação.\".format(DIRETORIO_MODELO))\n","\n","        model = BertForSequenceClassification.from_pretrained(DIRETORIO_MODELO, \n","                                                              num_labels=model_args.num_labels,\n","                                                              output_attentions=model_args.output_attentions,\n","                                                              output_hidden_states=model_args.output_hidden_states)\n","            \n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para classificação.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertForSequenceClassification.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                                              num_labels=model_args.num_labels,\n","                                                              output_attentions=model_args.output_attentions,\n","                                                              output_hidden_states=model_args.output_hidden_states)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"-uFDhRTZe2Js"},"source":["### Função carrega o BERT"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"QVtAUbUBe2iS","executionInfo":{"status":"ok","timestamp":1664487255851,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def carregaBERT(model_args):\n","    \"\"\" \n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:    \n","        `model` - Um objeto do modelo BERT carregado.       \n","        `tokenizer` - Um objeto tokenizador BERT carregado.       \n","    \"\"\"\n","            \n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","    \n","    # Variável para conter o modelo\n","    model = None\n","    \n","    # Verifica o tipo do modelo em model_args    \n","    if type(model_args) == ModeloArgumentosMedida:\n","        # Carrega o modelo para cálculo da medida\n","        model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","        \n","    else:\n","        # Carrega o modelo para classificação\n","        model = carregaModeloClassifica(DIRETORIO_MODELO, model_args)\n","        \n","        # Recupera o dispositivo da GPU \n","        device = getDeviceGPU()\n","    \n","        # Conecta o modelo a GPU\n","        model = conectaGPU(model, device)\n","                       \n","    # Carrega o tokenizador. \n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","    \n","    return model, tokenizer"]},{"cell_type":"markdown","metadata":{"id":"x5NTxBRKfAcT"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"D6sPjTQnuQV2","executionInfo":{"status":"ok","timestamp":1664487255851,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"wJdbTzeejhOE"},"source":["# 4 Treino"]},{"cell_type":"markdown","metadata":{"id":"IrKMXRNm7OI6"},"source":["## 4.1 Wandb\n","\n","https://wandb.ai/osmar-braz/AjusteFinoCohebert_C_SB_KF_v1/table?workspace=user-osmar-braz\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ezk8hklEvPYq"},"source":["### Função de inicialização wandb"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"rdsn_fhsvPwO","executionInfo":{"status":"ok","timestamp":1664487255852,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Importando a biblioteca.\n","import wandb\n","\n","def inicializacaoWandb():\n","\n","  if model_args.use_wandb:\n","\n","    #Login via linha de comando\n","    !wandb login aded3bc0ea651fff536cc08ba69caf8ac4141cfd\n","\n","    # Inicializando o registro do experimento.\n","    # Na execução só pode existir de um init  para que não gere dois registros no wandb.\n","    # O projeto no wandb recebe o nome base mais o número de um fold especifico.\n","    wandb.init(project=NOME_BASE_SAIDA, name=training_args.output_dir + str(model_args.fold))\n","    \n","    # Atualiza os parâmetros do modelo no wandb.\n","    wandb.config.update(model_args)\n","    # Atualiza os parâmetros de treinamento no wandb.\n","    wandb.config.update(training_args)\n","    wandb.config.dataset = DIRETORIO_COHEBERT\n","    wandb.config.batch_size = training_args.per_device_train_batch_size\n","    \n","    # Registra os parämetros não literais do model_args.    \n","    wandb.log({\"max_seq_len\": model_args.max_seq_len})\n","    wandb.log({\"do_lower_case\": model_args.do_lower_case})\n","    wandb.log({\"output_hidden_states\": model_args.output_hidden_states})\n","  \n","    return wandb"]},{"cell_type":"markdown","metadata":{"id":"OimJrCug6f_-"},"source":["## 4.2 Carregamento dos arquivos de dados kfold"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["### Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"bNgwJRC2uGJb","executionInfo":{"status":"ok","timestamp":1664487255852,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_FOLD_COMPACTADO = DIRETORIO_COHEBERT + \"_KFOLD_10\" + \"_P\" +  str(model_args.documentos_perturbados) + \"_K\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"pviuxToMCxQw","executionInfo":{"status":"ok","timestamp":1664487255852,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def copiaArquivoFold():\n","  \n","  # Se estiver executando no Google Colaboratory\n","  if IN_COLAB:\n","\n","    criaDiretorioLocal()\n","    \n","    !cp \"$DIRETORIO_DRIVE\"\"/validacao_classificacao_palavra/kfold/\"\"$NOME_ARQUIVO_FOLD_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","      \n","    logging.info(\"Terminei a cópia.\")"]},{"cell_type":"code","source":["copiaArquivoFold()"],"metadata":{"id":"RVUqgRNNLBmy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487257150,"user_tz":180,"elapsed":1306,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"fe41b6ee-f9ad-4889-c1db-539ca03e168e"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_COIN_PTBR.\n","INFO:root:Terminei a cópia.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"dbHl3d88mouc","executionInfo":{"status":"ok","timestamp":1664487257151,"user_tz":180,"elapsed":29,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def descompactaArquivoFold():\n","  \n","  # Se estiver executando no Google Colaboratory\n","  if IN_COLAB:\n","    !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_FOLD_COMPACTADO\" -d \"/content/validacao_kfold\"\n","\n","    logging.info(\"Terminei a descompactação.\")"]},{"cell_type":"code","source":["descompactaArquivoFold()"],"metadata":{"id":"RSlCSpKhLLKT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664487257153,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"bcae8c00-9f91-40ab-ea0a-f4dc4bc42b71"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a descompactação.\n"]}]},{"cell_type":"markdown","metadata":{"id":"cKaU03Si1U4E"},"source":["### 4.2.4 Função de carregamento dos dados de um fold"]},{"cell_type":"code","source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","def carregamentoDadosFold(fold):\n","\n","  logging.info(\"Carregando os arquivos do fold de treino e avaliação.\")\n","  \n","  # Diretório dos arquivos de dados.\n","  DIRETORIO = \"/content/validacao_kfold\"\n","\n","  # Define o prefixo do nome dos arquivos dos folds\n","  PREFIXO_NOME_ARQUIVO_TREINO = DIRETORIO_COHEBERT + \"_Train_f\"\n","  PREFIXO_NOME_ARQUIVO_TESTE = DIRETORIO_COHEBERT + \"_Test_f\"\n","\n","  # Nome dos arquivos.\n","  ARQUIVO_TREINO = DIRETORIO + \"/\" + PREFIXO_NOME_ARQUIVO_TREINO + str(fold) + \".csv\"\n","  ARQUIVO_TESTE = DIRETORIO + \"/\" + PREFIXO_NOME_ARQUIVO_TESTE + str(fold) + \".csv\" \n","\n","  logging.info(\"Carregando arquivo de treino: {}.\".format(ARQUIVO_TREINO))\n","  logging.info(\"Carregando arquivo de teste: {}.\".format(ARQUIVO_TESTE))\n","\n","  # Verifica se o arquivo existe\n","  if not os.path.isfile(ARQUIVO_TREINO):\n","      # Caso contrário copia o arquivo do drive e descompacta\n","      copiaArquivoFold()\n","      descompactaArquivoFold()\n","\n","  # Carrega o conjunto de dados de treino e teste.\n","  df_dados_train = pd.read_csv(ARQUIVO_TREINO, sep=';')  \n","  df_dados_test = pd.read_csv(ARQUIVO_TESTE, sep=';')  \n","  #logging.info(\"Qtde de dados de treino: {} e teste {}.\".format(len(df_dados_train), len(df_dados_test)))\n","\n","  return df_dados_train, df_dados_test"],"metadata":{"id":"ySfBoIpeLSu8","executionInfo":{"status":"ok","timestamp":1664487257154,"user_tz":180,"elapsed":26,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 4.3 Análise"]},{"cell_type":"markdown","metadata":{"id":"N2wEm3z-2Lld"},"source":["### Função descarte documentos muito grandes"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"nPeajX8C2QX-","executionInfo":{"status":"ok","timestamp":1664487257154,"user_tz":180,"elapsed":25,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def descarteDocumentosGrandes(tokenizer, \n","                              tamanho_maximo_token, \n","                              df_dados_train, \n","                              df_dados_test):\n","\n","  logging.info(\"Descartando documentos grandes dos conjuntos de dados.\")\n","\n","  # Define o tamanho máximo para os tokens.\n","  tamanho_maximo = tamanho_maximo_token\n","\n","  # Tokenize a codifica as setenças para o BERT.     \n","  df_dados_train[\"input_ids\"] = df_dados_train[\"documento\"].apply(lambda tokens: tokenizer.encode(tokens, add_special_tokens=True))\n","        \n","  df_dados_train = df_dados_train[df_dados_train[\"input_ids\"].apply(len)<tamanho_maximo]\n","\n","  # Remove as colunas desnecessárias.\n","  df_dados_train = df_dados_train.drop(columns=[\"input_ids\"])\n","\n","  # Tokenize a codifica as setenças para o BERT.     \n","  df_dados_test[\"input_ids\"] = df_dados_test[\"documento\"].apply(lambda tokens: tokenizer.encode(tokens, add_special_tokens=True))\n","\n","  # Corta os inputs para o tamanho máximo 512.\n","  df_dados_test = df_dados_test[df_dados_test[\"input_ids\"].apply(len)<tamanho_maximo]\n","\n","  #logging.info(\"Tamanho do conjunto de dados: {} / Treino: {} / Teste: {}.\".format((len(df_dados_train)+len(df_dados_test)),len(df_dados_train), len(df_dados_test)))\n","    \n","  # Remove as colunas desnecessárias.\n","  df_dados_test = df_dados_test.drop(columns=[\"input_ids\"])\n","\n","  del tokenizer\n","  del tamanho_maximo\n","\n","  return df_dados_train, df_dados_test"]},{"cell_type":"markdown","metadata":{"id":"8bwa6Rts-02-"},"source":["## 4.4 Treinando o modelo de classificação"]},{"cell_type":"markdown","metadata":{"id":"qRWT-D4U_Pvx"},"source":["### Otimizador e Agendador de Taxas de Aprendizado/Optimizer & Learning Rate Scheduler\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8o-VEBobKwHk"},"source":["Agora que temos nosso modelo carregado, precisamos pegar os hiperparâmetros de treinamento no modelo armazenado.\n","\n","Para fins de ajuste fino, os autores recomendam escolher entre os seguintes valores (no Apêndice A.3 do [artigo BERT](https://arxiv.org/pdf/1810.04805.pdf)):\n","\n","> - **Tamanho do lote(Batch size):** 16, 32\n","- **Taxa de aprendizado (Adam):** 5e-5, 3e-5, 2e-5\n","- **Número de épocas:** 2, 3, 4\n","\n","O parâmetro epsilon `eps = 1e-6` é\" um número muito pequeno para impedir qualquer divisão por zero na implementação \"(a partir de [aqui](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n","\n","Você pode encontrar a criação do otimizador do AdamW em `run_glue.py` [aqui](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."]},{"cell_type":"markdown","metadata":{"id":"MKecsl5K3LR9"},"source":["### Função carrega otimizador\n"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"ajnrdhF63N-r","executionInfo":{"status":"ok","timestamp":1664487257155,"user_tz":180,"elapsed":26,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import AdamW\n","\n","def carregaOtimizador(training_args, model):\n","  '''\n","    Esta função carrega o otimizador utilizado no agendador de aprendizado.\n","  '''\n","\n","  # Nota: AdamW é uma classe da biblioteca huggingface (ao contrário de pytorch).\n","  # Eu acredito que o 'W' significa 'Correção de redução de peso \"\n","  optimizer = AdamW(model.parameters(),\n","                  lr = training_args.learning_rate, # (ou alfa) A taxa de aprendizado a ser usada. - default é 3e-5\n","                  # betas = (0.9, 0.999), # (beta1, beta2) - default é (0.9, 0.999)\n","                    # beta1 é taxa de decaimento exponencial para as estimativas do primeiro momento. \n","                    # beta2 é taxa de decaimento exponencial para as estimativas do segundo momento. Este valor deve ser definido próximo a 1,0 em problemas com gradiente esparso (por exemplo, PNL e problemas de visão de computacional)\n","                  # eps = 1e-6, #  É um número muito pequeno para evitar qualquer divisão por zero na implementação - default é 1e-6.\n","                  # weight_decay = 0.0, # Correção de redução de peso. - default é 0.0\n","                    # A redução da taxa de aprendizagem também pode ser usada com Adam. A taxa de decaimento é atualizada a cada época para a demonstração da regressão logística.\n","                  # correct_bias = True #  Se não deve corrigir o viés(bias) no Adam mudar para False.- default é True\n","                )\n","  \n","  return optimizer"]},{"cell_type":"markdown","metadata":{"id":"N-Aqb27R3cci"},"source":["### Função carrega agendador"]},{"cell_type":"markdown","metadata":{"id":"W2MT7UK84srM"},"source":["A função **get_linear_schedule_with_warmup** cria um agendador com uma taxa de aprendizado que diminua linearmente da taxa de aprendizagem inicial definido no otimizador até 0, após um período de aquecimento durante o qual ele aumenta linearmente de 0 para a taxa de aprendizagem inicial definido no otimizador.\n","\n","Se `num_warmup_steps=0` e `weight_decay=0`(otimizador) não ocorre a etapa de aquecimento."]},{"cell_type":"code","execution_count":61,"metadata":{"id":"XMCaS1VqNr5y","executionInfo":{"status":"ok","timestamp":1664487257156,"user_tz":180,"elapsed":26,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import get_linear_schedule_with_warmup\n","\n","def carregaAgendador(training_args, optimizer, numero_etapas):\n","  '''\n","    Esta função carrega o agendador com um taxa de aprendizado que diminua linearmente até 0.\n","  '''\n","\n","  # O número total de etapas de ajuste fino é [número de lotes] x [número de épocas].\n","  # (Observe que este não é o mesmo que o número de amostras de ajuste fino).\n","  total_etapas = numero_etapas * training_args.num_train_epochs\n","\n","  #Cria o agendador de taxa de aprendizagem.\n","  scheduler = get_linear_schedule_with_warmup(optimizer, # O otimizador para o qual agendar a taxa de aprendizado.\n","                                            num_warmup_steps = 0, # O número de etapas para a fase de aquecimento. Valor default value em run_glue.py\n","                                            num_training_steps = total_etapas) # O número total de etapas de treinamento.\n","\n","\n","  logging.info(\"Total de etapas: {}\".format(total_etapas))\n","\n","  return scheduler"]},{"cell_type":"markdown","metadata":{"id":"O0my3USqpC45"},"source":["### Função cria lotes inteligentes"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"hGpsZgnDolp9","executionInfo":{"status":"ok","timestamp":1664487257156,"user_tz":180,"elapsed":26,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","import random\n","\n","def criarLotesInteligentes(tokenizer,\n","                           documentos, \n","                           classes, \n","                           id_documentos, \n","                           batch_size):\n","    '''\n","    Esta função combina todos os passos para preparar os lotes.\n","    '''\n","    logging.info(\"Criando Lotes Inteligentes de {:,} amostras com tamanho de lote {:,}...\".format(len(documentos), batch_size))\n","\n","    # ============================\n","    #   Tokenização & Truncamento\n","    # ============================\n","\n","    input_ids_completos = []\n","    \n","    # Tokeniza todas as amostras de treinamento\n","    logging.info(\"Tokenizando {:,} amostra...\".format(len(classes)))\n","    \n","    # Escolha o intervalo que o progresso será atualizado.\n","    intervalo_atualizacao = obterIntervaloAtualizacao(total_iteracoes=len(classes), numero_atualizacoes=10)\n","    \n","    # Barra de progresso dos documentos\n","    documentos_bar = tqdm_notebook(documentos, desc=f'Documentos ', unit=f'documento', total=len(documentos))\n","\n","    # Para cada amostra de treinamento...\n","    for documento in documentos_bar:\n","    \n","        # Relatório de progresso\n","        #if ((len(input_ids_completos) % intervalo_atualizacao) == 0):\n","        #    logging.info(\"  Tokenizado {:,} amostras.\".format(len(input_ids_completos)))\n","\n","        # Tokeniza a amostra.\n","        input_ids = tokenizer.encode(text=documento,                    # Documento a ser codificado.\n","                                    add_special_tokens=True,            # Adiciona os ttokens especiais.\n","                                    max_length=model_args.max_seq_len,  # Tamanho do truncamento!\n","                                    truncation=True,                    # Faz o truncamento!\n","                                    padding=False)                      # Não preenche.\n","                \n","        # Adicione o resultado tokenizado à nossa lista.\n","        input_ids_completos.append(input_ids)\n","\n","        del input_ids\n","    \n","    del documentos    \n","    \n","    logging.info(\"{:>10,} amostras tokenizadas.\".format(len(input_ids_completos)))\n","\n","    # =========================\n","    #      Seleciona os Lotes\n","    # =========================    \n","    \n","    # Classifique as duas listas pelo comprimento da sequência de entrada.\n","    amostras = sorted(zip(input_ids_completos, classes, id_documentos), key=lambda x: len(x[0]))\n","\n","    del input_ids_completos\n","    del classes\n","    del id_documentos\n","\n","    logging.info(\"{:>10,} amostras após classificação.\".format(len(amostras)))\n","\n","    # Lista de lotes que iremos construir.\n","    batch_ordered_documentos = []\n","    batch_ordered_classes = []\n","    batch_ordered_id_documentos = []\n","\n","    logging.info(\"Criando lotes de tamanho {:}...\".format(batch_size))\n","\n","    # Escolha um intervalo no qual imprimir atualizações de progresso.\n","    intervalo_atualizacao = obterIntervaloAtualizacao(total_iteracoes=len(amostras), numero_atualizacoes=10)\n","        \n","    # Faça um loop em todas as amostras de entrada ... \n","    while len(amostras) > 0:\n","        \n","        # Mostra o progresso.\n","        if ((len(batch_ordered_documentos) % intervalo_atualizacao) == 0 \\\n","            and not len(batch_ordered_documentos) == 0):\n","            logging.info(\"  Selecionado {:,} lotes.\".format(len(batch_ordered_documentos)))\n","        \n","        # `to_take` é o tamanho real do nosso lote. Será `batch_size` até\n","        # chegamos ao último lote, que pode ser menor.\n","        to_take = min(batch_size, len(amostras))\n","        \n","        # Escolha um índice aleatório na lista de amostras restantes para começar o nosso lote.\n","        select = random.randint(0, len(amostras) - to_take)\n","\n","        # Selecione um lote contíguo de amostras começando em `select`.\n","        #print (\"Selecionando lote de {:} a {:}\".format(select, select+to_take))\n","        batch = amostras[select:(select + to_take)]\n","\n","        #print(\"Tamanho do lote:\", len(batch))\n","        \n","        # Cada amostra é uma tupla --divida para criar uma lista separada de\n","        # sequências e uma lista de rótulos para este lote.\n","        batch_ordered_documentos.append([s[0] for s in batch])\n","        batch_ordered_classes.append([s[1] for s in batch])\n","        batch_ordered_id_documentos.append([s[2] for s in batch])\n","        \n","        # Remova a amostra da lista\n","        del amostras[select:select + to_take]\n","\n","    logging.info(\"  FEITO - Selecionado {:,} lotes.\".format(len(batch_ordered_documentos)))\n","\n","    # =========================\n","    #        Adicionando o preenchimento\n","    # =========================    \n","\n","    logging.info(\"Preenchendo sequências dentro de cada lote...\")\n","\n","    py_input_ids = []\n","    py_attention_masks = []\n","    py_labels = []\n","    list_id_documentos = []\n","\n","    # Para cada lote...\n","    for (batch_input_ids, batch_labels, batch_id_documentos) in zip(batch_ordered_documentos, batch_ordered_classes, batch_ordered_id_documentos):\n","\n","        # Nova versão do lote, desta vez com sequências preenchidas e agora com\n","        # as máscaras de atenção definidas.\n","        batch_padded_input_ids = []\n","        batch_attention_masks = []\n","                \n","        # Primeiro, encontre a amostra mais longa do lote.\n","        # Observe que as sequências atualmente incluem os tokens especiais!\n","        max_size = max([len(input) for input in batch_input_ids])\n","        \n","        # Para cada entrada neste lote...\n","        for input in batch_input_ids:\n","                        \n","            # Quantos tokens pad precisam ser adicionados\n","            num_pads = max_size - len(input)\n","\n","            # Adiciona `num_pads` do pad token(tokenizer.pad_token_id) até o final da sequência.\n","            padded_input = input + [tokenizer.pad_token_id] * num_pads\n","\n","            # Define a máscara de atenção --é apenas um `1` para cada token real\n","            # e um `0` para cada token de preenchimento(pad).\n","            attention_mask = [1] * len(input) + [0] * num_pads\n","            \n","            # Adiciona o resultado preenchido ao lote.\n","            batch_padded_input_ids.append(padded_input)\n","            batch_attention_masks.append(attention_mask)\n","\n","            del padded_input\n","            del attention_mask\n","        \n","        # Nosso lote foi preenchido, portanto, precisamos salvar este lote atualizado.\n","        # Também precisamos que as entradas sejam tensores PyTorch, então faremos isso aqui.\n","        py_input_ids.append(torch.tensor(batch_padded_input_ids))\n","        py_attention_masks.append(torch.tensor(batch_attention_masks))\n","        py_labels.append(torch.tensor(batch_labels))\n","        list_id_documentos.append(batch_id_documentos)\n","        \n","        del batch_padded_input_ids\n","        del batch_attention_masks\n","\n","    del batch_ordered_documentos\n","    del batch_ordered_classes\n","    del batch_ordered_id_documentos\n","    \n","    del tokenizer    \n","\n","    # Retorna o conjunto de dados em lotes inteligentes!\n","    return (py_input_ids, py_attention_masks, py_labels, list_id_documentos)"]},{"cell_type":"markdown","metadata":{"id":"Thh-qfv5q4tI"},"source":["### Função de Treinamento"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"ox8cl_CZDxc-","executionInfo":{"status":"ok","timestamp":1664487257157,"user_tz":180,"elapsed":27,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas\n","import random\n","import numpy as np\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def realizaTreinamento(model, \n","                       tokenizer, \n","                       optimizer, \n","                       scheduler,  \n","                       documentos_treino, \n","                       classes_treino, \n","                       id_documentos_treino, \n","                       documentos_teste, \n","                       classes_teste, \n","                       id_documentos_teste, \n","                       EPOCAS = 4):\n","  \n","  #logging.info(\"Realizando treinamento e avaliação do fold: {}\".format(model_args.fold))\n","\n","  # Defina o valor da semente em todos os lugares para torná-lo reproduzível.\n","  seed_val = training_args.seed\n","  random.seed(seed_val)\n","  np.random.seed(seed_val)\n","  torch.manual_seed(seed_val)\n","  torch.cuda.manual_seed_all(seed_val)\n","\n","  # Medida do tempo total de treinamento e avaliação.\n","  treinamento_avaliacao_t0 = time.time()\n","\n","  # Limpa o cache da GPU.\n","  torch.cuda.empty_cache()\n","\n","  # Coloque o modelo em modo de treinamento. \n","  model.train()\n","\n","  # Acumula as perdas do treinamento.\n","  train_losses = []\n","  test_losses = []\n","   \n","  # Barra de progresso da época.\n","  epoca_bar = tqdm_notebook(range(0,training_args.num_train_epochs+1), desc=f'Épocas', unit=f'épocas')\n","  \n","  # Para cada época.\n","  for epoca_i in epoca_bar:\n","  \n","    # ========================================\n","    #               Inicialização\n","    # ========================================\n","\n","    # Atualiza a época corrente      \n","    model_args.epoca = epoca_i\n","\n","    # Atualiza o nome da saída corrente\n","    training_args.output_dir = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args, model_args)\n","\n","    # Inicializa o wandb para registro\n","    # Gera uma entrada para cada todas as epocas, com a taxa de aprendizagem, lote e fold    \n","    wandb = inicializacaoWandb()\n","    \n","    # Log das métidas com wandb.\n","    if model_args.use_wandb:    \n","      wandb.watch(model)  \n","\n","    # Recupera o lote inteligente\n","    (py_input_ids, py_attention_masks, py_labels, documentoids) = criarLotesInteligentes(tokenizer, \n","                                                                                         documentos_treino, \n","                                                                                         classes_treino, \n","                                                                                         id_documentos_treino, \n","                                                                                         training_args.per_device_train_batch_size)\n","   \n","    # ========================================\n","    #               Avaliação época 0, sem treinamento\n","    # ========================================\n","    if epoca_i == 0:\n","\n","      # Registra o tempo inicial.\n","      avaliacao_epoca_t0 = time.time()\n","      \n","      # Realiza a avaliação do modelo.    \n","      media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao = realizaAvaliacao(epoca_i, \n","                                                                                                                     model, \n","                                                                                                                     tokenizer, \n","                                                                                                                     optimizer, \n","                                                                                                                     scheduler, \n","                                                                                                                     wandb, \n","                                                                                                                     documentos_teste, \n","                                                                                                                     classes_teste, \n","                                                                                                                     id_documentos_teste)\n","\n","      logging.info(\"   Avaliação loss: {:.8f}; Acc: {:.8f}; Rec: {:.8f}; Pre: {:.8f}, F1:{:.8f}, vp: {:3d}; vn: {:3d}; fp: {:3d}; fn: {:3d}\".format(media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s))      \n","      logging.info(\"   Acurácia do fold {} na época {}: {:.8f}.\".format(model_args.fold, epoca_i, acc))  \n","\n","      # Não acura acumula a perda de treinamento da época pois não ocorreu treinamento.\n","      # test_losses.append(media_test_epoca_loss)\n","\n","      # Medida de quanto tempo levou a execução da avaliação.\n","      avaliacao_epoca_total = formataTempo(time.time() - avaliacao_epoca_t0)\n","\n","      logging.info(\"   Média perda(loss) do avaliação da época   : {0:.8f}.\".format(media_test_epoca_loss))\n","      logging.info(\"   Tempo de avaliação da época               : {:}.\".format(avaliacao_epoca_total))    \n","      logging.info(\"   Tempo parcial do processamento            : {:} (h:mm:ss)\".format(formataTempo(time.time()-treinamento_avaliacao_t0)))\n","\n","      ################# Salva a classificação e avaliação para a época\n","\n","      # Salva o resultado da classificação da época\n","      salvaResultadoClassificacao(lista_resultado_avaliacao)\n","\n","      # Salva o resultado da avaliação da épóca\n","      treinamento_avaliacao_total_t0 = format(formataTempo(time.time()-treinamento_avaliacao_t0))\n","      salvaResultadoAvaliacao(media_test_epoca_loss, \n","                              acc, \n","                              rec, \n","                              pre, \n","                              f1, \n","                              vp_s, \n","                              vn_s, \n","                              fp_s, \n","                              fn_s, \n","                              treinamento_avaliacao_total_t0)\n","\n","      # Log das métricas com wandb.\n","      if model_args.use_wandb:    \n","        NOME_EXECUCAO = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args,model_args)\n","        wandb.log({\"nome_execucao\": NOME_EXECUCAO[:-2], # -2 para retirar \"_f\" do fina do nome da execução\n","                  \"acuracia\": acc,\n","                  \"vp\": vp_s , \n","                  \"vn\": vn_s,  \n","                  \"fp\": fp_s,\n","                  \"fn\": fn_s, \n","                  \"media_train_epoca_loss\" : 0,\n","                  \"tempo_train\" : 0,\n","                  \"media_test_epoca_loss\" : media_test_epoca_loss,\n","                  \"tempo_test\" : avaliacao_epoca_total})\n","      \n","    else:\n","      # ========================================\n","      #               Treinamento e Avaliação para as épocas > 0\n","      # ========================================\n","\n","      # Execute uma passada completa sobre o conjunto de treinamento.\n","      logging.info(\"Realizando treinamento do fold {} na época: {}.\".format(model_args.fold, model_args.epoca))\n","\n","      # Medida de quanto tempo leva o período de treinamento.\n","      treinamento_epoca_t0 = time.time()\n","\n","      # Acumula as perdas do treinamento da época.\n","      train_batch_losses = []\n","\n","      # Barras de progresso.    \n","      lote_treino_bar = tqdm_notebook(range(0, len(py_input_ids)), desc=f'Epoca {epoca_i}', unit=f'lotes', total=len(py_input_ids) )\n","\n","      # Para cada lote dos dados de treinamento.\n","      for index in lote_treino_bar:      \n","\n","          # Descompacte este lote de treinamento de nosso dataloader.\n","          #\n","          # À medida que descompactamos o lote, também copiaremos cada tensor para a GPU usando o\n","          # o método `to`\n","          #\n","          # `lote` é uma lista contém três tensores pytorch:\n","          #   [0]: input ids \n","          #   [1]: attention masks\n","          #   [2]: labels \n","\n","          # Recupera os tensores do lote e copia para a GPU usando o método `to` \n","          d_input_ids = py_input_ids[index].to(device)\n","          d_input_mask = py_attention_masks[index].to(device)\n","          d_labels = py_labels[index].to(device)     \n","          \n","          # Sempre limpe quaisquer gradientes calculados anteriormente antes de realizar um\n","          # passe para trás. PyTorch não faz isso automaticamente porque\n","          # acumular os gradientes é \"conveniente durante o treinamento de RNNs\".\n","          # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","          model.zero_grad()\n","\n","          # Execute um passe para frente (avalie o modelo neste lote de treinamento).\n","          # A documentação para esta função `model` está aqui:\n","          # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","          # Ele retorna diferentes números de parâmetros dependendo de quais argumentos\n","          # são fornecidos e quais sinalizadores estão definidos. Para nosso uso aqui, ele retorna\n","          # a perda (porque fornecemos rótulos) e os \"logits\" - o modelo de saídas antes da ativação.     \n","\n","          # last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n","          outputs = model(d_input_ids, \n","                          token_type_ids=None, \n","                          attention_mask=d_input_mask, \n","                          labels=d_labels)\n","          \n","          # A perda(loss) é retornado em outputs[0] porque fornecemos rótulos(labels))                  \n","          loss = outputs[0]\n","\n","          # E outputs[1] os \"logits\" - o modelo de saídas antes da ativação.\n","          # logits possui duas dimensões, a primeira do lote e a segunda do rótulo da predição                        \n","          # A função `.detach().cpu()` retira da gpu.\n","          logits = outputs[1].detach().cpu()\n","    \n","          # Acumule a perda de treinamento em todos os lotes da época para que possamos\n","          # calcular a perda média no final da época. `loss` é um tensor contendo um único valor.   \n","          # A função `.item ()` retorna apenas o valor Python do tensor.\n","          train_batch_losses.append(loss.item())\n","\n","          # Mostra a perda na barra de progresso.\n","          lote_treino_bar.set_postfix(loss=loss.item())\n","\n","          # Log das métricas com wandb.\n","          if model_args.use_wandb:          \n","            wandb.log({\"train_batch_loss\": loss.item()})\n","\n","          # Execute uma passagem para trás para calcular os gradientes.\n","          # Todos os parâmetros do modelo deve ter sido setado para param.requires_grad = False\n","          loss.backward()            \n","\n","          # Corte a norma dos gradientes para 1.0.\n","          # Isso ajuda a evitar o problema de \"gradientes explosivos\".\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        \n","          # Atualize os parâmetros e dê um passo usando o gradiente calculado.\n","          # O otimizador dita a \"regra de atualização\" - como os parâmetros são\n","          # modificados com base em seus gradientes, taxa de aprendizagem, etc.\n","          optimizer.step()\n","                            \n","          # Atualize a taxa de aprendizagem.\n","          scheduler.step()\n","\n","          # Apaga variáveis não utilizadas\n","          del outputs\n","\n","      # Média da perda do treinamento de todos os lotes da época.\n","      media_train_epoca_loss = np.mean(train_batch_losses)\n","\n","      # Acumule a perda de treinamento de todas as épocas para calcular a perda média do treinamento.    \n","      train_losses.append(media_train_epoca_loss)\n","\n","      # Medida de quanto tempo levou o treinamento desta época.\n","      treinamento_epoca_total = formataTempo(time.time() - treinamento_epoca_t0)\n","\n","      logging.info(\"   Média perda(loss) do treinamento da época : {0:.8f}.\".format(media_train_epoca_loss))\n","      logging.info(\"   Tempo de treinamento da época             : {:}.\".format(treinamento_epoca_total))    \n","      logging.info(\"   Tempo parcial processamento               : {:} (h:mm:ss)\".format(formataTempo(time.time()-treinamento_avaliacao_t0)))\n","\n","      ################# Avaliação da época\n","      \n","      # Registra o tempo inicial.\n","      avaliacao_epoca_t0 = time.time()\n","\n","      # Realiza a avaliação do modelo.    \n","      media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao = realizaAvaliacao(epoca_i, model, \n","                                                                                                                     tokenizer, \n","                                                                                                                     optimizer, \n","                                                                                                                     scheduler, \n","                                                                                                                     wandb, \n","                                                                                                                     documentos_teste, \n","                                                                                                                     classes_teste, \n","                                                                                                                     id_documentos_teste)\n","\n","      logging.info(\"   Avaliação loss: {:.8f}; Acc: {:.8f}; Rec: {:.8f}; Pre: {:.8f}, F1:{:.8f}, vp: {:3d}; vn: {:3d}; fp: {:3d}; fn: {:3d}\".format(media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s))      \n","      logging.info(\"   Acurácia do fold {} na época {}: {:.8f}.\".format(model_args.fold, epoca_i, acc))  \n","      \n","      # Acumule a perda de treinamento da época para calcular a perda média do treinamento.    \n","      test_losses.append(media_test_epoca_loss)\n","\n","      # Medida de quanto tempo levou a execução da avaliação\n","      avaliacao_epoca_total = formataTempo(time.time() - avaliacao_epoca_t0)\n","\n","      logging.info(\"   Média perda(loss) do avaliação da época   : {0:.8f}.\".format(media_test_epoca_loss))\n","      logging.info(\"   Tempo de avaliação da época               : {:}.\".format(avaliacao_epoca_total))    \n","      logging.info(\"   Tempo parcial do processamento            : {:} (h:mm:ss)\".format(formataTempo(time.time()-treinamento_avaliacao_t0)))\n","\n","      ################# Salva a classificação e avaliação para a época\n","\n","      # Salva o resultado da classificação da época\n","      salvaResultadoClassificacao(lista_resultado_avaliacao)\n","\n","      # Salva o resultado da avaliação da épóca\n","      treinamento_avaliacao_total_t0 = format(formataTempo(time.time()-treinamento_avaliacao_t0))\n","      salvaResultadoAvaliacao(media_test_epoca_loss, \n","                              acc, \n","                              rec, \n","                              pre, \n","                              f1, \n","                              vp_s, \n","                              vn_s, \n","                              fp_s, \n","                              fn_s, \n","                              treinamento_avaliacao_total_t0)\n","\n","      ################# Salva o modelo ajustado no wandb\n","      salvaModeloWandb(model, model_args)\n","\n","      ################# Salva o modelo ajustado\n","      salvaModelo(model, tokenizer, model_args)\n","\n","      # Apaga variáveis não utilizadas\n","      del py_input_ids\n","      del py_attention_masks\n","      del py_labels\n","      del train_batch_losses\n","      del lote_treino_bar\n","\n","      # Log das métricas com wandb.\n","      if model_args.use_wandb:    \n","        NOME_EXECUCAO = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args,model_args)\n","        wandb.log({\"nome_execucao\": NOME_EXECUCAO[:-2], # -2 para retirar \"_f\" do fina do nome da execução\n","                  \"acuracia\": acc,\n","                  \"vp\": vp_s , \n","                  \"vn\": vn_s,  \n","                  \"fp\": fp_s,\n","                  \"fn\": fn_s, \n","                  \"media_train_epoca_loss\" : media_train_epoca_loss,\n","                  \"tempo_train\" : treinamento_epoca_total,\n","                  \"media_test_epoca_loss\" : media_test_epoca_loss,\n","                  \"tempo_test\" : avaliacao_epoca_total})\n","        \n","    # Finaliza o wandb\n","    if model_args.use_wandb:\n","      wandb.finish()  \n","     \n","  # Média da perda do treinamento de todas as épocas.\n","  media_train_loss = np.mean(train_losses)\n","  media_test_loss = np.mean(test_losses)\n","\n","  logging.info(\"  Média perda(loss) treinamento : {0:.8f}.\".format(media_train_loss))\n","  logging.info(\"  Média perda(loss) avaliação   : {0:.8f}.\".format(media_test_loss))\n","\n","  # Apaga variáveis não utilizadas\n","  del train_losses\n","  del epoca_bar\n","  \n","  del model\n","  del tokenizer  \n","  del documentos_treino\n","  del classes_treino\n","  del id_documentos_treino\n","  del documentos_teste\n","  del classes_teste\n","  del id_documentos_teste"]},{"cell_type":"markdown","metadata":{"id":"av-_hPByrUCA"},"source":["## 4.5 Avaliação\n","\n","Avaliando o modelo treinado no conjunto de dados de teste."]},{"cell_type":"markdown","metadata":{"id":"teXptLZNjszT"},"source":["### Função de avaliação"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"R8DIJXnmjw5v","executionInfo":{"status":"ok","timestamp":1664487257158,"user_tz":180,"elapsed":27,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def realizaAvaliacao(epoca, \n","                     model, \n","                     tokenizer, \n","                     optimizer, \n","                     scheduler, \n","                     wandb,\n","                     documentos_teste, \n","                     classes_teste, \n","                     id_documentos_teste):\n","   \n","  # Armazena o resultado da avaliação executada\n","  lista_resultado_avaliacao = []\n","\n","  logging.info(\"Realizando avaliação do fold {} na época: {}.\".format(model_args.fold, epoca))\n","\n","  # Use nossa nova função para preparar completamente nosso conjunto de dados.\n","  (py_input_ids, py_attention_masks, py_labels, documentosids) = criarLotesInteligentes(tokenizer, documentos_teste, classes_teste, id_documentos_teste, training_args.per_device_eval_batch_size)\n","\n","  # Coloque o modelo em modo de avaliação.\n","  model.eval()\n","\n","  # Acumula as perdas dos testes dos lotes.\n","  test_batch_losses = []\n","\n","  # Acumula os resultados dos testes.\n","  vp = [] # Verdadeiro positivo\n","  vn = [] # Verdadeiro negativo\n","  fp = [] # Falso positivo\n","  fn = [] # Falso negativo\n","\n","  # Barra de progresso dos lotes de teste.\n","  lote_teste_bar = tqdm_notebook(range(0, len(py_input_ids)), desc=f'Lotes ', unit=f'lotes', total=len(py_input_ids))\n","\n","  # Para cada lote dos dados de avaliação(teste).\n","  for index in lote_teste_bar:\n","\n","    # Copia o lote para a GPU.\n","    d_input_ids = py_input_ids[index].to(device)\n","    d_input_mask = py_attention_masks[index].to(device)\n","    d_labels = py_labels[index].to(device)\n","    d_id_documentos = documentosids[index]\n","\n","    # Diga a pytorch para não se preocupar em construir o gráfico de computação durante\n","    # o passe para frente, já que isso só é necessário para backprop (treinamento).\n","    with torch.no_grad():\n","        # Obtenha a saída de \"logits\" pelo modelo. Os \"logits\" são a saída\n","        # valores antes de aplicar uma função de ativação como o softmax.        \n","        # Retorno de model quando ´last_hidden_state=True´ é setado:    \n","        # last_hidden_state = outputs[0], pooler_output = outputs[1], hidden_states = outputs[2]\n","        outputs = model(d_input_ids,\n","                        token_type_ids=None, \n","                        attention_mask=d_input_mask, \n","                        labels=d_labels)\n","        \n","    # A perda(loss) é retornado em outputs[0] porque fornecemos rótulos(labels). \n","    # É útil para comparar com a perda do treinamento, quando é realizado a avaliação entre as épocas de treinamento.\n","    loss = outputs[0]\n","\n","    # E outputs[1] os \"logits\" - o modelo de saídas antes da ativação.\n","    # logits possui duas dimensões, a primeira do lote e a segunda do rótulo da predição                        \n","    logits = outputs[1]\n","        \n","    # Acumule a perda da avaliação em todos os lotes para que possamos\n","    # calcular a perda média no final. `loss` é um tensor contendo um único valor.\n","    # A função '.cpu()' move loss para a cpu.\n","    # A função `.item ()` retorna apenas o valor Python do tensor.         \n","    test_batch_losses.append(loss.cpu().item())\n","\n","    # Log das métricas com wandb.\n","    if model_args.use_wandb:\n","        wandb.log({\"test_batch_loss\": loss.cpu().item()})\n","\n","    # Recupera o índice do melhor resultado, maior valor dos tensores para coluna(1)\n","    _, classificacao = torch.max(logits, 1)\n","\n","    # Verifica a classificação realizada e o rótulo previsto\n","    vp.append(((classificacao==1) & (d_labels==1)).sum().cpu().item())\n","    vn.append(((classificacao==0) & (d_labels==0)).sum().cpu().item())\n","    fp.append(((classificacao==1) & (d_labels==0)).sum().cpu().item())\n","    fn.append(((classificacao==0) & (d_labels==1)).sum().cpu().item())\n","\n","    # Adiciona o documento de teste, o rótulo e a classificação realizada a lista de resultado\n","    for lote in range(len(d_labels)):\n","                \n","        lista_resultado_avaliacao.append([d_id_documentos[lote],\n","                                d_labels[lote].cpu().item(), \n","                                classificacao[lote].cpu().item()])\n","\n","    del outputs\n","    del d_input_ids\n","    del d_input_mask\n","    del d_labels\n","    del d_id_documentos\n","\n","  # Soma as classificações realizadas\n","  vp_s, vn_s, fp_s, fn_s = sum(vp), sum(vn), sum(fp), sum(fn)\n","  \n","  # Acurácia indica uma performance geral do modelo. \n","  # Dentre todas as classificações, quantas o modelo classificou corretamente(vp=1 e vn=0).\n","  if (vp_s+vn_s+fp_s+fn_s) != 0:\n","      acc = (vp_s+vn_s)/(vp_s+vn_s+fp_s+fn_s)\n","  else:\n","      acc = 0\n","\n","  # Recall(Revocação) avalia todas as situações da classe Positivo(vp=1) com o valor esperado e quantas estão corretas.\n","  if (vp_s+fn_s) != 0:\n","      rec = (vp_s)/(vp_s+fn_s)\n","  else:\n","      rec = 0\n","  \n","  # Precisão avalia as classificações da classe positivo(vp=1 e fp=0) que o modelo fez e quantas estão corretas.\n","  if (vp_s+fp_s) != 0:\n","      pre = (vp_s)/(vp_s+fp_s)\n","  else:\n","      pre = 0  \n","\n","  # F1 é a média harmônica entre precisão e recall.\n","  if (pre + rec) != 0:  \n","    f1 = 2 * ((pre * rec)/(pre + rec))\n","  else:\n","    f1 = 0\n","\n","  # Média da perda da avaliação  \n","  media_test_epoca_loss = np.mean(test_batch_losses)\n","\n","  del py_input_ids\n","  del py_attention_masks\n","  del py_labels\n","  del test_batch_losses\n","  del lote_teste_bar\n","  \n","  del model\n","  del tokenizer\n","  del documentos_teste\n","  del classes_teste\n","  del id_documentos_teste\n","\n","  return media_test_epoca_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, lista_resultado_avaliacao"]},{"cell_type":"markdown","metadata":{"id":"VtblUQT0EAO5"},"source":["### Função que salva o resultado da classificação"]},{"cell_type":"code","source":["def getNomeDiretorioResultados(training_args, model_args):\n","  \n","  # Monta o nome do arquivo com parâmetros\n","  nome_arquivo = \"\"\n","  nome_arquivo = nome_arquivo + \"P_\" + str(model_args.documentos_perturbados)\n","  nome_arquivo = nome_arquivo + \"_K_\" + str(model_args.top_k_predicao) \n","     \n","  return nome_arquivo"],"metadata":{"id":"aeVZS2Lxy_UK","executionInfo":{"status":"ok","timestamp":1664487257158,"user_tz":180,"elapsed":27,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","execution_count":66,"metadata":{"id":"vnu6iKHwAaTb","executionInfo":{"status":"ok","timestamp":1664487257159,"user_tz":180,"elapsed":27,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import datetime\n","\n","def salvaResultadoClassificacao(lista_resultado_avaliacao):\n","\n","  if model_args.salvar_classificacao:\n","\n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","    \n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_CLASSIFICACAO = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args, model_args) + str(model_args.fold) + MODELO_BERT + TAMANHO_BERT \n","  \n","    # Diretório para salvar o arquivo.\n","    DIRETORIO_CLASSIFICACAO_DRIVE = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/kfold/Classificacao/\" + getNomeDiretorioResultados(training_args, model_args) + \"/\"\n","\n","    # Diretório local para salvar o arquivo\n","    DIRETORIO_CLASSIFICACAO_LOCAL = DIRETORIO_LOCAL + \"Classificacao/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_CLASSIFICACAO_DRIVE):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_CLASSIFICACAO_DRIVE)\n","      logging.info(\"Diretório criado: {}.\".format(DIRETORIO_CLASSIFICACAO_DRIVE))\n","    else:\n","      logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_CLASSIFICACAO_DRIVE))\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_CLASSIFICACAO_LOCAL):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_CLASSIFICACAO_LOCAL)\n","      logging.info(\"Diretório criado: {}.\".format(DIRETORIO_CLASSIFICACAO_LOCAL))\n","    else:\n","      logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_CLASSIFICACAO_LOCAL))      \n","\n","    # Caminho completo do arquivo compactado no drive\n","    NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO = DIRETORIO_CLASSIFICACAO_DRIVE + NOME_ARQUIVO_CLASSIFICACAO + \".zip\"\n","    # print(\"NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO:\", NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO)\n","\n","    # Caminho completo do arquivo compactado no local\n","    NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO = DIRETORIO_CLASSIFICACAO_LOCAL + NOME_ARQUIVO_CLASSIFICACAO + \".zip\"\n","    # print(\"NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO:\", NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO)\n","\n","    # Caminho completo do arquivo no local\n","    NOME_ARQUIVO_CLASSIFICACAO_LOCAL = DIRETORIO_CLASSIFICACAO_LOCAL + NOME_ARQUIVO_CLASSIFICACAO + \".csv\"\n","    # print(\"NOME_ARQUIVO_CLASSIFICACAO_LOCAL:\", NOME_ARQUIVO_CLASSIFICACAO_LOCAL)\n","\n","    # Gera todo o conteúdo a ser salvo no arquivo\n","    novo_conteudo = \"\"        \n","    for resultado in lista_resultado_avaliacao:      \n","      novo_conteudo = novo_conteudo + data_e_hora.strftime(\"%d/%m/%Y %H:%M\") + \";\" + str(resultado[0]) + \";\" + str(resultado[1]) + \";\" + str(resultado[2]) + \"\\n\"\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO):\n","\n","      # Copia arquivo da classificação compactado do google drive para o drive local\n","      !cp \"$NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO\" \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO\"  \n","      # Descompacta arquivo da classificação compactado no drive local\n","      !unzip -o -j -q \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO\" -d \"$DIRETORIO_CLASSIFICACAO_LOCAL\"\n","\n","      logging.info(\"Atualizando arquivo classificação: {}.\".format(NOME_ARQUIVO_CLASSIFICACAO_LOCAL))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_LOCAL,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novo_conteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_LOCAL,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)  \n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      # Compacta o arquivo da classificação\n","      !zip -o -q -j \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO\" \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL\"\n","      # Copia o arquivo da classificação compactado para o drive\n","      !cp \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO\" \"$NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO\"\n","\n","      del conteudo\n","      del arquivo\n","      del lista_resultado_avaliacao\n","      \n","    else:\n","      logging.info(\"Criando arquivo classificação: {}.\".format(NOME_ARQUIVO_CLASSIFICACAO_LOCAL))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_CLASSIFICACAO_LOCAL,'w')\n","      arquivo.writelines('data;id;classe;predicao\\n' + novo_conteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      # Compacta o arquivo da classificação\n","      !zip -o -q -j \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO\" \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL\"\n","      # Copia o arquivo da classificação compactado para o drive\n","      !cp \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO\" \"$NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO\"\n","\n","      del arquivo\n","      del lista_resultado_avaliacao    "]},{"cell_type":"markdown","metadata":{"id":"DloA0HIShFzW"},"source":["### Função que salva o resultado da avaliação\n","\n","Salva o resultado da avaliação do conjunto de dados de teste do fold especificado."]},{"cell_type":"code","execution_count":67,"metadata":{"id":"4aiVdm7P_TlV","executionInfo":{"status":"ok","timestamp":1664487257159,"user_tz":180,"elapsed":27,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import datetime\n","\n","def salvaResultadoAvaliacao(media_test_loss, acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s, treinamento_total):\n","\n","  if model_args.salvar_avaliacao:\n","    \n","    # Recupera a hora do sistema.\n","    data_e_hora = datetime.datetime.now()\n","\n","    # Nome arquivo resultado\n","    NOME_ARQUIVO_AVALIACAO = NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args, model_args) + str(model_args.fold) + MODELO_BERT + TAMANHO_BERT \n","\n","    # Diretório para salvar o arquivo.\n","    DIRETORIO_AVALIACAO = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/kfold/Avaliacao/\" + getNomeDiretorioResultados(training_args, model_args) + \"/\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_AVALIACAO):  \n","      # Cria o diretório\n","      os.makedirs(DIRETORIO_AVALIACAO)\n","      logging.info(\"Diretório criado: {}.\".format(DIRETORIO_AVALIACAO))\n","    else:\n","      logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_AVALIACAO))\n","\n","    # Nome do arquivo a ser aberto.\n","    NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + \".csv\"\n","\n","    # Conteúdo a ser adicionado.\n","    novo_conteudo = NOME_ARQUIVO_AVALIACAO + \";\" +  data_e_hora.strftime(\"%d/%m/%Y %H:%M\") + \";\"  + treinamento_total + \";\"  + str(acc) + \";\"  +  str(vp_s) + \";\"  +  str(vn_s) + \";\" +  str(fp_s) + \";\" +  str(fn_s) + \"\\n\"\n","\n","    # Verifica se o arquivo existe.\n","    if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","      logging.info(\"Atualizando arquivo resultado: {}.\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre o arquivo para leitura.\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'r')\n","      # Leitura de todas as linhas do arquivo.\n","      conteudo = arquivo.readlines()\n","      # Conteúdo a ser adicionado.\n","      conteudo.append(novo_conteudo)\n","\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      # escreva o conteúdo criado anteriormente nele.\n","      arquivo.writelines(conteudo)  \n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      del conteudo\n","      del arquivo\n","\n","    else:\n","      logging.info(\"Criando arquivo resultado: {}.\".format(NOME_ARQUIVO_AVALIACAO_COMPLETO))\n","      # Abre novamente o arquivo (escrita).\n","      arquivo = open(NOME_ARQUIVO_AVALIACAO_COMPLETO,'w')\n","      arquivo.writelines('arquivo;data;tempo;acuracia;vp;vn;fp;fn\\n' + novo_conteudo)  # escreva o conteúdo criado anteriormente nele.\n","      # Fecha o arquivo.\n","      arquivo.close()\n","\n","      del arquivo"]},{"cell_type":"markdown","metadata":{"id":"bUskOwzJmpDB"},"source":["### Função que carrega e calcula a média da acurácia dos folds\n"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"C7e4KBUq5iHF","executionInfo":{"status":"ok","timestamp":1664487257160,"user_tz":180,"elapsed":28,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import pandas as pd\n","\n","def carregaResultadoAvaliacao(NOME_ARQUIVO_AVALIACAO):\n","\n","  NOME_ARQUIVO_EXECUCAO = NOME_ARQUIVO_AVALIACAO + \"X\" + MODELO_BERT + TAMANHO_BERT\n","\n","  logging.info(\"Média dos arquivos: {}\".format(NOME_ARQUIVO_EXECUCAO))\n","\n","  # Diretório para salvar o arquivo.\n","  DIRETORIO_AVALIACAO = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/kfold/Avaliacao/\" + getNomeDiretorioResultados(training_args, model_args) + \"/\"\n","\n","  # Verifica se o diretório dos resultados existem.\n","  if os.path.exists(DIRETORIO_AVALIACAO):\n","    # Acumuladores.\n","    soma_acuracia = 0\n","    listaTempo = []\n","    conta_folds = 0\n","\n","    # Percorre os arquivos de resultados.\n","    for f in range(10):  \n","      # Nome do arquivo a ser aberto.\n","      NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO + NOME_ARQUIVO_AVALIACAO + str(f+1) + MODELO_BERT + TAMANHO_BERT + \".csv\"    \n","      # Verifica se o arquivo existe.\n","      if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","        \n","        # Carrega os dados do arquivo  \n","        dados = pd.read_csv(NOME_ARQUIVO_AVALIACAO_COMPLETO, sep=';')\n","        # Mostra os dados do teste do fold.\n","        for index, linha in dados.iterrows():\n","        \n","          # Cálculo das estatísticas\n","          acc = (linha['vp']+linha['vn'])/(linha['vp']+linha['vn']+linha['fp']+linha['fn'])\n","          if (linha['vp']+linha['fn']) != 0:\n","              rec = (linha['vp'])/(linha['vp']+linha['fn'])\n","          else:\n","              rec = 0\n","          if (linha['vp']+linha['fp']) != 0:\n","              pre = (linha['vp'])/(linha['vp']+linha['fp'])\n","          else:  \n","              pre = 0\n","          if (pre + rec) != 0:  \n","              f1 = 2 * ((pre * rec)/(pre + rec))\n","          else:\n","              f1 = 0\n","          qtde_testes = linha['vp']+linha['vn']+linha['fp']+linha['fn']\n","          logging.info(\"Arquivo: {}, Data: {}, Tempo: {}, QtdeTeste: {:3d}, Acc: {:.8f}, Rec: {:.8f}, Pre: {:.8f}, F1:{:.8f}, vp: {:4d}; vn: {:4d}; fp: {:4d}; fn: {:4d}\".format( \n","               linha[\"arquivo\"], linha[\"data\"], linha[\"tempo\"], qtde_testes, acc, rec, pre, f1, linha[\"vp\"], linha[\"vn\"], linha[\"fp\"], linha[\"fn\"]))    \n","           \n","          # Guarda o tempo.\n","          listaTempo.append(str(linha['tempo']))\n","\n","        # Procura a maior acurácia.\n","        soma_acuracia = soma_acuracia + dados['acuracia'].max()\n","        # Conta o número de folds.\n","        conta_folds = conta_folds + 1\n","\n","        del dados\n","    \n","    # Mostra a soma da acurácia . \n","    logging.info(\"Total acurácia                                       : {:.8f}.\".format(soma_acuracia))\n","    # Mostra a quantidade de folds.\n","    logging.info(\"Quantidade de folds                                  : {}.\".format(conta_folds))  \n","    # Calcula a média.\n","    if conta_folds != 0:\n","      media = soma_acuracia/conta_folds\n","      logging.info(\"A média da acurácia de {:2d} folds é                    : {:.8f}.\".format(conta_folds, media))\n","      logging.info(\"O tempo gasto na execução do treinamentoa {:2d} folds é : {}.\".format(conta_folds, somaTempo(listaTempo)))\n","      logging.info(\"A média de tempo de execução de {:2d} folds é           : {}.\".format(conta_folds, mediaTempo(listaTempo)))\n","      # Guarda o resultado da execução\n","      lista_resultado_execucoes.append(NOME_ARQUIVO_EXECUCAO + \";\" + str(media) + \";\" + str(somaTempo(listaTempo)))\n","  else:\n","    logging.info(\"Diretório com os resultados não encontrado.\")\n","  \n","  del listaTempo"]},{"cell_type":"markdown","metadata":{"id":"TXHxIz73vcet"},"source":["## 4.6 Salva e copia o modelo ajustado"]},{"cell_type":"markdown","metadata":{"id":"XDvwRckAwXt1"},"source":["### Função que salva o modelo ajustado no wandb\n"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"93KTjqixwb_e","executionInfo":{"status":"ok","timestamp":1664487257160,"user_tz":180,"elapsed":28,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def salvaModeloWandb(model, model_args):\n","  \n","  # Salvando o Modelo para o wandb\n","  if model_args.use_wandb and model_args.salvar_modelo_wandb:\n","  \n","    # Salva o modelo para o wandb    \n","    torch.save(model.state_dict(), os.path.join(wandb.run.dir, 'model_dict.pt'))\n","\n","    logging.info(\"Modelo salvo no wandb.\")"]},{"cell_type":"markdown","metadata":{"id":"q2079Qyn8Mt8"},"source":["### Função que salva e copia o modelo ajustado\n","\n","Salva e  modelo e o tokenizador no disco e copia para o google drive."]},{"cell_type":"code","execution_count":70,"metadata":{"id":"6ulTWaOr8QNY","executionInfo":{"status":"ok","timestamp":1664487257161,"user_tz":180,"elapsed":28,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def salvaModelo(model, tokenizer, model_args):\n","  \n","  if model_args.salvar_modelo:\n","\n","    # Salvando as melhores práticas: se você usar nomes padrão para o modelo, você pode recarregá-lo usando from_pretrained ()\n","\n","    # Diretório de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = '/content/modelo_ajustado/' + model_args.fold\n","\n","    # Cria o diretório de saída se necessário.\n","    if not os.path.exists(DIRETORIO_LOCAL_MODELO_AJUSTADO):\n","      os.makedirs(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    logging.info(\"Salvando o modelo para {}.\".format(DIRETORIO_LOCAL_MODELO_AJUSTADO))\n","\n","    # Salve um modelo treinado, configuração e tokenizer usando `save_pretrained ()`.\n","    # Eles podem então ser recarregados usando `from_pretrained ()`.\n","    model_to_save = model.module if hasattr(model, 'module') else model  # Cuide do treinamento distribuído/paralelo\n","    model_to_save.save_pretrained(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","    tokenizer.save_pretrained(DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    # Boa prática: salve seus argumentos de treinamento junto com o modelo treinado.\n","    torch.save(model_args, os.path.join (DIRETORIO_LOCAL_MODELO_AJUSTADO, 'mode_args.bin'))\n","    torch.save(training_args, os.path.join (DIRETORIO_LOCAL_MODELO_AJUSTADO, 'training_args.bin'))\n","\n","    logging.info(\"Modelo salvo.\")\n","\n","    # Para salvar seu modelo nas sessões do Colab Notebook, faça o download no seu computador local ou, idealmente, copie-o no seu Google Drive.\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    !cp -r '$DIRETORIO_LOCAL_MODELO_AJUSTADO'* '$DIRETORIO_REMOTO_MODELO_AJUSTADO'\n","\n","    logging.info(\"Modelo copiado.\")\n"]},{"cell_type":"markdown","metadata":{"id":"MPRD4HkL2Ymp"},"source":["# 5 Execução do treinamento e avaliação "]},{"cell_type":"markdown","metadata":{"id":"D9XIk5yXkeV2"},"source":["Gera o sufixo do nome do arquivo de saída com os parâmetros da execução\n","\n","Exemplo de formado de sufixo.\n","`K_1_P_1_E_4_e_1_lr_5_b_8_4_f`\n","  - P = documentos perturbados\n","  - K = previsões palavras \n","  - E = número total de épocas de treinamento\n","  - e = número da época executada\n","  - lr = taxa de aprendizagem\n","  - b = lotes de treino e avaliação  \n","  - f = número do fold"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"khYfqBd7kgMm","executionInfo":{"status":"ok","timestamp":1664487257161,"user_tz":180,"elapsed":28,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["def getSufixoNomeArquivoSaida(training_args, model_args):\n","\n","  # Recupera o número inteiro da taxa de aprendizagem\n","  taxa_inteiro = int(training_args.learning_rate*100000)\n","\n","  # Monta o nome do arquivo com parâmetros\n","  nome_arquivo = \"\"\n","  nome_arquivo = nome_arquivo + \"_P_\" + str(model_args.documentos_perturbados) \n","  nome_arquivo = nome_arquivo + \"_K_\" + str(model_args.top_k_predicao) \n","  nome_arquivo = nome_arquivo + \"_E_\" + str(training_args.num_train_epochs)\n","  nome_arquivo = nome_arquivo + \"_e_\" + str(model_args.epoca)   \n","  nome_arquivo = nome_arquivo + \"_lr_\" + str(taxa_inteiro)  \n","  nome_arquivo = nome_arquivo + \"_b_\" + str(training_args.per_device_train_batch_size) \n","  nome_arquivo = nome_arquivo + \"_\" + str( training_args.per_device_eval_batch_size) \n","  nome_arquivo = nome_arquivo + \"_f\" \n","   \n","  return nome_arquivo"]},{"cell_type":"markdown","metadata":{"id":"rlXjlhoFjUAH"},"source":["## 5.1 Função de treinamento e avaliação de todos os folds\n","\n","Carrega os folds para serem avaliados"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"XTt9_BAS2adF","executionInfo":{"status":"ok","timestamp":1664487257162,"user_tz":180,"elapsed":29,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[],"source":["# Import das bibliotecas\n","from tqdm.notebook import tqdm as tqdm_notebook\n","import time\n","import datetime\n","import gc\n","\n","def procedimentoTreinamentoAvaliacaoFolds(modelo, taxa_de_aprendizagem):\n","  \n","  # Barra de progresso dos folds\n","  fold_bar = tqdm_notebook(range(inicio_fold, fim_fold+1), desc=f'Folds ', unit=f'fold', total=fim_fold)\n","\n","  # Percorre todos os folds do intervalo de inicio_fold até fim_fold\n","  for ifold in fold_bar:\n","\n","    # Seta o parâmetro do fold\n","    model_args.fold = ifold\n","\n","    logging.info(\"Processamendo do fold: {}.\".format(model_args.fold))\n","    logging.info(\"   com o modelo: {}\".format(modelo))\n","    logging.info(\"   até época {} e taxa de aprendizagem {}.\".format(training_args.num_train_epochs, taxa_de_aprendizagem))  \n","    \n","    # Marca o tempo de início do processamento\n","    processamento_fold_t0 = time.time()\n","\n","    # Carregando o modelo   \n","    model, tokenizer = carregaBERT(model_args)\n","        \n","    # Conecta o modelo a GPU\n","    model = conectaGPU(model, device)\n","\n","    # Função de carregamento dos dados de um fold\n","    df_dados_train, df_dados_test = carregamentoDadosFold(model_args.fold)\n","\n","    # Descartando documentos muito grandes\n","    df_dados_train, df_dados_test = descarteDocumentosGrandes(tokenizer, model_args.max_seq_len, df_dados_train, df_dados_test)\n","    \n","    # Pega as listas de documentos de treino e seus rótulos.\n","    documentos_treino = df_dados_train.documento.values\n","    classes_treino = df_dados_train.classe.values\n","    id_documentos_treino = df_dados_train.id.values\n","\n","    # Pega as listas de documentos teste e seus rótulos.\n","    documentos_teste = df_dados_test.documento.values\n","    classes_teste = df_dados_test.classe.values\n","    id_documentos_teste = df_dados_test.id.values\n","\n","    del df_dados_train\n","    del df_dados_test\n","\n","    # Mostra o resultado dos dados carregados.\n","    logging.info(\"Tamanho do conjunto de dados : {} / Treino: {} / Teste: {}.\".format(len(documentos_treino) + len(documentos_teste), len(documentos_treino), len(documentos_teste)))\n","    \n","    #################  Treinamento\n","\n","    # Carrega o otimizador\n","    optimizer = carregaOtimizador(training_args, model)\n","\n","    # Carrega o agendador\n","    scheduler = carregaAgendador(training_args, optimizer, numero_etapas=len(documentos_treino))\n","\n","    # Registra o tempo inicial.\n","    treinamento_t0 = time.time()\n","    \n","    # Realiza o treinamento.\n","    realizaTreinamento(model, tokenizer, optimizer, scheduler, \n","                       documentos_treino, classes_treino, id_documentos_treino, \n","                       documentos_teste, classes_teste, id_documentos_teste, training_args.num_train_epochs)\n","    \n","    # Medida de quanto tempo levou a execução do treinamento.\n","    treinamento_f = time.time()\n","    treinamento_total = formataTempo(treinamento_f - treinamento_t0)  \n","    logging.info(\"  Tempo total treinamento       : {:}.\".format(treinamento_total))\n","    \n","    #################  Treinamento\n","\n","    # Apaga os dados\n","    del documentos_treino\n","    del classes_treino\n","    del id_documentos_treino\n","    \n","    del documentos_teste\n","    del classes_teste\n","    del id_documentos_teste\n","\n","    del optimizer\n","    del scheduler\n","    del model\n","    del tokenizer\n","\n","    # Pega o tempo atual menos o tempo do início do processamento.\n","    processamento_fold_f = time.time()\n","    processamento_fold_total = formataTempo(processamento_fold_f - processamento_fold_t0)    \n","    logging.info(\"  Tempo processamento fold: {:} (h:mm:ss)\\n\".format(processamento_fold_total))    \n","\n","    # Chama o coletor de lixo para esvaziar a memória\n","    gc.collect()    "]},{"cell_type":"markdown","metadata":{"id":"F-VmBiSsc71L"},"source":["## 5.2 Execução o procedimento de treinamento e avaliação para todos os parâmetros"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"ercO4HqjYLxb","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"17w6ud9mjQIP2or8Zx7xLMshV_dav5urI"},"outputId":"2b04c43d-4def-4237-fe96-0294016a1b46","executionInfo":{"status":"ok","timestamp":1664503925293,"user_tz":180,"elapsed":16668159,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Import das bibliotecas\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","# Barra de progresso modelos\n","modelo_bar = tqdm_notebook(enumerate(NOMES_MODELO), desc=f'Modelos ', unit=f'modelo', total=len(NOMES_MODELO))\n","\n","# Percorre todos os modelos a serem avaliados\n","for modelo_i, modelo in modelo_bar:\n","\n","  # Seta o parâmetro do modelo\n","  model_args.pretrained_model_name_or_path = modelo\n","\n","  # Barra de progresso das taxas de aprendizagem\n","  taxa_de_aprendizagem_bar = tqdm_notebook(enumerate(TAXAS_DE_APRENDIZAGEM), desc=f'Taxas de aprendizagem ', unit=f'taxa', total=len(TAXAS_DE_APRENDIZAGEM))\n","\n","  # Executa o treinamento e avaliação para diversas taxas de aprendizagem\n","  for taxas_de_aprendizagem_i, taxa_de_aprendizagem in taxa_de_aprendizagem_bar:\n","\n","    # Atualiza a taxa de aprendizagem da avaliação\n","    training_args.learning_rate = taxa_de_aprendizagem\n","\n","    # Marca o tempo de início do processamento dos folds\n","    processamento_todos_fold_t0 = time.time()\n","\n","    # Executa o treinamento e avaliacao de todos folds para o modelo e taxa de aprendizagem\n","    procedimentoTreinamentoAvaliacaoFolds(modelo, taxa_de_aprendizagem)\n","\n","    # Pega o tempo atual menos o tempo do início do processamento.\n","    processamento_todos_fold_f = time.time()\n","    processamento_todos_fold_total = formataTempo(processamento_todos_fold_f - processamento_todos_fold_t0)    \n","    logging.info(\"  Tempo processamento de todos os folds: {:} (h:mm:ss)\\n\".format(processamento_todos_fold_total))    \n"]},{"cell_type":"markdown","metadata":{"id":"sbE7bMqSO6Uy"},"source":["## 5.3 Carregando a acurácia média das execuções"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"W9qG17x0Su-0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926444,"user_tz":180,"elapsed":1186,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"9b9455ed-e6c2-4de5-9859-a0133166b902"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Modelos :   0%|          | 0/1 [00:00<?, ?modelo/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2071779d9f249669b3d81fbde2b9ab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Taxas de aprendizagem :   0%|          | 0/5 [00:00<?, ?taxa/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f54847d474f44a48871d5dd28655af64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Épocas :   0%|          | 0/5 [00:00<?, ?época/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c5b573273b8416a990ca859f43650b9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 0 e taxa de treinamento 1e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 21:34, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.49875000, Rec: 0.91500000, Pre: 0.49931787, F1:0.64607237, vp:  366; vn:   33; fp:  367; fn:   34\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 21:39, Tempo: 0:00:09, QtdeTeste: 800, Acc: 0.44625000, Rec: 0.32750000, Pre: 0.42950820, F1:0.37163121, vp:  131; vn:  226; fp:  174; fn:  269\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 21:44, Tempo: 0:00:09, QtdeTeste: 800, Acc: 0.42625000, Rec: 0.28750000, Pre: 0.39792388, F1:0.33381713, vp:  115; vn:  226; fp:  174; fn:  285\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 21:50, Tempo: 0:00:09, QtdeTeste: 800, Acc: 0.40625000, Rec: 0.28000000, Pre: 0.37458194, F1:0.32045780, vp:  112; vn:  213; fp:  187; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 21:55, Tempo: 0:00:10, QtdeTeste: 800, Acc: 0.41750000, Rec: 0.30750000, Pre: 0.39423077, F1:0.34550562, vp:  123; vn:  211; fp:  189; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:00, Tempo: 0:00:12, QtdeTeste: 800, Acc: 0.41500000, Rec: 0.28000000, Pre: 0.38356164, F1:0.32369942, vp:  112; vn:  220; fp:  180; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 22:05, Tempo: 0:00:13, QtdeTeste: 800, Acc: 0.41875000, Rec: 0.32500000, Pre: 0.40000000, F1:0.35862069, vp:  130; vn:  205; fp:  195; fn:  270\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 22:10, Tempo: 0:00:11, QtdeTeste: 800, Acc: 0.42500000, Rec: 0.30750000, Pre: 0.40196078, F1:0.34844193, vp:  123; vn:  217; fp:  183; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 22:16, Tempo: 0:00:11, QtdeTeste: 800, Acc: 0.43000000, Rec: 0.28500000, Pre: 0.40140845, F1:0.33333333, vp:  114; vn:  230; fp:  170; fn:  286\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 22:21, Tempo: 0:00:12, QtdeTeste: 800, Acc: 0.42000000, Rec: 0.30500000, Pre: 0.39610390, F1:0.34463277, vp:  122; vn:  214; fp:  186; fn:  278\n","INFO:root:Total acurácia                                       : 4.30375000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.43037500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:01:51.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:00:11.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 1 e taxa de treinamento 1e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 21:35, Tempo: 0:01:22, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 21:40, Tempo: 0:01:17, QtdeTeste: 800, Acc: 0.98750000, Rec: 0.98250000, Pre: 0.99242424, F1:0.98743719, vp:  393; vn:  397; fp:    3; fn:    7\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 21:46, Tempo: 0:01:21, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 21:51, Tempo: 0:01:18, QtdeTeste: 800, Acc: 0.94875000, Rec: 0.90500000, Pre: 0.99178082, F1:0.94640523, vp:  362; vn:  397; fp:    3; fn:   38\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 21:56, Tempo: 0:01:19, QtdeTeste: 800, Acc: 0.97375000, Rec: 1.00000000, Pre: 0.95011876, F1:0.97442144, vp:  400; vn:  379; fp:   21; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:01, Tempo: 0:01:24, QtdeTeste: 800, Acc: 0.97750000, Rec: 0.95500000, Pre: 1.00000000, F1:0.97698210, vp:  382; vn:  400; fp:    0; fn:   18\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 22:06, Tempo: 0:01:24, QtdeTeste: 800, Acc: 0.93250000, Rec: 0.87000000, Pre: 0.99428571, F1:0.92800000, vp:  348; vn:  398; fp:    2; fn:   52\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 22:12, Tempo: 0:01:21, QtdeTeste: 800, Acc: 0.93500000, Rec: 0.87000000, Pre: 1.00000000, F1:0.93048128, vp:  348; vn:  400; fp:    0; fn:   52\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 22:17, Tempo: 0:01:22, QtdeTeste: 800, Acc: 0.96750000, Rec: 0.93750000, Pre: 0.99734043, F1:0.96649485, vp:  375; vn:  399; fp:    1; fn:   25\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 22:22, Tempo: 0:01:25, QtdeTeste: 800, Acc: 0.98625000, Rec: 0.98000000, Pre: 0.99240506, F1:0.98616352, vp:  392; vn:  397; fp:    3; fn:    8\n","INFO:root:Total acurácia                                       : 9.70375000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.97037500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:13:33.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:01:21.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 2 e taxa de treinamento 1e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 21:37, Tempo: 0:02:31, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 21:42, Tempo: 0:02:27, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 21:47, Tempo: 0:02:30, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 21:52, Tempo: 0:02:29, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 21:57, Tempo: 0:02:29, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:02, Tempo: 0:02:34, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 22:08, Tempo: 0:02:35, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 22:13, Tempo: 0:02:31, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 22:18, Tempo: 0:02:35, QtdeTeste: 800, Acc: 0.96125000, Rec: 0.92250000, Pre: 1.00000000, F1:0.95968791, vp:  369; vn:  400; fp:    0; fn:   31\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 22:23, Tempo: 0:02:37, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Total acurácia                                       : 9.94750000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.99475000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:25:18.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:02:31.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 3 e taxa de treinamento 1e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 21:38, Tempo: 0:03:40, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 21:43, Tempo: 0:03:38, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 21:48, Tempo: 0:03:40, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 21:53, Tempo: 0:03:41, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 21:58, Tempo: 0:03:39, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:03, Tempo: 0:03:46, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 22:09, Tempo: 0:03:45, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 22:14, Tempo: 0:03:42, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 22:19, Tempo: 0:03:46, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 22:24, Tempo: 0:03:49, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Total acurácia                                       : 9.97875000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.99787500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:37:06.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:03:42.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 4 e taxa de treinamento 1e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 21:39, Tempo: 0:04:49, QtdeTeste: 800, Acc: 0.98500000, Rec: 0.97250000, Pre: 0.99743590, F1:0.98481013, vp:  389; vn:  399; fp:    1; fn:   11\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 21:44, Tempo: 0:04:46, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 21:49, Tempo: 0:04:51, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 21:54, Tempo: 0:04:53, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 21:59, Tempo: 0:04:52, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:05, Tempo: 0:04:58, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 22:10, Tempo: 0:04:55, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 22:15, Tempo: 0:04:53, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 22:20, Tempo: 0:04:57, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 22:26, Tempo: 0:05:01, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Total acurácia                                       : 9.97000000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.99700000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:48:55.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:04:53.\n"]},{"output_type":"display_data","data":{"text/plain":["Épocas :   0%|          | 0/5 [00:00<?, ?época/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93fd95697ea943fdba7907e0063abee6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 0 e taxa de treinamento 2e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 22:26, Tempo: 0:00:12, QtdeTeste: 800, Acc: 0.43125000, Rec: 0.29500000, Pre: 0.40549828, F1:0.34153401, vp:  118; vn:  227; fp:  173; fn:  282\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 22:32, Tempo: 0:00:12, QtdeTeste: 800, Acc: 0.44625000, Rec: 0.32750000, Pre: 0.42950820, F1:0.37163121, vp:  131; vn:  226; fp:  174; fn:  269\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 22:37, Tempo: 0:00:13, QtdeTeste: 800, Acc: 0.42625000, Rec: 0.28750000, Pre: 0.39792388, F1:0.33381713, vp:  115; vn:  226; fp:  174; fn:  285\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 22:42, Tempo: 0:00:13, QtdeTeste: 800, Acc: 0.40625000, Rec: 0.28000000, Pre: 0.37458194, F1:0.32045780, vp:  112; vn:  213; fp:  187; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 22:48, Tempo: 0:00:13, QtdeTeste: 800, Acc: 0.41750000, Rec: 0.30750000, Pre: 0.39423077, F1:0.34550562, vp:  123; vn:  211; fp:  189; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:53, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.41500000, Rec: 0.28000000, Pre: 0.38356164, F1:0.32369942, vp:  112; vn:  220; fp:  180; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 22:59, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.41875000, Rec: 0.32500000, Pre: 0.40000000, F1:0.35862069, vp:  130; vn:  205; fp:  195; fn:  270\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 23:04, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.42500000, Rec: 0.30750000, Pre: 0.40196078, F1:0.34844193, vp:  123; vn:  217; fp:  183; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 23:10, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.43000000, Rec: 0.28500000, Pre: 0.40140845, F1:0.33333333, vp:  114; vn:  230; fp:  170; fn:  286\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 23:15, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.42000000, Rec: 0.30500000, Pre: 0.39610390, F1:0.34463277, vp:  122; vn:  214; fp:  186; fn:  278\n","INFO:root:Total acurácia                                       : 4.23625000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.42362500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:02:13.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:00:13.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 1 e taxa de treinamento 2e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 22:27, Tempo: 0:01:25, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 22:33, Tempo: 0:01:25, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 22:38, Tempo: 0:01:26, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 22:44, Tempo: 0:01:27, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 22:49, Tempo: 0:01:28, QtdeTeste: 800, Acc: 0.97500000, Rec: 0.95000000, Pre: 1.00000000, F1:0.97435897, vp:  380; vn:  400; fp:    0; fn:   20\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:55, Tempo: 0:01:28, QtdeTeste: 800, Acc: 0.89500000, Rec: 0.79000000, Pre: 1.00000000, F1:0.88268156, vp:  316; vn:  400; fp:    0; fn:   84\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:00, Tempo: 0:01:28, QtdeTeste: 800, Acc: 0.96875000, Rec: 0.94250000, Pre: 0.99472296, F1:0.96790757, vp:  377; vn:  398; fp:    2; fn:   23\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 23:06, Tempo: 0:01:28, QtdeTeste: 800, Acc: 0.98125000, Rec: 1.00000000, Pre: 0.96385542, F1:0.98159509, vp:  400; vn:  385; fp:   15; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 23:11, Tempo: 0:01:28, QtdeTeste: 800, Acc: 0.97750000, Rec: 0.95500000, Pre: 1.00000000, F1:0.97698210, vp:  382; vn:  400; fp:    0; fn:   18\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 23:17, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Total acurácia                                       : 9.78125000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.97812500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:14:32.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:01:27.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 2 e taxa de treinamento 2e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 22:29, Tempo: 0:02:39, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 22:34, Tempo: 0:02:39, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 22:39, Tempo: 0:02:40, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 22:45, Tempo: 0:02:41, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 22:50, Tempo: 0:02:41, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:56, Tempo: 0:02:42, QtdeTeste: 800, Acc: 0.99000000, Rec: 0.98000000, Pre: 1.00000000, F1:0.98989899, vp:  392; vn:  400; fp:    0; fn:    8\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:01, Tempo: 0:02:42, QtdeTeste: 800, Acc: 0.98375000, Rec: 1.00000000, Pre: 0.96852300, F1:0.98400984, vp:  400; vn:  387; fp:   13; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 23:07, Tempo: 0:02:42, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 23:12, Tempo: 0:02:43, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 23:18, Tempo: 0:02:43, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Total acurácia                                       : 9.95500000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.99550000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:26:52.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:02:41.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 3 e taxa de treinamento 2e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 22:30, Tempo: 0:03:51, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 22:35, Tempo: 0:03:52, QtdeTeste: 800, Acc: 0.94500000, Rec: 0.89750000, Pre: 0.99171271, F1:0.94225722, vp:  359; vn:  397; fp:    3; fn:   41\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 22:41, Tempo: 0:03:54, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 22:46, Tempo: 0:03:55, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 22:52, Tempo: 0:03:56, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:57, Tempo: 0:03:56, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:03, Tempo: 0:03:58, QtdeTeste: 800, Acc: 0.96125000, Rec: 0.92500000, Pre: 0.99730458, F1:0.95979248, vp:  370; vn:  399; fp:    1; fn:   30\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 23:08, Tempo: 0:03:57, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 23:14, Tempo: 0:03:57, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 23:19, Tempo: 0:03:57, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Total acurácia                                       : 9.89500000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.98950000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:39:13.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:03:55.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 4 e taxa de treinamento 2e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 22:31, Tempo: 0:05:06, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 22:36, Tempo: 0:05:06, QtdeTeste: 800, Acc: 0.98875000, Rec: 0.98250000, Pre: 0.99493671, F1:0.98867925, vp:  393; vn:  398; fp:    2; fn:    7\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 22:42, Tempo: 0:05:08, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 22:47, Tempo: 0:05:09, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 22:53, Tempo: 0:05:11, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 22:58, Tempo: 0:05:10, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:04, Tempo: 0:05:13, QtdeTeste: 800, Acc: 0.97375000, Rec: 1.00000000, Pre: 0.95011876, F1:0.97442144, vp:  400; vn:  379; fp:   21; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f8_BERTimbau_large, Data: 29/09/2022 23:09, Tempo: 0:05:11, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f9_BERTimbau_large, Data: 29/09/2022 23:15, Tempo: 0:05:11, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_f10_BERTimbau_large, Data: 29/09/2022 23:20, Tempo: 0:05:12, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Total acurácia                                       : 9.95500000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.99550000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:51:37.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:05:09.\n"]},{"output_type":"display_data","data":{"text/plain":["Épocas :   0%|          | 0/5 [00:00<?, ?época/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b074ccef2d9498192eae1678affcfe5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 0 e taxa de treinamento 3e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 23:21, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.43125000, Rec: 0.29500000, Pre: 0.40549828, F1:0.34153401, vp:  118; vn:  227; fp:  173; fn:  282\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 23:26, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.44625000, Rec: 0.32750000, Pre: 0.42950820, F1:0.37163121, vp:  131; vn:  226; fp:  174; fn:  269\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 23:32, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.42625000, Rec: 0.28750000, Pre: 0.39792388, F1:0.33381713, vp:  115; vn:  226; fp:  174; fn:  285\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 23:37, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.40625000, Rec: 0.28000000, Pre: 0.37458194, F1:0.32045780, vp:  112; vn:  213; fp:  187; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 23:43, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.41750000, Rec: 0.30750000, Pre: 0.39423077, F1:0.34550562, vp:  123; vn:  211; fp:  189; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 23:49, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.41500000, Rec: 0.28000000, Pre: 0.38356164, F1:0.32369942, vp:  112; vn:  220; fp:  180; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:54, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.41875000, Rec: 0.32500000, Pre: 0.40000000, F1:0.35862069, vp:  130; vn:  205; fp:  195; fn:  270\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 00:00, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.42500000, Rec: 0.30750000, Pre: 0.40196078, F1:0.34844193, vp:  123; vn:  217; fp:  183; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 00:05, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.43000000, Rec: 0.28500000, Pre: 0.40140845, F1:0.33333333, vp:  114; vn:  230; fp:  170; fn:  286\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 00:11, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.42000000, Rec: 0.30500000, Pre: 0.39610390, F1:0.34463277, vp:  122; vn:  214; fp:  186; fn:  278\n","INFO:root:Total acurácia                                       : 4.23625000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.42362500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:02:21.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:00:14.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 1 e taxa de treinamento 3e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 23:22, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.95625000, Rec: 0.92500000, Pre: 0.98666667, F1:0.95483871, vp:  370; vn:  395; fp:    5; fn:   30\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 23:28, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.95875000, Rec: 0.96000000, Pre: 0.95760599, F1:0.95880150, vp:  384; vn:  383; fp:   17; fn:   16\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 23:33, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.98875000, Rec: 1.00000000, Pre: 0.97799511, F1:0.98887515, vp:  400; vn:  391; fp:    9; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 23:39, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.95000000, Rec: 0.90750000, Pre: 0.99180328, F1:0.94778068, vp:  363; vn:  397; fp:    3; fn:   37\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 23:44, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.97000000, Rec: 0.97500000, Pre: 0.96534653, F1:0.97014925, vp:  390; vn:  386; fp:   14; fn:   10\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 23:50, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.85000000, Rec: 1.00000000, Pre: 0.76923077, F1:0.86956522, vp:  400; vn:  280; fp:  120; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:55, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.86000000, Rec: 0.73250000, Pre: 0.98322148, F1:0.83954155, vp:  293; vn:  395; fp:    5; fn:  107\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 00:01, Tempo: 0:01:30, QtdeTeste: 800, Acc: 0.98750000, Rec: 1.00000000, Pre: 0.97560976, F1:0.98765432, vp:  400; vn:  390; fp:   10; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 00:07, Tempo: 0:01:29, QtdeTeste: 800, Acc: 0.87000000, Rec: 0.91250000, Pre: 0.84101382, F1:0.87529976, vp:  365; vn:  331; fp:   69; fn:   35\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 00:12, Tempo: 0:01:30, QtdeTeste: 800, Acc: 0.93500000, Rec: 0.88000000, Pre: 0.98876404, F1:0.93121693, vp:  352; vn:  396; fp:    4; fn:   48\n","INFO:root:Total acurácia                                       : 9.32625000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.93262500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:14:52.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:01:29.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 2 e taxa de treinamento 3e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 23:23, Tempo: 0:02:43, QtdeTeste: 800, Acc: 0.62000000, Rec: 1.00000000, Pre: 0.56818182, F1:0.72463768, vp:  400; vn:   96; fp:  304; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 23:29, Tempo: 0:02:43, QtdeTeste: 800, Acc: 0.97125000, Rec: 0.94500000, Pre: 0.99736148, F1:0.97047497, vp:  378; vn:  399; fp:    1; fn:   22\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 23:34, Tempo: 0:02:45, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 23:40, Tempo: 0:02:43, QtdeTeste: 800, Acc: 0.99500000, Rec: 1.00000000, Pre: 0.99009901, F1:0.99502488, vp:  400; vn:  396; fp:    4; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 23:46, Tempo: 0:02:46, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 23:51, Tempo: 0:02:43, QtdeTeste: 800, Acc: 0.95750000, Rec: 0.97250000, Pre: 0.94417476, F1:0.95812808, vp:  389; vn:  377; fp:   23; fn:   11\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:57, Tempo: 0:02:46, QtdeTeste: 800, Acc: 0.93000000, Rec: 0.87000000, Pre: 0.98863636, F1:0.92553191, vp:  348; vn:  396; fp:    4; fn:   52\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 00:02, Tempo: 0:02:46, QtdeTeste: 800, Acc: 0.95625000, Rec: 0.91500000, Pre: 0.99727520, F1:0.95436767, vp:  366; vn:  399; fp:    1; fn:   34\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 00:08, Tempo: 0:02:46, QtdeTeste: 800, Acc: 0.90500000, Rec: 0.86250000, Pre: 0.94262295, F1:0.90078329, vp:  345; vn:  379; fp:   21; fn:   55\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 00:14, Tempo: 0:02:48, QtdeTeste: 800, Acc: 0.96500000, Rec: 0.94000000, Pre: 0.98947368, F1:0.96410256, vp:  376; vn:  396; fp:    4; fn:   24\n","INFO:root:Total acurácia                                       : 9.29750000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.92975000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:27:29.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:02:44.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 3 e taxa de treinamento 3e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 23:25, Tempo: 0:03:58, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 23:30, Tempo: 0:03:59, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 23:36, Tempo: 0:04:00, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 23:41, Tempo: 0:03:58, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 23:47, Tempo: 0:04:02, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 23:52, Tempo: 0:03:58, QtdeTeste: 800, Acc: 0.94500000, Rec: 0.90000000, Pre: 0.98901099, F1:0.94240838, vp:  360; vn:  396; fp:    4; fn:   40\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:58, Tempo: 0:04:02, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 00:04, Tempo: 0:04:03, QtdeTeste: 800, Acc: 0.92750000, Rec: 1.00000000, Pre: 0.87336245, F1:0.93240093, vp:  400; vn:  342; fp:   58; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 00:09, Tempo: 0:04:01, QtdeTeste: 800, Acc: 0.94750000, Rec: 0.89500000, Pre: 1.00000000, F1:0.94459103, vp:  358; vn:  400; fp:    0; fn:   42\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 00:15, Tempo: 0:04:05, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Total acurácia                                       : 9.30750000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.93075000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:40:06.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:04:00.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 4 e taxa de treinamento 3e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f1_BERTimbau_large, Data: 29/09/2022 23:26, Tempo: 0:05:14, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f2_BERTimbau_large, Data: 29/09/2022 23:31, Tempo: 0:05:14, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f3_BERTimbau_large, Data: 29/09/2022 23:37, Tempo: 0:05:16, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f4_BERTimbau_large, Data: 29/09/2022 23:42, Tempo: 0:05:14, QtdeTeste: 800, Acc: 0.99375000, Rec: 1.00000000, Pre: 0.98765432, F1:0.99378882, vp:  400; vn:  395; fp:    5; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f5_BERTimbau_large, Data: 29/09/2022 23:48, Tempo: 0:05:16, QtdeTeste: 800, Acc: 0.96750000, Rec: 0.96500000, Pre: 0.96984925, F1:0.96741855, vp:  386; vn:  388; fp:   12; fn:   14\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f6_BERTimbau_large, Data: 29/09/2022 23:54, Tempo: 0:05:14, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f7_BERTimbau_large, Data: 29/09/2022 23:59, Tempo: 0:05:19, QtdeTeste: 800, Acc: 0.98625000, Rec: 1.00000000, Pre: 0.97323601, F1:0.98643650, vp:  400; vn:  389; fp:   11; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 00:05, Tempo: 0:05:19, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 00:10, Tempo: 0:05:17, QtdeTeste: 800, Acc: 0.97000000, Rec: 1.00000000, Pre: 0.94339623, F1:0.97087379, vp:  400; vn:  376; fp:   24; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 00:16, Tempo: 0:05:21, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Total acurácia                                       : 9.40750000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.94075000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:52:44.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:05:16.\n"]},{"output_type":"display_data","data":{"text/plain":["Épocas :   0%|          | 0/5 [00:00<?, ?época/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86ec140bd16b4ec2b06525a48783a5bf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 0 e taxa de treinamento 4e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 00:17, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.43125000, Rec: 0.29500000, Pre: 0.40549828, F1:0.34153401, vp:  118; vn:  227; fp:  173; fn:  282\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 00:22, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.44625000, Rec: 0.32750000, Pre: 0.42950820, F1:0.37163121, vp:  131; vn:  226; fp:  174; fn:  269\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 00:28, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.42625000, Rec: 0.28750000, Pre: 0.39792388, F1:0.33381713, vp:  115; vn:  226; fp:  174; fn:  285\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 00:34, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.40625000, Rec: 0.28000000, Pre: 0.37458194, F1:0.32045780, vp:  112; vn:  213; fp:  187; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 00:39, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.41750000, Rec: 0.30750000, Pre: 0.39423077, F1:0.34550562, vp:  123; vn:  211; fp:  189; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 00:45, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.41500000, Rec: 0.28000000, Pre: 0.38356164, F1:0.32369942, vp:  112; vn:  220; fp:  180; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 00:51, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.41875000, Rec: 0.32500000, Pre: 0.40000000, F1:0.35862069, vp:  130; vn:  205; fp:  195; fn:  270\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 00:56, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.42500000, Rec: 0.30750000, Pre: 0.40196078, F1:0.34844193, vp:  123; vn:  217; fp:  183; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 01:02, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.43000000, Rec: 0.28500000, Pre: 0.40140845, F1:0.33333333, vp:  114; vn:  230; fp:  170; fn:  286\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 01:08, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.42000000, Rec: 0.30500000, Pre: 0.39610390, F1:0.34463277, vp:  122; vn:  214; fp:  186; fn:  278\n","INFO:root:Total acurácia                                       : 4.23625000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.42362500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:02:23.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:00:14.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 1 e taxa de treinamento 4e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 00:18, Tempo: 0:01:31, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 00:24, Tempo: 0:01:30, QtdeTeste: 800, Acc: 0.99375000, Rec: 1.00000000, Pre: 0.98765432, F1:0.99378882, vp:  400; vn:  395; fp:    5; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 00:29, Tempo: 0:01:30, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 00:35, Tempo: 0:01:30, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 00:41, Tempo: 0:01:30, QtdeTeste: 800, Acc: 0.94250000, Rec: 0.91500000, Pre: 0.96825397, F1:0.94087404, vp:  366; vn:  388; fp:   12; fn:   34\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 00:46, Tempo: 0:01:31, QtdeTeste: 800, Acc: 0.97250000, Rec: 1.00000000, Pre: 0.94786730, F1:0.97323601, vp:  400; vn:  378; fp:   22; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 00:52, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.56250000, Rec: 0.14000000, Pre: 0.90322581, F1:0.24242424, vp:   56; vn:  394; fp:    6; fn:  344\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 00:58, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.99250000, Rec: 1.00000000, Pre: 0.98522167, F1:0.99255583, vp:  400; vn:  394; fp:    6; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 01:03, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.95500000, Rec: 0.98250000, Pre: 0.93127962, F1:0.95620438, vp:  393; vn:  371; fp:   29; fn:    7\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 01:09, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.93500000, Rec: 0.88000000, Pre: 0.98876404, F1:0.93121693, vp:  352; vn:  396; fp:    4; fn:   48\n","INFO:root:Total acurácia                                       : 7.85375000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.78537500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:15:10.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:01:31.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 2 e taxa de treinamento 4e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 00:19, Tempo: 0:02:47, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 00:25, Tempo: 0:02:47, QtdeTeste: 800, Acc: 0.98000000, Rec: 0.96500000, Pre: 0.99484536, F1:0.97969543, vp:  386; vn:  398; fp:    2; fn:   14\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 00:31, Tempo: 0:02:46, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 00:36, Tempo: 0:02:46, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 00:42, Tempo: 0:02:47, QtdeTeste: 800, Acc: 0.98000000, Rec: 0.96500000, Pre: 0.99484536, F1:0.97969543, vp:  386; vn:  398; fp:    2; fn:   14\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 00:48, Tempo: 0:02:48, QtdeTeste: 800, Acc: 0.95625000, Rec: 0.98750000, Pre: 0.92941176, F1:0.95757576, vp:  395; vn:  370; fp:   30; fn:    5\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 00:53, Tempo: 0:02:47, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 00:59, Tempo: 0:02:48, QtdeTeste: 800, Acc: 0.94000000, Rec: 0.92750000, Pre: 0.95128205, F1:0.93924051, vp:  371; vn:  381; fp:   19; fn:   29\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 01:04, Tempo: 0:02:48, QtdeTeste: 800, Acc: 0.96250000, Rec: 0.94000000, Pre: 0.98429319, F1:0.96163683, vp:  376; vn:  394; fp:    6; fn:   24\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 01:10, Tempo: 0:02:48, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Total acurácia                                       : 7.81500000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.78150000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:27:52.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:02:47.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 3 e taxa de treinamento 4e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 00:21, Tempo: 0:04:03, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 00:26, Tempo: 0:04:03, QtdeTeste: 800, Acc: 0.97750000, Rec: 1.00000000, Pre: 0.95693780, F1:0.97799511, vp:  400; vn:  382; fp:   18; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 00:32, Tempo: 0:04:03, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 00:37, Tempo: 0:04:02, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 00:43, Tempo: 0:04:04, QtdeTeste: 800, Acc: 0.98875000, Rec: 1.00000000, Pre: 0.97799511, F1:0.98887515, vp:  400; vn:  391; fp:    9; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 00:49, Tempo: 0:04:04, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 00:54, Tempo: 0:04:05, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 01:00, Tempo: 0:04:05, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 01:06, Tempo: 0:04:05, QtdeTeste: 800, Acc: 0.97000000, Rec: 0.94000000, Pre: 1.00000000, F1:0.96907216, vp:  376; vn:  400; fp:    0; fn:   24\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 01:11, Tempo: 0:04:05, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Total acurácia                                       : 7.43250000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.74325000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:40:39.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:04:03.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 4 e taxa de treinamento 4e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 00:22, Tempo: 0:05:20, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 00:27, Tempo: 0:05:20, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 00:33, Tempo: 0:05:19, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 00:39, Tempo: 0:05:19, QtdeTeste: 800, Acc: 0.53750000, Rec: 0.41750000, Pre: 0.54934211, F1:0.47443182, vp:  167; vn:  263; fp:  137; fn:  233\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 00:44, Tempo: 0:05:20, QtdeTeste: 800, Acc: 0.96875000, Rec: 1.00000000, Pre: 0.94117647, F1:0.96969697, vp:  400; vn:  375; fp:   25; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 00:50, Tempo: 0:05:21, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 00:56, Tempo: 0:05:21, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 01:01, Tempo: 0:05:22, QtdeTeste: 800, Acc: 0.99875000, Rec: 1.00000000, Pre: 0.99750623, F1:0.99875156, vp:  400; vn:  399; fp:    1; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 01:07, Tempo: 0:05:21, QtdeTeste: 800, Acc: 0.97000000, Rec: 1.00000000, Pre: 0.94339623, F1:0.97087379, vp:  400; vn:  376; fp:   24; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 01:13, Tempo: 0:05:22, QtdeTeste: 800, Acc: 0.98000000, Rec: 1.00000000, Pre: 0.96153846, F1:0.98039216, vp:  400; vn:  384; fp:   16; fn:    0\n","INFO:root:Total acurácia                                       : 6.95500000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.69550000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:53:25.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:05:20.\n"]},{"output_type":"display_data","data":{"text/plain":["Épocas :   0%|          | 0/5 [00:00<?, ?época/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac47c335c569408ab26c47c19c925b1e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 0 e taxa de treinamento 5e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 01:13, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.43125000, Rec: 0.29500000, Pre: 0.40549828, F1:0.34153401, vp:  118; vn:  227; fp:  173; fn:  282\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 01:19, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.44625000, Rec: 0.32750000, Pre: 0.42950820, F1:0.37163121, vp:  131; vn:  226; fp:  174; fn:  269\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 01:25, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.42625000, Rec: 0.28750000, Pre: 0.39792388, F1:0.33381713, vp:  115; vn:  226; fp:  174; fn:  285\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 01:31, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.40625000, Rec: 0.28000000, Pre: 0.37458194, F1:0.32045780, vp:  112; vn:  213; fp:  187; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 01:36, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.41750000, Rec: 0.30750000, Pre: 0.39423077, F1:0.34550562, vp:  123; vn:  211; fp:  189; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 01:42, Tempo: 0:00:14, QtdeTeste: 800, Acc: 0.41500000, Rec: 0.28000000, Pre: 0.38356164, F1:0.32369942, vp:  112; vn:  220; fp:  180; fn:  288\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 01:48, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.41875000, Rec: 0.32500000, Pre: 0.40000000, F1:0.35862069, vp:  130; vn:  205; fp:  195; fn:  270\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 01:54, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.42500000, Rec: 0.30750000, Pre: 0.40196078, F1:0.34844193, vp:  123; vn:  217; fp:  183; fn:  277\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 02:00, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.43000000, Rec: 0.28500000, Pre: 0.40140845, F1:0.33333333, vp:  114; vn:  230; fp:  170; fn:  286\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 02:06, Tempo: 0:00:15, QtdeTeste: 800, Acc: 0.42000000, Rec: 0.30500000, Pre: 0.39610390, F1:0.34463277, vp:  122; vn:  214; fp:  186; fn:  278\n","INFO:root:Total acurácia                                       : 4.23625000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.42362500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:02:29.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:00:14.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 1 e taxa de treinamento 5e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 01:15, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 01:20, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.80875000, Rec: 0.69000000, Pre: 0.90491803, F1:0.78297872, vp:  276; vn:  371; fp:   29; fn:  124\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 01:26, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 01:32, Tempo: 0:01:33, QtdeTeste: 800, Acc: 0.78875000, Rec: 0.62250000, Pre: 0.93258427, F1:0.74662669, vp:  249; vn:  382; fp:   18; fn:  151\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 01:38, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 01:44, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.90250000, Rec: 1.00000000, Pre: 0.83682008, F1:0.91116173, vp:  400; vn:  322; fp:   78; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 01:49, Tempo: 0:01:32, QtdeTeste: 800, Acc: 0.98375000, Rec: 1.00000000, Pre: 0.96852300, F1:0.98400984, vp:  400; vn:  387; fp:   13; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 01:55, Tempo: 0:01:33, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 02:01, Tempo: 0:01:33, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 02:07, Tempo: 0:01:33, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Total acurácia                                       : 6.98375000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.69837500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:15:24.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:01:32.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 2 e taxa de treinamento 5e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 01:16, Tempo: 0:02:49, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 01:22, Tempo: 0:02:51, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 01:27, Tempo: 0:02:52, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 01:33, Tempo: 0:02:51, QtdeTeste: 800, Acc: 0.92750000, Rec: 1.00000000, Pre: 0.87336245, F1:0.93240093, vp:  400; vn:  342; fp:   58; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 01:39, Tempo: 0:02:54, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 01:45, Tempo: 0:02:51, QtdeTeste: 800, Acc: 0.98500000, Rec: 0.97250000, Pre: 0.99743590, F1:0.98481013, vp:  389; vn:  399; fp:    1; fn:   11\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 01:51, Tempo: 0:02:52, QtdeTeste: 800, Acc: 0.99375000, Rec: 1.00000000, Pre: 0.98765432, F1:0.99378882, vp:  400; vn:  395; fp:    5; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 01:57, Tempo: 0:02:51, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 02:02, Tempo: 0:02:52, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 02:08, Tempo: 0:02:50, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Total acurácia                                       : 6.90625000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.69062500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:28:33.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:02:51.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 3 e taxa de treinamento 5e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 01:17, Tempo: 0:04:07, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 01:23, Tempo: 0:04:09, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 01:29, Tempo: 0:04:10, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 01:35, Tempo: 0:04:09, QtdeTeste: 800, Acc: 0.88000000, Rec: 0.76250000, Pre: 0.99673203, F1:0.86402266, vp:  305; vn:  399; fp:    1; fn:   95\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 01:40, Tempo: 0:04:12, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 01:46, Tempo: 0:04:10, QtdeTeste: 800, Acc: 0.98875000, Rec: 1.00000000, Pre: 0.97799511, F1:0.98887515, vp:  400; vn:  391; fp:    9; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 01:52, Tempo: 0:04:10, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 01:58, Tempo: 0:04:09, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 02:04, Tempo: 0:04:10, QtdeTeste: 800, Acc: 0.97875000, Rec: 1.00000000, Pre: 0.95923261, F1:0.97919217, vp:  400; vn:  383; fp:   17; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 02:10, Tempo: 0:04:07, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Total acurácia                                       : 6.84500000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.68450000.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:41:33.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:04:09.\n","INFO:root:\n","\n","INFO:root:Acurácia do modelo: neuralmind/bert-large-portuguese-cased\n","INFO:root:   com época 4 e taxa de treinamento 5e-05.\n","INFO:root:Média dos arquivos: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_fX_BERTimbau_large\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f1_BERTimbau_large, Data: 30/09/2022 01:18, Tempo: 0:05:25, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f2_BERTimbau_large, Data: 30/09/2022 01:24, Tempo: 0:05:27, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f3_BERTimbau_large, Data: 30/09/2022 01:30, Tempo: 0:05:31, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f4_BERTimbau_large, Data: 30/09/2022 01:36, Tempo: 0:05:28, QtdeTeste: 800, Acc: 0.99750000, Rec: 1.00000000, Pre: 0.99502488, F1:0.99750623, vp:  400; vn:  398; fp:    2; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f5_BERTimbau_large, Data: 30/09/2022 01:42, Tempo: 0:05:31, QtdeTeste: 800, Acc: 0.50000000, Rec: 0.00000000, Pre: 0.00000000, F1:0.00000000, vp:    0; vn:  400; fp:    0; fn:  400\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f6_BERTimbau_large, Data: 30/09/2022 01:47, Tempo: 0:05:28, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f7_BERTimbau_large, Data: 30/09/2022 01:53, Tempo: 0:05:27, QtdeTeste: 800, Acc: 0.99625000, Rec: 1.00000000, Pre: 0.99255583, F1:0.99626401, vp:  400; vn:  397; fp:    3; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f8_BERTimbau_large, Data: 30/09/2022 01:59, Tempo: 0:05:28, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f9_BERTimbau_large, Data: 30/09/2022 02:05, Tempo: 0:05:27, QtdeTeste: 800, Acc: 1.00000000, Rec: 1.00000000, Pre: 1.00000000, F1:1.00000000, vp:  400; vn:  400; fp:    0; fn:    0\n","INFO:root:Arquivo: AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_f10_BERTimbau_large, Data: 30/09/2022 02:11, Tempo: 0:05:25, QtdeTeste: 800, Acc: 0.50000000, Rec: 1.00000000, Pre: 0.50000000, F1:0.66666667, vp:  400; vn:    0; fp:  400; fn:    0\n","INFO:root:Total acurácia                                       : 6.99375000.\n","INFO:root:Quantidade de folds                                  : 10.\n","INFO:root:A média da acurácia de 10 folds é                    : 0.69937500.\n","INFO:root:O tempo gasto na execução do treinamentoa 10 folds é : 00:54:37.\n","INFO:root:A média de tempo de execução de 10 folds é           : 00:05:27.\n"]}],"source":["# Import das bibliotecas\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","TAXAS_DE_APRENDIZAGEM = [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]\n","\n","LISTA_EPOCAS = [*range(0,EPOCAS+1)]\n","\n","# Guarda um resumo das execuções\n","lista_resultado_execucoes = []\n","\n","# Barra de progresso modelos\n","modelo_bar = tqdm_notebook(enumerate(NOMES_MODELO), desc=f'Modelos ', unit=f'modelo', total=len(NOMES_MODELO))\n","\n","# Percorre todos os modelos a serem avaliados\n","for modelo_i, modelo in modelo_bar:\n","\n","  # Barra de progresso das taxas de aprendizagem\n","  taxa_de_aprendizagem_bar = tqdm_notebook(enumerate(TAXAS_DE_APRENDIZAGEM), desc=f'Taxas de aprendizagem ', unit=f'taxa', total=len(TAXAS_DE_APRENDIZAGEM))\n","\n","  # Executa o treinamento e avaliação para diversas taxas de aprendizagem\n","  for taxas_de_aprendizagem_i, taxa_de_aprendizagem in taxa_de_aprendizagem_bar:\n","\n","    # Barra de progresso épocas\n","    epoca_bar = tqdm_notebook(enumerate(LISTA_EPOCAS), desc=f'Épocas ', unit=f'época', total=len(LISTA_EPOCAS))\n","\n","    # Percorre todos as épocas a serem avaliadas\n","    for epoca_i, epoca in epoca_bar:\n","\n","      logging.info(\"\\n\")\n","      logging.info(\"Acurácia do modelo: {}\".format(modelo))\n","      logging.info(\"   com época {} e taxa de treinamento {}.\".format(epoca, taxa_de_aprendizagem))\n","\n","      # Seta o parâmetro do modelo\n","      model_args.pretrained_model_name_or_path = modelo\n","\n","      # Seta o parâmetro do modelo\n","      training_args.learning_rate = taxa_de_aprendizagem\n","\n","      # Seta o parâmetro do modelo\n","      model_args.epoca = epoca\n","   \n","      # Monta o nome do arquivo de log\n","      NOME_ARQUIVO_AVALIACAO =  NOME_BASE_SAIDA + getSufixoNomeArquivoSaida(training_args, model_args)\n","      \n","      # Carrega o resultado\n","      carregaResultadoAvaliacao(NOME_ARQUIVO_AVALIACAO)"]},{"cell_type":"markdown","metadata":{"id":"pQxpMBDQz-jp"},"source":["Resumo da execução"]},{"cell_type":"markdown","source":["Acurácia por época."],"metadata":{"id":"n6b1qngkxylP"}},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):  \n","  if \"e_1\" in linha:\n","    print(linha)"],"metadata":{"id":"56KwUc34wdiC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926445,"user_tz":180,"elapsed":76,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"0c1d7d75-8ee4-4b3d-acb8-81131c65591b"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_fX_BERTimbau_large;0.970375;00:13:33\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_fX_BERTimbau_large;0.978125;00:14:32\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_fX_BERTimbau_large;0.932625;00:14:52\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_fX_BERTimbau_large;0.7853749999999999;00:15:10\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_fX_BERTimbau_large;0.698375;00:15:24\n"]}]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_e_2\" in linha:\n","    print(linha)"],"metadata":{"id":"InM8K00Awbkj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926445,"user_tz":180,"elapsed":72,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"dc77afe9-0cdf-4f9e-912d-158d5132a6a1"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_fX_BERTimbau_large;0.9947500000000001;00:25:18\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_fX_BERTimbau_large;0.9955;00:26:52\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_fX_BERTimbau_large;0.92975;00:27:29\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_fX_BERTimbau_large;0.7815;00:27:52\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_fX_BERTimbau_large;0.690625;00:28:33\n"]}]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_e_3\" in linha:\n","    print(linha)"],"metadata":{"id":"sJSlDXEcwZA1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926446,"user_tz":180,"elapsed":66,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"f3d984cf-e257-41f3-cd2c-d833925690a1"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_fX_BERTimbau_large;0.997875;00:37:06\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_fX_BERTimbau_large;0.9894999999999999;00:39:13\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_fX_BERTimbau_large;0.9307500000000001;00:40:06\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_fX_BERTimbau_large;0.7432500000000001;00:40:39\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_fX_BERTimbau_large;0.6845;00:41:33\n"]}]},{"cell_type":"code","execution_count":78,"metadata":{"id":"xCaqrur60Ayt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926446,"user_tz":180,"elapsed":62,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"e663bbf2-10d5-4e7b-fab4-244cb2b19dd0"},"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_fX_BERTimbau_large;0.9970000000000001;00:48:55\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_fX_BERTimbau_large;0.9955;00:51:37\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_fX_BERTimbau_large;0.9407500000000001;00:52:44\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_fX_BERTimbau_large;0.6955;00:53:25\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_fX_BERTimbau_large;0.6993750000000001;00:54:37\n"]}],"source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_e_4\" in linha:\n","    print(linha)"]},{"cell_type":"markdown","source":["Acurácia por taxa de aprendizagem."],"metadata":{"id":"s36FN2Cpx5ne"}},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_1\" in linha:\n","    print(linha)"],"metadata":{"id":"ZmokTJQrxpx7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926447,"user_tz":180,"elapsed":59,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"bca11879-59ce-4639-94cd-1c0e2f99f703"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_1_b_32_32_fX_BERTimbau_large;0.43037500000000006;00:01:51\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_1_b_32_32_fX_BERTimbau_large;0.970375;00:13:33\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_1_b_32_32_fX_BERTimbau_large;0.9947500000000001;00:25:18\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_1_b_32_32_fX_BERTimbau_large;0.997875;00:37:06\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_1_b_32_32_fX_BERTimbau_large;0.9970000000000001;00:48:55\n"]}]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_2\" in linha:\n","    print(linha)"],"metadata":{"id":"aPCTc4Mtx9c2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926447,"user_tz":180,"elapsed":56,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"117c9540-2dde-4c12-c871-566c8c4f202f"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_2_b_32_32_fX_BERTimbau_large;0.42362500000000003;00:02:13\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_2_b_32_32_fX_BERTimbau_large;0.978125;00:14:32\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_2_b_32_32_fX_BERTimbau_large;0.9955;00:26:52\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_2_b_32_32_fX_BERTimbau_large;0.9894999999999999;00:39:13\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_2_b_32_32_fX_BERTimbau_large;0.9955;00:51:37\n"]}]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_3\" in linha:\n","    print(linha)"],"metadata":{"id":"yND48p1Cx-tU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926448,"user_tz":180,"elapsed":53,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"1d33da9e-770a-4f3e-e8e4-a799c6c48e6b"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_3_b_32_32_fX_BERTimbau_large;0.42362500000000003;00:02:21\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_3_b_32_32_fX_BERTimbau_large;0.932625;00:14:52\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_3_b_32_32_fX_BERTimbau_large;0.92975;00:27:29\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_3_b_32_32_fX_BERTimbau_large;0.9307500000000001;00:40:06\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_3_b_32_32_fX_BERTimbau_large;0.9407500000000001;00:52:44\n"]}]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_4\" in linha:\n","    print(linha)"],"metadata":{"id":"7cJRaMApyCBX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926448,"user_tz":180,"elapsed":49,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ed920d24-82a4-4383-ecf7-e26133a84cc9"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_4_b_32_32_fX_BERTimbau_large;0.42362500000000003;00:02:23\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_4_b_32_32_fX_BERTimbau_large;0.7853749999999999;00:15:10\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_4_b_32_32_fX_BERTimbau_large;0.7815;00:27:52\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_4_b_32_32_fX_BERTimbau_large;0.7432500000000001;00:40:39\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_4_b_32_32_fX_BERTimbau_large;0.6955;00:53:25\n"]}]},{"cell_type":"code","source":["for i, linha in enumerate(lista_resultado_execucoes):\n","  if \"_lr_5\" in linha:\n","    print(linha)"],"metadata":{"id":"ck0rofyjyDzg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926449,"user_tz":180,"elapsed":46,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"5a610c22-3149-401c-cf04-70ce78acfbbe"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_0_lr_5_b_32_32_fX_BERTimbau_large;0.42362500000000003;00:02:29\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_1_lr_5_b_32_32_fX_BERTimbau_large;0.698375;00:15:24\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_2_lr_5_b_32_32_fX_BERTimbau_large;0.690625;00:28:33\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_3_lr_5_b_32_32_fX_BERTimbau_large;0.6845;00:41:33\n","AjusteFinoCohQuADCoInptbr_C_SB_KF_v1_P_100_K_100_E_4_e_4_lr_5_b_32_32_fX_BERTimbau_large;0.6993750000000001;00:54:37\n"]}]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"3EUXuiZNpBtL"},"source":["## 6.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"H50_GKJwpDha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664503926449,"user_tz":180,"elapsed":42,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"b16ab57d-c94c-4cbc-e0bd-dfb8870c9eec"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento: 4:37:48 (h:mm:ss)\n"]}],"source":[" # Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento: {:} (h:mm:ss)\".format(tempo_total_processamento))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}