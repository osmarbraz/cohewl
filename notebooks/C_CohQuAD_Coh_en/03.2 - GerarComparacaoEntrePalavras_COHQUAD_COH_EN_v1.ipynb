{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e89ea7f0bd5a43a59c8576b5e294c8e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac4157c3a31340259b07dc4f2b7397e1","IPY_MODEL_986bc06cc8d340ee9da1c50a2affec98","IPY_MODEL_266279c5e9594179ab2d2b8a9addd543"],"layout":"IPY_MODEL_362bb536a39a41d78a38ae0cd8007ec6"}},"ac4157c3a31340259b07dc4f2b7397e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ac6479499054912854e02edef1c7cca","placeholder":"​","style":"IPY_MODEL_32d2db0f55264fc2a50a2e49386da3dd","value":"Documentos: 100%"}},"986bc06cc8d340ee9da1c50a2affec98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_458eddcddc24475786525cc84da70b67","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2de5a375e384dc98d4678f3fe00ab28","value":20}},"266279c5e9594179ab2d2b8a9addd543":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_834443d34ea94c47a3e657a1b6d4182e","placeholder":"​","style":"IPY_MODEL_700acfcee6274713a4d196182cff0895","value":" 20/20 [00:00&lt;00:00, 75.91 documento/s]"}},"362bb536a39a41d78a38ae0cd8007ec6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ac6479499054912854e02edef1c7cca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32d2db0f55264fc2a50a2e49386da3dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"458eddcddc24475786525cc84da70b67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2de5a375e384dc98d4678f3fe00ab28":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"834443d34ea94c47a3e657a1b6d4182e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"700acfcee6274713a4d196182cff0895":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90ef60236b2642969620c91079f8f2e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f2be98dfc7440c68c067c3cbcb3571c","IPY_MODEL_703cd1caf59245448c8fe0233e5c9b28","IPY_MODEL_482c1b21c95b400a9b56c5e290f2e484"],"layout":"IPY_MODEL_990b0c827d9e4d23a92b38f6ac8a8ae0"}},"1f2be98dfc7440c68c067c3cbcb3571c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6a1f8007d724ca38efcfbf440806965","placeholder":"​","style":"IPY_MODEL_2351de1bfc9f461c9ea2a9728c9ba384","value":"Documentos: 100%"}},"703cd1caf59245448c8fe0233e5c9b28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d04ec4b70b94dd1ac68de8f2b3c2c2f","max":2020,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36d72cd5145145a789902c68a419f1c1","value":2020}},"482c1b21c95b400a9b56c5e290f2e484":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e485fe601db4aff84c1555bbc87cff5","placeholder":"​","style":"IPY_MODEL_7c030804f23c4a589c94e4224362738d","value":" 2020/2020 [12:25&lt;00:00,  2.57 documento/s]"}},"990b0c827d9e4d23a92b38f6ac8a8ae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6a1f8007d724ca38efcfbf440806965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2351de1bfc9f461c9ea2a9728c9ba384":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d04ec4b70b94dd1ac68de8f2b3c2c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36d72cd5145145a789902c68a419f1c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e485fe601db4aff84c1555bbc87cff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c030804f23c4a589c94e4224362738d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# Gerar comparação entre palavras das sentenças dos documentos originais e perturbados do CohQuAD Co en\n","\n","Gera a comparação entre as palavras das sentenças dos documentos do conjunto de dados utilizando os arquivos:\n","- `original.zip`\n","- `originalpos.zip`\n","- `perturbado_pX_kY.zip`\n","- `perturbadopos_pX_kY.zip`\n","\n","Nos nomes dos arquivos `perturbado_pX_kY.zip`,`perturbadopos_pX_kY.zip`, X é o número de documentos perturbados e Y o valor de top K predições.\n","\n","Cria o arquivo `comparacao_palavra_pX_kY.zip` com as comparações entre as palavras do documento, onde X é o número de documentos perturbados e Y o valor de top K predições.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OP33KWAtBMWs"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"PKUr9Vk4BNLC"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","metadata":{"id":"JXclHCRQBSF2"},"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"],"metadata":{"id":"OPRnA-mk5-c4"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================\n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.\n","    \"\"\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):\n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","\n","    return DIRETORIO_COHEBERT"],"metadata":{"id":"Fj5TaAH_5-nB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Realiza o download e um arquivo"],"metadata":{"id":"yDCOeh2y5jOH"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","\n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.\n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","\n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download\n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]\n","\n","    # Define o nome e caminho do arquivo temporário\n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","\n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","\n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:\n","        tamanho_conteudo = data.headers.get(\"Content-Length\")\n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)\n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):\n","            if chunk:\n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","\n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","\n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"],"metadata":{"id":"5B1mvfAU5jZf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","metadata":{"id":"6qwKjGvyLG4v"},"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","\n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","metadata":{"id":"jirIzIstLea0"},"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    sentencas = []\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas"],"metadata":{"id":"EC9Xppq-_R0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def salvar(nome_arquivo,texto):\n","    \"\"\"\n","      Salva um texto em arquivo.\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.\n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"],"metadata":{"id":"fkVk5LQT_G3f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","metadata":{"id":"Guy6B4whsZFR"},"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempoArredondado = int(round((tempo)))\n","\n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempoArredondado))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModelArguments) de definição dos parâmetros do modelo"]},{"cell_type":"code","metadata":{"id":"zgmN6RqDRDZS"},"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )\n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HIN413rj50EI"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","metadata":{"id":"bxV4-3Yg50EI"},"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","metadata":{"id":"DcopxbGZqDip"},"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","metadata":{"id":"YMiH0E3OnRa1"},"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yuHoA4Dx6K1M"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"0zhAltEP6K1M"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"IxAlgXv66K1M"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","metadata":{"id":"Cmva6ltA6K1M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664422412152,"user_tz":180,"elapsed":3804,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"f7ca26ea-7128-4f2a-9447-f2d6ee4ab023"},"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Dispositivo GPU não encontrado\n"]}]},{"cell_type":"markdown","metadata":{"id":"XrC2SG3x6K1M"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOnQUkWZ6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def getDeviceGPU():\n","    \"\"\"\n","    Retorna um dispositivo de GPU se disponível ou CPU.\n","\n","    Retorno:\n","    `device` - Um device de GPU ou CPU.\n","    \"\"\"\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","\n","        # Diz ao PyTorch para usar GPU.\n","        device = torch.device(\"cuda\")\n","\n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:\n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","\n","    return device"]},{"cell_type":"code","source":["device = getDeviceGPU()"],"metadata":{"id":"WcMhNxsE6K1N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664422415004,"user_tz":180,"elapsed":17,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"00689f7d-9393-43d1-9684-16fc7ad1c5e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Sem GPU disponível, usando CPU.\n"]}]},{"cell_type":"markdown","source":["Conecta o modelo ao device"],"metadata":{"id":"kkdlEouHftcJ"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def conectaGPU(model, device):\n","    \"\"\"\n","      Conecta um modelo BERT a GPU.\n","\n","      Parâmetros:\n","        `model` - Um modelo BERT carregado.\n","        `device` - Um device de GPU.\n","\n","      Retorno:\n","        `model` - Um objeto model BERT conectado a GPU.\n","    \"\"\"\n","    # Associa a GPU ao modelo.\n","    model.to(device)\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        # Diga ao pytorch para rodar este modelo na GPU.\n","        logging.info(\"Pytorch rodando o modelo na GPU.\")\n","        model.cuda()\n","\n","    else:\n","        logging.info(\"Pytorch rodando sem GPU.\")\n","\n","    return model"],"metadata":{"id":"a-znVDGyfsVx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRdtvR_J6K1N"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","metadata":{"id":"hSmGz55H6K1N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664422415005,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"aba50504-53eb-4405-ebc2-02c50a7ff0c8"},"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","metadata":{"id":"ysnDDapMQK8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664422479040,"user_tz":180,"elapsed":64043,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"c6756b61-bd3e-4d7e-a60a-b5d76992233e"},"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","metadata":{"id":"ejzpgGrFM0-j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664422493232,"user_tz":180,"elapsed":14199,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4fe288ab-156d-4177-8957-81489b1df054"},"source":["!pip install --upgrade wandb"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 47.4 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 55.8 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 60.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 55.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 64.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 76.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 72.8 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 49.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 69.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 58.6 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c8271696041fb414f0d93f940e5e3c081184d33b43ef0e27107d53af51405eed\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"J0LeiOTx0Dlk"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","metadata":{"id":"EaMM4WdxgvQ7","colab":{"base_uri":"https://localhost:8080/","height":524},"executionInfo":{"status":"ok","timestamp":1664422509480,"user_tz":180,"elapsed":16260,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"88a1d138-ad04-4b9b-fb0c-322ac1db660f"},"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.4.0-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 48.2 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","numba 0.56.2 requires setuptools<60, but you have setuptools 65.4.0 which is incompatible.\u001b[0m\n","Successfully installed pip-22.2.2 setuptools-65.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"w4p3Rz2qDq94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664422530076,"user_tz":180,"elapsed":20616,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ccdd0787-cf72-4a78-cc1a-680835e1d900"},"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.10)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.4)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.7)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.8)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.9.2\n","    Uninstalling pydantic-1.9.2:\n","      Successfully uninstalled pydantic-1.9.2\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.0\n","    Uninstalling thinc-8.1.0:\n","      Successfully uninstalled thinc-8.1.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.1\n","    Uninstalling spacy-3.4.1:\n","      Successfully uninstalled spacy-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typing-extensions-3.10.0.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.9 Instalação do BERT"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face.\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"code","metadata":{"id":"1RfUN_KolV-f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664422542211,"user_tz":180,"elapsed":12142,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"1754a03b-3fa0-4d0c-8679-268086390a54"},"source":["!pip install -U transformers==4.5.1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.8.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=c14543b926291a8cecd12200a5b0f55b67346e89fdee84ddb7a1fed347213616\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","source":["## Gerais"],"metadata":{"id":"ifrYNTwGwKal"}},{"cell_type":"code","source":["# Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 1\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 1"],"metadata":{"id":"5uiH9pNpwI6g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Específicos"],"metadata":{"id":"mhByVujAwNAU"}},{"cell_type":"markdown","source":["Parâmetros do modelo"],"metadata":{"id":"Mhkc9sW21zV7"}},{"cell_type":"code","metadata":{"id":"oJ15-ylRRRdD"},"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosMedida(\n","    max_seq_len = 512,\n","\n","    pretrained_model_name_or_path = \"bert-large-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-cased\"\n","    #pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","\n","    modelo_spacy = \"en_core_web_lg\",\n","    #modelo_spacy = \"en_core_web_md\",\n","    #modelo_spacy = \"en_core_web_sm\",\n","    #modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","\n","    versao_modelo_spacy = \"3.2.0\",\n","    sentenciar_documento = False,\n","    do_lower_case = False, # default True\n","    output_attentions = False, # default False\n","    output_hidden_states = True, # default False, se True retorna todas as camadas do modelo para as operações de soma e concatenação\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path.\n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 20 e 100. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Nome do diretório dos arquivos de dados"],"metadata":{"id":"WlF4PKP6Iopi"}},{"cell_type":"code","source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_CO_EN\""],"metadata":{"id":"55PNP2s6Iopi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","source":["### Função download modelo spaCy"],"metadata":{"id":"PWd_9X0nOYnF"}},{"cell_type":"code","source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"],"metadata":{"id":"DjWGu-9D5URZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","source":["### Função descompacta modelo spaCy"],"metadata":{"id":"XAc1tSwvOc4d"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","\n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivo_tar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")\n","    arquivo_tar.extractall(DIRETORIO_COHEBERT)\n","    arquivo_tar.close()\n","\n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):\n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"],"metadata":{"id":"Dq9PnXO77bPQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","source":["### Função carrega modelo spaCy"],"metadata":{"id":"3iFBoyWMOgKz"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","\n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp"],"metadata":{"id":"ePOccj0s8WMg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Carrega o modelo spaCy\n"],"metadata":{"id":"cAk5hHx7OnHn"}},{"cell_type":"code","metadata":{"id":"nbELnrpgA4T1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423049501,"user_tz":180,"elapsed":5158,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"270524f7-db6f-4718-b792-10e53a879c6e"},"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:spaCy carregado.\n"]}]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"],"metadata":{"id":"AEzytjZi5Iw2"}},{"cell_type":"code","metadata":{"id":"zKg-_XyWoy8o"},"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","\n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.\n","    \"\"\"\n","\n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","metadata":{"id":"s1o8jevtoy8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423049501,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"05a3b213-bb49-4479-bd76-5105701538bd"},"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Quantidade de stopwords: 326.\n"]},{"output_type":"stream","name":"stdout","text":["{'together', 'about', 'among', 'into', 'first', 'becoming', 'quite', 'while', 'between', 'wherein', 'whoever', 'further', 'him', 'somehow', 'four', 'were', 'whence', 'thus', 'another', 'give', 'whereupon', 'being', 'anyway', 'whereafter', 'still', 'himself', 'may', 'herself', 'or', 'against', 'yours', 'whether', \"'re\", 'could', 'beyond', 'before', 'become', 'of', 'less', 'his', '‘s', 'few', 'make', 'see', 'seeming', 'seem', 'around', 'fifteen', 'must', 'hereby', 'themselves', 'formerly', 'often', 'here', 'this', 'are', 'behind', 'anywhere', 'name', 'keep', 'only', 'three', 'call', 'some', 'that', \"'m\", 'down', 'something', 'over', 'therein', 'throughout', 'onto', 'so', 'had', 'therefore', 'until', 'part', 'if', 'twelve', 'hers', 'all', 'for', 'the', 'was', 'back', 'hundred', 'also', 'whither', 'ourselves', 'somewhere', 'cannot', 'i', 'upon', 'becomes', 'due', 'hence', 'her', 'those', 'itself', 'amount', 'seems', '‘re', '‘d', 'thru', 'anyone', 'eleven', 'she', 'from', 'its', 'already', 'again', 'latter', 'there', 'have', 'eight', 'thereupon', 'nobody', 'beforehand', 'should', 'full', 'am', 'really', 'several', 'nowhere', 'by', 'sometimes', 'as', 'top', 'above', 'perhaps', 'former', 'us', 'various', 'in', 'meanwhile', 'via', 'without', \"'d\", 'afterwards', 'n’t', 'how', 'wherever', 'herein', 'your', 'be', 'anyhow', 'up', 'and', 'else', 'across', 'most', 'any', 'a', 'me', 'forty', 'everything', 'show', 'might', '’re', 'anything', \"n't\", 'seemed', 'more', 'my', '‘ll', 'both', 'bottom', 'almost', 'unless', 'because', 'has', 'done', 'toward', 'besides', 'enough', 'ever', 'although', 'it', 'namely', 'latterly', 'after', 'whole', 'sixty', 'during', 'go', 'neither', 'ca', 'one', 'where', 'twenty', 'you', 'myself', 'then', 'yet', 'two', 'their', 'yourself', 'whereby', 'own', 'now', 'ours', 'take', 'does', 'doing', 'whereas', 'however', 'towards', 'ten', 'rather', 'just', 'same', 'thereby', 'will', 'nine', \"'ve\", 'many', 'these', 'do', '’s', 'regarding', 'whose', 'never', 'no', \"'s\", 'at', '‘ve', 'whom', 'yourselves', 'on', 'every', 'though', 'whenever', 'thence', 'who', 'them', 'too', 'other', 'even', 'n‘t', 'hereafter', 'became', 'been', '’ll', 'serious', 'would', 'alone', 'please', 'none', 'our', 'last', 'not', 'used', '‘m', 'whatever', 'along', 'very', 'did', 'moreover', 'hereupon', 'say', 'each', 'but', 'much', 'front', 'elsewhere', 'is', 'six', 'either', 'fifty', 'mostly', 'noone', 'an', 'indeed', 'mine', 'everyone', 'empty', 'once', 'nor', 'side', 'using', 'beside', 'get', 'than', \"'ll\", '’ve', 'through', 'under', 'someone', 'move', '’d', 'which', 'can', 'since', 'otherwise', 'next', 'everywhere', 'others', 'what', 'below', 'per', 'always', 'thereafter', 'amongst', 'off', '’m', 'nothing', 'why', 'he', 'five', 'put', 'out', 'except', 'made', 'within', 'we', 'such', 'least', 're', 'with', 'when', 'they', 'third', 'well', 'sometime', 'nevertheless', 'to'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","metadata":{"id":"6hdqVdfxm-_W"},"source":["# Import das bibliotecas.\n","import spacy\n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ]\n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal\n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ]\n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},\n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar\n","               ]\n","\n","matcherv = Matcher(nlp.vocab)\n","\n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):\n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","\n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","\n","  return lista2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novo_dic = dict()\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novo_dic[classe_gramatical] = qtde\n","\n","  return novo_dic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novo_dic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novo_dic[classe_gramatical] = qtde\n","\n","  return novo_dic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","metadata":{"id":"j9SA61kD6sJY"},"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","\n","  # Soma os dicionários da lista\n","  novo_dic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n","\n","  return novo_dic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","metadata":{"id":"gWxyAo54AOHU"},"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.text)\n","\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","metadata":{"id":"Gvd99wd_pwmt"},"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista_tokens = []\n","  lista_post = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:\n","    lista_tokens.append(token.text)\n","    lista_post.append(token.pos_)\n","\n","  return lista_tokens, lista_post"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","metadata":{"id":"NpCUpOs06sJY"},"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","\n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\"\n","  return traduzido"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","metadata":{"id":"rMb0uDWzKZXP"},"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","metadata":{"id":"zxTCYFzcJZD6"},"source":["def getSentencaSalientePOS(sentenca, pos, tipoSaliente=\"NOUN\"):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especeficado\n","    if pos[i] == tipoSaliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xaeX0oTVQ5t"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","metadata":{"id":"NIaQ9bzBVQ5t"},"source":["def removeStopWord(documento, stopwords):\n","\n","  # Remoção das stopwords do documento\n","  documento_sem_stopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documento_sem_stopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7NAe8ogCf1y"},"source":["### retornaRelevante\n","\n","Retorna somente os palavras do documento ou sentença do tipo especificado."]},{"cell_type":"code","metadata":{"id":"UNNfykypChn-"},"source":["def retornaRelevante(documento, classe_relevante=\"NOUN\"):\n","\n","  # Corrigir!\n","  # Utilizar o documento já tokenizado pelo spacy!!!!\n","  # Existe uma lista com o documento e a sentença tokenizada pelo spacy\n","\n","  # Realiza o parsing no spacy\n","  doc = nlp(documento)\n","\n","  # Retorna a lista das palavras relevantes\n","  documento_com_substantivos = []\n","  for token in doc:\n","    #print(\"token:\", token.pos_)\n","    if token.pos_ == classe_relevante:\n","      documento_com_substantivos.append(token.text)\n","\n","  # Concatena o documento com os substantivos\n","  documento_concatenado = \" \".join(documento_com_substantivos)\n","\n","  # Retorna o documento\n","  return documento_concatenado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IBY7q_uH8JSE"},"source":["# 4 BERT"]},{"cell_type":"markdown","source":["## 4.1 Modelo Pré-treinado BERT"],"metadata":{"id":"MBGTMy8Ic7GK"}},{"cell_type":"markdown","source":["### Funções Auxiliares"],"metadata":{"id":"uiuxdXe9t1BX"}},{"cell_type":"code","source":["def getNomeModeloBERT(model_args):\n","    '''\n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","\n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"\n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","        else:\n","            if 'bert' in model_args.pretrained_model_name_or_path:\n","                MODELO_BERT = \"_BERT\"\n","\n","    return MODELO_BERT"],"metadata":{"id":"9Huw0x5kt1Le"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getTamanhoBERT(model_args):\n","    '''\n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","\n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","\n","    return TAMANHO_BERT"],"metadata":{"id":"jYJB4ik7t5xe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Função download Modelo Pre-treinado BERT"],"metadata":{"id":"rHt4e5pAcEMd"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","\n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","\n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo!\")\n","            # Apaga o diretório e os arquivos existentes\n","            shutil.rmtree(DIRETORIO_MODELO)\n","\n","        # Realiza o download do arquivo do modelo\n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.\n","        arquivo_zip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivo_zip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.\n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","\n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta!\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada!\")\n","\n","    return DIRETORIO_MODELO"],"metadata":{"id":"peDUrV2ccEXA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Copia o modelo do BERT ajustado"],"metadata":{"id":"V74WUpHqcfoI"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\"\n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    logging.info(\"Modelo BERT ajustado copiado!\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"],"metadata":{"id":"iQMpf9yycf8f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Verifica de onde utilizar o modelo do BERT"],"metadata":{"id":"eaneOhAKcO-3"}},{"cell_type":"code","source":["def verificaModelo(model_args):\n","    \"\"\"\n","    Verifica de onde utilizar o modelo.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    DIRETORIO_MODELO = None\n","\n","    if model_args.usar_mcl_ajustado == True:\n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","\n","        logging.info(\"Usando modelo BERT ajustado.\")\n","\n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")\n","\n","    return DIRETORIO_MODELO"],"metadata":{"id":"TTy1TXz3cPKS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Tokenizador BERT"],"metadata":{"id":"6tKcaIfReqdy"}},{"cell_type":"markdown","source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf)."],"metadata":{"id":"e8n7Z5s-QZF8"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","\n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"],"metadata":{"id":"mzAuptkwQZR3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"],"metadata":{"id":"GYRV9KfHQE6v"}},{"cell_type":"markdown","source":["### Função carrega modelo BERT medida"],"metadata":{"id":"-pZZrUKRhR3e"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","from transformers import BertModel # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:\n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertModel.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertModel.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"],"metadata":{"id":"1JUEyjCChUQh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Função carrega o BERT"],"metadata":{"id":"-uFDhRTZe2Js"}},{"cell_type":"code","source":["def carregaBERT(model_args):\n","    \"\"\"\n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","        `tokenizer` - Um objeto tokenizador BERT carregado.\n","    \"\"\"\n","\n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","\n","    # Variável para conter o modelo\n","    model = None\n","\n","    # Carrega o modelo para cálculo da medida\n","    model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","\n","    # Carrega o tokenizador.\n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","\n","    return model, tokenizer"],"metadata":{"id":"QVtAUbUBe2iS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Carrega o BERT"],"metadata":{"id":"x5NTxBRKfAcT"}},{"cell_type":"code","source":["# Carrega o modelo e tokenizador do BERT\n","model, tokenizer = carregaBERT(model_args)"],"metadata":{"id":"ZYMLJJYSQHY3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423063882,"user_tz":180,"elapsed":14391,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"3b362fe1-4403-4863-9485-d8d56fef2919"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Variável URL_MODELO não setada!\n","INFO:root:Usando modelo BERT pré-treinado.\n","INFO:root:Carregando o modelo BERT da comunidade bert-large-cased para cálculo de medidas.\n","INFO:root:Carregando o tokenizador BERT do diretório bert-large-cased.\n"]}]},{"cell_type":"markdown","metadata":{"id":"d7KprWqyZBQZ"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6sPjTQnuQV2"},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"khTFfBVbnsx9"},"source":["## 4.4 Funções auxiliares do BERT"]},{"cell_type":"markdown","source":["### concatenaListas"],"metadata":{"id":"lCJzsw8T0I-5"}},{"cell_type":"code","source":["def concatenaListas(lista, pos=1):\n","  lista_concat = []\n","\n","  for x in lista:\n","      lista_concat = lista_concat + x[pos]\n","\n","  return lista_concat"],"metadata":{"id":"IpmDZ1mI0JHR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s42mgtmSZ8MR"},"source":["### getEmbeddingsCamadas\n","\n","Funções que recuperam os embeddings das camadas:\n","- Primeira camada;\n","- Penúltima camada;\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"sgo3EBTRZ9-3"},"source":["def getEmbeddingPrimeiraCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][0]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingPenultimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-2]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingUltimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-1]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingSoma4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][-4:]\n","  # Saída: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado\n","\n","def getEmbeddingConcat4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Cria uma lista com os tensores a serem concatenados\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Lista com os tensores a serem concatenados\n","  lista_concat = []\n","\n","  # Percorre os 4 últimos\n","  for i in [-1,-2,-3,-4]:\n","      # Concatena da lista\n","      lista_concat.append(output[2][i])\n","\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Realiza a concatenação dos embeddings de todos as camadas\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  resultado = torch.cat(lista_concat, dim=-1)\n","\n","  # Saída: Entrada: (<1(lote)> x <qtde_tokens> x <3072 ou 4096>)\n","  return resultado\n","\n","def getEmbeddingSomaTodasAsCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas as camadas descontando a primeira(0)\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][1:]\n","  # Saída: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q7nx_eZ8hSlr"},"source":["### getEmbeddingsVisual\n","\n","Função para gerar as coordenadas de plotagem a partir das sentenças de embeddings.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"pLdbOT8-g43V"},"source":["def getEmbeddingsVisualUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAf9lJJ2hZbt"},"source":["def getEmbeddingsVisualSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XpwSN1ghpnz"},"source":["def getEmbeddingsVisualConcat4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3KU1EFrnSPK"},"source":["def getEmbeddingsVisualSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8MjE0utzlZT"},"source":["### getEmbeddings\n","\n","Função para gerar os embeddings de sentenças.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"2QcqOuwS067Q"},"source":["def getEmbeddingsUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BK1wDGBl067Y"},"source":["def getEmbeddingsSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hym19Hxr067Y"},"source":["def getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer):\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-PLZiUR067Z"},"source":["def getEmbeddingsSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingsDocumento\n","\n","Recupera os embeddings e tokens do documento sem buffer."],"metadata":{"id":"Pyra3_pECsoJ"}},{"cell_type":"code","source":["def getEmbeddingsDocumento(documento, modelo, tokenizer):\n","\n","    return getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer)"],"metadata":{"id":"XdDBSRDcCxHp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingsDocumentoBuffer\n","\n","Recupera os embeddings e tokens do documento com buffer."],"metadata":{"id":"-rLcMuDHC-F5"}},{"cell_type":"code","source":["buffer_token_embeddings = {}\n","\n","def getEmbeddingsDocumentoBuffer(documento, modelo, tokenizer):\n","\n","    # Se documento está no dicionário retorna o embedding e os tokens\n","    if documento in buffer_token_embeddings:\n","        registro_buffer = buffer_token_embeddings.get(documento)\n","        return registro_buffer[0], registro_buffer[1]\n","    else:\n","        # Gera o embedding\n","        token_embeddings, documento_tokenizado = getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer)\n","        buffer_token_embeddings.update({documento: [token_embeddings, documento_tokenizado]})\n","\n","        return  token_embeddings, documento_tokenizado"],"metadata":{"id":"OogUm0kuC7wK"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTRcghhuet76"},"source":["def limpaBufferEmbedding():\n","    buffer_token_embeddings.clear()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zFd1rse11DpZ"},"source":["### getDocumentoTokenizado\n","\n","Retorna o documento tokenizado"]},{"cell_type":"code","metadata":{"id":"gvWIBFTLJ7z9"},"source":["def getDocumentoTokenizado(documento, tokenizer):\n","    \"\"\"\n","      Retorna o documento tokenizado pelo BERT.\n","\n","      Parâmetros:\n","      `documento` - Documento a ser tokenizado.\n","      `tokenizer` - Tokenizador do BERT.\n","    \"\"\"\n","\n","    # Adiciona os tokens especiais.\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Documento tokenizado\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    del tokenizer\n","\n","    return documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3wvgXwN81RCz"},"source":["### encontrarIndiceSubLista\n","\n","Retorna os índices de início e fim da sublista na lista"]},{"cell_type":"code","metadata":{"id":"abS44M4yvFxf"},"source":["def encontrarIndiceSubLista(lista: List, sublista: List):\n","    \"\"\"\n","    Localiza os índices de início e fim de uma sublista em uma lista.\n","    Baseado no algoritmo de https://codereview.stackexchange.com/questions/19627/finding-sub-list\n","    de  https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n","\n","    Parâmetros:\n","      `lista` - Uma lista.\n","      `sublista` - Uma sublista a ser localizada na lista.\n","\n","    Retorno:\n","      Os índices de início e fim da sublista na lista.\n","    \"\"\"\n","    # Tamanho da lista\n","    h = len(lista)\n","    # Tamanho da sblista\n","    n = len(sublista)\n","    # Cria um dicionário com os saltos descrescentes dos elementos n-1 da sublista\n","    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n","    i = n - 1\n","    # Percorre a lista\n","    while i < h:\n","        # Percorre a sublista\n","        for j in range(n):\n","            # Se elemento da lista diferente da sublista pula a interação\n","            if lista[i - j] != sublista[-j - 1]:\n","              # Passa para o próximo elemento da lista saltando a sublista\n","              i += skip.get(lista[i], n)\n","              # Interrompe o for.\n","              break\n","        else:\n","            #Finalizando a pesquisa depois de executar todo o for(sem break)\n","            indice_inicio = i - n + 1\n","            indice_fim = indice_inicio + len(sublista)-1\n","\n","            # Retorna o início e fim da sublista na lista\n","            return indice_inicio, indice_fim\n","\n","    # Não encontrou a sublista na lista\n","    return -1, -1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGL37G6XFcwp"},"source":["### getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras\n","\n","A partir dos embeddings do documento, localiza o indíce de início e fim de uma sentença no documento e retorna os embeddings da sentença."]},{"cell_type":"code","metadata":{"id":"uI07Y_M8__HG"},"source":["# Import das bibliotecas.\n","import numpy as np\n","\n","def getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                           token_BERT_documento,\n","                                                           sentenca,\n","                                                           tokenizer):\n","\n","  # Tokeniza a sentença\n","  sentenca_tokenizada_BERT = getDocumentoTokenizado(sentenca, tokenizer)\n","  #print(sentenca_tokenizada_BERT)\n","\n","  # Remove os tokens de início e fim da sentença\n","  sentenca_tokenizada_BERT.remove(\"[CLS]\")\n","  sentenca_tokenizada_BERT.remove(\"[SEP]\")\n","  #print(len(sentenca_tokenizada_BERT))\n","\n","  # Localiza os índices dos tokens da sentença no documento\n","  inicio, fim = encontrarIndiceSubLista(token_BERT_documento, sentenca_tokenizada_BERT)\n","  #print(inicio,fim)\n","\n","  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do documento\n","  embeddingSentenca = embedding_documento[inicio:fim+1]\n","  #print(\"embeddingSentenca=\", embeddingSentenca.shape)\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del sentenca\n","  del tokenizer\n","\n","  # Retorna o embedding da sentença no documento\n","  return embeddingSentenca, sentenca_tokenizada_BERT"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"THFhXGGmIO_r"},"source":["### getEmbeddingDocumentoComTodasPalavrasMean"]},{"cell_type":"code","metadata":{"id":"IhW_OiEsIPJI"},"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento excluindo os tokens\n","    especiais [CLS] do início e [SEP] do fim.\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embedding do documento.\n","  \"\"\"\n","\n","\n","  # Calcula a média dos embeddings para os tokens de embedding_documento, removendo a primeira dimensão.\n","  # Entrada: <qtde_tokens> x <768 ou 1024>\n","  #print(\"embedding_documento1=\", embedding_documento.shape)\n","  media_embedding_documento = torch.mean(embedding_documento[1:-1], dim=0)\n","  # Saída: <768 ou 1024>\n","\n","  del embedding_documento\n","\n","  return media_embedding_documento"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingDocumentoRelevanteMean"],"metadata":{"id":"1Ko_of60YuNd"}},{"cell_type":"code","source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                       index_sentenca,\n","                                       embedding_documento,\n","                                       token_BERT_documento,\n","                                       documento,\n","                                       tokenizer,\n","                                       token_documento,\n","                                       pos_documento,\n","                                       filtro):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento considerando tokens do tipo\n","    especificado no filtro\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","\n","  \"\"\"\n","\n","  # Recupera a lista de tokens do documento, a lista dos postagging e a lista dos seus embeddings com um mesmo tamanho\n","  lista_tokens, lista_postagging, lista_embeddings = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                    index_sentenca,\n","                                                                                    embedding_documento,\n","                                                                                    token_BERT_documento,\n","                                                                                    documento,\n","                                                                                    tokenizer,\n","                                                                                    token_documento,\n","                                                                                    pos_documento)\n","\n","  #print(\"len(token_BERT_documento):\", len(token_BERT_documento))\n","  #print(\"token_BERT_documento:\", token_BERT_documento)\n","  #print(\"len(pos_documento):\", len(pos_documento))\n","  #print(\"pos_documento:\", pos_documento)\n","  #print(\"filtro:\", filtro)\n","  #print()\n","\n","  # Lista com os tensores selecionados\n","  lista_tokens_selecionados = []\n","  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word no documento\n","  for i, token_documento in enumerate(lista_tokens):\n","      if (lista_postagging[i] in filtro):\n","          #print(\"Adicionando palavra do embedding:\", lista_tokens[i])\n","          lista_tokens_selecionados.append(lista_embeddings[i])\n","\n","  if  len(lista_tokens_selecionados) != 0:\n","      # Empila os embeddings da lista pela dimensão 0\n","      embedding_relevante = torch.stack(lista_tokens_selecionados, dim=0)\n","      #print(\"embedding_relevante.shape:\",embedding_relevante.shape)\n","\n","      # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n","      # Entrada: <qtde_tokens> x <768 ou 1024>\n","      media_embedding_relevante = torch.mean(embedding_relevante, dim=0)\n","      # Saída: <768 ou 1024>\n","      #print(\"media_embedding_relevante.shape:\", media_embedding_relevante.shape)\n","  else:\n","      media_embedding_relevante = None\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del documento\n","  del tokenizer\n","  del token_documento\n","  del pos_documento\n","\n","  return media_embedding_relevante"],"metadata":{"id":"wDokSSODY0Sf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingDocumentoMean\n","\n","Filtros:\n","- ALL - Sentença com todas as palavras\n","- NOUN - Sentença somente com substantivos\n","- VERB - Sentença somente com verbos\n","- VERB,NOUN - Sentença somente com verbos e substantivos"],"metadata":{"id":"L_vknrk7YSpF"}},{"cell_type":"code","source":["def getEmbeddingDocumentoMean(id_documento,\n","                              index_sentenca,\n","                              embedding_documento,\n","                              token_BERT_documento,\n","                              documento,\n","                              tokenizer,\n","                              token_documento,\n","                              pos_documento,\n","                              filtro=[\"ALL\"]):\n","  \"\"\"\n","    Rediciona o cálculo da média dos embeddings de acordo com o filtro especificado.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","  \"\"\"\n","\n","  if \"ALL\" in filtro:\n","    return getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento)\n","  else:\n","    return getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                              index_sentenca,\n","                                              embedding_documento,\n","                                              token_BERT_documento,\n","                                              documento,\n","                                              tokenizer,\n","                                              token_documento,\n","                                              pos_documento,\n","                                              filtro)"],"metadata":{"id":"Pd8B76YyYS02"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7W-7V3QFbpR"},"source":["# 5 Comparar Palavras"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 5.1 Carregamento dos arquivos de dados originais e perturbados"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["#### 5.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","metadata":{"id":"bNgwJRC2uGJb"},"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.1.2 Cria o diretório local para receber os dados"],"metadata":{"id":"CGF4D4B1JY9P"}},{"cell_type":"code","metadata":{"id":"gFYIHcIHE985","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423064461,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"655a3b0d-a7a8-4e7c-b084-8708dd56e357"},"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):\n","    # Cria o diretório\n","    os.makedirs(dirbase)\n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:\n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_CO_EN.\n"]}]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","metadata":{"id":"pviuxToMCxQw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423066250,"user_tz":180,"elapsed":1796,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"c55e1ce6-60ec-433d-b5f0-d8b5b5f1b56d"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a cópia.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens\n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","metadata":{"id":"dbHl3d88mouc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423067501,"user_tz":180,"elapsed":1254,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"8f79e069-e9d9-4b66-9f63-08a453cd6c9d"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a descompactação.\n"]}]},{"cell_type":"markdown","metadata":{"id":"qzhYJNWJm1z4"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais e pertubados"]},{"cell_type":"markdown","metadata":{"id":"Usr1uRzQeJSb"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","metadata":{"id":"QRHlixdHEDTb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423067501,"user_tz":180,"elapsed":8,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"663b125b-8060-4290-e4c1-b9cfe89ab764"},"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO ORIGINAIS: 20.\n","INFO:root:TERMINADO ORIGINAIS POS: 20.\n"]}]},{"cell_type":"code","metadata":{"id":"jJ5STBZPLlie","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1664423068299,"user_tz":180,"elapsed":802,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"508fda43-e0ab-4115-d106-67718e51ee44"},"source":["lista_documentos_originais.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    id                                          sentencas  \\\n","7    8  ['How to pop elements in a stack data structur...   \n","9   10  ['What is a queue and how to enqueue its eleme...   \n","14  15  ['What is a stack and how to push and pop its ...   \n","12  13  ['What is a queue and how to enqueue an elemen...   \n","17  18  ['How are the operations to enqueue and dequeu...   \n","\n","                                            documento  \n","7      How to pop elements in a stack data structure?  \n","9     What is a queue and how to enqueue its element?  \n","14  What is a stack and how to push and pop its el...  \n","12  What is a queue and how to enqueue an element ...  \n","17  How are the operations to enqueue and dequeue ...  "],"text/html":["\n","  <div id=\"df-af274b72-a7cf-42bc-bcfb-53e3e7a2cdb1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>['How to pop elements in a stack data structur...</td>\n","      <td>How to pop elements in a stack data structure?</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>['What is a queue and how to enqueue its eleme...</td>\n","      <td>What is a queue and how to enqueue its element?</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>['What is a stack and how to push and pop its ...</td>\n","      <td>What is a stack and how to push and pop its el...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>['What is a queue and how to enqueue an elemen...</td>\n","      <td>What is a queue and how to enqueue an element ...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>['How are the operations to enqueue and dequeu...</td>\n","      <td>How are the operations to enqueue and dequeue ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af274b72-a7cf-42bc-bcfb-53e3e7a2cdb1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-af274b72-a7cf-42bc-bcfb-53e3e7a2cdb1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-af274b72-a7cf-42bc-bcfb-53e3e7a2cdb1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":284}]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais = lista_documentos_originais.astype(tipos)"],"metadata":{"id":"BYddg8UODmdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbaWPXE2jK26","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1664423068300,"user_tz":180,"elapsed":42,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"6ef05b1e-90ab-46e7-ee8b-edbb393353b8"},"source":["lista_documentos_originais_pos.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    id                                      pos_documento\n","5    6  [[['How', 'to', 'push', 'and', 'pop', 'element...\n","2    3  [[['How', 'to', 'push', 'elements', 'in', 'a',...\n","7    8  [[['How', 'to', 'pop', 'elements', 'in', 'a', ...\n","12  13  [[['What', 'is', 'a', 'queue', 'and', 'how', '...\n","3    4  [[['How', 'to', 'push', 'and', 'pop', 'element..."],"text/html":["\n","  <div id=\"df-13fd1d23-f362-424e-bd1f-62e334a78c16\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>[[['How', 'to', 'push', 'and', 'pop', 'element...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>[[['How', 'to', 'push', 'elements', 'in', 'a',...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>[[['How', 'to', 'pop', 'elements', 'in', 'a', ...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>[[['What', 'is', 'a', 'queue', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>[[['How', 'to', 'push', 'and', 'pop', 'element...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13fd1d23-f362-424e-bd1f-62e334a78c16')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-13fd1d23-f362-424e-bd1f-62e334a78c16 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-13fd1d23-f362-424e-bd1f-62e334a78c16');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":286}]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais_pos = lista_documentos_originais_pos.astype(tipos)"],"metadata":{"id":"d96IZl9nDfHf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"-hfUpvKqXoqe"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"metadata":{"id":"lj9sJVavMccj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423068301,"user_tz":180,"elapsed":41,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"9c261837-6a87-48c5-88ed-dc22a868dcee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO ORIGINAIS: 20.\n","INFO:root:TERMINADO CORREÇÃO ORIGINAIS POS: 20.\n"]}]},{"cell_type":"markdown","source":["#### Criando dados indexados originais"],"metadata":{"id":"8yyRt4jnYxsU"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"B9INo4nBS8aQ","executionInfo":{"status":"ok","timestamp":1664423068301,"user_tz":180,"elapsed":36,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"94707f56-7db5-46cb-9b31-aaad817cfb32"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            sentencas  \\\n","id                                                      \n","1               [How to enqueue elements in a queue?]   \n","2               [How to dequeue elements in a queue?]   \n","3                  [How to push elements in a stack?]   \n","4          [How to push and pop elements in a stack?]   \n","5   [How to push elements in a stack data structure?]   \n","\n","                                          documento  \n","id                                                   \n","1               How to enqueue elements in a queue?  \n","2               How to dequeue elements in a queue?  \n","3                  How to push elements in a stack?  \n","4          How to push and pop elements in a stack?  \n","5   How to push elements in a stack data structure?  "],"text/html":["\n","  <div id=\"df-5e1d8288-5901-4b06-a8a1-b59f75b86257\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>[How to enqueue elements in a queue?]</td>\n","      <td>How to enqueue elements in a queue?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[How to dequeue elements in a queue?]</td>\n","      <td>How to dequeue elements in a queue?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[How to push elements in a stack?]</td>\n","      <td>How to push elements in a stack?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[How to push and pop elements in a stack?]</td>\n","      <td>How to push and pop elements in a stack?</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[How to push elements in a stack data structure?]</td>\n","      <td>How to push elements in a stack data structure?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e1d8288-5901-4b06-a8a1-b59f75b86257')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5e1d8288-5901-4b06-a8a1-b59f75b86257 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5e1d8288-5901-4b06-a8a1-b59f75b86257');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":289}]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"j70x_r30T_bx","executionInfo":{"status":"ok","timestamp":1664423068301,"user_tz":180,"elapsed":34,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"20c90831-68cc-4c15-d016-f6c7669c8cac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        pos_documento\n","id                                                   \n","1   [[[How, to, enqueue, elements, in, a, queue, ?...\n","2   [[[How, to, dequeue, elements, in, a, queue, ?...\n","3   [[[How, to, push, elements, in, a, stack, ?], ...\n","4   [[[How, to, push, and, pop, elements, in, a, s...\n","5   [[[How, to, push, elements, in, a, stack, data..."],"text/html":["\n","  <div id=\"df-af1f3711-b898-482a-9952-45b2fa493034\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>[[[How, to, enqueue, elements, in, a, queue, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[[[How, to, dequeue, elements, in, a, queue, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[[[How, to, push, elements, in, a, stack, ?], ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[[[How, to, push, and, pop, elements, in, a, s...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[[[How, to, push, elements, in, a, stack, data...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af1f3711-b898-482a-9952-45b2fa493034')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-af1f3711-b898-482a-9952-45b2fa493034 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-af1f3711-b898-482a-9952-45b2fa493034');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":290}]},{"cell_type":"markdown","metadata":{"id":"zJXcpioo7Bhn"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","metadata":{"id":"gB500dmd7Bho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423068302,"user_tz":180,"elapsed":34,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ee97b507-2907-41e9-a5d3-82629fd330b2"},"source":["# Abre o arquivo e retorna o DataFrame\n","lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO PERTURBADOS: 2000.\n","INFO:root:TERMINADO PERTURBADOS POS: 2000.\n"]}]},{"cell_type":"markdown","source":["Alguns csv estão com o nome da coluna errado."],"metadata":{"id":"jfZEITKEHHWW"}},{"cell_type":"code","source":["lista_documentos_perturbados = lista_documentos_perturbados.rename(columns={'documentoPerturbado':'documento_perturbado'})"],"metadata":{"id":"quf5o1KkHLkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ9cgAz47Bhp","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1664423068303,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"55de821f-7ec4-4640-aea4-48604ac404c6"},"source":["lista_documentos_perturbados.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                         perturbado  \\\n","507     6_pert_7  ['How to rock and pop elements in a stack data...   \n","1009   11_pert_9  ['What is a queue and how to locate an element...   \n","592    6_pert_92  ['How to take and pop elements in a stack data...   \n","1633  17_pert_33  ['How are the operations to push and pop eleme...   \n","722    8_pert_22  ['How to construct elements in a stack data st...   \n","\n","                                   documento_perturbado  \\\n","507   How to rock and pop elements in a stack data s...   \n","1009  What is a queue and how to locate an element i...   \n","592   How to take and pop elements in a stack data s...   \n","1633  How are the operations to push and pop element...   \n","722   How to construct elements in a stack data stru...   \n","\n","                                              sentencas  \n","507   [['How to [MASK] and pop elements in a stack d...  \n","1009  [['What is a queue and how to [MASK] an elemen...  \n","592   [['How to [MASK] and pop elements in a stack d...  \n","1633  [['How are the operations to push and pop elem...  \n","722   [['How to [MASK] elements in a stack data stru...  "],"text/html":["\n","  <div id=\"df-54486b3c-2c8b-4aed-a140-72e0e9d15747\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>507</th>\n","      <td>6_pert_7</td>\n","      <td>['How to rock and pop elements in a stack data...</td>\n","      <td>How to rock and pop elements in a stack data s...</td>\n","      <td>[['How to [MASK] and pop elements in a stack d...</td>\n","    </tr>\n","    <tr>\n","      <th>1009</th>\n","      <td>11_pert_9</td>\n","      <td>['What is a queue and how to locate an element...</td>\n","      <td>What is a queue and how to locate an element i...</td>\n","      <td>[['What is a queue and how to [MASK] an elemen...</td>\n","    </tr>\n","    <tr>\n","      <th>592</th>\n","      <td>6_pert_92</td>\n","      <td>['How to take and pop elements in a stack data...</td>\n","      <td>How to take and pop elements in a stack data s...</td>\n","      <td>[['How to [MASK] and pop elements in a stack d...</td>\n","    </tr>\n","    <tr>\n","      <th>1633</th>\n","      <td>17_pert_33</td>\n","      <td>['How are the operations to push and pop eleme...</td>\n","      <td>How are the operations to push and pop element...</td>\n","      <td>[['How are the operations to push and pop elem...</td>\n","    </tr>\n","    <tr>\n","      <th>722</th>\n","      <td>8_pert_22</td>\n","      <td>['How to construct elements in a stack data st...</td>\n","      <td>How to construct elements in a stack data stru...</td>\n","      <td>[['How to [MASK] elements in a stack data stru...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54486b3c-2c8b-4aed-a140-72e0e9d15747')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-54486b3c-2c8b-4aed-a140-72e0e9d15747 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-54486b3c-2c8b-4aed-a140-72e0e9d15747');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":293}]},{"cell_type":"code","metadata":{"id":"3pXGee7H7Bhp","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1664423068304,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"fdebd937-2270-4436-c329-c42fcca73d82"},"source":["lista_documentos_perturbados.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                         perturbado  \\\n","1053  11_pert_53  ['What is a queue and how to resolve an elemen...   \n","1087  11_pert_87  ['What is a queue and how to navigate an eleme...   \n","1600   17_pert_0  ['How are the operations to push and pop eleme...   \n","238    3_pert_38          ['How to organise elements in a stack ?']   \n","927   10_pert_27  ['What is a queue and how to discover its elem...   \n","\n","                                   documento_perturbado  \\\n","1053  What is a queue and how to resolve an element ...   \n","1087  What is a queue and how to navigate an element...   \n","1600  How are the operations to push and pop element...   \n","238               How to organise elements in a stack ?   \n","927   What is a queue and how to discover its element ?   \n","\n","                                              sentencas  \n","1053  [['What is a queue and how to [MASK] an elemen...  \n","1087  [['What is a queue and how to [MASK] an elemen...  \n","1600  [['How are the operations to push and pop elem...  \n","238   [['How to [MASK] elements in a stack ?', 'push...  \n","927   [['What is a queue and how to [MASK] its eleme...  "],"text/html":["\n","  <div id=\"df-1eb6482c-954a-4372-bc01-d0d09365b39a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1053</th>\n","      <td>11_pert_53</td>\n","      <td>['What is a queue and how to resolve an elemen...</td>\n","      <td>What is a queue and how to resolve an element ...</td>\n","      <td>[['What is a queue and how to [MASK] an elemen...</td>\n","    </tr>\n","    <tr>\n","      <th>1087</th>\n","      <td>11_pert_87</td>\n","      <td>['What is a queue and how to navigate an eleme...</td>\n","      <td>What is a queue and how to navigate an element...</td>\n","      <td>[['What is a queue and how to [MASK] an elemen...</td>\n","    </tr>\n","    <tr>\n","      <th>1600</th>\n","      <td>17_pert_0</td>\n","      <td>['How are the operations to push and pop eleme...</td>\n","      <td>How are the operations to push and pop element...</td>\n","      <td>[['How are the operations to push and pop elem...</td>\n","    </tr>\n","    <tr>\n","      <th>238</th>\n","      <td>3_pert_38</td>\n","      <td>['How to organise elements in a stack ?']</td>\n","      <td>How to organise elements in a stack ?</td>\n","      <td>[['How to [MASK] elements in a stack ?', 'push...</td>\n","    </tr>\n","    <tr>\n","      <th>927</th>\n","      <td>10_pert_27</td>\n","      <td>['What is a queue and how to discover its elem...</td>\n","      <td>What is a queue and how to discover its element ?</td>\n","      <td>[['What is a queue and how to [MASK] its eleme...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1eb6482c-954a-4372-bc01-d0d09365b39a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1eb6482c-954a-4372-bc01-d0d09365b39a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1eb6482c-954a-4372-bc01-d0d09365b39a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":294}]},{"cell_type":"code","source":["lista_documentos_perturbados_pos.sample(5)"],"metadata":{"id":"IE1xJdZWkc5I","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1664423068305,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"6f602be8-b17e-42ca-a947-626a5da6f27a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                      pos_documento\n","1195  12_pert_95  [[['What', 'is', 'a', 'stack', 'and', 'how', '...\n","1384  14_pert_84  [[['What', 'is', 'a', 'stack', 'and', 'how', '...\n","1720  18_pert_20  [[['How', 'are', 'the', 'operations', 'to', 'e...\n","1586  16_pert_86  [[['What', 'is', 'a', 'queue', 'and', 'how', '...\n","244    3_pert_44  [[['How', 'to', 'express', 'elements', 'in', '..."],"text/html":["\n","  <div id=\"df-9eba50dd-adb0-451f-b83c-3018d8f36bc4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1195</th>\n","      <td>12_pert_95</td>\n","      <td>[[['What', 'is', 'a', 'stack', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>1384</th>\n","      <td>14_pert_84</td>\n","      <td>[[['What', 'is', 'a', 'stack', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>1720</th>\n","      <td>18_pert_20</td>\n","      <td>[[['How', 'are', 'the', 'operations', 'to', 'e...</td>\n","    </tr>\n","    <tr>\n","      <th>1586</th>\n","      <td>16_pert_86</td>\n","      <td>[[['What', 'is', 'a', 'queue', 'and', 'how', '...</td>\n","    </tr>\n","    <tr>\n","      <th>244</th>\n","      <td>3_pert_44</td>\n","      <td>[[['How', 'to', 'express', 'elements', 'in', '...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9eba50dd-adb0-451f-b83c-3018d8f36bc4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9eba50dd-adb0-451f-b83c-3018d8f36bc4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9eba50dd-adb0-451f-b83c-3018d8f36bc4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":295}]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"VrfZzjjpsUOU"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHf-7dgSsUOU","executionInfo":{"status":"ok","timestamp":1664423068305,"user_tz":180,"elapsed":29,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"9d387c8f-876b-40c8-b2f2-b33e122c902c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO PERTURBADO: 2000.\n","INFO:root:TERMINADO CORREÇÃO PERTURBADO POS: 2000.\n"]}]},{"cell_type":"markdown","source":["#### Criando dados indexados perturbados"],"metadata":{"id":"Ix-Q5fZXY3HR"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"FqRQnYUtSxzB","executionInfo":{"status":"ok","timestamp":1664423068306,"user_tz":180,"elapsed":26,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4134ec1f-4efc-4125-ffc4-438b83fd1b65"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                       perturbado  \\\n","id                                                  \n","1_pert_0     [How to place elements in a queue ?]   \n","1_pert_1   [How to arrange elements in a queue ?]   \n","1_pert_2  [How to organize elements in a queue ?]   \n","1_pert_3    [How to manage elements in a queue ?]   \n","1_pert_4       [How to put elements in a queue ?]   \n","\n","                           documento_perturbado  \\\n","id                                                \n","1_pert_0     How to place elements in a queue ?   \n","1_pert_1   How to arrange elements in a queue ?   \n","1_pert_2  How to organize elements in a queue ?   \n","1_pert_3    How to manage elements in a queue ?   \n","1_pert_4       How to put elements in a queue ?   \n","\n","                                                  sentencas  \n","id                                                           \n","1_pert_0  [[How to [MASK] elements in a queue ?, enqueue...  \n","1_pert_1  [[How to [MASK] elements in a queue ?, enqueue...  \n","1_pert_2  [[How to [MASK] elements in a queue ?, enqueue...  \n","1_pert_3  [[How to [MASK] elements in a queue ?, enqueue...  \n","1_pert_4  [[How to [MASK] elements in a queue ?, enqueue...  "],"text/html":["\n","  <div id=\"df-74ce5f0a-5a66-4a31-8aae-ea32797060f8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1_pert_0</th>\n","      <td>[How to place elements in a queue ?]</td>\n","      <td>How to place elements in a queue ?</td>\n","      <td>[[How to [MASK] elements in a queue ?, enqueue...</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_1</th>\n","      <td>[How to arrange elements in a queue ?]</td>\n","      <td>How to arrange elements in a queue ?</td>\n","      <td>[[How to [MASK] elements in a queue ?, enqueue...</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_2</th>\n","      <td>[How to organize elements in a queue ?]</td>\n","      <td>How to organize elements in a queue ?</td>\n","      <td>[[How to [MASK] elements in a queue ?, enqueue...</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_3</th>\n","      <td>[How to manage elements in a queue ?]</td>\n","      <td>How to manage elements in a queue ?</td>\n","      <td>[[How to [MASK] elements in a queue ?, enqueue...</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_4</th>\n","      <td>[How to put elements in a queue ?]</td>\n","      <td>How to put elements in a queue ?</td>\n","      <td>[[How to [MASK] elements in a queue ?, enqueue...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74ce5f0a-5a66-4a31-8aae-ea32797060f8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-74ce5f0a-5a66-4a31-8aae-ea32797060f8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-74ce5f0a-5a66-4a31-8aae-ea32797060f8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":297}]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados_pos.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"s0aDUbeZT1M8","executionInfo":{"status":"ok","timestamp":1664423068306,"user_tz":180,"elapsed":25,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ef6fc05b-e2bf-45a5-bf97-764cd5b8fb43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              pos_documento\n","id                                                         \n","1_pert_0  [[[How, to, place, elements, in, a, queue, ?],...\n","1_pert_1  [[[How, to, arrange, elements, in, a, queue, ?...\n","1_pert_2  [[[How, to, organize, elements, in, a, queue, ...\n","1_pert_3  [[[How, to, manage, elements, in, a, queue, ?]...\n","1_pert_4  [[[How, to, put, elements, in, a, queue, ?], [..."],"text/html":["\n","  <div id=\"df-17d7c37d-215f-449b-9d71-946dbb013fe8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1_pert_0</th>\n","      <td>[[[How, to, place, elements, in, a, queue, ?],...</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_1</th>\n","      <td>[[[How, to, arrange, elements, in, a, queue, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_2</th>\n","      <td>[[[How, to, organize, elements, in, a, queue, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_3</th>\n","      <td>[[[How, to, manage, elements, in, a, queue, ?]...</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_4</th>\n","      <td>[[[How, to, put, elements, in, a, queue, ?], [...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17d7c37d-215f-449b-9d71-946dbb013fe8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-17d7c37d-215f-449b-9d71-946dbb013fe8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-17d7c37d-215f-449b-9d71-946dbb013fe8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":298}]},{"cell_type":"markdown","source":["### 5.1.5 Agrupar os dados originais e perturbados"],"metadata":{"id":"kq0-NGaC76jP"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","lista_documentos_agrupados = []\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_originais_bar:\n","  #if i < 2:\n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    #print(\"id_documento:\",id_documento)\n","\n","    # Carrega a lista das sentenças do documento\n","    lista_sentenca_documento = linha_documento[1]\n","    #print(\"\\nlista_sentenca_documento:\",lista_sentenca_documento)\n","    #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","\n","    # Adiciona o original a lista dos dados agrupados, considerando como coerente(1)\n","    lista_documentos_agrupados.append([id_documento, lista_sentenca_documento, linha_documento[2], 1])\n","\n","    # Percorre os documentos perturbados apartir do original\n","    for j in range(0, model_args.documentos_perturbados):\n","\n","      # Id do documento perturbado\n","      id_perturbado = str(id_documento) + \"_pert_\" + str(j)\n","\n","      # localiza o documento perturbado\n","      documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","      # print(\"documento_perturbado:\", documento_perturbado)\n","      # print(\"len(documento_perturbado):\", len(documento_perturbado))\n","      # Recupera a sentença do documento perturbado\n","      lista_perturbado = documento_perturbado[0]\n","\n","      # Adiciona o perturbado a lista dos dados agrupados considerando como incoerente(0)\n","      lista_documentos_agrupados.append([id_perturbado, lista_perturbado, documento_perturbado[1], 0])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["e89ea7f0bd5a43a59c8576b5e294c8e1","ac4157c3a31340259b07dc4f2b7397e1","986bc06cc8d340ee9da1c50a2affec98","266279c5e9594179ab2d2b8a9addd543","362bb536a39a41d78a38ae0cd8007ec6","9ac6479499054912854e02edef1c7cca","32d2db0f55264fc2a50a2e49386da3dd","458eddcddc24475786525cc84da70b67","c2de5a375e384dc98d4678f3fe00ab28","834443d34ea94c47a3e657a1b6d4182e","700acfcee6274713a4d196182cff0895"]},"id":"t_HVTlvaxqoM","executionInfo":{"status":"ok","timestamp":1664423072889,"user_tz":180,"elapsed":4605,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7578a9d5-2e77-45fa-bad3-8ebdb2d83d11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processando 20 documentos originais\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/20 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e89ea7f0bd5a43a59c8576b5e294c8e1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO AGRUPAMENTO: 2020.\n"]}]},{"cell_type":"markdown","source":["Converte em um dataframe"],"metadata":{"id":"THHBPK6Ov8WV"}},{"cell_type":"code","source":["# Cria o dataframe da lista\n","lista_documentos_agrupados = pd.DataFrame(lista_documentos_agrupados, columns = [\"id\",\"sentencas\",\"documento\",\"classe\"])"],"metadata":{"id":"sWz4b8Fpv8ki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str, \"sentencas\": object, \"documento\": str, \"classe\": int}\n","\n","lista_documentos_agrupados = lista_documentos_agrupados.astype(tipos)"],"metadata":{"id":"AsbAU3pnAjYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lista_documentos_agrupados.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"LExAiKee0nhm","executionInfo":{"status":"ok","timestamp":1664423072890,"user_tz":180,"elapsed":40,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"e91c1809-8a8f-4069-a82b-4b22fc4cb560"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                          sentencas  \\\n","226    3_pert_23                 [How to add elements in a stack ?]   \n","1418   15_pert_3  [What is a stack and how to try and pop its el...   \n","10      1_pert_9            [How to identify elements in a queue ?]   \n","594    6_pert_88  [How to draw and pop elements in a stack data ...   \n","877    9_pert_68  [What is a stack and how to interpret its elem...   \n","1058  11_pert_47  [What is a queue and how to obtain an element ...   \n","698    7_pert_91             [How to bring elements from a stack ?]   \n","1312  13_pert_99  [What is a queue and how to discover an elemen...   \n","120    2_pert_18              [How to create elements in a queue ?]   \n","200    2_pert_98             [How to replace elements in a queue ?]   \n","\n","                                              documento  classe  \n","226                    How to add elements in a stack ?       0  \n","1418  What is a stack and how to try and pop its ele...       0  \n","10                How to identify elements in a queue ?       0  \n","594   How to draw and pop elements in a stack data s...       0  \n","877   What is a stack and how to interpret its eleme...       0  \n","1058  What is a queue and how to obtain an element i...       0  \n","698                How to bring elements from a stack ?       0  \n","1312  What is a queue and how to discover an element...       0  \n","120                 How to create elements in a queue ?       0  \n","200                How to replace elements in a queue ?       0  "],"text/html":["\n","  <div id=\"df-3e89c0c4-2400-42a8-b035-a59edfa812e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>226</th>\n","      <td>3_pert_23</td>\n","      <td>[How to add elements in a stack ?]</td>\n","      <td>How to add elements in a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1418</th>\n","      <td>15_pert_3</td>\n","      <td>[What is a stack and how to try and pop its el...</td>\n","      <td>What is a stack and how to try and pop its ele...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1_pert_9</td>\n","      <td>[How to identify elements in a queue ?]</td>\n","      <td>How to identify elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>594</th>\n","      <td>6_pert_88</td>\n","      <td>[How to draw and pop elements in a stack data ...</td>\n","      <td>How to draw and pop elements in a stack data s...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>877</th>\n","      <td>9_pert_68</td>\n","      <td>[What is a stack and how to interpret its elem...</td>\n","      <td>What is a stack and how to interpret its eleme...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1058</th>\n","      <td>11_pert_47</td>\n","      <td>[What is a queue and how to obtain an element ...</td>\n","      <td>What is a queue and how to obtain an element i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>698</th>\n","      <td>7_pert_91</td>\n","      <td>[How to bring elements from a stack ?]</td>\n","      <td>How to bring elements from a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1312</th>\n","      <td>13_pert_99</td>\n","      <td>[What is a queue and how to discover an elemen...</td>\n","      <td>What is a queue and how to discover an element...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>2_pert_18</td>\n","      <td>[How to create elements in a queue ?]</td>\n","      <td>How to create elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>2_pert_98</td>\n","      <td>[How to replace elements in a queue ?]</td>\n","      <td>How to replace elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e89c0c4-2400-42a8-b035-a59edfa812e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3e89c0c4-2400-42a8-b035-a59edfa812e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3e89c0c4-2400-42a8-b035-a59edfa812e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":302}]},{"cell_type":"code","source":["lista_documentos_agrupados.sample(10)"],"metadata":{"id":"P3qemxYGwHL7","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1664423072891,"user_tz":180,"elapsed":39,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4a4d54c0-b2fc-4793-aa0c-6315f3a35d72"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                          sentencas  \\\n","1851  19_pert_32  [In a stack does the pop operation follow at w...   \n","651    7_pert_44             [How to count elements from a stack ?]   \n","1816  18_pert_98  [How are the operations to enqueue and dequeue...   \n","1973  20_pert_53  [In a queue does the enqueue operation care at...   \n","1896  19_pert_77  [In a stack does the pop operation end at whic...   \n","221    3_pert_18              [How to create elements in a stack ?]   \n","35     1_pert_34                 [How to set elements in a queue ?]   \n","1402  14_pert_88  [What is a stack and how to assemble an elemen...   \n","38     1_pert_37                [How to link elements in a queue ?]   \n","1702  17_pert_85  [How are the operations to push and pop elemen...   \n","\n","                                              documento  classe  \n","1851  In a stack does the pop operation follow at wh...       0  \n","651                How to count elements from a stack ?       0  \n","1816  How are the operations to enqueue and dequeue ...       0  \n","1973  In a queue does the enqueue operation care at ...       0  \n","1896  In a stack does the pop operation end at which...       0  \n","221                 How to create elements in a stack ?       0  \n","35                     How to set elements in a queue ?       0  \n","1402  What is a stack and how to assemble an element...       0  \n","38                    How to link elements in a queue ?       0  \n","1702  How are the operations to push and pop element...       0  "],"text/html":["\n","  <div id=\"df-3fc1b96f-eff9-4150-a5c2-1775329ea576\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1851</th>\n","      <td>19_pert_32</td>\n","      <td>[In a stack does the pop operation follow at w...</td>\n","      <td>In a stack does the pop operation follow at wh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>651</th>\n","      <td>7_pert_44</td>\n","      <td>[How to count elements from a stack ?]</td>\n","      <td>How to count elements from a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1816</th>\n","      <td>18_pert_98</td>\n","      <td>[How are the operations to enqueue and dequeue...</td>\n","      <td>How are the operations to enqueue and dequeue ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1973</th>\n","      <td>20_pert_53</td>\n","      <td>[In a queue does the enqueue operation care at...</td>\n","      <td>In a queue does the enqueue operation care at ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1896</th>\n","      <td>19_pert_77</td>\n","      <td>[In a stack does the pop operation end at whic...</td>\n","      <td>In a stack does the pop operation end at which...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>221</th>\n","      <td>3_pert_18</td>\n","      <td>[How to create elements in a stack ?]</td>\n","      <td>How to create elements in a stack ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>1_pert_34</td>\n","      <td>[How to set elements in a queue ?]</td>\n","      <td>How to set elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1402</th>\n","      <td>14_pert_88</td>\n","      <td>[What is a stack and how to assemble an elemen...</td>\n","      <td>What is a stack and how to assemble an element...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>1_pert_37</td>\n","      <td>[How to link elements in a queue ?]</td>\n","      <td>How to link elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1702</th>\n","      <td>17_pert_85</td>\n","      <td>[How are the operations to push and pop elemen...</td>\n","      <td>How are the operations to push and pop element...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fc1b96f-eff9-4150-a5c2-1775329ea576')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3fc1b96f-eff9-4150-a5c2-1775329ea576 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3fc1b96f-eff9-4150-a5c2-1775329ea576');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":303}]},{"cell_type":"code","source":["# Importa das bibliotecas\n","import pandas as pd\n","\n","# Concatena as listas de documentos originais e perturbados\n","lista_documentos_agrupados_pos = pd.concat([lista_documentos_originais_pos, lista_documentos_perturbados_pos])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO POS: {}.\".format(len(lista_documentos_agrupados_pos)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TJbwpcYtsN3","executionInfo":{"status":"ok","timestamp":1664423072891,"user_tz":180,"elapsed":37,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"976dd811-3991-4269-c684-da7d8af5034c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO AGRUPAMENTO POS: 2020.\n"]}]},{"cell_type":"code","source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_agrupados_pos = lista_documentos_agrupados_pos.astype(tipos)"],"metadata":{"id":"JvDXTxtRuvrX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lista_documentos_agrupados_pos.sample(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"dDW4pj8vuh2I","executionInfo":{"status":"ok","timestamp":1664423072892,"user_tz":180,"elapsed":34,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"106c07a6-79a2-470d-e623-9ad61333e893"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                      pos_documento\n","812    9_pert_12  [[[What, is, a, stack, and, how, to, identify,...\n","1152  12_pert_52  [[[What, is, a, stack, and, how, to, modify, a...\n","701     8_pert_1  [[[How, to, organize, elements, in, a, stack, ...\n","1083  11_pert_83  [[[What, is, a, queue, and, how, to, drop, an,...\n","1769  18_pert_69  [[[How, are, the, operations, to, enqueue, and..."],"text/html":["\n","  <div id=\"df-1d84fd5d-3382-4a69-bcb0-f5b0fe9be5a5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>812</th>\n","      <td>9_pert_12</td>\n","      <td>[[[What, is, a, stack, and, how, to, identify,...</td>\n","    </tr>\n","    <tr>\n","      <th>1152</th>\n","      <td>12_pert_52</td>\n","      <td>[[[What, is, a, stack, and, how, to, modify, a...</td>\n","    </tr>\n","    <tr>\n","      <th>701</th>\n","      <td>8_pert_1</td>\n","      <td>[[[How, to, organize, elements, in, a, stack, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1083</th>\n","      <td>11_pert_83</td>\n","      <td>[[[What, is, a, queue, and, how, to, drop, an,...</td>\n","    </tr>\n","    <tr>\n","      <th>1769</th>\n","      <td>18_pert_69</td>\n","      <td>[[[How, are, the, operations, to, enqueue, and...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d84fd5d-3382-4a69-bcb0-f5b0fe9be5a5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1d84fd5d-3382-4a69-bcb0-f5b0fe9be5a5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1d84fd5d-3382-4a69-bcb0-f5b0fe9be5a5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":306}]},{"cell_type":"markdown","source":["#### Criar dados indexados"],"metadata":{"id":"viicg1E7mXLK"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_indexado = lista_documentos_agrupados.set_index([\"id\"])\n","lista_documentos_agrupados_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"0YBdkvoPm2vO","executionInfo":{"status":"ok","timestamp":1664423072892,"user_tz":180,"elapsed":33,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"ac3d70ec-a531-4987-f119-2998afef6bbb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        sentencas  \\\n","id                                                  \n","1           [How to enqueue elements in a queue?]   \n","1_pert_0     [How to place elements in a queue ?]   \n","1_pert_1   [How to arrange elements in a queue ?]   \n","1_pert_2  [How to organize elements in a queue ?]   \n","1_pert_3    [How to manage elements in a queue ?]   \n","\n","                                      documento  classe  \n","id                                                       \n","1           How to enqueue elements in a queue?       1  \n","1_pert_0     How to place elements in a queue ?       0  \n","1_pert_1   How to arrange elements in a queue ?       0  \n","1_pert_2  How to organize elements in a queue ?       0  \n","1_pert_3    How to manage elements in a queue ?       0  "],"text/html":["\n","  <div id=\"df-ae3422bf-c9ac-4976-9388-f65e910c5a60\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>[How to enqueue elements in a queue?]</td>\n","      <td>How to enqueue elements in a queue?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_0</th>\n","      <td>[How to place elements in a queue ?]</td>\n","      <td>How to place elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_1</th>\n","      <td>[How to arrange elements in a queue ?]</td>\n","      <td>How to arrange elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_2</th>\n","      <td>[How to organize elements in a queue ?]</td>\n","      <td>How to organize elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1_pert_3</th>\n","      <td>[How to manage elements in a queue ?]</td>\n","      <td>How to manage elements in a queue ?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae3422bf-c9ac-4976-9388-f65e910c5a60')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ae3422bf-c9ac-4976-9388-f65e910c5a60 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ae3422bf-c9ac-4976-9388-f65e910c5a60');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":307}]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_pos_indexado = lista_documentos_agrupados_pos.set_index([\"id\"])\n","lista_documentos_agrupados_pos_indexado.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"NQjlOJzOmbsp","executionInfo":{"status":"ok","timestamp":1664423072892,"user_tz":180,"elapsed":32,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7410e359-38a7-4d0d-aa82-88d6e8b84daf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        pos_documento\n","id                                                   \n","1   [[[How, to, enqueue, elements, in, a, queue, ?...\n","2   [[[How, to, dequeue, elements, in, a, queue, ?...\n","3   [[[How, to, push, elements, in, a, stack, ?], ...\n","4   [[[How, to, push, and, pop, elements, in, a, s...\n","5   [[[How, to, push, elements, in, a, stack, data..."],"text/html":["\n","  <div id=\"df-41da22b5-1374-4e51-9964-8867c4fa405f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>[[[How, to, enqueue, elements, in, a, queue, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[[[How, to, dequeue, elements, in, a, queue, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[[[How, to, push, elements, in, a, stack, ?], ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[[[How, to, push, and, pop, elements, in, a, s...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[[[How, to, push, elements, in, a, stack, data...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41da22b5-1374-4e51-9964-8867c4fa405f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-41da22b5-1374-4e51-9964-8867c4fa405f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-41da22b5-1374-4e51-9964-8867c4fa405f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":308}]},{"cell_type":"markdown","metadata":{"id":"d1yGaGzzyEiy"},"source":["## 5.2 Gerando as comparações\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xKaqQPs8VQ5u"},"source":["### 5.2.1 Medidas de similaridade\n"]},{"cell_type":"markdown","metadata":{"id":"jt06PTN5idrg"},"source":["Similaridade do cosseno entre os embeddings.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n","\n","A função spatial.distance.cosine do módulo scipy calcula a distância em vez da similaridade do cosseno, mas para conseguir isso, podemos subtrair o valor da distância de 1.\n","\n","Intervalo de [-1,1]\n","\n","Vetores iguais a distância é igual 1.\n","\n","Vetores diferentes medida próxima de -1."]},{"cell_type":"code","metadata":{"id":"6vbXj-brOlMF"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cosine\n","\n","def similaridadeCosseno(embeddings1, embeddings2):\n","    \"\"\"\n","      Similaridade do cosseno dos embeddings dos textos.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    similaridade = 1 - cosine(embeddings1, embeddings2)\n","\n","    return similaridade"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fazAuLMUr_c0"},"source":["### 5.2.2 Medidas de distância"]},{"cell_type":"markdown","metadata":{"id":"_IcrjAbhwake"},"source":["Distância euclidiana entre os embeddings.\n","\n","Possui outros nomes como distância L2 ou norma L2.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean"]},{"cell_type":"code","metadata":{"id":"mIrTId9jwakh"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import euclidean\n","\n","def distanciaEuclidiana(embeddings1, embeddings2):\n","    \"\"\"\n","      Distância euclidiana entre os embeddings dos textos.\n","      Possui outros nomes como distância L2 ou norma L2.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    distancia = euclidean(embeddings1, embeddings2)\n","\n","    return distancia"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-uJlqYCSXdVk"},"source":["Distância Manhattan entre os embeddings.\n","\n","Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cityblock.html#scipy.spatial.distance.cityblock"]},{"cell_type":"code","metadata":{"id":"jFG5UT_SXdVn"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cityblock\n","\n","def distanciaManhattan(embeddings1, embeddings2):\n","    \"\"\"\n","      Distância Manhattan entre os embeddings dos textos\n","      Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    distancia = cityblock(embeddings1, embeddings2)\n","\n","    return distancia"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6A6-Xwg8GJw"},"source":["### 5.2.3 Retorna todas as medidas dos embeddings"]},{"cell_type":"code","metadata":{"id":"qHzQ98zg8GWJ"},"source":["def getMedidasEmbedding(embedding_wi, embedding_wj):\n","\n","  \"\"\"\n","    Retorna as medidas de similaridade do cosseno(cos), distância Euclidiana(euc) e\n","    distância de Manhattan(man) entre os embeddings.\n","\n","    Parâmetros:\n","    `embeddings_wi` - Um embedding de uma palavra a ser medido.\n","    `embeddings_wj` - Um embedding de uma palavra a ser medido.\n","  \"\"\"\n","\n","  #print(\"embedding_wi=\", embedding_wi.shape)\n","  #print(\"embedding_wj=\", embedding_wj.shape)\n","\n","  # Similaridade do cosseno entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  cos = similaridadeCosseno(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  # Distância euclidiana entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  euc = distanciaEuclidiana(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  # Distância de manhattan entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  man = distanciaManhattan(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  del embedding_wi\n","  del embedding_wj\n","\n","  # Retorno das medidas das sentenças\n","  return cos, euc, man"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KEtmDaKqAL-9"},"source":["### 5.2.4 getTokensEmbeddingsPOSSentenca\n","Gera os tokens, POS e embeddings de cada sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXPWq5JyIoQf"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar mais tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera mais tokens que a tokenização das palavras do spaCy\n","dic_excecao_maior = {\"\":-1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89oBywgbIxzV"},"outputs":[],"source":["def getExcecaoDicMaior(id, token, dic_excecao_maior):\n","\n","  valor = dic_excecao_maior.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPODj-AWfhxW"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar menos tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera menos tokens que a tokenização das palavras do spaCy\n","dic_excecao_menor = {\"1°\":1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xy2bzLBWfeqi"},"outputs":[],"source":["def getExcecaoDicMenor(id, token, dic_excecao_menor):\n","\n","  valor = dic_excecao_menor.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"markdown","source":["Função que retorna os embeddings, tokens e POS da sentença com um mesmo tamamnho."],"metadata":{"id":"LLRdNsbo0qxA"}},{"cell_type":"code","metadata":{"id":"OykQrpVsILpM"},"source":["# Importa a biblioteca\n","import torch\n","\n","def getTokensEmbeddingsPOSSentenca(id_documento,\n","                                   index_sentenca,\n","                                   embedding_documento,\n","                                   token_BERT_documento,\n","                                   sentenca,\n","                                   tokenizer,\n","                                   sentenca_token = None,\n","                                   sentenca_postagging = None,\n","                                   estrategia_medida = 0):\n","    \"\"\"\n","      Retorna os tokens, as POS-Tagging e os embeddings dos tokens igualando a quantidade de tokens do spaCy com a tokenização do BERT de acordo com a estratégia de pooling para palavras fora do vocabulário do BERT.\n","      Usa a estratégia MEAN para calcular a média dos embeddings dos tokens que formam uma palavra fora do vocabulário do BERT.\n","      Usa a estratégia MAX para calcular o valor máximo dos embeddings dos tokens que formam uma palavra fora do vocabulário do BERT.\n","    \"\"\"\n","\n","    #Guarda os tokens e embeddings\n","    lista_tokens = []\n","    lista_embeddings_mean = []\n","    lista_embeddings_max = []\n","\n","    # Se a sentença não for tokenizada\n","    if sentenca_token == None:\n","      # Gera a tokenização e POS-Tagging da sentença\n","      sentenca_token, sentenca_postagging = getListaTokensPOSSentenca(sentenca)\n","\n","    #print(\"\\nsentenca                :\",sentenca)\n","    #print(\"id_documento                :\",id_documento)\n","    #print(\"index_sentenca              :\",index_sentenca)\n","    #print(\"sentenca_token              :\",sentenca_token)\n","    #print(\"len(sentenca_token)         :\",len(sentenca_token))\n","    #print(\"sentenca_postagging         :\",sentenca_postagging)\n","    #print(\"len(sentenca_postagging)    :\",len(sentenca_postagging))\n","\n","    # Recupera os embeddings da sentença dos embeddings dentro dos embeddings do documento\n","    embedding_sentenca, sentenca_tokenizada_BERT = getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                                                                       token_BERT_documento,\n","                                                                                                       sentenca,\n","                                                                                                       tokenizer)\n","\n","    # embedding <qtde_tokens x 4096>\n","    #print(\"embedding_sentenca          :\",embedding_sentenca.shape)\n","    #print(\"sentenca_tokenizada_BERT     :\",sentenca_tokenizada_BERT)\n","    #print(\"len(sentenca_tokenizada_BERT):\",len(sentenca_tokenizada_BERT))\n","\n","    # Seleciona os pares de palavra a serem avaliadas\n","    pos_wi = 0 # Posição do token da palavra gerado pelo spaCy\n","    pos_wj = pos_wi # Posição do token da palavra gerado pelo BERT\n","    pos2 = -1\n","\n","    # Enquanto o indíce da palavra pos_wj(2a palavra) não chegou ao final da quantidade de tokens do BERT\n","    while pos_wj < len(sentenca_tokenizada_BERT):\n","\n","      # Seleciona os tokens da sentença\n","      wi = sentenca_token[pos_wi] # Recupera o token da palavra gerado pelo spaCy\n","      wi1 = \"\"\n","      pos2 = -1\n","      if pos_wi+1 < len(sentenca_token):\n","        wi1 = sentenca_token[pos_wi+1] # Recupera o próximo token da palavra gerado pelo spaCy\n","\n","        # Localiza o deslocamento da exceção\n","        pos2 = getExcecaoDicMenor(id_documento, wi+wi1, dic_excecao_menor)\n","        #print(\"Exceção pos2:\", pos2)\n","\n","      wj = sentenca_tokenizada_BERT[pos_wj] # Recupera o token da palavra gerado pelo BERT\n","      #print(\"wi[\",pos_wi,\"]=\", wi)\n","      #print(\"wj[\",pos_wj,\"]=\", wj)\n","\n","      # Tratando exceções\n","      # Localiza o deslocamento da exceção\n","      pos = getExcecaoDicMaior(id_documento, wi, dic_excecao_maior)\n","      #print(\"Exceção pos:\", pos)\n","\n","      if pos != -1 or pos2 != -1:\n","        if pos != -1:\n","          #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","          lista_tokens.append(wi)\n","          # Verifica se tem mais de um token\n","          if pos != 1:\n","            indice_token = pos_wj + pos\n","            #print(\"Calcula a média de :\", pos_wj , \"até\", indice_token)\n","            embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","            #print(\"embeddings_tokens_palavra:\",embeddings_tokens_palavra.shape)\n","            # calcular a média dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_mean = torch.mean(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_mean:\",embedding_estrategia_mean.shape)\n","            lista_embeddings_mean.append(embedding_estrategia_mean)\n","\n","            # calcular o máximo dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_max, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_max:\",embedding_estrategia_max.shape)\n","            lista_embeddings_max.append(embedding_estrategia_max)\n","          else:\n","            # Adiciona o embedding do token a lista de embeddings\n","            lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","            lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + pos\n","          #print(\"Proxima:\")\n","          #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","          #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","        else:\n","          if pos2 != -1:\n","            #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","            lista_tokens.append(wi+wi1)\n","            # Verifica se tem mais de um token\n","            if pos2 == 1:\n","              # Adiciona o embedding do token a lista de embeddings\n","              lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","              lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","\n","            # Avança para a próxima palavra e token do BERT\n","            pos_wi = pos_wi + 2\n","            pos_wj = pos_wj + pos2\n","            #print(\"Proxima:\")\n","            #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","            #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","      else:\n","        # Tokens iguais adiciona a lista, o token não possui subtoken\n","        if (wi == wj or wj==\"[UNK]\"):\n","          # Adiciona o token a lista de tokens\n","          #print(\"Adiciona 2 wi==wj or wj==[UNK]:\", wi )\n","          lista_tokens.append(wi)\n","          # Adiciona o embedding do token a lista de embeddings\n","          lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","          lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","          #print(\"embedding1[pos_wj]:\", embedding_sentenca[pos_wj].shape)\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + 1\n","\n","        else:\n","          # A palavra foi tokenizada pelo Wordpice com ## ou diferente do spaCy ou desconhecida\n","          # Inicializa a palavra a ser montada\n","          palavra_postagging = wj\n","          indice_token = pos_wj + 1\n","          while  ((palavra_postagging != wi) and indice_token < len(sentenca_tokenizada_BERT)):\n","              if \"##\" in sentenca_tokenizada_BERT[indice_token]:\n","                # Remove os caracteres \"##\" do token\n","                parte = sentenca_tokenizada_BERT[indice_token][2:]\n","              else:\n","                parte = sentenca_tokenizada_BERT[indice_token]\n","\n","              palavra_postagging = palavra_postagging + parte\n","              #print(\"palavra_postagging:\",palavra_postagging)\n","              # Avança para o próximo token do BERT\n","              indice_token = indice_token + 1\n","\n","          #print(\"\\nMontei palavra:\",palavra_postagging)\n","          if (palavra_postagging == wi or palavra_postagging == \"[UNK]\"):\n","              # Adiciona o token a lista\n","              #print(\"Adiciona 3 palavra == wi or palavra_postagging = [UNK]:\",wi)\n","              lista_tokens.append(wi)\n","              # Calcula a média dos tokens da palavra\n","              #print(\"Calcula o máximo :\", pos_wj , \"até\", indice_token)\n","              embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra)\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra.shape)\n","\n","              # calcular a média dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_mean = torch.mean(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_mean:\",embedding_estrategia_mean)\n","              #print(\"embedding_estrategia_mean.shape:\",embedding_estrategia_mean.shape)\n","              lista_embeddings_mean.append(embedding_estrategia_mean)\n","\n","              # calcular o valor máximo dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_max, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_max:\",embedding_estrategia_max)\n","              #print(\"embedding_estrategia_max.shape:\",embedding_estrategia_max.shape)\n","              lista_embeddings_max.append(embedding_estrategia_max)\n","\n","          # Avança para o próximo token do spaCy\n","          pos_wi = pos_wi + 1\n","          # Pula para o próximo token do BERT\n","          pos_wj = indice_token\n","\n","    # Verificação se as listas estão com o mesmo tamanho\n","    #if (len(lista_tokens) != len(sentenca_token)) or (len(lista_embeddings_mean) != len(sentenca_token)):\n","    if (len(lista_tokens) !=  len(lista_embeddings_mean)):\n","       print(\"\\nsentenca                  :\",sentenca)\n","       print(\"id_documento              :\",id_documento)\n","       print(\"index_sentenca            :\",index_sentenca)\n","       print(\"sentenca_postagging       :\",sentenca_postagging)\n","       print(\"sentenca_token            :\",sentenca_token)\n","       print(\"sentenca_tokenizada_BERT  :\",sentenca_tokenizada_BERT)\n","       print(\"lista_tokens              :\",lista_tokens)\n","       print(\"len(lista_tokens)         :\",len(lista_tokens))\n","       print(\"lista_embeddings_mean     :\",lista_embeddings_mean)\n","       print(\"len(lista_embeddings_mean):\",len(lista_embeddings_mean))\n","       print(\"lista_embeddings_max      :\",lista_embeddings_max)\n","       print(\"len(lista_embeddings_max) :\",len(lista_embeddings_max))\n","\n","    del embedding_sentenca\n","    del token_BERT_documento\n","    del tokenizer\n","    del sentenca_tokenizada_BERT\n","    del sentenca_token\n","\n","    return lista_tokens, sentenca_postagging, lista_embeddings_mean, lista_embeddings_max"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kw0qQ6zoQhkq"},"source":["### 5.2.5 comparaPalavrasSentencaTodas"]},{"cell_type":"code","metadata":{"id":"Of3EOJwpQg-B"},"source":["def comparaPalavrasSentencaTodas(id_documento,\n","                                 index_documento,\n","                                 index_sentenca,\n","                                 embedding_documento,\n","                                 token_BERT_documento,\n","                                 sentenca,\n","                                 tokenizer,\n","                                 sentenca_token = None,\n","                                 sentenca_postagging = None):\n","\n","  lista_tokens, lista_postagging, lista_embeddings_mean, lista_embeddings_max = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                                  index_sentenca,\n","                                                                                                  embedding_documento,\n","                                                                                                  token_BERT_documento,\n","                                                                                                  sentenca,\n","                                                                                                  tokenizer,\n","                                                                                                  sentenca_token,\n","                                                                                                  sentenca_postagging)\n","  #print(\"\\nSentença   :\",lista_tokens)\n","  #print(\"POS Tagging:\",lista_postagging)\n","  #print(\"Quantidade de palavras:\",len(lista_tokens))\n","\n","  # Quantidade de palavras no documento\n","  n = len(lista_tokens)\n","\n","  # Guarda a comparação da sentença\n","  lista_comparacao = []\n","\n","  # Realiza o combinação das palavras C(n,p)=(n!/(p!(n-p)!))\n","  # n = Número de elementos e p as combinações\n","  # C(5,2) = 10\n","\n","  # Percorre as palavras da sentença\n","  for i in range(0,n-1):\n","\n","    # Seleciona a palavra i da sentença\n","    wi = lista_tokens[i]\n","    pos_i = lista_postagging[i]\n","    #print(\"i:\",i)\n","\n","    # Percorre as palavras da sentença a partir de i + 1\n","    # Para não comparar a palavra com ela mesma\n","    for j in range(i+1,n):\n","\n","        # Seleciona a palavra j da sentença\n","        wj = lista_tokens[j]\n","        pos_j = lista_postagging[j]\n","\n","        # Recupera as medidas dos embeddings das palavras usando as estratégias MEAN\n","        cos_mean, euc_mean, man_mean = getMedidasEmbedding(lista_embeddings_mean[i], lista_embeddings_mean[j])\n","        # Recupera as medidas dos embeddings das palavras usando as estratégias MAX\n","        cos_max, euc_max, man_max = getMedidasEmbedding(lista_embeddings_max[i], lista_embeddings_max[j])\n","\n","        # Agrupa as medidas\n","        comparacao = [id_documento,   #Id do documento\n","                      index_documento,#Índice do documento no conjunto de dados\n","                      index_sentenca, #[Indice da sentença no documento\n","                      i,              #Índice da palavra i na sentença\n","                      str(wi),        #Palavra i da sentença\n","                      pos_i,          #POS-Tagging da palavra i\n","                      j,              #Índice da palavra j na sentença\n","                      str(wj),        #Palavra j da sentença\n","                      pos_j,          #POS-Tagging da palavra j\n","                      cos_mean,       #Cos de wi e wj usando a média dos embeddings das subpalavras\n","                      euc_mean,       #Euc de wi e wj usando a média dos embeddings das subpalavras\n","                      man_mean,       #Man de wi e wj usando a média dos embeddings das subpalavras\n","                      cos_max,        #Cos de wi e wj usando o máximo dos embeddings das subpalavras\n","                      euc_max,        #Euc de wi e wj usando o máximo dos embeddings das subpalavras\n","                      man_max]        #Man de wi e wj usando o máximo dos embeddings das subpalavras\n","\n","        # Guardas as medidas da comparação na lista\n","        lista_comparacao.append(comparacao)\n","\n","        #print(comparacao)\n","        #print(\"Compara :\", i, \" com \", j)\n","        #print(\"Compara :\", wi, \" com \", wj)\n","        # print(\"     cos_mean:\", cos_mean)\n","        # print(\"     euc_mean:\", euc_mean)\n","        # print(\"     man_mean:\", man_mean)\n","        # print(\"     cos_max:\", cos_max)\n","        # print(\"     euc_max:\", euc_max)\n","        # print(\"     man_max:\", man_max)\n","\n","  del lista_tokens\n","  del lista_postagging\n","  del lista_embeddings_mean\n","  del lista_embeddings_max\n","\n","  return lista_comparacao"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXNhBApgbULb"},"source":["### 5.2.6 Realiza a comparação de todas as palavras"]},{"cell_type":"code","metadata":{"id":"CfGFsRaPDBMt","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["90ef60236b2642969620c91079f8f2e9","1f2be98dfc7440c68c067c3cbcb3571c","703cd1caf59245448c8fe0233e5c9b28","482c1b21c95b400a9b56c5e290f2e484","990b0c827d9e4d23a92b38f6ac8a8ae0","c6a1f8007d724ca38efcfbf440806965","2351de1bfc9f461c9ea2a9728c9ba384","0d04ec4b70b94dd1ac68de8f2b3c2c2f","36d72cd5145145a789902c68a419f1c1","8e485fe601db4aff84c1555bbc87cff5","7c030804f23c4a589c94e4224362738d"],"height":66},"executionInfo":{"status":"ok","timestamp":1664423815574,"user_tz":180,"elapsed":742707,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4d8122b1-41b2-4294-ff37-df353c8de2f9"},"source":["# Import das bibliotecas\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","logging.info(\"Processando {} documentos originais e perturbados.\".format(len(lista_documentos_agrupados)))\n","\n","# Guarda a comparacação das sentenças\n","resultado_comparacao = []\n","\n","# Conta sentenças comparadas e não comparadas\n","conta_sentenca = 0\n","\n","# Limpa o buffer antes de realizar a comparação\n","limpaBufferEmbedding()\n","\n","# Barra de progresso dos documentos\n","lista_documentos_bar = tqdm_notebook(lista_documentos_agrupados.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_agrupados))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_bar:\n","    # if i < 2:\n","    # print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    # print(\"id_documento:\",id_documento)\n","\n","    # Recupera as sentenças do documento\n","    lista_sentenca_documento = linha_documento[1]\n","    # print(\"lista_sentenca_documento:\",lista_sentenca_documento)\n","    # print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","\n","    # Recupera o documento\n","    documento = linha_documento[2]\n","    #print(\"documento:\",documento)\n","    # Recupera a classe documento (1-original 0-perturbado)\n","    #classe = linha_documento[3]\n","    #print(\"classe:\",classe)\n","\n","    # Localiza a POSTagging do documento agrupado\n","    lista_pos_documento = lista_documentos_agrupados_pos_indexado.loc[id_documento][0]\n","    # print(\"lista_pos_documento:\",lista_pos_documento)\n","    # print(\"len(lista_pos_documento):\",len(lista_pos_documento))\n","\n","    # Troca o documento por uma versão da concatenação das palavras geradas pelo spaCy\n","    # Percorre a lista_pos concatenando a posição 0 dos tokens\n","    documento_concatenado = \" \".join(concatenaListas(lista_pos_documento, pos=0))\n","    # print(\"documento_concatenado:\", documento_concatenado)\n","    documento = documento_concatenado\n","\n","    # Gera os embeddings do documento utiliza a concatenação das 4 últimas camadas\n","    # Somente para os documentos originais\n","    if \"_pert_\" not in id_documento:\n","      embedding_documento, token_BERT_documento = getEmbeddingsDocumentoBuffer(documento, model, tokenizer)\n","    else:\n","      embedding_documento, token_BERT_documento = getEmbeddingsDocumento(documento, model, tokenizer)\n","    # embedding <qtde_tokens x 4096>\n","    # print(\"embedding_documento:\",embedding_documento.shape)\n","    # print(\"token_BERT_documento:\",token_BERT_documento)\n","    # print(\"len(token_BERT_documento):\",len(token_BERT_documento))\n","\n","    # Percorre as sentenças do documento\n","    for j, sentenca in enumerate(lista_sentenca_documento):\n","      #print(\"id_documento:\",id_documento)\n","      #print(\"sentenca:\",sentenca)\n","\n","      sentenca_token = lista_pos_documento[j][0]\n","      sentenca_postagging = lista_pos_documento[j][1]\n","      #sentenca_verbos = lista_pos_documento[j][2]\n","\n","      #print(\"sentenca_token:\",sentenca_token)\n","      #print(\"len(sentenca_token):\",len(sentenca_token))\n","\n","      #print(\"sentenca_postagging:\",sentenca_postagging)\n","      #print(\"len(sentenca_postagging):\",len(sentenca_postagging))\n","\n","      #print(\"sentenca_verbos:\",sentenca_verbos)\n","      #print(\"len(sentenca_verbos):\",len(sentenca_verbos))\n","\n","      # Conta o número de sentenças com palavras comparadas\n","      conta_sentenca = conta_sentenca + 1\n","\n","      # Realiza uma contenação dos tokens da sentença\n","      sentenca_concatenada = \" \".join(sentenca_token)\n","      # print(\"sentenca_concatenada:\", sentenca_concatenada)\n","\n","      # Recupera as maiores e menores medidas entre as palavras\n","      lista_comparacao = comparaPalavrasSentencaTodas(id_documento,\n","                                                      i,\n","                                                      j,\n","                                                      embedding_documento,\n","                                                      token_BERT_documento,\n","                                                      sentenca_concatenada,\n","                                                      tokenizer,\n","                                                      sentenca_token,\n","                                                      sentenca_postagging)\n","      #print(len(lista_comparacao))\n","      #print(lista_comparacao)\n","\n","      # Guarda o resultado da comparação\n","      resultado_comparacao = resultado_comparacao + lista_comparacao"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Processando 2020 documentos originais e perturbados.\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/2020 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ef60236b2642969620c91079f8f2e9"}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"ugwTe8C3ebjy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423815575,"user_tz":180,"elapsed":25,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"792c839c-cce6-4141-d87c-7b933e57e8f9"},"source":["logging.info(\"Número de sentenças com palavras comparadas: {}.\".format(conta_sentenca))\n","logging.info(\"Número de comparações                      : {}.\".format(len(resultado_comparacao)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Número de sentenças com palavras comparadas: 2020.\n","INFO:root:Número de comparações                      : 121705.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rMg19DZzYjHB"},"source":["## 5.3 Gera arquivo das comparações"]},{"cell_type":"markdown","metadata":{"id":"waF8KYDlYEH2"},"source":["### 5.3.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","metadata":{"id":"kahGlJdWdP8f"},"source":["# Nome do arquivo\n","NOME_ARQUIVO_COMPARACAO_PALAVRA = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"midCJ2AYes2x"},"source":["### 5.3.2 Gera arquivo comparação"]},{"cell_type":"code","metadata":{"id":"vdHTuPLDYjHB"},"source":["# Cria o dataframe da lista\n","resultado_comparacao = pd.DataFrame(resultado_comparacao, columns = [\"id\",\n","                                                                       \"index_documento\",\n","                                                                       \"index_sentenca\",\n","                                                                       \"index_wi\",\n","                                                                       \"wi\",\n","                                                                       \"pos_i\",\n","                                                                       \"index_wj\",\n","                                                                       \"wj\",\n","                                                                       \"pos_j\",\n","                                                                       \"cos_mean\",\n","                                                                       \"euc_mean\",\n","                                                                       \"man_mean\",\n","                                                                       \"cos_max\",\n","                                                                       \"euc_max\",\n","                                                                       \"man_max\"])\n","\n","# Nome do arquivo original\n","nome_arquivo = DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_PALAVRA\n","\n","# Salva o arquivo original\n","resultado_comparacao.to_csv(nome_arquivo,  sep=\";\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9JSH-_lYjHB"},"source":["### 5.3.3 Carrega os dados\n","\n","Carrega os dados das sentencas a partir dos arquivos.\n"]},{"cell_type":"code","metadata":{"id":"9ob-mUkjYjHC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423817902,"user_tz":180,"elapsed":19,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"f4683175-98e4-43c2-9152-c5c3e3de9d54"},"source":["# Importa das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_comparacao_palavra = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_PALAVRA, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"Quantidade de comparações: {}.\".format(len(lista_comparacao_palavra)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Quantidade de comparações: 121705.\n"]}]},{"cell_type":"code","metadata":{"id":"vNCI53tPYjHC","colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"status":"ok","timestamp":1664423817903,"user_tz":180,"elapsed":7,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7b6f9e15-91b4-4f0d-a9ad-940b094f6210"},"source":["lista_comparacao_palavra.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                id  index_documento  index_sentenca  index_wi   wi  pos_i  \\\n","49734   11_pert_88             1099               0         8   an    DET   \n","4084     2_pert_43              145               0         4   in    ADP   \n","120328  20_pert_79             1999               0         0   In    ADP   \n","146       1_pert_4                5               0         0  How  SCONJ   \n","78830   15_pert_57             1472               0         8  and  CCONJ   \n","\n","        index_wj   wj  pos_j  cos_mean   euc_mean   man_mean   cos_max  \\\n","49734         10   in    ADP  0.494065  46.857166  2391.4468  0.494065   \n","4084           7    ?  PUNCT  0.449552  47.337517  2400.0340  0.449552   \n","120328        10  end   NOUN  0.420758  50.172058  2447.7769  0.420758   \n","146            7    ?  PUNCT  0.587739  41.028988  1996.9133  0.587739   \n","78830         12    ?  PUNCT -0.140048  54.101357  1931.9780 -0.140048   \n","\n","          euc_max    man_max  \n","49734   46.857166  2391.4468  \n","4084    47.337517  2400.0340  \n","120328  50.172058  2447.7769  \n","146     41.028988  1996.9133  \n","78830   54.101357  1931.9780  "],"text/html":["\n","  <div id=\"df-eb947cda-5c67-4123-85d8-7b522a6fb400\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>index_documento</th>\n","      <th>index_sentenca</th>\n","      <th>index_wi</th>\n","      <th>wi</th>\n","      <th>pos_i</th>\n","      <th>index_wj</th>\n","      <th>wj</th>\n","      <th>pos_j</th>\n","      <th>cos_mean</th>\n","      <th>euc_mean</th>\n","      <th>man_mean</th>\n","      <th>cos_max</th>\n","      <th>euc_max</th>\n","      <th>man_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49734</th>\n","      <td>11_pert_88</td>\n","      <td>1099</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>an</td>\n","      <td>DET</td>\n","      <td>10</td>\n","      <td>in</td>\n","      <td>ADP</td>\n","      <td>0.494065</td>\n","      <td>46.857166</td>\n","      <td>2391.4468</td>\n","      <td>0.494065</td>\n","      <td>46.857166</td>\n","      <td>2391.4468</td>\n","    </tr>\n","    <tr>\n","      <th>4084</th>\n","      <td>2_pert_43</td>\n","      <td>145</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>in</td>\n","      <td>ADP</td>\n","      <td>7</td>\n","      <td>?</td>\n","      <td>PUNCT</td>\n","      <td>0.449552</td>\n","      <td>47.337517</td>\n","      <td>2400.0340</td>\n","      <td>0.449552</td>\n","      <td>47.337517</td>\n","      <td>2400.0340</td>\n","    </tr>\n","    <tr>\n","      <th>120328</th>\n","      <td>20_pert_79</td>\n","      <td>1999</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>In</td>\n","      <td>ADP</td>\n","      <td>10</td>\n","      <td>end</td>\n","      <td>NOUN</td>\n","      <td>0.420758</td>\n","      <td>50.172058</td>\n","      <td>2447.7769</td>\n","      <td>0.420758</td>\n","      <td>50.172058</td>\n","      <td>2447.7769</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>1_pert_4</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>How</td>\n","      <td>SCONJ</td>\n","      <td>7</td>\n","      <td>?</td>\n","      <td>PUNCT</td>\n","      <td>0.587739</td>\n","      <td>41.028988</td>\n","      <td>1996.9133</td>\n","      <td>0.587739</td>\n","      <td>41.028988</td>\n","      <td>1996.9133</td>\n","    </tr>\n","    <tr>\n","      <th>78830</th>\n","      <td>15_pert_57</td>\n","      <td>1472</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>and</td>\n","      <td>CCONJ</td>\n","      <td>12</td>\n","      <td>?</td>\n","      <td>PUNCT</td>\n","      <td>-0.140048</td>\n","      <td>54.101357</td>\n","      <td>1931.9780</td>\n","      <td>-0.140048</td>\n","      <td>54.101357</td>\n","      <td>1931.9780</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb947cda-5c67-4123-85d8-7b522a6fb400')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-eb947cda-5c67-4123-85d8-7b522a6fb400 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-eb947cda-5c67-4123-85d8-7b522a6fb400');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":324}]},{"cell_type":"markdown","metadata":{"id":"DFMUo8Oo2CJp"},"source":["### 5.4.4 Compacta e copia o arquivo para uma pasta do GoogleDrive\n","\n","Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"7eb_zukpuHq3"},"source":["Compacta o arquivo.\n","\n","Usa o zip para compactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens"]},{"cell_type":"code","metadata":{"id":"NunMOJWR2O8H"},"source":["!zip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"49_9c2P2nrOx"},"source":["Copia o arquivo  para o GoogleDrive"]},{"cell_type":"code","metadata":{"id":"LqDBH5pUnrOx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423818590,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7f3617bd-c78a-489f-9f56-8294d9a90e65"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","    # Copia o arquivo das comparações para o google drive\n","    !cp \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" \"$DIRETORIO_DRIVE\"\n","\n","    logging.info(\"Terminei a cópia do arquivo.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia do arquivo.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Bcjt085lZGUr"},"source":["## 6.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","metadata":{"id":"H50_GKJwpDha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664423818590,"user_tz":180,"elapsed":21,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"a03a7e38-ba68-48e3-a5d3-aa3c20f631f5"},"source":["# Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempo_total_processamento))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento:  0:23:30 (h:mm:ss)\n"]}]}]}