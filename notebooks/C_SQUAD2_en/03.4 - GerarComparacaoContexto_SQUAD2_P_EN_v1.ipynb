{"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# Gerar comparação entre o contexto e as palavras das sentenças do SQUAD2 P(1,0%) EN\n","\n","Gera a comparação das palavras das sentenças com o contexto do documento do conjunto de dados SQUAD2 P(1,0%) pt-br utilizando os arquivos:\n","- `original.zip`\n","- `originalpos.zip`\n","- `perturbado_pX_kY.zip`\n","- `perturbadopos_pX_kY.zip`\n","\n","Nos nomes dos arquivos `perturbado_pX_kY.zip`,`perturbadopos_pX_kY.zip`, X é o número de documentos perturbados e Y o valor de top K predições.\n","\n","Cria o arquivo `comparacao_palavra1_pX_kY.zip` com as comparações entre as palavras do documento, onde X é o número de documentos perturbados e Y o valor de top K predições.\n","\n","O arquivo é unido no segundo notebook.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qit180yNeQYl"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"O5v8ai15eQYm"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dCk_jGZSeQYm"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"ObnklJwXeQYn"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj5TaAH_5-nB"},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================\n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.\n","    \"\"\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):\n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","\n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B1mvfAU5jZf"},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","\n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.\n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","\n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download\n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]\n","\n","    # Define o nome e caminho do arquivo temporário\n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","\n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","\n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:\n","        tamanho_conteudo = data.headers.get(\"Content-Length\")\n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)\n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):\n","            if chunk:\n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","\n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","\n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"tb9mqHFAeQYp"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O-fJQfmkeQYp"},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","\n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jirIzIstLea0"},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC9Xppq-_R0w"},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    sentencas = []\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkVk5LQT_G3f"},"outputs":[],"source":["def salvar(nome_arquivo,texto):\n","    \"\"\"\n","      Salva um texto em arquivo.\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.\n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"hbL-_hPVeQYs"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3-jjDBGeQYs"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","\n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))"]},{"cell_type":"markdown","metadata":{"id":"6_GuPXq8eQYs"},"source":["Classe(ModelArguments) de definição dos parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2KA6_v6eQYt"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )\n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )"]},{"cell_type":"markdown","metadata":{"id":"HIN413rj50EI"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxV4-3Yg50EI"},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"jppdXhjgeQYu"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8yGkbcCaeQYv"},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"rKENjjmoeQYv"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3-HZPWaeQYv"},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"yuHoA4Dx6K1M"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"0zhAltEP6K1M"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"IxAlgXv66K1M"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cmva6ltA6K1M"},"outputs":[],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"XrC2SG3x6K1M"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOnQUkWZ6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def getDeviceGPU():\n","    \"\"\"\n","    Retorna um dispositivo de GPU se disponível ou CPU.\n","\n","    Retorno:\n","    `device` - Um device de GPU ou CPU.\n","    \"\"\"\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","\n","        # Diz ao PyTorch para usar GPU.\n","        device = torch.device(\"cuda\")\n","\n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:\n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","\n","    return device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WcMhNxsE6K1N"},"outputs":[],"source":["device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"kkdlEouHftcJ"},"source":["Conecta o modelo ao device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-znVDGyfsVx"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def conectaGPU(model, device):\n","    \"\"\"\n","      Conecta um modelo BERT a GPU.\n","\n","      Parâmetros:\n","        `model` - Um modelo BERT carregado.\n","        `device` - Um device de GPU.\n","\n","      Retorno:\n","        `model` - Um objeto model BERT conectado a GPU.\n","    \"\"\"\n","    # Associa a GPU ao modelo.\n","    model.to(device)\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        # Diga ao pytorch para rodar este modelo na GPU.\n","        logging.info(\"Pytorch rodando o modelo na GPU.\")\n","        model.cuda()\n","\n","    else:\n","        logging.info(\"Pytorch rodando sem GPU.\")\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"CRdtvR_J6K1N"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSmGz55H6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"NTGkgZyieQY1"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50421,"status":"ok","timestamp":1660748255110,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"uHV2-UO0eQY1","outputId":"57610601-9140-442d-87ad-c3ea570df6ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Import das bibliotecas.\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"K6TZM-wxeQY2"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"4zVknYZUeQY2"},"source":["Instalação"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8220,"status":"ok","timestamp":1660748263239,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"qkYkNZn7eQY2","outputId":"d68ec2c3-9302-4697-d3a9-ed1b630889c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.1-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 4.1 MB/s \n","\u001b[?25hCollecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 52.1 MB/s \n","\u001b[?25hCollecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 65.0 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 58.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 59.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 57.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 47.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 56.5 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=f248b4996d0e4a6af50a114e51612ccfdd7bdc2a18d8b19be98ab2a0aba98065\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.1\n"]}],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"UOFYAzn4eQY3"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"elapsed":16495,"status":"ok","timestamp":1660748279725,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"xRXXJTvHeQY3","outputId":"792796d7-4f26-4684-8229-a6652bdf2c0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.0.2-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 40.7 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n","Successfully installed pip-22.2.2 setuptools-65.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13447,"status":"ok","timestamp":1660748293161,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"6hPxPU7HeQY4","outputId":"1234bcda-f1dc-45e3-b727-0fd5af79cd5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.6)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.4)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.0)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.7)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.0.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.6.15)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.9.1\n","    Uninstalling pydantic-1.9.1:\n","      Successfully uninstalled pydantic-1.9.1\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.0\n","    Uninstalling thinc-8.1.0:\n","      Successfully uninstalled thinc-8.1.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.1\n","    Uninstalling spacy-3.4.1:\n","      Successfully uninstalled spacy-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typing-extensions-3.10.0.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"markdown","metadata":{"id":"XrC6U1rBeQY4"},"source":["## 1.9 Instalação do BERT da Hugging Face"]},{"cell_type":"markdown","metadata":{"id":"lyMJYvxqeQY4"},"source":["Instala a interface pytorch para o BERT by Hugging Face."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10795,"status":"ok","timestamp":1660748303949,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"J3PgjX8-eQY5","outputId":"944fda30-35ea-41c7-d63f-983c7b48b19a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=4fa7b14178eab03346eeb16004bd7a0f2434249a8a68d9e4871f017210d66639\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -U transformers==4.5.1"]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uiH9pNpwI6g"},"outputs":[],"source":["# Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 20\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 20"]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"Mhkc9sW21zV7"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosMedida(\n","    max_seq_len = 512,\n","\n","    pretrained_model_name_or_path = \"bert-large-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-cased\"\n","    #pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","\n","    modelo_spacy = \"en_core_web_lg\",\n","    #modelo_spacy = \"en_core_web_md\",\n","    #modelo_spacy = \"en_core_web_sm\",\n","    #modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","\n","    versao_modelo_spacy = \"3.2.0\",\n","    sentenciar_documento = False,\n","    do_lower_case = False, # default True\n","    output_attentions = False, # default False\n","    output_hidden_states = True, # default False, se True retorna todas as camadas do modelo para as operações de soma e concatenação\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path.\n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100, 500 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",")"]},{"cell_type":"markdown","metadata":{"id":"WlF4PKP6Iopi"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55PNP2s6Iopi"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"SQUAD2_P_EN\""]},{"cell_type":"markdown","metadata":{"id":"Q7U67lmuaq2p"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nIYuQAxaq2s"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjWGu-9D5URZ"},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dq9PnXO77bPQ"},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","\n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivo_tar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")\n","    arquivo_tar.extractall(DIRETORIO_COHEBERT)\n","    arquivo_tar.close()\n","\n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):\n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePOccj0s8WMg"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","\n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp"]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbELnrpgA4T1","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2a36b0b79b844dbaa227bc30d5fc4397","8e6a2c9ea8514926a6969f839d1cfb63","b20b28b12a7d45e8b217e228ce32a3cb","9bf85a276836436c85ae6ccb32655e14","18bfdb309f9141adbc3861f290ff95a0","1d31a142057949ad94265fd1a44d5c1a","38fd6f4ac01642a5aa70303f9f01ff01","1f9b8f754cad4443a46fabf2fe348093","a5c3533be57c4b19878fe5b30103310a","4a80a6c520b04759ad8d03397bd57665","1f0ef954cc5f4e9eaf3bc4575cf9c71e"]},"executionInfo":{"status":"ok","timestamp":1660748445536,"user_tz":180,"elapsed":140371,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"643aae0c-21e8-4475-c00f-461f6ef67a4a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/777M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a36b0b79b844dbaa227bc30d5fc4397"}},"metadata":{}}],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","metadata":{"id":"AEzytjZi5Iw2"},"source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKg-_XyWoy8o"},"outputs":[],"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","\n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.\n","    \"\"\"\n","\n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords"]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1660748445537,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"s1o8jevtoy8p","outputId":"2df1b5f8-5230-455e-c2b6-68a242933f75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Quantidade de stopwords: 326\n","{'even', '‘d', 'forty', \"'m\", 'although', '‘ll', 'eight', 'up', 'really', 'cannot', 'down', 'an', 'three', 'at', 'these', 'some', 'somehow', 'name', 'in', 'doing', 'used', '‘re', 'otherwise', 'own', 'take', 'another', 'might', 'most', 'get', 'anything', 'someone', 'hereupon', 'that', 'below', 'anywhere', 'this', 'therefore', 'than', 'nobody', 'only', '‘ve', 'former', 'again', 'beforehand', 'via', 'formerly', 'whether', \"n't\", 'together', 'once', 'itself', \"'s\", 'anyone', 'nevertheless', 'six', 'never', 'therein', 'from', 'toward', 'which', 'her', 'about', 'eleven', 'fifteen', 'also', 'ten', 'whatever', 'but', 'due', 'hereafter', 'those', 'been', 'our', 'because', 'should', 'if', 'there', 'except', 'were', 'you', 'keep', 'per', 'other', 'least', 'would', 'nine', 'hence', 'was', 'became', 'onto', 'nowhere', 'back', 'wherever', 'last', 'more', 'or', 'made', 'make', 'their', 'i', 'am', 'no', 'always', 'become', 'still', 'whoever', 'top', '‘m', 'go', 'enough', 'each', 'behind', 'herein', 'rather', 'why', 'towards', 'yourself', 'thru', 'nor', 'yourselves', 'seemed', 'whither', 'part', 'using', 'can', 'until', 'around', 'elsewhere', 'whole', 'noone', 'seems', 'much', 'its', 'whereafter', 'here', 'whenever', 'on', 'though', 'however', 'then', 'anyway', 'something', 'among', 'when', 'off', 're', 'during', 'serious', 'ours', 'two', 'less', 'n’t', 'into', 'between', 'latter', 'could', 'across', 'him', 'hundred', 'will', 'myself', 'seeming', 'within', 'see', 'over', '’ve', 'thence', 'through', 'quite', 'twelve', 'say', 'bottom', 'what', 'everything', 'fifty', 'becomes', 'whereupon', 'after', 'beyond', 'latterly', 'seem', 'others', 'third', 'very', 'both', 'one', 'by', \"'ve\", 'becoming', 'moreover', 'put', 'neither', 'twenty', 'five', 'it', \"'ll\", 'whereby', 'ca', 'full', 'must', 'such', 'empty', 'your', 'while', 'be', '’s', 'almost', 'me', 'further', 'without', 'everyone', 'everywhere', 'we', 'out', 'often', 'against', 'n‘t', 'do', 'us', 'herself', 'along', 'above', 'too', 'nothing', 'had', 'many', 'yet', \"'d\", 'and', 'sometimes', 'well', 'meanwhile', 'various', 'sixty', 'yours', 'did', 'his', 'with', 'amount', 'afterwards', 'ever', 'any', 'has', 'whereas', 'indeed', 'besides', 'next', 'hereby', 'as', 'who', 'somewhere', 'is', 'alone', 'how', 'hers', 'where', '’m', 'regarding', 'may', 'either', 'front', 'so', '’ll', 'thereupon', 'please', 'same', 'ourselves', 'none', 'the', 'before', 'anyhow', 'of', 'he', 'them', 'just', 'my', 'already', 'whence', 'thus', 'give', 'whose', 'few', 'thereafter', 'a', 'she', 'does', \"'re\", 'side', 'under', 'done', 'being', 'himself', 'mostly', 'beside', 'every', 'several', 'are', 'they', 'have', 'else', '‘s', 'amongst', 'thereby', 'call', 'not', 'unless', 'for', 'four', '’re', 'mine', 'sometime', 'upon', 'perhaps', 'wherein', 'now', 'since', 'to', 'show', 'throughout', 'themselves', 'whom', 'all', 'namely', 'first', '’d', 'move'}\n"]}],"source":["print(\"Quantidade de stopwords:\", len(getStopwords(nlp)))\n","\n","print(getStopwords(nlp))"]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hdqVdfxm-_W"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy\n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ]\n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal\n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ]\n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},\n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar\n","               ]\n","\n","matcherv = Matcher(nlp.vocab)\n","\n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):\n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","\n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","\n","  return lista2"]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novo_dic = dict()\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novo_dic[classe_gramatical] = qtde\n","\n","  return novo_dic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novo_dic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novo_dic[classe_gramatical] = qtde\n","\n","  return novo_dic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9SA61kD6sJY"},"outputs":[],"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","\n","  # Soma os dicionários da lista\n","  novo_dic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n","\n","  return novo_dic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWxyAo54AOHU"},"outputs":[],"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.text)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gvd99wd_pwmt"},"outputs":[],"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista_tokens = []\n","  lista_pos = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:\n","    lista_tokens.append(token.text)\n","    lista_pos.append(token.pos_)\n","\n","  return lista_tokens, lista_pos"]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpCUpOs06sJY"},"outputs":[],"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","\n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\"\n","  return traduzido"]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMb0uDWzKZXP"},"outputs":[],"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxTCYFzcJZD6"},"outputs":[],"source":["def getSentencaSalientePOS(sentenca, pos, tipoSaliente=\"NOUN\"):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especeficado\n","    if pos[i] == tipoSaliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"_xaeX0oTVQ5t"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIaQ9bzBVQ5t"},"outputs":[],"source":["def removeStopWord(documento, stopwords):\n","\n","  # Remoção das stopwords do documento\n","  documento_sem_stopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documento_sem_stopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"]},{"cell_type":"markdown","metadata":{"id":"A7NAe8ogCf1y"},"source":["### retornaRelevante\n","\n","Retorna somente os palavras do documento ou sentença do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNNfykypChn-"},"outputs":[],"source":["def retornaRelevante(documento, classe_relevante=\"NOUN\"):\n","\n","  # Corrigir!\n","  # Utilizar o documento já tokenizado pelo spacy!!!!\n","  # Existe uma lista com o documento e a sentença tokenizada pelo spacy\n","\n","  # Realiza o parsing no spacy\n","  doc = nlp(documento)\n","\n","  # Retorna a lista das palavras relevantes\n","  documento_com_substantivos = []\n","  for token in doc:\n","    #print(\"token:\", token.pos_)\n","    if token.pos_ == classe_relevante:\n","      documento_com_substantivos.append(token.text)\n","\n","  # Concatena o documento com os substantivos\n","  documento_concatenado = \" \".join(documento_com_substantivos)\n","\n","  # Retorna o documento\n","  return documento_concatenado"]},{"cell_type":"markdown","metadata":{"id":"IBY7q_uH8JSE"},"source":["# 4 BERT"]},{"cell_type":"markdown","metadata":{"id":"MBGTMy8Ic7GK"},"source":["## 4.1 Modelo Pré-treinado BERT"]},{"cell_type":"markdown","metadata":{"id":"uiuxdXe9t1BX"},"source":["### Funções Auxiliares"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Huw0x5kt1Le"},"outputs":[],"source":["def getNomeModeloBERT(model_args):\n","    '''\n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","\n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"\n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","        else:\n","            if 'bert' in model_args.pretrained_model_name_or_path:\n","                MODELO_BERT = \"_BERT\"\n","\n","    return MODELO_BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYJB4ik7t5xe"},"outputs":[],"source":["def getTamanhoBERT(model_args):\n","    '''\n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","\n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","\n","    return TAMANHO_BERT"]},{"cell_type":"markdown","metadata":{"id":"rHt4e5pAcEMd"},"source":["### Função download Modelo Pre-treinado BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peDUrV2ccEXA"},"outputs":[],"source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","\n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","\n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo!\")\n","            # Apaga o diretório e os arquivos existentes\n","            shutil.rmtree(DIRETORIO_MODELO)\n","\n","        # Realiza o download do arquivo do modelo\n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.\n","        arquivo_zip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivo_zip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.\n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","\n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta!\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada!\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"V74WUpHqcfoI"},"source":["### Copia o modelo do BERT ajustado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQMpf9yycf8f"},"outputs":[],"source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\"\n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    logging.info(\"Modelo BERT ajustado copiado!\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"]},{"cell_type":"markdown","metadata":{"id":"eaneOhAKcO-3"},"source":["### Verifica de onde utilizar o modelo do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTy1TXz3cPKS"},"outputs":[],"source":["def verificaModelo(model_args):\n","    \"\"\"\n","    Verifica de onde utilizar o modelo.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    DIRETORIO_MODELO = None\n","\n","    if model_args.usar_mcl_ajustado == True:\n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","\n","        logging.info(\"Usando modelo BERT ajustado.\")\n","\n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"6tKcaIfReqdy"},"source":["## 4.2 Tokenizador BERT"]},{"cell_type":"markdown","metadata":{"id":"e8n7Z5s-QZF8"},"source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf).\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzAuptkwQZR3"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","\n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"]},{"cell_type":"markdown","metadata":{"id":"GYRV9KfHQE6v"},"source":["## 4.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"markdown","metadata":{"id":"-pZZrUKRhR3e"},"source":["### Função carrega modelo BERT medida\n","\n","A implementação do huggingface pytorch inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PNL. Embora essas interfaces sejam todas construídas sobre um modelo treinado de BERT, cada uma possui diferentes camadas superiores e tipos de saída projetados para acomodar suas tarefas específicas de PNL.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JUEyjCChUQh"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertModel # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:\n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertModel.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertModel.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"-uFDhRTZe2Js"},"source":["### Função carrega o BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVtAUbUBe2iS"},"outputs":[],"source":["def carregaBERT(model_args):\n","    \"\"\"\n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","        `tokenizer` - Um objeto tokenizador BERT carregado.\n","    \"\"\"\n","\n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","\n","    # Variável para conter o modelo\n","    model = None\n","\n","    # Carrega o modelo para cálculo da medida\n","    model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","\n","    # Carrega o tokenizador.\n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","\n","    return model, tokenizer"]},{"cell_type":"markdown","metadata":{"id":"x5NTxBRKfAcT"},"source":["### Carrega o BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYMLJJYSQHY3","colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["6e1d94ad09f245e3b780a35266dd242e","93b22eaae1b441558f04c97bef5bd448","cb661d27585c405ea5781ec862c6ba7d","2c8cf1a3a9cb4b999a034edd14435793","0e46ad3b1d9d4892a86fd0a8c2e22b21","5a6db49d3a3d4ba19283cf10b0498a63","93ccada0e4364ecab907cd6cc8a6c921","beac9bc26a76483cbdbe1d7679787af1","83c5c9c32c2543e295a22ee89f7d1f9b","c006ae7b43ef469a947a6d6ab3be2e5a","4514d7f4f75d4318bb88548bc1637769","4f644915a68d4399bc7eb66ac7d573af","8a9e4b55cfad46058c8fd8d749b39284","c1f07abbc1794a6d974a39c29633aba2","eb5f8e5d527a4d718c99215833c732a4","cd5cf1797b944243af63468bafcff9fe","3b5cc195c1cc4be4af9ea44d135c3d09","fd0a84d3743e45999706131023f50f70","83320fdc59774a48b977f4dc8a9ee842","fa594b46702045f7990f4c012f2f1c12","91fe1e8cd2774d4cbb9b83dfd29c9ebe","75c66700c0a54a699a7ee51b74055cba","be34fae4846c44e4a26bea269b869142","3e470fb5bcc048af93df89a1608f3aad","8810a46f27424a7599cb4330fbec2961","6f32e9eaba4c4d928bd9111a3e4c018c","2e8b70f34b8b499f82eeac694da53a35","bd6f756c0cff42d5826931726e33b58b","4b21454ab17347939066816a3f7e203c","08c1a31da62d4c41b1dd09fb1cce9dbe","d506bb68ac2b40fba26accaaa43dd722","5523936bd34b4a288f9d91180b4a0911","77604daa81154489a8539afbef630322","9cfbe400a7de48ddb867148991ca3c67","c3e6ffcbdb034dd0b57adc24333889b4","2ec7e59177174f5682a1727acf5ff900","86990a969b574fd6b1ff49f95fb0c458","5c6f61c0131e40029d202e5c824163a4","8107c820d64e477cbed413e255e88f94","c77d58c2fe0b4944bbdd9f6b5081dc06","da7c81835e4b47a3b2148ad9350acc1a","0896f3299b454588b3052efd5609f561","ba296be0c5c34534818910aa8a7a205f","ffb3b76f790c48b4a366689d5dd5fb0b","0eacfb3d8d2545b48c460616f889ff20","9a56f361817a4bff9c61f8521d23a58f","ae1bd06de5b848f59c4811c4968ebb69","49c23e6e84af43fd92d888741343ce36","cf39055d20584aae8f0bb9ebd37c33c4","62b35a0b042445d7ac40587960724981","fef89090c1e948628e5638a92b5e3536","eb0aefce27b2405baf17a59b6037548d","c59b60c6ee264ce498a15f4ca4c7b37b","8726dd29f04f4cd2b3454baa744359a4","767fa111ce6d4c89b0b0366266b3f791"]},"executionInfo":{"status":"ok","timestamp":1660748564125,"user_tz":180,"elapsed":118608,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"902b2604-2f15-4e1e-bc9e-d0f628fa600a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1d94ad09f245e3b780a35266dd242e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f644915a68d4399bc7eb66ac7d573af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be34fae4846c44e4a26bea269b869142"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cfbe400a7de48ddb867148991ca3c67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0eacfb3d8d2545b48c460616f889ff20"}},"metadata":{}}],"source":["# Carrega o modelo e tokenizador do BERT\n","model, tokenizer = carregaBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"d7KprWqyZBQZ"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6sPjTQnuQV2"},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"khTFfBVbnsx9"},"source":["## 4.4 Funções auxiliares do BERT"]},{"cell_type":"markdown","metadata":{"id":"lCJzsw8T0I-5"},"source":["### concatenaListas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpmDZ1mI0JHR"},"outputs":[],"source":["def concatenaListas(lista, pos=1):\n","  lista_concat = []\n","\n","  for x in lista:\n","      lista_concat = lista_concat + x[pos]\n","\n","  return lista_concat"]},{"cell_type":"markdown","metadata":{"id":"s42mgtmSZ8MR"},"source":["### getEmbeddingsCamadas\n","\n","Funções que recuperam os embeddings das camadas:\n","- Primeira camada;\n","- Penúltima camada;\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgo3EBTRZ9-3"},"outputs":[],"source":["def getEmbeddingPrimeiraCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][0]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingPenultimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-2]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingUltimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-1]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingSoma4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][-4:]\n","  # Saída: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado\n","\n","def getEmbeddingConcat4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Cria uma lista com os tensores a serem concatenados\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Lista com os tensores a serem concatenados\n","  lista_concat = []\n","\n","  # Percorre os 4 últimos\n","  for i in [-1,-2,-3,-4]:\n","      # Concatena da lista\n","      lista_concat.append(output[2][i])\n","\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Realiza a concatenação dos embeddings de todos as camadas\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  resultado = torch.cat(lista_concat, dim=-1)\n","\n","  # Saída: Entrada: (<1(lote)> x <qtde_tokens> x <3072 ou 4096>)\n","  return resultado\n","\n","def getEmbeddingSomaTodasAsCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas as camadas descontando a primeira(0)\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][1:]\n","  # Saída: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado"]},{"cell_type":"markdown","metadata":{"id":"q7nx_eZ8hSlr"},"source":["### getEmbeddingsVisual\n","\n","Função para gerar as coordenadas de plotagem a partir das sentenças de embeddings.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLdbOT8-g43V"},"outputs":[],"source":["def getEmbeddingsVisualUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAf9lJJ2hZbt"},"outputs":[],"source":["def getEmbeddingsVisualSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4XpwSN1ghpnz"},"outputs":[],"source":["def getEmbeddingsVisualConcat4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3KU1EFrnSPK"},"outputs":[],"source":["def getEmbeddingsVisualSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"Y8MjE0utzlZT"},"source":["### getEmbeddings\n","\n","Função para gerar os embeddings de sentenças.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QcqOuwS067Q"},"outputs":[],"source":["def getEmbeddingsUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BK1wDGBl067Y"},"outputs":[],"source":["def getEmbeddingsSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hym19Hxr067Y"},"outputs":[],"source":["def getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer):\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-PLZiUR067Z"},"outputs":[],"source":["def getEmbeddingsSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"Pyra3_pECsoJ"},"source":["### getEmbeddingsDocumento\n","\n","Recupera os embeddings e tokens do documento sem buffer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdDBSRDcCxHp"},"outputs":[],"source":["def getEmbeddingsDocumento(documento, modelo, tokenizer):\n","\n","    return getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"-rLcMuDHC-F5"},"source":["### getEmbeddingsDocumentoBuffer\n","\n","Recupera os embeddings e tokens do documento com buffer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OogUm0kuC7wK"},"outputs":[],"source":["buffer_token_embeddings = {}\n","\n","def getEmbeddingsDocumentoBuffer(documento, modelo, tokenizer):\n","\n","    # Se documento está no dicionário retorna o embedding e os tokens\n","    if documento in buffer_token_embeddings:\n","        registro_buffer = buffer_token_embeddings.get(documento)\n","        return registro_buffer[0], registro_buffer[1]\n","    else:\n","        # Gera o embedding\n","        token_embeddings, documento_tokenizado = getEmbeddingsDocumento(documento, modelo, tokenizer)\n","        buffer_token_embeddings.update({documento: [token_embeddings, documento_tokenizado]})\n","\n","        return  token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTRcghhuet76"},"outputs":[],"source":["def limpaBufferEmbedding():\n","    buffer_token_embeddings.clear()"]},{"cell_type":"markdown","metadata":{"id":"zFd1rse11DpZ"},"source":["### getDocumentoTokenizado\n","\n","Retorna o documento tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvWIBFTLJ7z9"},"outputs":[],"source":["def getDocumentoTokenizado(documento, tokenizer):\n","    \"\"\"\n","      Retorna o documento tokenizado pelo BERT.\n","\n","      Parâmetros:\n","      `documento` - Documento a ser tokenizado.\n","      `tokenizer` - Tokenizador do BERT.\n","    \"\"\"\n","\n","    # Adiciona os tokens especiais.\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Documento tokenizado\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    del tokenizer\n","\n","    return documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"3wvgXwN81RCz"},"source":["### encontrarIndiceSubLista\n","\n","Retorna os índices de início e fim da sublista na lista"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abS44M4yvFxf"},"outputs":[],"source":["# Localiza os índices de início e fim de uma sublista em uma lista\n","def encontrarIndiceSubLista(lista, sublista):\n","\n","    \"\"\"\n","      Localiza os índices de início e fim de uma sublista em uma lista.\n","\n","      Parâmetros:\n","      `lista` - Uma lista.\n","      `sublista` - Uma sublista a ser localizada na lista.\n","    \"\"\"\n","    # https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n","\n","    # Recupera o tamanho da lista\n","    h = len(lista)\n","    # Recupera o tamanho da sublista\n","    n = len(sublista)\n","    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n","    i = n - 1\n","    while i < h:\n","      for j in range(n):\n","        if lista[i - j] != sublista[-j - 1]:\n","            i += skip.get(lista[i], n)\n","            break\n","        else:\n","            indice_inicio = i - n + 1\n","            indice_fim = indice_inicio + len(sublista)-1\n","\n","            return indice_inicio, indice_fim\n","\n","    # Não encontrou a sublista na lista\n","    return -1, -1"]},{"cell_type":"markdown","metadata":{"id":"xTSJPncXxdMt"},"source":["### getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras\n","\n","A partir dos embeddings do documento, localiza o indíce de início e fim de uma sentença no documento e retorna os embeddings da sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TBGJhjhxdMt"},"outputs":[],"source":["def getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                           token_BERT_documento,\n","                                                           sentenca,\n","                                                           tokenizer):\n","\n","  # Tokeniza a sentença\n","  sentenca_tokenizada_BERT = getDocumentoTokenizado(sentenca, tokenizer)\n","  #print(sentenca_tokenizada_BERT)\n","\n","  # Remove os tokens de início e fim da sentença\n","  sentenca_tokenizada_BERT.remove(\"[CLS]\")\n","  sentenca_tokenizada_BERT.remove(\"[SEP]\")\n","  #print(len(sentenca_tokenizada_BERT))\n","\n","  # Localiza os índices dos tokens da sentença no documento\n","  inicio, fim = encontrarIndiceSubLista(token_BERT_documento, sentenca_tokenizada_BERT)\n","  #print(inicio,fim)\n","\n","  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do documento\n","  embedding_sentenca = embedding_documento[inicio:fim+1]\n","  #print(\"embedding_sentenca=\", embedding_sentenca.shape)\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del sentenca\n","  del tokenizer\n","\n","  # Retorna o embedding da sentença no documento\n","  return embedding_sentenca, sentenca_tokenizada_BERT"]},{"cell_type":"markdown","metadata":{"id":"SCIGKFv-xdMu"},"source":["### getEmbeddingDocumentoComTodasPalavrasMean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kolTZ9ZHxdMu"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento excluindo os tokens\n","    especiais [CLS] do início e [SEP] do fim.\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embedding do documento.\n","  \"\"\"\n","\n","  # Calcula a média dos embeddings para os tokens de embedding_documento, removendo a primeira dimensão.\n","  # Entrada: <qtde_tokens> x <768 ou 1024>\n","  #print(\"embedding_documento1=\", embedding_documento.shape)\n","  media_embedding_documento = torch.mean(embedding_documento[1:-1], dim=0)\n","  # Saída: <768 ou 1024>\n","\n","  del embedding_documento\n","\n","  return media_embedding_documento"]},{"cell_type":"markdown","metadata":{"id":"i7C6tZjpkuQz"},"source":["### getEmbeddingDocumentoSemStopWordMean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sT1NB5zDkub1"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoSemStopWordMean(id_documento,\n","                                         index_sentenca,\n","                                         embedding_documento,\n","                                         token_BERT_documento,\n","                                         documento,\n","                                         tokenizer,\n","                                         token_documento,\n","                                         postagging_documento):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento considerando tokens do tipo\n","    especificado no filtro\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `postagging_documento` - Lista com as POS-Tagging do documento.\n","  \"\"\"\n","\n","  # Recupera a lista de tokens do documento, a lista dos postagging e a lista dos seus embeddings com um mesmo tamanho\n","  lista_tokens, lista_postagging, lista_embeddings_mean, lista_embeddings_max = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                                               index_sentenca,\n","                                                                                                               embedding_documento,\n","                                                                                                               token_BERT_documento,\n","                                                                                                               documento,\n","                                                                                                               tokenizer,\n","                                                                                                               token_documento,\n","                                                                                                               postagging_documento)\n","\n","  #print(\"len(token_BERT_documento):\", len(token_BERT_documento))\n","  #print(\"token_BERT_documento:\", token_BERT_documento)\n","  #print(\"len(postagging_documento):\", len(postagging_documento))\n","  #print(\"postagging_documento:\", postagging_documento)\n","  #print(\"filtro:\", filtro)\n","  #print()\n","  # Lista com os tensores selecionados\n","  lista_tokens_selecionados_mean = []\n","\n","  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word no documento\n","  for i, token_documento in enumerate(lista_tokens):\n","      if lista_tokens[i].lower() not in getStopwords(nlp):\n","          #print(\"Adicionando palavra do embedding:\", lista_tokens[i])\n","          lista_tokens_selecionados_mean.append(lista_embeddings_mean[i])\n","\n","  if  len(lista_tokens_selecionados_mean) != 0:\n","      # Empilha os embeddings da lista pela dimensão 0\n","      embedding_sem_stopword = torch.stack(lista_tokens_selecionados_mean, dim=0)\n","      #print(\"embedding_sem_stopword.shape:\",embedding_sem_stopword.shape)\n","\n","      # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n","      # Entrada: <qtde_tokens> x <768 ou 1024>\n","      media_embedding_sem_stopword = torch.mean(embedding_sem_stopword, dim=0)\n","      # Saída: <768 ou 1024>\n","      #print(\"media_embedding_sem_stopword.shape:\", media_embedding_sem_stopword.shape)\n","  else:\n","      media_embedding_sem_stopword = None\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del documento\n","  del tokenizer\n","  del token_documento\n","  del postagging_documento\n","\n","  return media_embedding_sem_stopword"]},{"cell_type":"markdown","metadata":{"id":"1Ko_of60YuNd"},"source":["### getEmbeddingDocumentoRelevanteMean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDokSSODY0Sf"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                       index_sentenca,\n","                                       embedding_documento,\n","                                       token_BERT_documento,\n","                                       documento,\n","                                       tokenizer,\n","                                       token_documento,\n","                                       postagging_documento,\n","                                       filtro):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento considerando tokens do tipo\n","    especificado no filtro\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `postagging_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","\n","  \"\"\"\n","\n","  # Recupera a lista de tokens do documento, a lista dos postagging e a lista dos seus embeddings com um mesmo tamanho\n","  lista_tokens, lista_postagging, lista_embeddings_mean, lista_embeddings_max = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                                               index_sentenca,\n","                                                                                                               embedding_documento,\n","                                                                                                               token_BERT_documento,\n","                                                                                                               documento,\n","                                                                                                               tokenizer,\n","                                                                                                               token_documento,\n","                                                                                                               postagging_documento)\n","\n","  #print(\"len(token_BERT_documento):\", len(token_BERT_documento))\n","  #print(\"token_BERT_documento:\", token_BERT_documento)\n","  #print(\"len(postagging_documento):\", len(postagging_documento))\n","  #print(\"postagging_documento:\", postagging_documento)\n","  #print(\"filtro:\", filtro)\n","  #print()\n","\n","  # Lista com os tensores selecionados\n","  lista_tokens_selecionados = []\n","  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word no documento\n","  for i, token_documento in enumerate(lista_tokens):\n","    if (lista_postagging[i] in filtro):\n","      #print(\"Adicionando palavra do embedding:\", lista_tokens[i])\n","      lista_tokens_selecionados.append(lista_embeddings_mean[i])\n","\n","  if len(lista_tokens_selecionados) != 0:\n","      # Empila os embeddings da lista pela dimensão 0\n","      embedding_relevante = torch.stack(lista_tokens_selecionados, dim=0)\n","      #print(\"embedding_relevante.shape:\",embedding_relevante.shape)\n","\n","      # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n","      # Entrada: <qtde_tokens> x <768 ou 1024>\n","      media_embedding_relevante = torch.mean(embedding_relevante, dim=0)\n","      # Saída: <768 ou 1024>\n","      #print(\"media_embedding_relevante.shape:\", media_embedding_relevante.shape)\n","  else:\n","      media_embedding_relevante = None\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del documento\n","  del tokenizer\n","  del token_documento\n","  del postagging_documento\n","\n","  return media_embedding_relevante"]},{"cell_type":"markdown","metadata":{"id":"L_vknrk7YSpF"},"source":["### getEmbeddingDocumentoMean\n","\n","Filtros:\n","- ALL - Sentença com todas as palavras\n","- CLEAN - Sentença com todas as palavras menos as stopwords\n","- VERB,AUX - Sentença somente com verbos(VERB e AUX)\n","- NOUN - Sentença somente com substantivos\n","- VERB,NOUN,AUX - Sentença somente com verbos(VERB e AUX) e substantivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pd8B76YyYS02"},"outputs":[],"source":["def getEmbeddingDocumentoMean(id_documento,\n","                              index_sentenca,\n","                              embedding_documento,\n","                              token_BERT_documento,\n","                              documento,\n","                              tokenizer,\n","                              token_documento,\n","                              postagging_documento,\n","                              filtro=[\"ALL\"]):\n","  \"\"\"\n","    Rediciona o cálculo da média dos embeddings de acordo com o filtro especificado.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `postagging_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","  \"\"\"\n","\n","  if \"ALL\" in filtro:\n","    return getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento)\n","  else:\n","    if \"CLEAN\" in filtro:\n","      return getEmbeddingDocumentoSemStopWordMean(id_documento,\n","                                                  index_sentenca,\n","                                                  embedding_documento,\n","                                                  token_BERT_documento,\n","                                                  documento,\n","                                                  tokenizer,\n","                                                  token_documento,\n","                                                  postagging_documento)\n","    else:\n","      return getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                                index_sentenca,\n","                                                embedding_documento,\n","                                                token_BERT_documento,\n","                                                documento,\n","                                                tokenizer,\n","                                                token_documento,\n","                                                postagging_documento,\n","                                                filtro)"]},{"cell_type":"markdown","metadata":{"id":"Y7W-7V3QFbpR"},"source":["# 5 Comparar Contexto e Palavras"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 5.1 Carregamento dos arquivos de dados originais"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["### 5.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNgwJRC2uGJb"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"Y9BJwUYlJJmc"},"source":["### 5.1.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFYIHcIHE985"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):\n","    # Cria o diretório\n","    os.makedirs(dirbase)\n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:\n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pviuxToMCxQw"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a cópia.\")"]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens\n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbHl3d88mouc"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação!\")"]},{"cell_type":"markdown","metadata":{"id":"qzhYJNWJm1z4"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais"]},{"cell_type":"markdown","metadata":{"id":"Usr1uRzQeJSb"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRHlixdHEDTb"},"outputs":[],"source":["#Biblioteca\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1660748570119,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"jJ5STBZPLlie","outputId":"f5cb03fc-cb01-4d14-9a11-d3521f95ccc8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                           id  \\\n","869  5ad171fd645df0001a2d1bd9   \n","515  572a80b8111d821400f38b70   \n","13   572826634b864d19001645bf   \n","151  570c23e1ec8fbc190045bc80   \n","359  56f75e0fa6d7ea1400e1720e   \n","\n","                                             sentencas  \\\n","869  ['What caused a spike in difficulties between ...   \n","515  ['Under what government system does Miami oper...   \n","13   ['How many residents were recorded in the 2010...   \n","151  ['Did the FBI reassign agents from counter-int...   \n","359  ['Malyarchuk found Czech mtDNA lineages were t...   \n","\n","                                             documento  respondivel  \n","869  What caused a spike in difficulties between se...            0  \n","515   Under what government system does Miami operate?            1  \n","13   How many residents were recorded in the 2010 c...            1  \n","151  Did the FBI reassign agents from counter-intel...            1  \n","359  Malyarchuk found Czech mtDNA lineages were typ...            1  "],"text/html":["\n","  <div id=\"df-3bdcebd0-8d10-43b1-a79b-e76548f2ba96\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>respondivel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>869</th>\n","      <td>5ad171fd645df0001a2d1bd9</td>\n","      <td>['What caused a spike in difficulties between ...</td>\n","      <td>What caused a spike in difficulties between se...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>515</th>\n","      <td>572a80b8111d821400f38b70</td>\n","      <td>['Under what government system does Miami oper...</td>\n","      <td>Under what government system does Miami operate?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>572826634b864d19001645bf</td>\n","      <td>['How many residents were recorded in the 2010...</td>\n","      <td>How many residents were recorded in the 2010 c...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>570c23e1ec8fbc190045bc80</td>\n","      <td>['Did the FBI reassign agents from counter-int...</td>\n","      <td>Did the FBI reassign agents from counter-intel...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>359</th>\n","      <td>56f75e0fa6d7ea1400e1720e</td>\n","      <td>['Malyarchuk found Czech mtDNA lineages were t...</td>\n","      <td>Malyarchuk found Czech mtDNA lineages were typ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bdcebd0-8d10-43b1-a79b-e76548f2ba96')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3bdcebd0-8d10-43b1-a79b-e76548f2ba96 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3bdcebd0-8d10-43b1-a79b-e76548f2ba96');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":81}],"source":["lista_documentos_originais.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1uPIu-bRrYgw"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais = lista_documentos_originais.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1660748570120,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"IbaWPXE2jK26","outputId":"62332089-37eb-4966-aefa-4738b4a5cc65"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            id  \\\n","780   5ad04de377cf76001a686fa7   \n","208   5aced34532bba1001ae4b612   \n","24    572990451d04691400779538   \n","1002  5acd0c8407355d001abf3251   \n","87    5a671f70f038b7001ab0c218   \n","\n","                                          pos_documento  \n","780   [[['What', 'is', 'the', 'busiest', 'container'...  \n","208   [[['What', 'is', 'being', 'dismissed', '?'], [...  \n","24    [[['The', 'chemicals', 'used', 'by', 'insects'...  \n","1002  [[['What', 'level', 'physics', 'does', 'psycho...  \n","87    [[['What', 'is', 'the', 'name', 'for', 'the', ...  "],"text/html":["\n","  <div id=\"df-e17c13a3-24ea-4bb1-9034-626e630bc236\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>780</th>\n","      <td>5ad04de377cf76001a686fa7</td>\n","      <td>[[['What', 'is', 'the', 'busiest', 'container'...</td>\n","    </tr>\n","    <tr>\n","      <th>208</th>\n","      <td>5aced34532bba1001ae4b612</td>\n","      <td>[[['What', 'is', 'being', 'dismissed', '?'], [...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>572990451d04691400779538</td>\n","      <td>[[['The', 'chemicals', 'used', 'by', 'insects'...</td>\n","    </tr>\n","    <tr>\n","      <th>1002</th>\n","      <td>5acd0c8407355d001abf3251</td>\n","      <td>[[['What', 'level', 'physics', 'does', 'psycho...</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>5a671f70f038b7001ab0c218</td>\n","      <td>[[['What', 'is', 'the', 'name', 'for', 'the', ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e17c13a3-24ea-4bb1-9034-626e630bc236')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e17c13a3-24ea-4bb1-9034-626e630bc236 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e17c13a3-24ea-4bb1-9034-626e630bc236');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":83}],"source":["lista_documentos_originais_pos.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pt1Q2Hf0roJy"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais_pos = lista_documentos_originais_pos.astype(tipos)"]},{"cell_type":"markdown","metadata":{"id":"-hfUpvKqXoqe"},"source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lj9sJVavMccj"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"markdown","metadata":{"id":"8yyRt4jnYxsU"},"source":["#### Criando dados indexados originais"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1660748570120,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"B9INo4nBS8aQ","outputId":"112f8862-625b-442e-eab8-16478dbc1c82"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                  sentencas  \\\n","id                                                                            \n","5a8d89b5df8bba001a0f9afb  [Link's Edna form is faster than what other fo...   \n","5acfa4e977cf76001a6856da   [What two ministers fought for power uner Anne?]   \n","5ad19f40645df0001a2d213b  [What did Irving Langmuir find that would incr...   \n","56ce66aeaab44d1400b8875a  [In what year was the crystalline silicon sola...   \n","5acdabd307355d001abf48f0  [Since which year has the idea of a tunnel thr...   \n","\n","                                                                  documento  \\\n","id                                                                            \n","5a8d89b5df8bba001a0f9afb   Link's Edna form is faster than what other form?   \n","5acfa4e977cf76001a6856da     What two ministers fought for power uner Anne?   \n","5ad19f40645df0001a2d213b  What did Irving Langmuir find that would incre...   \n","56ce66aeaab44d1400b8875a  In what year was the crystalline silicon solar...   \n","5acdabd307355d001abf48f0  Since which year has the idea of a tunnel thro...   \n","\n","                          respondivel  \n","id                                     \n","5a8d89b5df8bba001a0f9afb            0  \n","5acfa4e977cf76001a6856da            0  \n","5ad19f40645df0001a2d213b            0  \n","56ce66aeaab44d1400b8875a            1  \n","5acdabd307355d001abf48f0            0  "],"text/html":["\n","  <div id=\"df-c9ec10fc-5331-4be7-8184-78a5472adf45\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>respondivel</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb</th>\n","      <td>[Link's Edna form is faster than what other fo...</td>\n","      <td>Link's Edna form is faster than what other form?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5acfa4e977cf76001a6856da</th>\n","      <td>[What two ministers fought for power uner Anne?]</td>\n","      <td>What two ministers fought for power uner Anne?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5ad19f40645df0001a2d213b</th>\n","      <td>[What did Irving Langmuir find that would incr...</td>\n","      <td>What did Irving Langmuir find that would incre...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>56ce66aeaab44d1400b8875a</th>\n","      <td>[In what year was the crystalline silicon sola...</td>\n","      <td>In what year was the crystalline silicon solar...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5acdabd307355d001abf48f0</th>\n","      <td>[Since which year has the idea of a tunnel thr...</td>\n","      <td>Since which year has the idea of a tunnel thro...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9ec10fc-5331-4be7-8184-78a5472adf45')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c9ec10fc-5331-4be7-8184-78a5472adf45 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c9ec10fc-5331-4be7-8184-78a5472adf45');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":86}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1660748570121,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"j70x_r30T_bx","outputId":"27ca9766-0f25-4bef-8f44-4a213fe0570b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              pos_documento\n","id                                                                         \n","5a8d89b5df8bba001a0f9afb  [[[Link, 's, Edna, form, is, faster, than, wha...\n","5acfa4e977cf76001a6856da  [[[What, two, ministers, fought, for, power, u...\n","5ad19f40645df0001a2d213b  [[[What, did, Irving, Langmuir, find, that, wo...\n","56ce66aeaab44d1400b8875a  [[[In, what, year, was, the, crystalline, sili...\n","5acdabd307355d001abf48f0  [[[Since, which, year, has, the, idea, of, a, ..."],"text/html":["\n","  <div id=\"df-676bf3a2-bf77-4caa-8860-915dcdf1edfd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb</th>\n","      <td>[[[Link, 's, Edna, form, is, faster, than, wha...</td>\n","    </tr>\n","    <tr>\n","      <th>5acfa4e977cf76001a6856da</th>\n","      <td>[[[What, two, ministers, fought, for, power, u...</td>\n","    </tr>\n","    <tr>\n","      <th>5ad19f40645df0001a2d213b</th>\n","      <td>[[[What, did, Irving, Langmuir, find, that, wo...</td>\n","    </tr>\n","    <tr>\n","      <th>56ce66aeaab44d1400b8875a</th>\n","      <td>[[[In, what, year, was, the, crystalline, sili...</td>\n","    </tr>\n","    <tr>\n","      <th>5acdabd307355d001abf48f0</th>\n","      <td>[[[Since, which, year, has, the, idea, of, a, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-676bf3a2-bf77-4caa-8860-915dcdf1edfd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-676bf3a2-bf77-4caa-8860-915dcdf1edfd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-676bf3a2-bf77-4caa-8860-915dcdf1edfd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":87}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"zJXcpioo7Bhn"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gB500dmd7Bho"},"outputs":[],"source":["# Abre o arquivo e retorna o DataFrame\n","lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1660748570121,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"3pXGee7H7Bhp","outputId":"5679cd1b-592b-4554-cb54-d86555ca9fd4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     id  \\\n","7664    56fc3a7400a8df1900403808_pert_4   \n","3577   5a567c226349e2001acdcdb3_pert_17   \n","3913   56d26bde59d6e41400145fb4_pert_13   \n","21620   572829d9ff5b5019007d9e5a_pert_0   \n","18843   572999816aef051400155010_pert_3   \n","\n","                                              perturbado  \\\n","7664   ['Aside from being active what other condition...   \n","3577   ['By what percentage have DIY and independent ...   \n","3913   ['The earliest Mahayana sutra as the very firs...   \n","21620  ['What branch does the United States intend to...   \n","18843         ['Beetles are also categorized as what ?']   \n","\n","                                    documento_perturbado  \\\n","7664   Aside from being active what other condition c...   \n","3577   By what percentage have DIY and independent CD...   \n","3913   The earliest Mahayana sutra as the very first ...   \n","21620  What branch does the United States intend to l...   \n","18843             Beetles are also categorized as what ?   \n","\n","                                               sentencas  \n","7664   [['Aside from being active what other conditio...  \n","3577   [['By what percentage have DIY and independent...  \n","3913   [['The earliest Mahayana sutra [MASK] the very...  \n","21620  [['What branch does the United States [MASK] t...  \n","18843  [['Beetles are also [MASK] as what ?', 'known'...  "],"text/html":["\n","  <div id=\"df-629e5324-25b9-454f-b55b-898f91f6ad67\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7664</th>\n","      <td>56fc3a7400a8df1900403808_pert_4</td>\n","      <td>['Aside from being active what other condition...</td>\n","      <td>Aside from being active what other condition c...</td>\n","      <td>[['Aside from being active what other conditio...</td>\n","    </tr>\n","    <tr>\n","      <th>3577</th>\n","      <td>5a567c226349e2001acdcdb3_pert_17</td>\n","      <td>['By what percentage have DIY and independent ...</td>\n","      <td>By what percentage have DIY and independent CD...</td>\n","      <td>[['By what percentage have DIY and independent...</td>\n","    </tr>\n","    <tr>\n","      <th>3913</th>\n","      <td>56d26bde59d6e41400145fb4_pert_13</td>\n","      <td>['The earliest Mahayana sutra as the very firs...</td>\n","      <td>The earliest Mahayana sutra as the very first ...</td>\n","      <td>[['The earliest Mahayana sutra [MASK] the very...</td>\n","    </tr>\n","    <tr>\n","      <th>21620</th>\n","      <td>572829d9ff5b5019007d9e5a_pert_0</td>\n","      <td>['What branch does the United States intend to...</td>\n","      <td>What branch does the United States intend to l...</td>\n","      <td>[['What branch does the United States [MASK] t...</td>\n","    </tr>\n","    <tr>\n","      <th>18843</th>\n","      <td>572999816aef051400155010_pert_3</td>\n","      <td>['Beetles are also categorized as what ?']</td>\n","      <td>Beetles are also categorized as what ?</td>\n","      <td>[['Beetles are also [MASK] as what ?', 'known'...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-629e5324-25b9-454f-b55b-898f91f6ad67')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-629e5324-25b9-454f-b55b-898f91f6ad67 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-629e5324-25b9-454f-b55b-898f91f6ad67');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":89}],"source":["lista_documentos_perturbados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1660748570122,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"IE1xJdZWkc5I","outputId":"24325db5-0383-4dc4-a31d-066ce21ac086"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     id  \\\n","13912  572b8a3b34ae481900deae84_pert_12   \n","12260   56fa0002f34c681400b0bf40_pert_0   \n","24868   572c061cdfb02c14005c6b6e_pert_8   \n","22127   572a600cfed8de19000d5bbd_pert_7   \n","21239  5acfb6df77cf76001a685a1a_pert_19   \n","\n","                                           pos_documento  \n","13912  [[['What', 'had', 'Czech', 'grown', 'by', 'the...  \n","12260  [[['In', 'what', 'geographic', 'part', 'of', '...  \n","24868  [[['And', 'a', 'famous', 'pantheist', '?'], ['...  \n","22127  [[['What', 'palace', 'was', 'the', 'place', 'o...  \n","21239  [[['Before', 'a', 'bill', 'is', 'passed', ',',...  "],"text/html":["\n","  <div id=\"df-0969cc1e-b51b-49a0-a217-5484c0b94437\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13912</th>\n","      <td>572b8a3b34ae481900deae84_pert_12</td>\n","      <td>[[['What', 'had', 'Czech', 'grown', 'by', 'the...</td>\n","    </tr>\n","    <tr>\n","      <th>12260</th>\n","      <td>56fa0002f34c681400b0bf40_pert_0</td>\n","      <td>[[['In', 'what', 'geographic', 'part', 'of', '...</td>\n","    </tr>\n","    <tr>\n","      <th>24868</th>\n","      <td>572c061cdfb02c14005c6b6e_pert_8</td>\n","      <td>[[['And', 'a', 'famous', 'pantheist', '?'], ['...</td>\n","    </tr>\n","    <tr>\n","      <th>22127</th>\n","      <td>572a600cfed8de19000d5bbd_pert_7</td>\n","      <td>[[['What', 'palace', 'was', 'the', 'place', 'o...</td>\n","    </tr>\n","    <tr>\n","      <th>21239</th>\n","      <td>5acfb6df77cf76001a685a1a_pert_19</td>\n","      <td>[[['Before', 'a', 'bill', 'is', 'passed', ',',...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0969cc1e-b51b-49a0-a217-5484c0b94437')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0969cc1e-b51b-49a0-a217-5484c0b94437 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0969cc1e-b51b-49a0-a217-5484c0b94437');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":90}],"source":["lista_documentos_perturbados_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"VrfZzjjpsUOU"},"source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHf-7dgSsUOU"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))"]},{"cell_type":"markdown","metadata":{"id":"Ix-Q5fZXY3HR"},"source":["#### Criando dados indexados perturbados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660748574296,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"FqRQnYUtSxzB","outputId":"c405d290-b0f7-409b-a68a-d491e47e64a6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                        perturbado  \\\n","id                                                                                   \n","5a8d89b5df8bba001a0f9afb_pert_0  [Link 's Edna form is faster than what other f...   \n","5a8d89b5df8bba001a0f9afb_pert_1  [Link 's Edna Form is faster than what other f...   \n","5a8d89b5df8bba001a0f9afb_pert_2  [Link 's Edna form is faster than what other f...   \n","5a8d89b5df8bba001a0f9afb_pert_3  [Link 's Edna mode is faster than what other f...   \n","5a8d89b5df8bba001a0f9afb_pert_4  [Link 's Edna shape is faster than what other ...   \n","\n","                                                              documento_perturbado  \\\n","id                                                                                   \n","5a8d89b5df8bba001a0f9afb_pert_0  Link 's Edna form is faster than what other fo...   \n","5a8d89b5df8bba001a0f9afb_pert_1  Link 's Edna Form is faster than what other fo...   \n","5a8d89b5df8bba001a0f9afb_pert_2  Link 's Edna form is faster than what other fo...   \n","5a8d89b5df8bba001a0f9afb_pert_3  Link 's Edna mode is faster than what other fo...   \n","5a8d89b5df8bba001a0f9afb_pert_4  Link 's Edna shape is faster than what other f...   \n","\n","                                                                         sentencas  \n","id                                                                                  \n","5a8d89b5df8bba001a0f9afb_pert_0  [[Link 's Edna [MASK] is faster than what othe...  \n","5a8d89b5df8bba001a0f9afb_pert_1  [[Link 's Edna [MASK] is faster than what othe...  \n","5a8d89b5df8bba001a0f9afb_pert_2  [[Link 's Edna [MASK] is faster than what othe...  \n","5a8d89b5df8bba001a0f9afb_pert_3  [[Link 's Edna [MASK] is faster than what othe...  \n","5a8d89b5df8bba001a0f9afb_pert_4  [[Link 's Edna [MASK] is faster than what othe...  "],"text/html":["\n","  <div id=\"df-cd2d45cb-dfcd-4181-8d57-f7196524c4fc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_0</th>\n","      <td>[Link 's Edna form is faster than what other f...</td>\n","      <td>Link 's Edna form is faster than what other fo...</td>\n","      <td>[[Link 's Edna [MASK] is faster than what othe...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_1</th>\n","      <td>[Link 's Edna Form is faster than what other f...</td>\n","      <td>Link 's Edna Form is faster than what other fo...</td>\n","      <td>[[Link 's Edna [MASK] is faster than what othe...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_2</th>\n","      <td>[Link 's Edna form is faster than what other f...</td>\n","      <td>Link 's Edna form is faster than what other fo...</td>\n","      <td>[[Link 's Edna [MASK] is faster than what othe...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_3</th>\n","      <td>[Link 's Edna mode is faster than what other f...</td>\n","      <td>Link 's Edna mode is faster than what other fo...</td>\n","      <td>[[Link 's Edna [MASK] is faster than what othe...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_4</th>\n","      <td>[Link 's Edna shape is faster than what other ...</td>\n","      <td>Link 's Edna shape is faster than what other f...</td>\n","      <td>[[Link 's Edna [MASK] is faster than what othe...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd2d45cb-dfcd-4181-8d57-f7196524c4fc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cd2d45cb-dfcd-4181-8d57-f7196524c4fc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cd2d45cb-dfcd-4181-8d57-f7196524c4fc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":92}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1660748574296,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"s0aDUbeZT1M8","outputId":"14ee4f70-4105-4c55-ece7-97495389e699"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                     pos_documento\n","id                                                                                \n","5a8d89b5df8bba001a0f9afb_pert_0  [[[Link, 's, Edna, form, is, faster, than, wha...\n","5a8d89b5df8bba001a0f9afb_pert_1  [[[Link, 's, Edna, Form, is, faster, than, wha...\n","5a8d89b5df8bba001a0f9afb_pert_2  [[[Link, 's, Edna, form, is, faster, than, wha...\n","5a8d89b5df8bba001a0f9afb_pert_3  [[[Link, 's, Edna, mode, is, faster, than, wha...\n","5a8d89b5df8bba001a0f9afb_pert_4  [[[Link, 's, Edna, shape, is, faster, than, wh..."],"text/html":["\n","  <div id=\"df-09e6029b-b896-406c-8a09-e78f0e75cf57\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_0</th>\n","      <td>[[[Link, 's, Edna, form, is, faster, than, wha...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_1</th>\n","      <td>[[[Link, 's, Edna, Form, is, faster, than, wha...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_2</th>\n","      <td>[[[Link, 's, Edna, form, is, faster, than, wha...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_3</th>\n","      <td>[[[Link, 's, Edna, mode, is, faster, than, wha...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_4</th>\n","      <td>[[[Link, 's, Edna, shape, is, faster, than, wh...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09e6029b-b896-406c-8a09-e78f0e75cf57')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-09e6029b-b896-406c-8a09-e78f0e75cf57 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-09e6029b-b896-406c-8a09-e78f0e75cf57');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":93}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados_pos.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"kq0-NGaC76jP"},"source":["### 5.1.5 Agrupar os dados originais e perturbados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["31e05142599d49e9a539e4f981496b4e","7ee7020b74de4719a144da00f89c3a8c","b442b54ccffe4c54a672f8f54f8ad10f","90a6603cd2014eb79e6bb31e7a5b28b6","c2d9fa4d3fd64cbe9a4d7554d3a9ba50","4be811066d374908b022b3a828256c58","25dbc2d82fc742b1a5fef9a46cf54dc6","d758ee06f3c64f18b030054b96c27c87","35f129dc843a42c695d447f75415ef48","0293f7aee61b4afe80012d995ba6fdf3","ad8e23f6405f4c3bbecb92fa1a4b54e0"]},"executionInfo":{"elapsed":2640,"status":"ok","timestamp":1660748576913,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"HWUvKfGZ8DMP","outputId":"472d7904-b0a7-41ad-88f7-7a20f9372e7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processando 1419 documentos originais\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/1419 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31e05142599d49e9a539e4f981496b4e"}},"metadata":{}}],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","lista_documentos_agrupados = []\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_originais_bar:\n","  #if i < 2:\n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    #print(\"id_documento:\",id_documento)\n","\n","    # Carrega a lista das sentenças do documento\n","    lista_sentenca_documento = linha_documento[1]\n","    #print(\"\\nlista_sentenca_documento:\",lista_sentenca_documento)\n","    #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","\n","    # Adiciona o original a lista dos dados agrupados, considerando como coerente(1)\n","    lista_documentos_agrupados.append([id_documento, lista_sentenca_documento, linha_documento[2], 1])\n","\n","    # Percorre os documentos perturbados apartir do original\n","    for j in range(0, model_args.documentos_perturbados):\n","\n","      # Id do documento perturbado\n","      id_perturbado = str(id_documento) + \"_pert_\" + str(j)\n","\n","      # localiza o documento perturbado\n","      documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","      # Recupera a sentença do documento perturbado\n","      lista_perturbado = documento_perturbado[0]\n","\n","      # Adiciona o perturbado a lista dos dados agrupados considerando como incoerente(0)\n","      lista_documentos_agrupados.append([id_perturbado, lista_perturbado, documento_perturbado[1], 0])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"]},{"cell_type":"markdown","metadata":{"id":"THHBPK6Ov8WV"},"source":["#### Converte a lista em um dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWz4b8Fpv8ki"},"outputs":[],"source":["# Cria o dataframe da lista\n","lista_documentos_agrupados = pd.DataFrame(lista_documentos_agrupados, columns = [\"id\",\"sentencas\",\"documento\",\"classe\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsbAU3pnAjYQ"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str, \"sentencas\": object, \"documento\": str, \"classe\": int}\n","\n","lista_documentos_agrupados = lista_documentos_agrupados.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"elapsed":67,"status":"ok","timestamp":1660748576916,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"P3qemxYGwHL7","outputId":"74b4f9b8-256a-475c-9a4b-a99c05f81350"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                    id  \\\n","1407          5727c79f3acd2414000dec2f   \n","4351   5726182438643c19005acfe4_pert_3   \n","27138  5a124e006614be00188f24d3_pert_5   \n","17935  5728d0ed2ca10214002da896_pert_0   \n","5314   57325556e99e3014001e66d2_pert_0   \n","\n","                                               sentencas  \\\n","1407           [Where is the Sprint All-Star Race held?]   \n","4351   [Who has been promoting Western culture and st...   \n","27138  [What is what is the name of the team of North...   \n","17935  [Along with some creationists , Popper argued ...   \n","5314   [What is the term for Jehovah 's Witnesses ' r...   \n","\n","                                               documento  classe  \n","1407             Where is the Sprint All-Star Race held?       1  \n","4351   Who has been promoting Western culture and sty...       0  \n","27138  What is what is the name of the team of North ...       0  \n","17935  Along with some creationists , Popper argued t...       0  \n","5314   What is the term for Jehovah 's Witnesses ' re...       0  "],"text/html":["\n","  <div id=\"df-969cc84e-e0e0-4f07-8e08-b0cf8e186d1f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1407</th>\n","      <td>5727c79f3acd2414000dec2f</td>\n","      <td>[Where is the Sprint All-Star Race held?]</td>\n","      <td>Where is the Sprint All-Star Race held?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4351</th>\n","      <td>5726182438643c19005acfe4_pert_3</td>\n","      <td>[Who has been promoting Western culture and st...</td>\n","      <td>Who has been promoting Western culture and sty...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27138</th>\n","      <td>5a124e006614be00188f24d3_pert_5</td>\n","      <td>[What is what is the name of the team of North...</td>\n","      <td>What is what is the name of the team of North ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17935</th>\n","      <td>5728d0ed2ca10214002da896_pert_0</td>\n","      <td>[Along with some creationists , Popper argued ...</td>\n","      <td>Along with some creationists , Popper argued t...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5314</th>\n","      <td>57325556e99e3014001e66d2_pert_0</td>\n","      <td>[What is the term for Jehovah 's Witnesses ' r...</td>\n","      <td>What is the term for Jehovah 's Witnesses ' re...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-969cc84e-e0e0-4f07-8e08-b0cf8e186d1f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-969cc84e-e0e0-4f07-8e08-b0cf8e186d1f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-969cc84e-e0e0-4f07-8e08-b0cf8e186d1f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":97}],"source":["lista_documentos_agrupados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_TJbwpcYtsN3"},"outputs":[],"source":["# Importa das bibliotecas\n","import pandas as pd\n","\n","# Concatena as listas de documentos originais e perturbados\n","lista_documentos_agrupados_pos = pd.concat([lista_documentos_originais_pos, lista_documentos_perturbados_pos])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO POS: {}.\".format(len(lista_documentos_agrupados_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvDXTxtRuvrX"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_agrupados_pos = lista_documentos_agrupados_pos.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":65,"status":"ok","timestamp":1660748576918,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"dDW4pj8vuh2I","outputId":"e27aad9a-e9d5-4677-d1a6-4ced1ab69dd5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     id  \\\n","10614  5ad68fcb191832001aa7b1f3_pert_14   \n","18703   57317e8d497a881900248f87_pert_3   \n","17502   5727de2c4b864d1900163edf_pert_2   \n","2453   57318a6305b4da19006bd265_pert_13   \n","1488    5ad547945b96ef001a10ac1b_pert_8   \n","\n","                                           pos_documento  \n","10614  [[[What, type, of, lines, does, color, paper, ...  \n","18703  [[[When, was, the, Armenian, Mosaic, re, ceipt...  \n","17502  [[[What, kind, of, controversy, has, emerged, ...  \n","2453   [[[What, organization, kidnapped, Gaddafi, 's,...  \n","1488   [[[What, do, all, these, models, not, had, in,...  "],"text/html":["\n","  <div id=\"df-327b9c3f-e173-41e7-bf6e-aca58bf96f76\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10614</th>\n","      <td>5ad68fcb191832001aa7b1f3_pert_14</td>\n","      <td>[[[What, type, of, lines, does, color, paper, ...</td>\n","    </tr>\n","    <tr>\n","      <th>18703</th>\n","      <td>57317e8d497a881900248f87_pert_3</td>\n","      <td>[[[When, was, the, Armenian, Mosaic, re, ceipt...</td>\n","    </tr>\n","    <tr>\n","      <th>17502</th>\n","      <td>5727de2c4b864d1900163edf_pert_2</td>\n","      <td>[[[What, kind, of, controversy, has, emerged, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2453</th>\n","      <td>57318a6305b4da19006bd265_pert_13</td>\n","      <td>[[[What, organization, kidnapped, Gaddafi, 's,...</td>\n","    </tr>\n","    <tr>\n","      <th>1488</th>\n","      <td>5ad547945b96ef001a10ac1b_pert_8</td>\n","      <td>[[[What, do, all, these, models, not, had, in,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-327b9c3f-e173-41e7-bf6e-aca58bf96f76')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-327b9c3f-e173-41e7-bf6e-aca58bf96f76 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-327b9c3f-e173-41e7-bf6e-aca58bf96f76');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":100}],"source":["lista_documentos_agrupados_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"viicg1E7mXLK"},"source":["#### Criar dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":64,"status":"ok","timestamp":1660748576919,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"0YBdkvoPm2vO","outputId":"a2ef3b8a-354f-4a99-f465-d334f645c803"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                         sentencas  \\\n","id                                                                                   \n","5a8d89b5df8bba001a0f9afb         [Link's Edna form is faster than what other fo...   \n","5a8d89b5df8bba001a0f9afb_pert_0  [Link 's Edna form is faster than what other f...   \n","5a8d89b5df8bba001a0f9afb_pert_1  [Link 's Edna Form is faster than what other f...   \n","5a8d89b5df8bba001a0f9afb_pert_2  [Link 's Edna form is faster than what other f...   \n","5a8d89b5df8bba001a0f9afb_pert_3  [Link 's Edna mode is faster than what other f...   \n","\n","                                                                         documento  \\\n","id                                                                                   \n","5a8d89b5df8bba001a0f9afb          Link's Edna form is faster than what other form?   \n","5a8d89b5df8bba001a0f9afb_pert_0  Link 's Edna form is faster than what other fo...   \n","5a8d89b5df8bba001a0f9afb_pert_1  Link 's Edna Form is faster than what other fo...   \n","5a8d89b5df8bba001a0f9afb_pert_2  Link 's Edna form is faster than what other fo...   \n","5a8d89b5df8bba001a0f9afb_pert_3  Link 's Edna mode is faster than what other fo...   \n","\n","                                 classe  \n","id                                       \n","5a8d89b5df8bba001a0f9afb              1  \n","5a8d89b5df8bba001a0f9afb_pert_0       0  \n","5a8d89b5df8bba001a0f9afb_pert_1       0  \n","5a8d89b5df8bba001a0f9afb_pert_2       0  \n","5a8d89b5df8bba001a0f9afb_pert_3       0  "],"text/html":["\n","  <div id=\"df-7527fbf5-c9fb-4fef-91dd-db8bb0487bb2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb</th>\n","      <td>[Link's Edna form is faster than what other fo...</td>\n","      <td>Link's Edna form is faster than what other form?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_0</th>\n","      <td>[Link 's Edna form is faster than what other f...</td>\n","      <td>Link 's Edna form is faster than what other fo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_1</th>\n","      <td>[Link 's Edna Form is faster than what other f...</td>\n","      <td>Link 's Edna Form is faster than what other fo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_2</th>\n","      <td>[Link 's Edna form is faster than what other f...</td>\n","      <td>Link 's Edna form is faster than what other fo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_3</th>\n","      <td>[Link 's Edna mode is faster than what other f...</td>\n","      <td>Link 's Edna mode is faster than what other fo...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7527fbf5-c9fb-4fef-91dd-db8bb0487bb2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7527fbf5-c9fb-4fef-91dd-db8bb0487bb2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7527fbf5-c9fb-4fef-91dd-db8bb0487bb2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":101}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_agrupados_indexado = lista_documentos_agrupados.set_index([\"id\"])\n","lista_documentos_agrupados_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":60,"status":"ok","timestamp":1660748576920,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"NQjlOJzOmbsp","outputId":"710344d1-03c7-4cd8-d7ae-a5d4f70496ba"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                              pos_documento\n","id                                                                         \n","5a8d89b5df8bba001a0f9afb  [[[Link, 's, Edna, form, is, faster, than, wha...\n","5acfa4e977cf76001a6856da  [[[What, two, ministers, fought, for, power, u...\n","5ad19f40645df0001a2d213b  [[[What, did, Irving, Langmuir, find, that, wo...\n","56ce66aeaab44d1400b8875a  [[[In, what, year, was, the, crystalline, sili...\n","5acdabd307355d001abf48f0  [[[Since, which, year, has, the, idea, of, a, ..."],"text/html":["\n","  <div id=\"df-686b7769-d5a6-40a9-a33f-54f734945335\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb</th>\n","      <td>[[[Link, 's, Edna, form, is, faster, than, wha...</td>\n","    </tr>\n","    <tr>\n","      <th>5acfa4e977cf76001a6856da</th>\n","      <td>[[[What, two, ministers, fought, for, power, u...</td>\n","    </tr>\n","    <tr>\n","      <th>5ad19f40645df0001a2d213b</th>\n","      <td>[[[What, did, Irving, Langmuir, find, that, wo...</td>\n","    </tr>\n","    <tr>\n","      <th>56ce66aeaab44d1400b8875a</th>\n","      <td>[[[In, what, year, was, the, crystalline, sili...</td>\n","    </tr>\n","    <tr>\n","      <th>5acdabd307355d001abf48f0</th>\n","      <td>[[[Since, which, year, has, the, idea, of, a, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-686b7769-d5a6-40a9-a33f-54f734945335')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-686b7769-d5a6-40a9-a33f-54f734945335 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-686b7769-d5a6-40a9-a33f-54f734945335');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":102}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_agrupados_pos_indexado = lista_documentos_agrupados_pos.set_index([\"id\"])\n","lista_documentos_agrupados_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"d1yGaGzzyEiy"},"source":["## 5.2 Gerando as comparações\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xKaqQPs8VQ5u"},"source":["### 5.2.1 Medidas de similaridade\n"]},{"cell_type":"markdown","metadata":{"id":"jt06PTN5idrg"},"source":["Similaridade do cosseno entre os embeddings.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n","\n","A função spatial.distance.cosine do módulo scipy calcula a distância em vez da similaridade do cosseno, mas para conseguir isso, podemos subtrair o valor da distância de 1.\n","\n","Intervalo de [-1,1]\n","\n","Vetores iguais a distância é igual 1.\n","\n","Vetores diferentes medida próxima de -1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6vbXj-brOlMF"},"outputs":[],"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cosine\n","\n","def similaridadeCosseno(embeddings1, embeddings2):\n","    \"\"\"\n","      Similaridade do cosseno dos embeddings dos textos.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    similaridade = 1 - cosine(embeddings1, embeddings2)\n","\n","    return similaridade"]},{"cell_type":"markdown","metadata":{"id":"fazAuLMUr_c0"},"source":["### 5.2.2 Medidas de distância"]},{"cell_type":"markdown","metadata":{"id":"_IcrjAbhwake"},"source":["Distância euclidiana entre os embeddings.\n","\n","Possui outros nomes como distância L2 ou norma L2.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIrTId9jwakh"},"outputs":[],"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import euclidean\n","\n","def distanciaEuclidiana(embeddings1, embeddings2):\n","    \"\"\"\n","    Distância euclidiana entre os embeddings dos textos.\n","    Possui outros nomes como distância L2 ou norma L2.\n","\n","    Parâmetros:\n","    `embeddings1` - Um embedding a ser medido.\n","    `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    distancia = euclidean(embeddings1, embeddings2)\n","\n","    return distancia"]},{"cell_type":"markdown","metadata":{"id":"-uJlqYCSXdVk"},"source":["Distância Manhattan entre os embeddings.\n","\n","Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cityblock.html#scipy.spatial.distance.cityblock"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jFG5UT_SXdVn"},"outputs":[],"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cityblock\n","\n","def distanciaManhattan(embeddings1, embeddings2):\n","    \"\"\"\n","    Distância Manhattan entre os embeddings dos textos\n","    Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","    Parâmetros:\n","    `embeddings1` - Um embedding a ser medido.\n","    `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    distancia = cityblock(embeddings1, embeddings2)\n","\n","    return distancia"]},{"cell_type":"markdown","metadata":{"id":"S6A6-Xwg8GJw"},"source":["### 5.2.3 Retorna as medidas dos embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qHzQ98zg8GWJ"},"outputs":[],"source":["def getMedidasEmbedding(embedding_wi, embedding_wj):\n","\n","  \"\"\"\n","    Retorna as medidas de similaridade do cosseno(cos), distância Euclidiana(euc) e\n","    distância de Manhattan(man) entre os embeddings.\n","\n","    Parâmetros:\n","    `embeddings_wi` - Um embedding de uma palavra a ser medido.\n","    `embeddings_wj` - Um embedding de uma palavra a ser medido.\n","  \"\"\"\n","\n","  #print(\"embedding_wi=\", embedding_wi.shape)\n","  #print(\"embedding_wj=\", embedding_wj.shape)\n","\n","  # Similaridade do cosseno entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  cos = similaridadeCosseno(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  # Distância euclidiana entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  euc = distanciaEuclidiana(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  # Distância de manhattan entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  man = distanciaManhattan(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  del embedding_wi\n","  del embedding_wj\n","\n","  # Retorno das medidas das sentenças\n","  return cos, euc, man"]},{"cell_type":"markdown","metadata":{"id":"KEtmDaKqAL-9"},"source":["### 5.2.4 getTokensEmbeddingsPOSSentenca\n","Gera os tokens, POS e embeddings de cada sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXPWq5JyIoQf"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar mais tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera mais tokens que a tokenização das palavras do spaCy\n","dic_excecao_maior = {\n","               \"U.S.\":4,\n","               \"D.C.\":4,\n","               \"U.N.\":4,\n","               \"St.\":2,\n","               }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89oBywgbIxzV"},"outputs":[],"source":["def getExcecaoDicMaior(id, token, dic_excecao_maior):\n","\n","  valor = dic_excecao_maior.get(token)\n","  if valor != None:\n","        return valor\n","  else:\n","      return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPODj-AWfhxW"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar menos tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera menos tokens que a tokenização das palavras do spaCy\n","# Concatena dois tokens gerados pelo BERT e verifica se gera somente 1 token no BERT\n","dic_excecao_menor = {\"1°\":1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xy2bzLBWfeqi"},"outputs":[],"source":["def getExcecaoDicMenor(id, token, dic_excecao_menor):\n","\n","  valor = dic_excecao_menor.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"markdown","metadata":{"id":"LLRdNsbo0qxA"},"source":["Função que retorna os embeddings, tokens e POS da sentença com um mesmo tamamnho."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OykQrpVsILpM"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getTokensEmbeddingsPOSSentenca(id_documento,\n","                                   index_sentenca,\n","                                   embedding_documento,\n","                                   token_BERT_documento,\n","                                   sentenca,\n","                                   tokenizer,\n","                                   sentenca_token = None,\n","                                   sentenca_postagging = None,\n","                                   estrategia_medida = 0):\n","    \"\"\"\n","      Retorna os tokens, as POS-Tagging e os embeddings dos tokens igualando a quantidade de tokens do spaCy com a tokenização do BERT de acordo com a estratégia de pooling para palavras fora do vocabulário do BERT.\n","      Usa a estratégia MEAN para calcular a média dos embeddings dos tokens que formam uma palavra fora do vocabulário do BERT.\n","      Usa a estratégia MAX para calcular o valor máximo dos embeddings dos tokens que formam uma palavra fora do vocabulário do BERT.\n","    \"\"\"\n","\n","    #Guarda os tokens e embeddings\n","    lista_tokens = []\n","    lista_embeddings_mean = []\n","    lista_embeddings_max = []\n","\n","    # Se a sentença não for tokenizada\n","    if sentenca_token == None:\n","      # Gera a tokenização e POS-Tagging da sentença\n","      sentenca_token, sentenca_postagging = getListaTokensPOSSentenca(sentenca)\n","\n","    # print(\"\\nsentenca                :\",sentenca)\n","    # print(\"id_documento                :\",id_documento)\n","    # print(\"index_sentenca              :\",index_sentenca)\n","    # print(\"sentenca_token              :\",sentenca_token)\n","    # print(\"len(sentenca_token)         :\",len(sentenca_token))\n","    # print(\"sentenca_postagging         :\",sentenca_postagging)\n","    # print(\"len(sentenca_postagging)    :\",len(sentenca_postagging))\n","\n","    # Recupera os embeddings da sentença dos embeddings dentro dos embeddings do documento\n","    embedding_sentenca, sentenca_tokenizada_BERT = getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                                                                       token_BERT_documento,\n","                                                                                                       sentenca,\n","                                                                                                       tokenizer)\n","\n","    # embedding <qtde_tokens x 4096>\n","    # print(\"embedding_sentenca          :\",embedding_sentenca.shape)\n","    # print(\"sentenca_tokenizada_BERT     :\",sentenca_tokenizada_BERT)\n","    # print(\"len(sentenca_tokenizada_BERT):\",len(sentenca_tokenizada_BERT))\n","\n","    # Seleciona os pares de palavra a serem avaliadas\n","    pos_wi = 0 # Posição do token da palavra gerado pelo spaCy\n","    pos_wj = pos_wi # Posição do token da palavra gerado pelo BERT\n","    pos2 = -1\n","\n","    # Enquanto o indíce da palavra pos_wj(2a palavra) não chegou ao final da quantidade de tokens do BERT\n","    while pos_wj < len(sentenca_tokenizada_BERT):\n","\n","      # Seleciona os tokens da sentença\n","      wi = sentenca_token[pos_wi] # Recupera o token da palavra gerado pelo spaCy\n","      wi1 = \"\"\n","      pos2 = -1\n","      if pos_wi+1 < len(sentenca_token):\n","        wi1 = sentenca_token[pos_wi+1] # Recupera o próximo token da palavra gerado pelo spaCy\n","\n","        # Localiza o deslocamento da exceção\n","        pos2 = getExcecaoDicMenor(id_documento, wi+wi1, dic_excecao_menor)\n","        # print(\"Exceção pos2:\", pos2, \" de \", wi+wi1)\n","\n","      wj = sentenca_tokenizada_BERT[pos_wj] # Recupera o token da palavra gerado pelo BERT\n","      #print(\"wi[\",pos_wi,\"]=\", wi)\n","      #print(\"wj[\",pos_wj,\"]=\", wj)\n","\n","      # Tratando exceções\n","      # Localiza o deslocamento da exceção\n","      pos = getExcecaoDicMaior(id_documento, wi, dic_excecao_maior)\n","      # print(\"Exceção pos:\", pos, \" de \", wi)\n","\n","      if pos != -1 or pos2 != -1:\n","        if pos != -1:\n","          #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","          lista_tokens.append(wi)\n","          # Verifica se tem mais de um token\n","          if pos != 1:\n","            indice_token = pos_wj + pos\n","            #print(\"Calcula a média de :\", pos_wj , \"até\", indice_token)\n","            embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","            #print(\"embeddings_tokens_palavra:\",embeddings_tokens_palavra.shape)\n","            # calcular a média dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_mean = torch.mean(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_mean:\",embedding_estrategia_mean.shape)\n","            lista_embeddings_mean.append(embedding_estrategia_mean)\n","\n","            # calcular o máximo dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_max, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_max:\",embedding_estrategia_max.shape)\n","            lista_embeddings_max.append(embedding_estrategia_max)\n","          else:\n","            # Adiciona o embedding do token a lista de embeddings\n","            lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","            lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + pos\n","          #print(\"Proxima:\")\n","          #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","          #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","        else:\n","          if pos2 != -1:\n","            #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","            lista_tokens.append(wi+wi1)\n","            # Verifica se tem mais de um token\n","            if pos2 == 1:\n","              # Adiciona o embedding do token a lista de embeddings\n","              lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","              lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","\n","            # Avança para a próxima palavra e token do BERT\n","            pos_wi = pos_wi + 2\n","            pos_wj = pos_wj + pos2\n","            #print(\"Proxima:\")\n","            #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","            #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","      else:\n","        # Tokens iguais adiciona a lista, o token não possui subtoken\n","        if (wi == wj or wj==\"[UNK]\"):\n","          # Adiciona o token a lista de tokens\n","          # print(\"Adiciona 2 wi==wj or wj==[UNK]:\", wi, wj )\n","          lista_tokens.append(wi)\n","          # Adiciona o embedding do token a lista de embeddings\n","          lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","          lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","          #print(\"embedding1[pos_wj]:\", embedding_sentenca[pos_wj].shape)\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + 1\n","\n","        else:\n","          # A palavra foi tokenizada pelo Wordpice com ## ou diferente do spaCy ou desconhecida\n","          # Inicializa a palavra a ser montada\n","          palavra_postagging = wj\n","          indice_token = pos_wj + 1\n","          while  ((palavra_postagging != wi) and indice_token < len(sentenca_tokenizada_BERT)):\n","              if \"##\" in sentenca_tokenizada_BERT[indice_token]:\n","                # Remove os caracteres \"##\" do token\n","                parte = sentenca_tokenizada_BERT[indice_token][2:]\n","              else:\n","                parte = sentenca_tokenizada_BERT[indice_token]\n","\n","              palavra_postagging = palavra_postagging + parte\n","              #print(\"palavra_postagging:\",palavra_postagging)\n","              # Avança para o próximo token do BERT\n","              indice_token = indice_token + 1\n","\n","          #print(\"\\nMontei palavra:\",palavra_postagging)\n","          if (palavra_postagging == wi or palavra_postagging == \"[UNK]\"):\n","              # Adiciona o token a lista\n","              #print(\"Adiciona 3 palavra == wi or palavra_postagging = [UNK]:\",wi)\n","              lista_tokens.append(wi)\n","              # Calcula a média dos tokens da palavra\n","              #print(\"Calcula o máximo :\", pos_wj , \"até\", indice_token)\n","              embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra)\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra.shape)\n","\n","              # calcular a média dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_mean = torch.mean(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_mean:\",embedding_estrategia_mean)\n","              #print(\"embedding_estrategia_mean.shape:\",embedding_estrategia_mean.shape)\n","              lista_embeddings_mean.append(embedding_estrategia_mean)\n","\n","              # calcular o valor máximo dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_max, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_max:\",embedding_estrategia_max)\n","              #print(\"embedding_estrategia_max.shape:\",embedding_estrategia_max.shape)\n","              lista_embeddings_max.append(embedding_estrategia_max)\n","\n","          # Avança para o próximo token do spaCy\n","          pos_wi = pos_wi + 1\n","          # Pula para o próximo token do BERT\n","          pos_wj = indice_token\n","\n","    # Verificação se as listas estão com o mesmo tamanho\n","    if ((len(lista_tokens) !=  len(lista_embeddings_mean)) or (len(lista_tokens) != len(sentenca_postagging))):\n","       print(\"\\nsentenca                  :\",sentenca)\n","       print(\"id_documento              :\",id_documento)\n","       print(\"index_sentenca            :\",index_sentenca)\n","       print(\"sentenca_postagging       :\",sentenca_postagging)\n","       print(\"len(sentenca_postagging)  :\",len(sentenca_postagging))\n","       print(\"sentenca_token            :\",sentenca_token)\n","       print(\"len(sentenca_token)       :\",len(sentenca_token))\n","       print(\"sentenca_tokenizada_BERT  :\",sentenca_tokenizada_BERT)\n","       print(\"lista_tokens              :\",lista_tokens)\n","       print(\"len(lista_tokens)         :\",len(lista_tokens))\n","       print(\"lista_embeddings_mean     :\",lista_embeddings_mean)\n","       print(\"len(lista_embeddings_mean):\",len(lista_embeddings_mean))\n","       print(\"lista_embeddings_max      :\",lista_embeddings_max)\n","       print(\"len(lista_embeddings_max) :\",len(lista_embeddings_max))\n","\n","    del embedding_sentenca\n","    del token_BERT_documento\n","    del tokenizer\n","    del sentenca_tokenizada_BERT\n","    del sentenca_token\n","\n","    return lista_tokens, sentenca_postagging, lista_embeddings_mean, lista_embeddings_max"]},{"cell_type":"markdown","metadata":{"id":"VxjEtWUqAOtm"},"source":["### 5.2.5 comparaContextoPalavrasTodas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BW7h3mM-APKW"},"outputs":[],"source":["def comparaContextoPalavrasTodas(id_documento,\n","                                 indexdocumento,\n","                                 index_sentenca,\n","                                 embedding_documento,\n","                                 token_BERT_documento,\n","                                 sentenca,\n","                                 tokenizer,\n","                                 sentenca_token,\n","                                 sentenca_postagging,\n","                                 contextos_documentos):\n","\n","  lista_tokens, lista_postagging, lista_embeddings_mean, lista_embeddings_max = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                                               index_sentenca,\n","                                                                                                               embedding_documento,\n","                                                                                                               token_BERT_documento,\n","                                                                                                               sentenca,\n","                                                                                                               tokenizer,\n","                                                                                                               sentenca_token,\n","                                                                                                               sentenca_postagging)\n","\n","  #print(\"\\nSentença   :\",lista_tokens)\n","  #print(\"POS Tagging:\",lista_postagging)\n","  #print(\"Quantidade de palavras:\",len(lista_tokens))\n","\n","  # Quantidade de palavras no documento\n","  k = len(lista_tokens)\n","\n","  # Guarda a comparação da sentença\n","  lista_comparacao = []\n","\n","  # Percorre as palavras da sentença\n","  for i in range(0,k):\n","    # Seleciona a palavra i da sentença\n","    wi = lista_tokens[i]\n","    posi = lista_postagging[i]\n","\n","    # Contexto de todas as palavras\n","    if contextos_documentos[0] != None:\n","      # Recupera as medidas dos embeddings das palavras usando as estratégias MEAN e MAX\n","      cos_ctxall_mean, euc_ctxall_mean, man_ctxall_mean = getMedidasEmbedding(lista_embeddings_mean[i],\n","                                                                        contextos_documentos[0])\n","      cos_ctxall_max, euc_ctxall_max, man_ctxall_max = getMedidasEmbedding(lista_embeddings_max[i],\n","                                                                     contextos_documentos[0])\n","    else:\n","      cos_ctxall_mean, euc_ctxall_mean, man_ctxall_mean = None, None ,None\n","      cos_ctxall_max, euc_ctxall_max, man_ctxall_max = None, None ,None\n","\n","    # Contexto de todas as palavras menos as stopswords\n","    if contextos_documentos[1] != None:\n","      # Recupera as medidas dos embeddings das palavras usando as estratégias MEAN e MAX\n","      cos_ctxclean_mean, euc_ctxclean_mean, man_ctxclean_mean = getMedidasEmbedding(lista_embeddings_mean[i],\n","                                                                              contextos_documentos[1])\n","      cos_ctxclean_max, euc_ctxclean_max, man_ctxclean_max = getMedidasEmbedding(lista_embeddings_max[i],\n","                                                                           contextos_documentos[1])\n","    else:\n","      cos_ctxclean_mean, euc_ctxclean_mean, man_ctxclean_mean = None, None ,None\n","      cos_ctxclean_max, euc_ctxclean_max, man_ctxclean_max = None, None ,None\n","\n","    # Contexto de todas as palavras verbos\n","    if contextos_documentos[2] != None:\n","      # Recupera as medidas dos embeddings das palavras usando as estratégias MEAN e MAX\n","      cos_ctxverb_mean, euc_ctxverb_mean, man_ctxverb_mean = getMedidasEmbedding(lista_embeddings_mean[i],\n","                                                                           contextos_documentos[2])\n","      cos_ctxverb_max, euc_ctxverb_max, man_ctxverb_max = getMedidasEmbedding(lista_embeddings_max[i],\n","                                                                        contextos_documentos[2])\n","    else:\n","      cos_ctxverb_mean, euc_ctxverb_mean, man_ctxverb_mean = None, None ,None\n","      cos_ctxverb_max, euc_ctxverb_max, man_ctxverb_max = None, None ,None\n","\n","    # Contexto de todas as palavras substantivos\n","    if contextos_documentos[3] != None:\n","      # Recupera as medidas dos embeddings das palavras usando as estratégias MEAN e MAX\n","      cos_ctxnoun_mean, euc_ctxnoun_mean, man_ctxnoun_mean = getMedidasEmbedding(lista_embeddings_mean[i],\n","                                                               contextos_documentos[3])\n","      cos_ctxnoun_max, euc_ctxnoun_max, man_ctxnoun_max = getMedidasEmbedding(lista_embeddings_max[i],\n","                                                               contextos_documentos[3])\n","    else:\n","      cos_ctxnoun_mean, euc_ctxnoun_mean, man_ctxnoun_mean = None, None ,None\n","      cos_ctxnoun_max, euc_ctxnoun_max, man_ctxnoun_max = None, None ,None\n","\n","    # Contexto de todas as palavras verbos e substantivos\n","    if contextos_documentos[4] != None:\n","      # Recupera as medidas dos embeddings das palavras usando as estratégias MEAN e MAX\n","      cos_ctxverbnoun_mean, euc_ctxverbnoun_mean, man_ctxverbnoun_mean = getMedidasEmbedding(lista_embeddings_mean[i],\n","                                                                           contextos_documentos[4])\n","      cos_ctxverbnoun_max, euc_ctxverbnoun_max, man_ctxverbnoun_max = getMedidasEmbedding(lista_embeddings_max[i],\n","                                                                           contextos_documentos[4])\n","    else:\n","      cos_ctxverbnoun_mean, euc_ctxverbnoun_mean, man_ctxverbnoun_mean = None, None ,None\n","      cos_ctxverbnoun_max, euc_ctxverbnoun_max, man_ctxverbnoun_max = None, None ,None\n","\n","    comparacao = [id_documento, indexdocumento, index_sentenca, i, str(wi), posi,\n","                  cos_ctxall_mean,        euc_ctxall_mean,      man_ctxall_mean,\n","                  cos_ctxclean_mean,      euc_ctxclean_mean,    man_ctxclean_mean,\n","                  cos_ctxverb_mean,       euc_ctxverb_mean,     man_ctxverb_mean,\n","                  cos_ctxnoun_mean,       euc_ctxnoun_mean,     man_ctxnoun_mean,\n","                  cos_ctxverbnoun_mean,   euc_ctxverbnoun_mean, man_ctxverbnoun_mean,\n","                  cos_ctxall_max,         euc_ctxall_max,       man_ctxall_max,\n","                  cos_ctxclean_max,       euc_ctxclean_max,     man_ctxclean_max,\n","                  cos_ctxverb_max,        euc_ctxverb_max,      man_ctxverb_max,\n","                  cos_ctxnoun_max,        euc_ctxnoun_max,      man_ctxnoun_max,\n","                  cos_ctxverbnoun_max,    euc_ctxverbnoun_max,  man_ctxverbnoun_max\n","                  ]\n","\n","    lista_comparacao.append(comparacao)\n","\n","    #print(comparacao)\n","    #print(\"Compara :\", i)\n","    #print(\"Compara :\", wi, \" com o contexto\")\n","    #print(\"     cos_ctxall_mean:\", cos_ctxall_mean)\n","    #print(\"     euc_ctxall_mean:\", euc_ctxall_mean)\n","    #print(\"     man_ctxall_mean:\", man_ctxall_mean)\n","\n","  del lista_tokens\n","  del lista_postagging\n","  del lista_embeddings_mean\n","  del lista_embeddings_max\n","\n","  return lista_comparacao"]},{"cell_type":"markdown","metadata":{"id":"TXNhBApgbULb"},"source":["### 5.2.6 Realiza a comparação do contexto com as palavras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["89970b00ef1c46c5b5dd7814f8618bf1","028f080fbb244e21acb77663011d2e7a","b3b8edd6b5b64960b0a5220dd17c7545","2d3f49ad96ec4637b4591303a87f88bc","3a6651c72d21461a8228ed68b8273f3f","ec0f86d0da574d54bdfb351f876c0dab","896a3cfa62e24bba90a974aa4ab73dcf","a85d62b4a25f4265adc21392d5bef1eb","f6cd8d12875849f49459c1449280a4c3","2b1bfe7b9b944d0ab43739c4b2c23ccd","7e0a4c52547c4ae88384737480c44630"]},"id":"CfGFsRaPDBMt","outputId":"35e1e5dd-6e9e-42d2-c133-31b1977edd9f","executionInfo":{"status":"ok","timestamp":1660760506649,"user_tz":180,"elapsed":394464,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89970b00ef1c46c5b5dd7814f8618bf1","version_major":2,"version_minor":0},"text/plain":["Documentos:   0%|          | 0/29799 [00:00<?, ? documento/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Import das bibliotecas\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","logging.info(\"Processando {} documentos originais e perturbados.\".format(len(lista_documentos_agrupados)))\n","\n","# Guarda a comparacação das sentenças\n","resultado_comparacao = []\n","\n","# Conta sentenças comparadas e não comparadas\n","conta_sentenca = 0\n","\n","# Limpa o buffer antes de realizar a comparação\n","limpaBufferEmbedding()\n","\n","# Barra de progresso dos documentos\n","lista_documentos_bar = tqdm_notebook(lista_documentos_agrupados.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_agrupados))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_bar:\n","  # if i < 10:\n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    #print(\"id_documento:\",id_documento)\n","\n","    # Carrega as listas das sentenças e postagging dos documento\n","    lista_sentenca_documento = linha_documento[1]\n","    # print(\"lista_sentenca_documento:\",lista_sentenca_documento)\n","    # print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","\n","    # Recupera o documento\n","    documento = linha_documento[2]\n","    #print(\"documento:\",documento)\n","    # Recupera a classe documento (1-original 0-perturbado)\n","    #classe = linha_documento[3]\n","    #print(\"classe:\",classe)\n","\n","    # Localiza a POSTagging do documento agrupado\n","    lista_pos_documento = lista_documentos_agrupados_pos_indexado.loc[id_documento][0]\n","    #print(\"lista_pos_documento:\",lista_pos_documento)\n","    #print(\"len(lista_pos_documento):\",len(lista_pos_documento))\n","\n","    # Troca o documento por uma versão da concatenação das palavras geradas pelo spaCy\n","    # Percorre a lista_pos concatenando a posição 0 dos tokens\n","    documento_concatenado = \" \".join(concatenaListas(lista_pos_documento, pos=0))\n","    # print(\"documento_concatenado:\", documento_concatenado)\n","    documento = documento_concatenado\n","\n","    # Concatena os tokens das sentenças do documento que estão em listas separadas\n","    token_documento = concatenaListas(lista_pos_documento,0)\n","\n","    # Concatena as pos das palavras do documento que estão em listas separadas\n","    pos_documento = concatenaListas(lista_pos_documento,1)\n","\n","    # Gera os embeddings do documento utiliza a concatenação das 4 últimas camadas\n","    # Somente para os documentos originais\n","    if \"_pert_\" not in id_documento:\n","      embedding_documento, token_BERT_documento = getEmbeddingsDocumentoBuffer(documento, model, tokenizer)\n","    else:\n","      embedding_documento, token_BERT_documento = getEmbeddingsDocumento(documento, model, tokenizer)\n","    # embedding <qtde_tokens x 4096>\n","    #print(\"embedding_documento:\",embedding_documento.shape)\n","    #print(\"token_BERT_documento:\",token_BERT_documento)\n","    #print(\"len(token_BERT_documento):\",len(token_BERT_documento))\n","\n","    # Gera os embeddings da média dos embeddings de todas as palavras do documento\n","    embedding_documento_all_mean = getEmbeddingDocumentoMean(id_documento,\n","                                                             None,\n","                                                             embedding_documento,\n","                                                             token_BERT_documento,\n","                                                             documento,\n","                                                             tokenizer,\n","                                                             token_documento,\n","                                                             pos_documento,\n","                                                             filtro=[\"ALL\"])\n","    #print(\"embedding_documento_all_mean:\",embedding_documento_all_mean.shape)\n","\n","   # Gera os embeddings da média dos embeddings de todas as palavras do documento desconsiderando stopwords\n","    embedding_documento_clean_mean = getEmbeddingDocumentoMean(id_documento,\n","                                                               None,\n","                                                               embedding_documento,\n","                                                               token_BERT_documento,\n","                                                               documento,\n","                                                               tokenizer,\n","                                                               token_documento,\n","                                                               pos_documento,\n","                                                               filtro=[\"CLEAN\"])\n","    #print(\"embedding_documento_clean_mean:\",embedding_documento_clean_mean.shape)\n","\n","    # Gera os embeddings da média dos embeddings de todas as palavras do documento da classe VERB\n","    embedding_documento_verb_mean = getEmbeddingDocumentoMean(id_documento,\n","                                                              None,\n","                                                              embedding_documento,\n","                                                              token_BERT_documento,\n","                                                              documento,\n","                                                              tokenizer,\n","                                                              token_documento,\n","                                                              pos_documento,\n","                                                              filtro=[\"VERB\",\"AUX\"])\n","    #print(\"embedding_documento_clean_mean:\",embedding_documento_verb_mean.shape)\n","\n","    # Gera os embeddings da média dos embeddings de todas as palavras do documento da classe NOUN\n","    embedding_documento_noun_mean = getEmbeddingDocumentoMean(id_documento,\n","                                                              None,\n","                                                              embedding_documento,\n","                                                              token_BERT_documento,\n","                                                              documento,\n","                                                              tokenizer,\n","                                                              token_documento,\n","                                                              pos_documento,\n","                                                              filtro=[\"NOUN\"])\n","    #print(\"embedding_documento_noun_mean:\",embedding_documento_noun_mean.shape)\n","\n","    # Gera os embeddings da média dos embeddings de todas as palavras do documento da classe VERB e NOUN\n","    embedding_documento_verbnoun_mean = getEmbeddingDocumentoMean(id_documento,\n","                                                                  None,\n","                                                                  embedding_documento,\n","                                                                  token_BERT_documento,\n","                                                                  documento,\n","                                                                  tokenizer,\n","                                                                  token_documento,\n","                                                                  pos_documento,\n","                                                                  filtro=[\"VERB\",\"NOUN\",\"AUX\"])\n","    #print(\"embedding_documento_verbnoun_mean:\",embedding_documento_verbnoun_mean.shape)\n","\n","    # Agrega os embeddings dos contextos\n","    contextos_documentos = [embedding_documento_all_mean,\n","                           embedding_documento_clean_mean,\n","                           embedding_documento_verb_mean,\n","                           embedding_documento_noun_mean,\n","                           embedding_documento_verbnoun_mean]\n","\n","    # Percorre as sentenças do documento\n","    for j, sentenca in enumerate(lista_sentenca_documento):\n","      #print(\"id_documento:\",id_documento)\n","      # print(\"sentenca:\",sentenca)\n","\n","      # Carrega as POSTagging da sentença\n","      sentenca_token = lista_pos_documento[j][0]\n","      sentenca_postagging = lista_pos_documento[j][1]\n","      sentenca_verbos = lista_pos_documento[j][2]\n","\n","      #print(\"sentenca_token:\",sentenca_token)\n","      #print(\"len(sentenca_token):\",len(sentenca_token))\n","\n","      #print(\"sentenca_postagging:\",sentenca_postagging)\n","      #print(\"len(sentenca_postagging):\",len(sentenca_postagging))\n","\n","      #print(\"sentenca_verbos:\",sentenca_verbos)\n","      #print(\"len(sentenca_verbos):\",len(sentenca_verbos))\n","\n","      # Conta o número de sentenças com palavras comparadas\n","      conta_sentenca = conta_sentenca + 1\n","\n","      # Realiza uma contenação dos tokens da sentença\n","      sentenca_concatenada = \" \".join(sentenca_token)\n","      # print(\"sentenca_concatenada:\", sentenca_concatenada)\n","\n","      # Recupera as medidas entre os contextos e as palavras\n","      lista_comparacao = comparaContextoPalavrasTodas(id_documento,\n","                                                      i, #index do documento\n","                                                      j, #index da sentença do documento i\n","                                                      embedding_documento,\n","                                                      token_BERT_documento,\n","                                                      sentenca_concatenada,\n","                                                      tokenizer,\n","                                                      sentenca_token,\n","                                                      sentenca_postagging,\n","                                                      contextos_documentos)\n","\n","      # Guarda o resultado da comparação\n","      resultado_comparacao = resultado_comparacao + lista_comparacao"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugwTe8C3ebjy"},"outputs":[],"source":["logging.info(\"Número de sentenças com palavras comparadas: {}.\".format(conta_sentenca))\n","logging.info(\"Número de comparações                      : {}.\".format(len(resultado_comparacao)))"]},{"cell_type":"markdown","metadata":{"id":"rMg19DZzYjHB"},"source":["## 5.3 Gera arquivo das comparações"]},{"cell_type":"markdown","metadata":{"id":"midCJ2AYes2x"},"source":["### 5.3.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kahGlJdWdP8f"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_COMPARACAO_CONTEXTO = \"comparacao_contexto_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO = \"comparacao_contexto_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"2QqMkV09ZShd"},"source":["### 5.3.2 Gera arquivo comparação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vdHTuPLDYjHB"},"outputs":[],"source":["# Importa das bibliotecas.\n","import pandas as pd\n","\n","# Cria o dataframe da lista\n","resultado_comparacao = pd.DataFrame(resultado_comparacao, columns = [\"id\",\n","                                                                       \"index_documento\",\n","                                                                       \"index_sentenca\",\n","                                                                       \"index_wi\",\n","                                                                       \"wi\",\n","                                                                       \"pos_i\",\n","                                                                       \"cos_ctxall_mean\",       \"euc_ctxall_mean\",        \"man_ctxall_mean\",\n","                                                                       \"cos_ctxclean_mean\",     \"euc_ctxclean_mean\",      \"man_ctxclean_mean\",\n","                                                                       \"cos_ctxverb_mean\",      \"euc_ctxverb_mean\",       \"man_ctxverb_mean\",\n","                                                                       \"cos_ctxnoun_mean\",      \"euc_ctxnoun_mean\",       \"man_ctxnoun_mean\",\n","                                                                       \"cos_ctxverbnoun_mean\",  \"euc_ctxverbnoun_mean\",   \"man_ctxverbnoun_mean\",\n","\n","                                                                       \"cos_ctxall_max\",        \"euc_ctxall_max\",         \"man_ctxall_max\",\n","                                                                       \"cos_ctxclean_max\",      \"euc_ctxclean_max\",       \"man_ctxclean_max\",\n","                                                                       \"cos_ctxverb_max\",       \"euc_ctxverb_max\",        \"man_ctxverb_max\",\n","                                                                       \"cos_ctxnoun_max\",       \"euc_ctxnoun_max\",        \"man_ctxnoun_max\",\n","                                                                       \"cos_ctxverbnoun_max\",   \"euc_ctxverbnoun_max\",    \"man_ctxverbnoun_max\"\n","                                                                       ])\n","\n","# Nome do arquivo original\n","nome_arquivo = DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_CONTEXTO\n","\n","# Salva o arquivo original\n","resultado_comparacao.to_csv(nome_arquivo,  sep=\";\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"F9JSH-_lYjHB"},"source":["### 5.3.3 Carrega os dados\n","\n","Carrega os dados das sentencas a partir dos arquivos.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ob-mUkjYjHC"},"outputs":[],"source":["# Importa das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","resultado_comparacao = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_CONTEXTO, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"Quantidade de comparações: {}.\".format(len(resultado_comparacao)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNCI53tPYjHC","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1660760529965,"user_tz":180,"elapsed":2,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"c703ffb2-7e1d-43c5-c1a3-880c11ceee9a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                      id  index_documento  index_sentenca  \\\n","134817  570db375df2f5219002ed106_pert_10            11981               0   \n","169328   5728c4ee3acd2414000dfdfc_pert_8            15087               0   \n","19650    56d2706859d6e41400145fdc_pert_9             1711               0   \n","24049    5a79ce7517ab25001a8a008d_pert_2             2103               0   \n","136226  570db606df2f5219002ed10c_pert_19            12095               0   \n","\n","        index_wi            wi  pos_i  cos_ctxall_mean  euc_ctxall_mean  \\\n","134817         9    throughout    ADP         0.726950        31.795378   \n","169328         7        Sahara  PROPN         0.785786        26.494869   \n","19650          3         early    ADJ         0.792268        28.209438   \n","24049         10   association   NOUN         0.787099        27.348953   \n","136226        13  construction   NOUN         0.701523        32.152115   \n","\n","        man_ctxall_mean  cos_ctxclean_mean  ...  man_ctxclean_max  \\\n","134817        1615.6772           0.681845  ...         1732.4253   \n","169328        1332.1638           0.845581  ...         1143.4348   \n","19650         1425.7041           0.813935  ...         1360.2152   \n","24049         1387.9971           0.827218  ...         1267.6790   \n","136226        1601.0765           0.750750  ...         1478.3983   \n","\n","        cos_ctxverb_max  euc_ctxverb_max  man_ctxverb_max  cos_ctxnoun_max  \\\n","134817         0.610551        38.068779      1920.864746         0.603902   \n","169328         0.590363        39.155334      1962.003662         0.652857   \n","19650          0.535733        45.099018      2284.870605         0.746259   \n","24049          0.614758        36.791355      1855.655029         0.883322   \n","136226         0.500619        44.227001      2232.218262         0.813946   \n","\n","        euc_ctxnoun_max  man_ctxnoun_max  cos_ctxverbnoun_max  \\\n","134817        38.448708      1951.329102             0.670602   \n","169328        35.420307      1752.543091             0.687592   \n","19650         30.683653      1560.639160             0.747319   \n","24049         20.782558      1056.652100             0.829124   \n","136226        26.210835      1306.556885             0.795464   \n","\n","        euc_ctxverbnoun_max  man_ctxverbnoun_max  \n","134817            34.569992          1759.945190  \n","169328            32.431366          1612.142700  \n","19650             30.600662          1549.735840  \n","24049             24.673475          1255.931519  \n","136226            27.340239          1363.473389  \n","\n","[5 rows x 36 columns]"],"text/html":["\n","  <div id=\"df-c98b09b6-f0b1-48aa-8d47-c85800b37a60\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>index_documento</th>\n","      <th>index_sentenca</th>\n","      <th>index_wi</th>\n","      <th>wi</th>\n","      <th>pos_i</th>\n","      <th>cos_ctxall_mean</th>\n","      <th>euc_ctxall_mean</th>\n","      <th>man_ctxall_mean</th>\n","      <th>cos_ctxclean_mean</th>\n","      <th>...</th>\n","      <th>man_ctxclean_max</th>\n","      <th>cos_ctxverb_max</th>\n","      <th>euc_ctxverb_max</th>\n","      <th>man_ctxverb_max</th>\n","      <th>cos_ctxnoun_max</th>\n","      <th>euc_ctxnoun_max</th>\n","      <th>man_ctxnoun_max</th>\n","      <th>cos_ctxverbnoun_max</th>\n","      <th>euc_ctxverbnoun_max</th>\n","      <th>man_ctxverbnoun_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>134817</th>\n","      <td>570db375df2f5219002ed106_pert_10</td>\n","      <td>11981</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>throughout</td>\n","      <td>ADP</td>\n","      <td>0.726950</td>\n","      <td>31.795378</td>\n","      <td>1615.6772</td>\n","      <td>0.681845</td>\n","      <td>...</td>\n","      <td>1732.4253</td>\n","      <td>0.610551</td>\n","      <td>38.068779</td>\n","      <td>1920.864746</td>\n","      <td>0.603902</td>\n","      <td>38.448708</td>\n","      <td>1951.329102</td>\n","      <td>0.670602</td>\n","      <td>34.569992</td>\n","      <td>1759.945190</td>\n","    </tr>\n","    <tr>\n","      <th>169328</th>\n","      <td>5728c4ee3acd2414000dfdfc_pert_8</td>\n","      <td>15087</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>Sahara</td>\n","      <td>PROPN</td>\n","      <td>0.785786</td>\n","      <td>26.494869</td>\n","      <td>1332.1638</td>\n","      <td>0.845581</td>\n","      <td>...</td>\n","      <td>1143.4348</td>\n","      <td>0.590363</td>\n","      <td>39.155334</td>\n","      <td>1962.003662</td>\n","      <td>0.652857</td>\n","      <td>35.420307</td>\n","      <td>1752.543091</td>\n","      <td>0.687592</td>\n","      <td>32.431366</td>\n","      <td>1612.142700</td>\n","    </tr>\n","    <tr>\n","      <th>19650</th>\n","      <td>56d2706859d6e41400145fdc_pert_9</td>\n","      <td>1711</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>early</td>\n","      <td>ADJ</td>\n","      <td>0.792268</td>\n","      <td>28.209438</td>\n","      <td>1425.7041</td>\n","      <td>0.813935</td>\n","      <td>...</td>\n","      <td>1360.2152</td>\n","      <td>0.535733</td>\n","      <td>45.099018</td>\n","      <td>2284.870605</td>\n","      <td>0.746259</td>\n","      <td>30.683653</td>\n","      <td>1560.639160</td>\n","      <td>0.747319</td>\n","      <td>30.600662</td>\n","      <td>1549.735840</td>\n","    </tr>\n","    <tr>\n","      <th>24049</th>\n","      <td>5a79ce7517ab25001a8a008d_pert_2</td>\n","      <td>2103</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>association</td>\n","      <td>NOUN</td>\n","      <td>0.787099</td>\n","      <td>27.348953</td>\n","      <td>1387.9971</td>\n","      <td>0.827218</td>\n","      <td>...</td>\n","      <td>1267.6790</td>\n","      <td>0.614758</td>\n","      <td>36.791355</td>\n","      <td>1855.655029</td>\n","      <td>0.883322</td>\n","      <td>20.782558</td>\n","      <td>1056.652100</td>\n","      <td>0.829124</td>\n","      <td>24.673475</td>\n","      <td>1255.931519</td>\n","    </tr>\n","    <tr>\n","      <th>136226</th>\n","      <td>570db606df2f5219002ed10c_pert_19</td>\n","      <td>12095</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>construction</td>\n","      <td>NOUN</td>\n","      <td>0.701523</td>\n","      <td>32.152115</td>\n","      <td>1601.0765</td>\n","      <td>0.750750</td>\n","      <td>...</td>\n","      <td>1478.3983</td>\n","      <td>0.500619</td>\n","      <td>44.227001</td>\n","      <td>2232.218262</td>\n","      <td>0.813946</td>\n","      <td>26.210835</td>\n","      <td>1306.556885</td>\n","      <td>0.795464</td>\n","      <td>27.340239</td>\n","      <td>1363.473389</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 36 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c98b09b6-f0b1-48aa-8d47-c85800b37a60')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c98b09b6-f0b1-48aa-8d47-c85800b37a60 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c98b09b6-f0b1-48aa-8d47-c85800b37a60');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":118}],"source":["resultado_comparacao.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"DFMUo8Oo2CJp"},"source":["### 5.3.4 Compacta e copia o arquivo para uma pasta do GoogleDrive\n","\n","Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"7eb_zukpuHq3"},"source":["Compacta o arquivo.\n","\n","Usa o zip para compactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NunMOJWR2O8H"},"outputs":[],"source":["!zip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_CONTEXTO\""]},{"cell_type":"markdown","metadata":{"id":"49_9c2P2nrOx"},"source":["Copia o arquivo  para o GoogleDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LqDBH5pUnrOx"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","    # Copia o arquivo das comparações para o google drive\n","    !cp \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO\" \"$DIRETORIO_DRIVE\"\n","\n","    logging.info(\"Terminei a cópia do arquivo.\")"]},{"cell_type":"markdown","metadata":{"id":"3EUXuiZNpBtL"},"source":["# Tempo final de processamento\n","\n","\n","20 = Tempo processamento:  3:25:43 (h:mm:ss)\n","100 = Tempo processamento:  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H50_GKJwpDha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660760540356,"user_tz":180,"elapsed":10,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7fb2e309-6824-4e04-cc0d-f6b6923ad4f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento:  3:25:43 (h:mm:ss)\n"]}],"source":["# Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempo_total_processamento))"]}],"metadata":{"colab":{"provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2a36b0b79b844dbaa227bc30d5fc4397":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e6a2c9ea8514926a6969f839d1cfb63","IPY_MODEL_b20b28b12a7d45e8b217e228ce32a3cb","IPY_MODEL_9bf85a276836436c85ae6ccb32655e14"],"layout":"IPY_MODEL_18bfdb309f9141adbc3861f290ff95a0"}},"8e6a2c9ea8514926a6969f839d1cfb63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d31a142057949ad94265fd1a44d5c1a","placeholder":"​","style":"IPY_MODEL_38fd6f4ac01642a5aa70303f9f01ff01","value":"100%"}},"b20b28b12a7d45e8b217e228ce32a3cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f9b8f754cad4443a46fabf2fe348093","max":777388222,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5c3533be57c4b19878fe5b30103310a","value":777388222}},"9bf85a276836436c85ae6ccb32655e14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a80a6c520b04759ad8d03397bd57665","placeholder":"​","style":"IPY_MODEL_1f0ef954cc5f4e9eaf3bc4575cf9c71e","value":" 777M/777M [02:04&lt;00:00, 5.84MB/s]"}},"18bfdb309f9141adbc3861f290ff95a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d31a142057949ad94265fd1a44d5c1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38fd6f4ac01642a5aa70303f9f01ff01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f9b8f754cad4443a46fabf2fe348093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5c3533be57c4b19878fe5b30103310a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a80a6c520b04759ad8d03397bd57665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f0ef954cc5f4e9eaf3bc4575cf9c71e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e1d94ad09f245e3b780a35266dd242e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93b22eaae1b441558f04c97bef5bd448","IPY_MODEL_cb661d27585c405ea5781ec862c6ba7d","IPY_MODEL_2c8cf1a3a9cb4b999a034edd14435793"],"layout":"IPY_MODEL_0e46ad3b1d9d4892a86fd0a8c2e22b21"}},"93b22eaae1b441558f04c97bef5bd448":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a6db49d3a3d4ba19283cf10b0498a63","placeholder":"​","style":"IPY_MODEL_93ccada0e4364ecab907cd6cc8a6c921","value":"Downloading: 100%"}},"cb661d27585c405ea5781ec862c6ba7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_beac9bc26a76483cbdbe1d7679787af1","max":762,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83c5c9c32c2543e295a22ee89f7d1f9b","value":762}},"2c8cf1a3a9cb4b999a034edd14435793":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c006ae7b43ef469a947a6d6ab3be2e5a","placeholder":"​","style":"IPY_MODEL_4514d7f4f75d4318bb88548bc1637769","value":" 762/762 [00:00&lt;00:00, 20.6kB/s]"}},"0e46ad3b1d9d4892a86fd0a8c2e22b21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a6db49d3a3d4ba19283cf10b0498a63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93ccada0e4364ecab907cd6cc8a6c921":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beac9bc26a76483cbdbe1d7679787af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83c5c9c32c2543e295a22ee89f7d1f9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c006ae7b43ef469a947a6d6ab3be2e5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4514d7f4f75d4318bb88548bc1637769":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f644915a68d4399bc7eb66ac7d573af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a9e4b55cfad46058c8fd8d749b39284","IPY_MODEL_c1f07abbc1794a6d974a39c29633aba2","IPY_MODEL_eb5f8e5d527a4d718c99215833c732a4"],"layout":"IPY_MODEL_cd5cf1797b944243af63468bafcff9fe"}},"8a9e4b55cfad46058c8fd8d749b39284":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b5cc195c1cc4be4af9ea44d135c3d09","placeholder":"​","style":"IPY_MODEL_fd0a84d3743e45999706131023f50f70","value":"Downloading: 100%"}},"c1f07abbc1794a6d974a39c29633aba2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83320fdc59774a48b977f4dc8a9ee842","max":1338740706,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa594b46702045f7990f4c012f2f1c12","value":1338740706}},"eb5f8e5d527a4d718c99215833c732a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91fe1e8cd2774d4cbb9b83dfd29c9ebe","placeholder":"​","style":"IPY_MODEL_75c66700c0a54a699a7ee51b74055cba","value":" 1.34G/1.34G [01:40&lt;00:00, 11.4MB/s]"}},"cd5cf1797b944243af63468bafcff9fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b5cc195c1cc4be4af9ea44d135c3d09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd0a84d3743e45999706131023f50f70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83320fdc59774a48b977f4dc8a9ee842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa594b46702045f7990f4c012f2f1c12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91fe1e8cd2774d4cbb9b83dfd29c9ebe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75c66700c0a54a699a7ee51b74055cba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be34fae4846c44e4a26bea269b869142":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e470fb5bcc048af93df89a1608f3aad","IPY_MODEL_8810a46f27424a7599cb4330fbec2961","IPY_MODEL_6f32e9eaba4c4d928bd9111a3e4c018c"],"layout":"IPY_MODEL_2e8b70f34b8b499f82eeac694da53a35"}},"3e470fb5bcc048af93df89a1608f3aad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd6f756c0cff42d5826931726e33b58b","placeholder":"​","style":"IPY_MODEL_4b21454ab17347939066816a3f7e203c","value":"Downloading: 100%"}},"8810a46f27424a7599cb4330fbec2961":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c1a31da62d4c41b1dd09fb1cce9dbe","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d506bb68ac2b40fba26accaaa43dd722","value":213450}},"6f32e9eaba4c4d928bd9111a3e4c018c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5523936bd34b4a288f9d91180b4a0911","placeholder":"​","style":"IPY_MODEL_77604daa81154489a8539afbef630322","value":" 213k/213k [00:00&lt;00:00, 276kB/s]"}},"2e8b70f34b8b499f82eeac694da53a35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd6f756c0cff42d5826931726e33b58b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b21454ab17347939066816a3f7e203c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08c1a31da62d4c41b1dd09fb1cce9dbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d506bb68ac2b40fba26accaaa43dd722":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5523936bd34b4a288f9d91180b4a0911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77604daa81154489a8539afbef630322":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cfbe400a7de48ddb867148991ca3c67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3e6ffcbdb034dd0b57adc24333889b4","IPY_MODEL_2ec7e59177174f5682a1727acf5ff900","IPY_MODEL_86990a969b574fd6b1ff49f95fb0c458"],"layout":"IPY_MODEL_5c6f61c0131e40029d202e5c824163a4"}},"c3e6ffcbdb034dd0b57adc24333889b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8107c820d64e477cbed413e255e88f94","placeholder":"​","style":"IPY_MODEL_c77d58c2fe0b4944bbdd9f6b5081dc06","value":"Downloading: 100%"}},"2ec7e59177174f5682a1727acf5ff900":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da7c81835e4b47a3b2148ad9350acc1a","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0896f3299b454588b3052efd5609f561","value":29}},"86990a969b574fd6b1ff49f95fb0c458":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba296be0c5c34534818910aa8a7a205f","placeholder":"​","style":"IPY_MODEL_ffb3b76f790c48b4a366689d5dd5fb0b","value":" 29.0/29.0 [00:00&lt;00:00, 541B/s]"}},"5c6f61c0131e40029d202e5c824163a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8107c820d64e477cbed413e255e88f94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c77d58c2fe0b4944bbdd9f6b5081dc06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da7c81835e4b47a3b2148ad9350acc1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0896f3299b454588b3052efd5609f561":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba296be0c5c34534818910aa8a7a205f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffb3b76f790c48b4a366689d5dd5fb0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0eacfb3d8d2545b48c460616f889ff20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a56f361817a4bff9c61f8521d23a58f","IPY_MODEL_ae1bd06de5b848f59c4811c4968ebb69","IPY_MODEL_49c23e6e84af43fd92d888741343ce36"],"layout":"IPY_MODEL_cf39055d20584aae8f0bb9ebd37c33c4"}},"9a56f361817a4bff9c61f8521d23a58f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62b35a0b042445d7ac40587960724981","placeholder":"​","style":"IPY_MODEL_fef89090c1e948628e5638a92b5e3536","value":"Downloading: 100%"}},"ae1bd06de5b848f59c4811c4968ebb69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb0aefce27b2405baf17a59b6037548d","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c59b60c6ee264ce498a15f4ca4c7b37b","value":435797}},"49c23e6e84af43fd92d888741343ce36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8726dd29f04f4cd2b3454baa744359a4","placeholder":"​","style":"IPY_MODEL_767fa111ce6d4c89b0b0366266b3f791","value":" 436k/436k [00:00&lt;00:00, 628kB/s]"}},"cf39055d20584aae8f0bb9ebd37c33c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b35a0b042445d7ac40587960724981":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fef89090c1e948628e5638a92b5e3536":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb0aefce27b2405baf17a59b6037548d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c59b60c6ee264ce498a15f4ca4c7b37b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8726dd29f04f4cd2b3454baa744359a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"767fa111ce6d4c89b0b0366266b3f791":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31e05142599d49e9a539e4f981496b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ee7020b74de4719a144da00f89c3a8c","IPY_MODEL_b442b54ccffe4c54a672f8f54f8ad10f","IPY_MODEL_90a6603cd2014eb79e6bb31e7a5b28b6"],"layout":"IPY_MODEL_c2d9fa4d3fd64cbe9a4d7554d3a9ba50"}},"7ee7020b74de4719a144da00f89c3a8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4be811066d374908b022b3a828256c58","placeholder":"​","style":"IPY_MODEL_25dbc2d82fc742b1a5fef9a46cf54dc6","value":"Documentos: 100%"}},"b442b54ccffe4c54a672f8f54f8ad10f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d758ee06f3c64f18b030054b96c27c87","max":1419,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35f129dc843a42c695d447f75415ef48","value":1419}},"90a6603cd2014eb79e6bb31e7a5b28b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0293f7aee61b4afe80012d995ba6fdf3","placeholder":"​","style":"IPY_MODEL_ad8e23f6405f4c3bbecb92fa1a4b54e0","value":" 1419/1419 [00:02&lt;00:00, 580.14 documento/s]"}},"c2d9fa4d3fd64cbe9a4d7554d3a9ba50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4be811066d374908b022b3a828256c58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25dbc2d82fc742b1a5fef9a46cf54dc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d758ee06f3c64f18b030054b96c27c87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35f129dc843a42c695d447f75415ef48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0293f7aee61b4afe80012d995ba6fdf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad8e23f6405f4c3bbecb92fa1a4b54e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89970b00ef1c46c5b5dd7814f8618bf1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_028f080fbb244e21acb77663011d2e7a","IPY_MODEL_b3b8edd6b5b64960b0a5220dd17c7545","IPY_MODEL_2d3f49ad96ec4637b4591303a87f88bc"],"layout":"IPY_MODEL_3a6651c72d21461a8228ed68b8273f3f"}},"028f080fbb244e21acb77663011d2e7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec0f86d0da574d54bdfb351f876c0dab","placeholder":"​","style":"IPY_MODEL_896a3cfa62e24bba90a974aa4ab73dcf","value":"Documentos: 100%"}},"b3b8edd6b5b64960b0a5220dd17c7545":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a85d62b4a25f4265adc21392d5bef1eb","max":29799,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6cd8d12875849f49459c1449280a4c3","value":29799}},"2d3f49ad96ec4637b4591303a87f88bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b1bfe7b9b944d0ab43739c4b2c23ccd","placeholder":"​","style":"IPY_MODEL_7e0a4c52547c4ae88384737480c44630","value":" 29799/29799 [3:18:49&lt;00:00,  2.79 documento/s]"}},"3a6651c72d21461a8228ed68b8273f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec0f86d0da574d54bdfb351f876c0dab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"896a3cfa62e24bba90a974aa4ab73dcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a85d62b4a25f4265adc21392d5bef1eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6cd8d12875849f49459c1449280a4c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b1bfe7b9b944d0ab43739c4b2c23ccd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e0a4c52547c4ae88384737480c44630":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}