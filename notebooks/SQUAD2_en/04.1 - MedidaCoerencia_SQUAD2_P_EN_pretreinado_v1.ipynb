{"cells":[{"cell_type":"markdown","metadata":{"id":"78HE8FLsKN9Q"},"source":["# Avaliação de Medidas (In)Coerência do conjunto de dados SQUAD 2 P(1,0%) EN usando BERT Pré-treinado\n","\n","Este notebook, realiza testes de medidas de (in)coerência entre pares de documentos do conjunto de dados SQUAD 2 utilizando BERT Pré-treinado. \n","\n","A medida de um documento(D) é realizada pela média da medida dos pares de palavras. Todo o documento é submetido ao BERT e os embeddings da concatenação das 4 últimas camadas é recuperado. Cada documento é analisado pelas medidas **Ccos**, **Ceuc** e **Cman**. Estas medidas de documento utilizam as medidas de palavras adjancentes.Cada par de palavras do documento é analisado utilizando os embedding da palavra\n","(**wi**) e os embeddings da palavra(**wj**) no documento.\n","\n","As seguintes medidas foram calculadas entre os embeddings das sentenças **wi** e **wj**:\n","- **Scos(wi,wj)** - Similaridade do cosseno entre a média dos embeddings Si e Sj.\n","- **Seuc(wi,wj)** - Distância euclidiana - usando a média dos embeddings Si e Sj das camadas especificadas\n","- **Sman(wi,wj)** - Distância de manhattan - usando a média dos embeddings wi e wj das camadas especificadas\n","\n","As medidas são avalidas considerando a concatenação das 4 últimas do modelo BERT.\n","\n","Características dos testes:\n"," - A avaliação das medidas são realizadas utilizando a implementação BERT da biblioteca Huggingface e os MCL BERT **Pré-treinado** no formato cased:\n","  - BERT de tamanho Large \n","  \n"," - Não é realizado ajuste fino do modelo.\n","\n","Utiliza os arquivos para gerar as medidas:\n","- `original.zip`\n","- `originalpos.zip`\n","- `perturbado_pX_kY.zip`\n","- `perturbadopos_pX_kY.zip`\n","- `comparacao_palavra_pX_kY.zip`\n","- `comparacao_contexto_pX_kY.zip`\n","\n","Nos nomes dos arquivos, `X` é o número de documentos perturbados e `Y` o valor de top `K` predições. \n","\n","----------------------------\n","\n","**Link biblioteca Transformers:**\n","https://github.com/huggingface/transformers\n","\n","\n","**Artigo original BERT:**\n","https://arxiv.org/pdf/1506.06724.pdf"]},{"cell_type":"markdown","metadata":{"id":"xyxb5Px3p1-e"},"source":["# 1 Preparação do ambiente\n","Preparação do ambiente para execução do exemplo."]},{"cell_type":"markdown","metadata":{"id":"cW_5CN8En7zl"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcTEKloUn-VK"},"outputs":[],"source":["# Import das bibliotecas\n","import time\n","import datetime\n","\n","#marca o tempo de início do processamento.\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj5TaAH_5-nB"},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================  \n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.    \n","    \"\"\"\n","    \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):  \n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","    \n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B1mvfAU5jZf"},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"    \n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","    \n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.      \n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.      \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","    \n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download    \n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]  \n","\n","    # Define o nome e caminho do arquivo temporário    \n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","    \n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","    \n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:        \n","        tamanho_conteudo = data.headers.get(\"Content-Length\")        \n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)                \n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):        \n","            if chunk:                \n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","    \n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","    \n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qwKjGvyLG4v"},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","    \n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jirIzIstLea0"},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.  \n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC9Xppq-_R0w"},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.   \n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    sentencas = []\n","    for linha in arquivo:        \n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkVk5LQT_G3f"},"outputs":[],"source":["def salvar(nome_arquivo,texto):                       \n","    \"\"\"\n","      Salva um texto em arquivo.\n","     \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.     \n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Guy6B4whsZFR"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","    \n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))    "]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModeloArgumentosMedida) de definição dos parâmetros do modelo para medida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgmN6RqDRDZS"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={'help': 'max seq len'},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default='neuralmind/bert-base-portuguese-cased',\n","        metadata={'help': 'nome do modelo pré-treinado do BERT.'},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={'help': 'define se o texto do modelo deve ser todo em minúsculo.'},\n","    )  \n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita se o modelo retorna os pesos de atenção.'},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita gerar as camadas ocultas do modelo.'},\n","    )\n","    use_wandb : bool = field(\n","        default=True,\n","        metadata={'help': 'habilita o uso do wandb.'},\n","    )\n","    salvar_avaliacao : bool = field(\n","        default=True,\n","        metadata={'help': 'habilita o salvamento do resultado da avaliação.'},\n","    )     \n","    salvar_medicao : bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o salvamento da medicao.'},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o carragamento de mcl ajustado.'},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    estrategia_medida: int = field(\n","        default=0, # 0 - MEAN estratégia média / 1 - MAX  estratégia maior\n","        metadata={'help': 'Estratégia de cálculo da médida dos embeddings.'},\n","    )\n","    filtro_palavra: int = field(\n","        default=0, # 0 - Considera todas as palavras das sentenças / 1 - Desconsidera as stopwords / 2 - Considera somente as palavras substantivas\n","        metadata={'help': 'Define o filtro de palavras das sentenças para gerar os embeddings.'},\n","    )"]},{"cell_type":"markdown","metadata":{"id":"HIN413rj50EI"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxV4-3Yg50EI"},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcopxbGZqDip"},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4  Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMiH0E3OnRa1"},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtaYZmc3Vbfj"},"outputs":[],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrjqDO6nWa8J"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","\n","def getDeviceGPU():\n","    \"\"\"\n","      Retorna um dispositivo de GPU se disponível ou CPU.\n","    \n","      Retorno:\n","        `device` - Um device de GPU ou CPU.       \n","    \"\"\"\n","        \n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        \n","        # Diz ao PyTorch para usar GPU.    \n","        device = torch.device(\"cuda\")\n","        \n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:        \n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","        \n","    return device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChDxmtXsKwjf"},"outputs":[],"source":["# Recupera o device com GPU ou CPU\n","device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"fGf59D0yVNx9"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1iC5-pSAVh7_"},"outputs":[],"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysnDDapMQK8K"},"outputs":[],"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejzpgGrFM0-j"},"outputs":[],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"oOd2MbBiDq93"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaMM4WdxgvQ7"},"outputs":[],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4p3Rz2qDq94"},"outputs":[],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1RfUN_KolV-f"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.9 Instalação do BERT"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face. \n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCVzCmy7pIOz"},"outputs":[],"source":["!pip install -U transformers==4.5.1"]},{"cell_type":"markdown","metadata":{"id":"giOsAS5v61go"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uiH9pNpwI6g"},"outputs":[],"source":["# Nome base das saidas do projeto\n","# Falta corrigir o nome para Squad2\n","NOME_BASE_SAIDA = \"MedidaCoerenciaSquad2_P_EN_v1\"\n","\n","# Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 1\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 1\n","\n","# Equação de coerência (0 - Palavras adjacentes / 1 - Combinação de todas as palavras / 2 - Palavra e contexto) \n","EQUACAO_MEDIDA_STR = [\"ADJACENTES\",\"COMBINAÇÃO\",\"CONTEXTO\"]\n","EQUACAO_MEDIDA = [0, 1, 2]\n","\n","# Estratégias a serem avaliadas (0 - Mean / 1 - Max) para as palavras formadas por mais de um token do BERT\n","ESTRATEGIA_MEDIDA_STR = [\"MEAN\", \"MAX\"]\n","ESTRATEGIA_MEDIDA = [0, 1]\n","\n","# Filtro de palavras das sentenças[0,1,2] 'TAP,SSW,SVS'\n","FILTRO_PALAVRAS_STR = [\"TODAS_AS_PALAVRAS\", \n","                       \"SEM_STOPWORDS\",                        \n","                       \"SOMENTE_VERBOS_SUBSTANTIVOS\"]\n","FILTRO_PALAVRAS = [0, 1, 2]"]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"Mhkc9sW21zV7"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Definição dos parâmetros do Modelo\n","model_args = ModeloArgumentosMedida(     \n","    max_seq_len = 512,    \n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",\n","    \n","    pretrained_model_name_or_path = \"bert-large-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-cased\"\n","    #pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",    \n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","\n","    modelo_spacy = \"en_core_web_lg\",\n","    #modelo_spacy = \"en_core_web_md\",\n","    #modelo_spacy = \"en_core_web_sm\",\n","    #modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","    \n","    versao_modelo_spacy = \"3.2.0\",\n","    do_lower_case = False,  # default True\n","    output_attentions = False,  # default False\n","    output_hidden_states = True, # default False\n","    use_wandb = True,    \n","    salvar_medicao = True, #Salva o resultado da medição\n","    salvar_avaliacao = True, # Salva o resultado da avaliação das medições\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path. \n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100, 500 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","    estrategia_medida = 0, # Atributo usado para os logs do wandb. 0 - MEAN estratégia média / 1 - MAX  estratégia maior\n","    filtro_palavra = 0, # Atributo usado para os logs do wandb. 0 - Considera todas as palavras das sentenças / 1 - Desconsidera as stopwords / 2 - Considera somente as palavras substantivas\n",")"]},{"cell_type":"markdown","metadata":{"id":"WlF4PKP6Iopi"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55PNP2s6Iopi"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"SQUAD2_P_EN\""]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"tDgJTbPOZ8SW"},"source":["## Inicialização diretórios"]},{"cell_type":"markdown","metadata":{"id":"qpSERA9TC4WU"},"source":["Diretório base local"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edg7eW2cDflg"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","def criaDiretorioLocal():\n","\n","  # Cria o diretório para receber os arquivos Originais e Permutados\n","  # Diretório a ser criado\n","  dirbase = DIRETORIO_LOCAL[:-1]\n","\n","  if not os.path.exists(dirbase):  \n","      # Cria o diretório\n","      os.makedirs(dirbase)    \n","      logging.info(\"Diretório criado: {}.\".format(dirbase))\n","  else:    \n","      logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xge0ar9MJoKy"},"outputs":[],"source":["criaDiretorioLocal()"]},{"cell_type":"markdown","metadata":{"id":"4FmT9nhbaE3D"},"source":["Diretório para conter as os resultados das medidas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zO76uzj_C3zQ"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioMedidacao():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"/validacao_medicao_palavra\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1Ot2h_bJuxy"},"outputs":[],"source":["criaDiretorioMedidacao()"]},{"cell_type":"markdown","metadata":{"id":"vIkT6ksqaQs3"},"source":["Diretório para conter os arquivos da avaliação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIV4xj6zDnb8"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioAvaliacao():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_medicao_palavra/Avaliacao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiOVjJ5BJzE1"},"outputs":[],"source":["criaDiretorioAvaliacao()"]},{"cell_type":"markdown","metadata":{"id":"cjP6v878aWR7"},"source":["Diretório para conter os arquivos das medidas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qf6UWAZYDsgm"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioMedicao():\n","\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_medicao_palavra/Medicao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IBBfHFuPJ3NM"},"outputs":[],"source":["criaDiretorioMedicao()"]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjWGu-9D5URZ"},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","        \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dq9PnXO77bPQ"},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    \n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivoTar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")    \n","    arquivoTar.extractall(DIRETORIO_COHEBERT)    \n","    arquivoTar.close()\n","    \n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):        \n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePOccj0s8WMg"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","    \n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.           \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","                  \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp "]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbELnrpgA4T1"},"outputs":[],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","metadata":{"id":"AEzytjZi5Iw2"},"source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKg-_XyWoy8o"},"outputs":[],"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","    \n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.           \n","    \"\"\"\n","    \n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords "]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1o8jevtoy8p"},"outputs":[],"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hdqVdfxm-_W"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy   \n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                                  \n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar   \n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ] \n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [               \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                   \n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal       \n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ] \n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}}, \n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar \n","               ] \n","\n","matcherv = Matcher(nlp.vocab)\n","         \n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):    \n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","  \n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","  \n","  return lista2"]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = dict()\n","  \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades    \n","  novodic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","    \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9SA61kD6sJY"},"outputs":[],"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","    \n","  # Soma os dicionários da lista\n","  novodic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n"," \n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWxyAo54AOHU"},"outputs":[],"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.text)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gvd99wd_pwmt"},"outputs":[],"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  listatokens = []\n","  listapos = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:    \n","    listatokens.append(token.text)\n","    listapos.append(token.pos_)\n","    \n","  return listatokens, listapos"]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpCUpOs06sJY"},"outputs":[],"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","  \n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\" \n","  return traduzido"]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMb0uDWzKZXP"},"outputs":[],"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxTCYFzcJZD6"},"outputs":[],"source":["def getSentencaSalientePOS(sentenca, pos, classe_saliente=[\"NOUN\"]):\n","  \n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especificado\n","    if pos[i] in classe_saliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"s07wG9F-qHOc"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkBatgxjqHOc"},"outputs":[],"source":["def removeStopWord(documento, stopwords):\n","  \n","  # Remoção das stopwords do documento\n","  documentoSemStopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documentoSemStopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"]},{"cell_type":"markdown","metadata":{"id":"khTFfBVbnsx9"},"source":["# 4 Funções auxiliares"]},{"cell_type":"markdown","metadata":{"id":"RZxAhgEI7KVs"},"source":["## getNomeModeloBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Huw0x5kt1Le"},"outputs":[],"source":["def getNomeModeloBERT(model_args):\n","    '''    \n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","    \n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"        \n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","        else:\n","            if 'bert' in model_args.pretrained_model_name_or_path:\n","                MODELO_BERT = \"_BERT\"  \n","            \n","    return MODELO_BERT"]},{"cell_type":"markdown","metadata":{"id":"Dyp6vN2l7L54"},"source":["## getTamanhoBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYJB4ik7t5xe"},"outputs":[],"source":["def getTamanhoBERT(model_args):\n","    '''    \n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","    \n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","    \n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","        \n","    return TAMANHO_BERT  "]},{"cell_type":"markdown","metadata":{"id":"lCJzsw8T0I-5"},"source":["## concatenaListas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpmDZ1mI0JHR"},"outputs":[],"source":["def concatenaListas(lista, pos=1):\n","  lista_concat = []\n","\n","  for x in lista:\n","      lista_concat = lista_concat + x[pos]\n","  \n","  return lista_concat"]},{"cell_type":"markdown","metadata":{"id":"3wvgXwN81RCz"},"source":["## encontrarIndiceSubLista \n","\n","Retorna os índices de início e fim da sublista na lista"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zI_n9hMgqHOi"},"outputs":[],"source":["# Localiza os índices de início e fim de uma sublista em uma lista\n","def encontrarIndiceSubLista(lista, sublista):\n","\n","    \"\"\"\n","      Localiza os índices de início e fim de uma sublista em uma lista.\n","    \n","      Parâmetros:\n","      `lista` - Uma lista.\n","      `sublista` - Uma sublista a ser localizada na lista.\n","    \"\"\"    \n","    # https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n","\n","    # Recupera o tamanho da lista \n","    h = len(lista)\n","    # Recupera o tamanho da sublista\n","    n = len(sublista)    \n","    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n","    i = n - 1\n","    while i < h:\n","        for j in range(n):\n","            if lista[i - j] != sublista[-j - 1]:\n","                i += skip.get(lista[i], n)\n","                break\n","        else:\n","            indice_inicio = i - n + 1\n","            indice_fim = indice_inicio + len(sublista)-1\n","            return indice_inicio, indice_fim\n","    return -1, -1"]},{"cell_type":"markdown","metadata":{"id":"qlZRwLGTq_r_"},"source":["# 5 Comparar documentos\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OimJrCug6f_-"},"source":["## 5.1 Carregamento dos arquivos de dados originais"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["### 5.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cpoPWweP9FMA"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"Y9BJwUYlJJmc"},"source":["### 5.1.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGIdHG969FMB"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pviuxToMCxQw"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n"," \n","  logging.info(\"Terminei a cópia.\")"]},{"cell_type":"markdown","metadata":{"id":"zgVjfZzJ9FMD"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UK8kJNoh9FMD"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"]},{"cell_type":"markdown","metadata":{"id":"yDymAgyu9FME"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais"]},{"cell_type":"markdown","metadata":{"id":"Usr1uRzQeJSb"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gLMsqXXF9FME"},"outputs":[],"source":["# Importando as bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Cw0Fdak9FMF"},"outputs":[],"source":["lista_documentos_originais.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytG1b5lv9FMG"},"outputs":[],"source":["lista_documentos_originais_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"APsgQVPO9FMG"},"source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qxsQGrh09FMH"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"markdown","source":["#### Criando dados indexados originais"],"metadata":{"id":"8yyRt4jnYxsU"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"],"metadata":{"id":"B9INo4nBS8aQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"],"metadata":{"id":"j70x_r30T_bx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJXcpioo7Bhn"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gB500dmd7Bho"},"outputs":[],"source":["# Abre o arquivo e retorna o DataFrame\n","lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pXGee7H7Bhp"},"outputs":[],"source":["lista_documentos_perturbados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IE1xJdZWkc5I"},"outputs":[],"source":["lista_documentos_perturbados_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"VrfZzjjpsUOU"},"source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHf-7dgSsUOU"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))"]},{"cell_type":"markdown","source":["#### Criando dados indexados perturbados"],"metadata":{"id":"Ix-Q5fZXY3HR"}},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"],"metadata":{"id":"FqRQnYUtSxzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"],"metadata":{"id":"s0aDUbeZT1M8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kq0-NGaC76jP"},"source":["### 5.1.5 Gerando pares de documentos originais e perturbados / Documento Original(1) e Documento Perturbado(0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWUvKfGZ8DMP"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","lista_documentos_agrupados = []\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_originais_bar: \n","  #if i < 2:\n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento_original = linha_documento[0]     \n","    #print(\"id_documento_original:\",id_documento_original)     \n"," \n","    # Carrega a lista das sentenças do documento\n","    lista_sentencas_original = linha_documento[1]    \n","    #print(\"\\lista_sentencas_original:\",lista_sentencas_original)\n","    #print(\"len(lista_sentencas_original):\",len(lista_sentencas_original)) \n","\n","    # Carrega o documento original\n","    documento_original = linha_documento[2]    \n","    #print(\"\\documento_original:\",documento_original)\n","    \n","    # Recupera a POS do documento original\n","    tokens_original = []\n","    tokens_original_pos = []    \n","    reg_original_pos = lista_documentos_originais_pos_indexado.loc[id_documento_original] \n","    # print(\"reg_original_pos:\",reg_original_pos)    \n","    pos_documento_original = reg_original_pos['pos_documento']\n","    for i, linha2 in enumerate(pos_documento_original):\n","      \n","      tokens_original.append(linha2[0])\n","      tokens_original_pos.append(linha2[1])\n","\n","    # Percorre os documentos perturbados apartir do original\n","    for j in range(0, model_args.documentos_perturbados):\n","  \n","        # Id do documento perturbado\n","        id_perturbado = str(id_documento_original) + \"_pert_\" + str(j)\n","        #print(\"id_perturbado:\", id_perturbado)\n","\n","        # Recupera o documento perturbado apartir do id original\n","        reg_documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","        # Recupera a sentença do documento perturbado\n","        lista_sentencas_perturbado = reg_documento_perturbado[\"perturbado\"]\n","        #print(\"\\lista_sentencas_perturbado:\",lista_sentencas_perturbado)\n","        #print(\"len(lista_sentencas_perturbado):\",len(lista_sentencas_perturbado)) \n","\n","        # Carrega o documento perturbado\n","        documento_perturbado = reg_documento_perturbado[2]    \n","        #print(\"\\documento_perturbado:\",documento_perturbado)\n","\n","        # Recupera a POS do documento perturbado\n","        tokens_perturbado = []\n","        tokens_perturbado_pos = []        \n","        reg_perturbado_pos = lista_documentos_perturbados_pos_indexado.loc[id_perturbado]\n","        #print(\"reg_perturbado_pos:\",reg_perturbado_pos)\n","        pos_documento_perturbado = reg_perturbado_pos['pos_documento']\n","        for i, linha2 in enumerate(pos_documento_perturbado):\n","          tokens_perturbado.append(linha2[0])\n","          tokens_perturbado_pos.append(linha2[1])\n","\n","        # Guarda o agrupamento de original e perturbado                \n","        lista_documentos_agrupados.append([id_documento_original, \n","                                           lista_sentencas_original, \n","                                           documento_original, \n","                                           tokens_original, \n","                                           tokens_original_pos, \n","                                           id_perturbado, \n","                                           lista_sentencas_perturbado, \n","                                           documento_perturbado, \n","                                           tokens_perturbado, \n","                                           tokens_perturbado_pos])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"]},{"cell_type":"markdown","metadata":{"id":"THHBPK6Ov8WV"},"source":["#### Converte a lista em um dataframe\n","\n","Atributos do dataframe:\n","Atributos do dataframe:\n","0. 'id_original' - Nome do arquivo original\n","1. 'sentencas_originais' - Lista das sentenças do documento original\n","2. 'documento_original' - Documento original\n","3. 'tokens_original' - Tokens do documento original\n","4. 'pos_original' - Postagging do documento original\n","5. 'id_perturbado' - Nome do arquivo perturbado\n","6. 'sentencas_perturbadas' - Lista das sentenças do documento perturbado\n","7. 'documento_perturbado' - Documento perturbado\n","8. 'tokens_perturbado' - Tokens do documento perturbado\n","9. 'pos_perturbado' - Postagging do documento perturbado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWz4b8Fpv8ki"},"outputs":[],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Converte a lista em um dataframe.\n","lista_documentos_agrupados = pd.DataFrame.from_records(lista_documentos_agrupados, \n","                                                         columns=['id_original',\n","                                                                  'sentencas_original',\n","                                                                  'documento_original',\n","                                                                  'tokens_original',\n","                                                                  'pos_original',\n","                                                                  'id_perturbado',\n","                                                                  'sentencas_perturbado',\n","                                                                  'documento_perturbado',\n","                                                                  'tokens_perturbado', \n","                                                                  'pos_perturbado'])\n","\n","# Número de linhas carregadas do arquivo.\n","logging.info('Total de registros              : {}'.format(len(lista_documentos_agrupados)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3qemxYGwHL7"},"outputs":[],"source":["lista_documentos_agrupados.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"ti5-qQCMA9qz"},"source":["Apaga as listas que não serão mais utilizadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQedeKG1A1xZ"},"outputs":[],"source":["del lista_documentos_originais\n","del lista_documentos_originais_pos\n","del lista_documentos_perturbados\n","del lista_documentos_perturbados_pos"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 5.2 Carregamento do arquivo de dado comparação entre palavras"]},{"cell_type":"markdown","metadata":{"id":"x-72P6oeZv3R"},"source":["### 5.2.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJUJ1oxia6St"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_COMPARACAO_PALAVRA = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"yDpiZYl_aqBR"},"source":["### 5.2.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFYIHcIHE985"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"M_JasFe_Zv3S"},"source":["### 5.2.3 Copia e descompacta os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rp1y9GNvZv3S"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  # Copia o arquivo de comparações do google drive para a diretório local\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\"\n","  \n","  logging.info(\"Terminei a cópia!\")"]},{"cell_type":"markdown","metadata":{"id":"o-JwkAWaSr-O"},"source":["Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWM_i2LaSr-O"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Descompactação realizada!\")"]},{"cell_type":"markdown","metadata":{"id":"SUa-E-R0a6Sv"},"source":["### 5.2.4 Carregamento das lista com os dados do arquivo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie_cJJV9a6Sv"},"outputs":[],"source":["#Biblioteca\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_comparacao_palavra = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_PALAVRA, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_comparacao_palavra)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQwMLwaCef3f"},"outputs":[],"source":["lista_comparacao_palavra.sample(5)"]},{"cell_type":"markdown","source":["### 5.2.5 Criando dados indexados"],"metadata":{"id":"08xModMIawfM"}},{"cell_type":"code","source":["# Faz uma cópia da lista não indexada\n","lista_comparacao_palavra_indexado = lista_comparacao_palavra.copy()\n","\n","# Expecifica o(s) campo(s) indexado(s)\n","lista_comparacao_palavra_indexado.set_index([\"id\", \"index_sentenca\", \"index_wi\", \"index_wj\"], inplace=True)\n","lista_comparacao_palavra_indexado.head()"],"metadata":{"id":"O0VlVLaJawfN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PSUgg524GTBo"},"source":["## 5.3 Carregamento do arquivo de dado comparação palavra e contexto"]},{"cell_type":"markdown","metadata":{"id":"aBRH9C3NGTBp"},"source":["### 5.3.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOJlmqKMGTBp"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_COMPARACAO_CONTEXTO = \"comparacao_contexto_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO = \"comparacao_contexto_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"IpmrXElxjFGZ"},"source":["### 5.3.2 Cria o diretório local para receber os dados\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ68voAdGTBp"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"I3rgdeCtGTBp"},"source":["### 5.3.3 Copia e descompacta os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5UzdVhwGTBq"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  # Copia o arquivo de comparações do google drive para a diretório local\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO\"\n","  \n","  logging.info(\"Terminei a cópia!\")"]},{"cell_type":"markdown","metadata":{"id":"mjdzgaD1GTBq"},"source":["Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QeeLwYMGTBq"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Descompactação realizada!\")"]},{"cell_type":"markdown","metadata":{"id":"eZTMYab5GTBq"},"source":["### 5.3.4 Carregamento das lista com os dados do arquivo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnD5ztw_GTBq"},"outputs":[],"source":["#Biblioteca\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_comparacao_contexto = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_CONTEXTO, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_comparacao_contexto))) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBIUSgwdGTBq"},"outputs":[],"source":["lista_comparacao_contexto.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"kXtflYPwsUwC"},"source":["Remove as pontuações"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xbXWB5uOrvrs"},"outputs":[],"source":["#lista_comparacao_contexto = lista_comparacao_contexto.query('posi != \"PUNCT\"')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzb1y13KsAS9"},"outputs":[],"source":["lista_comparacao_contexto.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W35NM_Swa6Sv"},"outputs":[],"source":["lista_comparacao_contexto.sample(5)"]},{"cell_type":"markdown","source":["### 5.3.5 Criando dados indexados"],"metadata":{"id":"EpE8R006bPr9"}},{"cell_type":"code","source":["# Faz uma cópia da lista não indexada\n","lista_comparacao_contexto_indexado = lista_comparacao_contexto.copy()\n","\n","# Expecifica o(s) campo(s) indexado(s)\n","lista_comparacao_contexto_indexado.set_index([\"id\", \"index_sentenca\", \"index_wi\"], inplace=True)\n","lista_comparacao_contexto_indexado.head()"],"metadata":{"id":"_o7sMOkEbPr-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"geCGsyphNfkK"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"3EUXuiZNpBtL"},"source":["## 6.1 Tempo final de processamento\n","\n","100 - Tempo processamento:  12:07:06  (h:mm:ss)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H50_GKJwpDha"},"outputs":[],"source":[" # Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print('')\n","print('  Tempo processamento:  {:} (h:mm:ss)'.format(tempo_total_processamento))"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1Er23iD96x_SzmRG8md1kVggbmz0su_Q5","timestamp":1602332127662}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}