{"cells":[{"cell_type":"markdown","metadata":{"id":"1JNgd_Bc55AB"},"source":["# Análise do Classificador KFold e conjunto de dados FaQuAD\n","\n","Realiza a análise do classificador binário kfold utilizando BERT no conjunto de dados FaQuAD que alcançou a melhor acurácia.\n","\n","Utiliza os arquivos resultantes da classificação kfold de `X` documentos perturbados e `Y` top K predições com a melhor acurácia de classificação.\n","\n","Classes:\n","- 1 - Documento original\n","- 0 - Documento perturbado\n","\n","----------------------------\n","\n","**Link biblioteca Transformers:**\n","https://github.com/huggingface/transformers\n","\n","**Artigo original BERT:**\n","https://arxiv.org/pdf/1506.06724.pdf\n"]},{"cell_type":"markdown","metadata":{"id":"9PGD3v3GDd0A"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"uaK6jWHcDd0B"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1660932369419,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"WdljRvJtDd0B"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"85FAzQcQDd0B"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"aV_80dO7Dd0B"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1660932369420,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"APzEyr_IDd0B"},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================  \n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.    \n","    \"\"\"\n","    \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):  \n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","    \n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"aqpK2s2sDd0B"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1660932369420,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"wc0ThDowDd0C"},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"    \n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","    \n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.      \n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.      \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","    \n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download    \n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]  \n","\n","    # Define o nome e caminho do arquivo temporário    \n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","    \n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","    \n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:        \n","        tamanho_conteudo = data.headers.get(\"Content-Length\")        \n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)                \n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):        \n","            if chunk:                \n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","    \n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","    \n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"K2-UVODUDd0C"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1660932369421,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"aE1ROeerDd0C"},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","    \n","    import re\n","\n","    documento_limpo = re.compile(\"\u003c.*?\u003e\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"UQzi3M0QDd0C"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1660932369421,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"EUVy16q3Dd0C"},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.  \n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1660932369422,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"gIl8D0KhDd0C"},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.   \n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","    \n","    sentencas = []\n","    for linha in arquivo:        \n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1660932369422,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"gNtG46NoDd0D"},"outputs":[],"source":["def salvar(nome_arquivo,texto):                       \n","    \"\"\"\n","      Salva um texto em arquivo.\n","     \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.     \n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"NGnFHmL7Dd0D"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1660932369423,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"hiiUwladDd0D"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","    \n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))    "]},{"cell_type":"markdown","metadata":{"id":"wDMe4LLFDd0D"},"source":["Calcula a média de uma lista tempo string no formato hh:mm:ss."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1660932369423,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ziT8qSfdDd0D"},"outputs":[],"source":["# Import das bibliotecas.\n","from cmath import rect, phase\n","from math import radians, degrees\n","  \n","def mediaAngulo(deg):\n","    return degrees(phase(sum(rect(1, radians(d)) for d in deg)/len(deg)))\n"," \n","def mediaTempo(tempos):\n","    '''\n","    Calcula a média de uma lista de tempo string no formato hh:mm:ss\n","    '''\n","    t = (tempo.split(':') for tempo in tempos)\n","    # Converte para segundos\n","    segundos = ((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)\n","    # Verifica se deu algum dia\n","    dia = 24 * 60 * 60\n","    # Converte para angulos\n","    para_angulos = [s * 360. / dia for s in segundos]\n","    # Calcula a média dos angulos\n","    media_como_angulo = mediaAngulo(para_angulos)\n","    media_segundos = media_como_angulo * dia / 360.\n","    if media_segundos \u003c 0:\n","        media_segundos += dia\n","    # Recupera as horas e os minutos  \n","    h, m = divmod(media_segundos, 3600)\n","    # Recupera os minutos e os segundos\n","    m, s = divmod(m, 60)    \n","    return '{:02d}:{:02d}:{:02d}'.format(int(h), int(m), int(s))"]},{"cell_type":"markdown","metadata":{"id":"8xVcthrRDd0D"},"source":["Calcula a soma de uma lista de tempo string no formato hh:mm:ss"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1660932369424,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"FQKhP8r6Dd0D"},"outputs":[],"source":["def somaTempo(tempos):\n","    '''\n","    Calcula a soma de uma lista de tempo string no formato hh:mm:ss\n","    '''\n","    t = (tempo.split(':') for tempo in tempos)\n","    # Converte para segundos\n","    segundos = ((float(s) + int(m) * 60 + int(h) * 3600) for h, m, s in t)\n","    # Soma os segundos\n","    soma_segundos = sum([s * 1. for s in segundos])\n","    # Recupera as horas e os minutos   \n","    h, m = divmod(soma_segundos, 3600)\n","    # Recupera os minutos e os segundos\n","    m, s = divmod(m, 60)    \n","    return '{:02d}:{:02d}:{:02d}'.format(int(h), int(m), int(s))"]},{"cell_type":"markdown","metadata":{"id":"K4o6ZzAMDd0E"},"source":["Classe(ModeloArgumentosMedida) de definição dos parâmetros do modelo para medida"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1660932369424,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ZqzKCM7hDd0E"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={'help': 'max seq len'},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default='neuralmind/bert-base-portuguese-cased',\n","        metadata={'help': 'nome do modelo pré-treinado do BERT.'},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={'help': 'define se o texto do modelo deve ser todo em minúsculo.'},\n","    )  \n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita se o modelo retorna os pesos de atenção.'},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita gerar as camadas ocultas do modelo.'},\n","    )\n","    use_wandb : bool = field(\n","        default=True,\n","        metadata={'help': 'habilita o uso do wandb.'},\n","    )\n","    salvar_avaliacao : bool = field(\n","        default=True,\n","        metadata={'help': 'habilita o salvamento do resultado da avaliação.'},\n","    )     \n","    salvar_medicao : bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o salvamento da medicao.'},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o carragamento de mcl ajustado.'},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )\n","    estrategia_medida: int = field(\n","        default=0, # 0 - MEAN estratégia média / 1 - MAX  estratégia maior\n","        metadata={'help': 'Estratégia de cálculo da médida dos embeddings.'},\n","    )\n","    filtro_palavra: int = field(\n","        default=0, # 0 - Considera todas as palavras das sentenças / 1 - Desconsidera as stopwords / 2 - Considera somente as palavras substantivas\n","        metadata={'help': 'Define o filtro de palavras das sentenças para gerar os embeddings.'},\n","    )"]},{"cell_type":"markdown","metadata":{"id":"1uvFnsC6Dd0E"},"source":["Classe(ModeloArgumentosClassificacao) de definição dos parâmetros do modelo para classificação"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1660932369425,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"EBlqJop3Dd0E"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosClassificacao:\n","    '''\n","    Classe(ModeloArgumentosClassificacao) de definição dos parâmetros do modelo BERT para a classificação de coerência.\n","    '''\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )\n","    num_labels: int = field(\n","        default=2,\n","        metadata={\"help\": \"número de rótulos a serem classificados.\"},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    optimizer: str = field(\n","        default=\"AdamW\",\n","        metadata={\"help\": \"otimizador do modelo.\"},\n","    )\n","    use_wandb : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o uso do wandb.\"},\n","    )\n","    salvar_modelo_wandb : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o salvamento do modelo no wandb.\"},\n","    )\n","    salvar_modelo : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o salvamento do modelo.\"},\n","    )\n","    salvar_avaliacao : bool = field(\n","        default=True,\n","        metadata={\"help\": \"habilita o salvamento do resultado da avaliação.\"},\n","    )     \n","    salvar_classificacao : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o salvamento da classificação.\"},\n","    )\n","    usar_mcl_ajustado: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o carragamento de mcl ajustado.'},\n","    )    \n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos perturbados comparados com o seu original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de previsões de palavras recuperadas mais próximas da máscara.\"},\n","    ) \n","    epoca: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Época a ser avaliada.\"},\n","    )    \n","    fold: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Fold a ser avaliado.\"},\n","    )    "]},{"cell_type":"markdown","metadata":{"id":"wnLEQeEQDd0E"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1660932369425,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"YlUWz_fsDd0E"},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"zZDCIc39Dd0E"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1660932369426,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ePrFfV3GDd0F"},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"Im9VepPWDd0F"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1660932369426,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"DqwP3NA3Dd0F"},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"NCp0sHR5Dd0F"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"cHk6syZwDd0F"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"5DlYJEkaDd0F"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -\u003e Notebook Settings -\u003e Hardware accelerator -\u003e (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2802,"status":"ok","timestamp":1660932372207,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"k-OwALHxDd0F","outputId":"cd145278-13e4-475c-dfc2-16a2b476366b"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Dispositivo GPU não encontrado\n"]}],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"FuXHv3udDd0H"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1508,"status":"ok","timestamp":1660932373712,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"7AgLel7YDd0H"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def getDeviceGPU():\n","    \"\"\"\n","    Retorna um dispositivo de GPU se disponível ou CPU.\n","    \n","    Retorno:\n","    `device` - Um device de GPU ou CPU.       \n","    \"\"\"\n","        \n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        \n","        # Diz ao PyTorch para usar GPU.    \n","        device = torch.device(\"cuda\")\n","        \n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:        \n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","        \n","    return device"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1660932373714,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ByQzSwkvDd0H","outputId":"012e735d-8bc3-4557-8c66-5272cdf3c450"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:Sem GPU disponível, usando CPU.\n"]}],"source":["device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"EYE9I9F-Dd0H"},"source":["Conecta o modelo ao device"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1660932373715,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"uccEVSkkDd0H"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def conectaGPU(model, device):\n","    \"\"\"\n","      Conecta um modelo BERT a GPU.\n","\n","      Parâmetros:\n","        `model` - Um modelo BERT carregado.       \n","        `device` - Um device de GPU.     \n","    \n","      Retorno:\n","        `model` - Um objeto model BERT conectado a GPU.     \n","    \"\"\"\n","    # Associa a GPU ao modelo.\n","    model.to(device)\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():    \n","        # Diga ao pytorch para rodar este modelo na GPU.\n","        logging.info(\"Pytorch rodando o modelo na GPU.\")\n","        model.cuda()\n","        \n","    else:\n","        logging.info(\"Pytorch rodando sem GPU.\")\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"GEUGK7eKDd0H"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1660932373716,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"ifkNghLQDd0I","outputId":"833d87c1-55ee-4c09-f1e1-2e5b9adabeb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução\u003e \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}],"source":["# Import das bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb \u003c 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução\u003e \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"XI-HGJYADd0I"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331586,"status":"ok","timestamp":1660932705294,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"6HGdSxIfDd0I","outputId":"166870f8-f2d6-488b-cfcd-208ca6a7a6b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Import das bibliotecas.\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"oOd2MbBiDq93"},"source":["## 1.7 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"elapsed":12709,"status":"ok","timestamp":1660932717996,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"EaMM4WdxgvQ7","outputId":"9b1a9dbe-686a-4330-bc62-1e85e5ac6109"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.1.0-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 52.9 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi\u003e=0.10, which is not installed.\u001b[0m\n","Successfully installed pip-22.2.2 setuptools-65.1.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{},"output_type":"display_data"}],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"w4p3Rz2qDq94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions\u003c4.0.0.0,\u003e=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: murmurhash\u003c1.1.0,\u003e=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.8)\n","Requirement already satisfied: pathy\u003e=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Requirement already satisfied: langcodes\u003c4.0.0,\u003e=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: blis\u003c0.8.0,\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.1.0)\n","Requirement already satisfied: wasabi\u003c1.1.0,\u003e=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: numpy\u003e=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: cymem\u003c2.1.0,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.6)\n","Requirement already satisfied: spacy-legacy\u003c3.1.0,\u003e=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.10)\n","Requirement already satisfied: spacy-loggers\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Collecting thinc\u003c8.1.0,\u003e=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: preshed\u003c3.1.0,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.7)\n","Requirement already satisfied: srsly\u003c3.0.0,\u003e=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.4)\n","Requirement already satisfied: tqdm\u003c5.0.0,\u003e=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.0)\n","Requirement already satisfied: requests\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Collecting pydantic!=1.8,!=1.8.1,\u003c1.9.0,\u003e=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer\u003c0.5.0,\u003e=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Requirement already satisfied: catalogue\u003c2.1.0,\u003e=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue\u003c2.1.0,\u003e=2.0.6-\u003espacy==3.2.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003espacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open\u003c6.0.0,\u003e=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy\u003e=0.3.5-\u003espacy==3.2.0) (5.2.1)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy==3.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy==3.2.0) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy==3.2.0) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0,\u003e=2.13.0-\u003espacy==3.2.0) (2022.6.15)\n","Requirement already satisfied: click\u003c9.0.0,\u003e=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer\u003c0.5.0,\u003e=0.3.0-\u003espacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-\u003espacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.9.2\n","    Uninstalling pydantic-1.9.2:\n","      Successfully uninstalled pydantic-1.9.2\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.0\n","    Uninstalling thinc-8.1.0:\n","      Successfully uninstalled thinc-8.1.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.1\n","    Uninstalling spacy-3.4.1:\n","      Successfully uninstalled spacy-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.0 requires spacy\u003c3.5.0,\u003e=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typing-extensions-3.10.0.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"markdown","metadata":{"id":"0pviY-2dDd0J"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"gvcqpNEJDd0J"},"source":["## Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bQrOJLiaDd0J"},"outputs":[],"source":["# Nome base das saidas do projeto C = Cris, SB = SmartBatch, KF = KFold\n","NOME_BASE_SAIDA = \"AjusteFinoFaquad_C_SB_KF_v1\""]},{"cell_type":"markdown","metadata":{"id":"_ozqXT_LDd0J"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"Mhkc9sW21zV7"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Definição dos parâmetros do Modelo\n","model_args = ModeloArgumentosMedida(     \n","    max_seq_len = 512,    \n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",\n","    pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",    \n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","    modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","    versao_modelo_spacy = \"3.2.0\",\n","    do_lower_case = False,  # default True\n","    output_attentions = False,  # default False\n","    output_hidden_states = True, # default False\n","    use_wandb = True,    \n","    salvar_medicao = True, #Salva o resultado da medição\n","    salvar_avaliacao = True, # Salva o resultado da avaliação das medições\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path. \n","    estrategia_medida = 0, # Atributo usado para os logs do wandb. 0 - MEAN estratégia média / 1 - MAX  estratégia maior\n","    filtro_palavra = 0, # Atributo usado para os logs do wandb. 0 - Considera todas as palavras das sentenças / 1 - Desconsidera as stopwords / 2 - Considera somente as palavras substantivas\n",")"]},{"cell_type":"markdown","metadata":{"id":"3OSzbEyqDd0J"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tdqS6-bhDd0J"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"FAQUAD\""]},{"cell_type":"markdown","metadata":{"id":"u7wFh9xVDd0K"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PIyY83UQDd0K"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DjWGu-9D5URZ"},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","        \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Dq9PnXO77bPQ"},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    \n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivoTar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")    \n","    arquivoTar.extractall(DIRETORIO_COHEBERT)    \n","    arquivoTar.close()\n","    \n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):        \n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ePOccj0s8WMg"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","    \n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.           \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","                  \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp "]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbELnrpgA4T1"},"outputs":[],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","metadata":{"id":"AEzytjZi5Iw2"},"source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKg-_XyWoy8o"},"outputs":[],"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","    \n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.           \n","    \"\"\"\n","    \n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords "]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1o8jevtoy8p"},"outputs":[],"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hdqVdfxm-_W"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy   \n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                                  \n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar   \n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ] \n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [               \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                   \n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal       \n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ] \n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}}, \n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar \n","               ] \n","\n","matcherv = Matcher(nlp.vocab)\n","         \n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):    \n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","  \n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","  \n","  return lista2"]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = dict()\n","  \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades    \n","  novodic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","    \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9SA61kD6sJY"},"outputs":[],"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","    \n","  # Soma os dicionários da lista\n","  novodic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n"," \n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWxyAo54AOHU"},"outputs":[],"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.text)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gvd99wd_pwmt"},"outputs":[],"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  listatokens = []\n","  listapos = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:    \n","    listatokens.append(token.text)\n","    listapos.append(token.pos_)\n","    \n","  return listatokens, listapos"]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpCUpOs06sJY"},"outputs":[],"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","  \n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\" \n","  return traduzido"]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMb0uDWzKZXP"},"outputs":[],"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxTCYFzcJZD6"},"outputs":[],"source":["def getSentencaSalientePOS(sentenca, pos, classe_saliente=[\"NOUN\"]):\n","  \n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especificado\n","    if pos[i] in classe_saliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"s07wG9F-qHOc"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkBatgxjqHOc"},"outputs":[],"source":["def removeStopWord(documento, stopwords):\n","  \n","  # Remoção das stopwords do documento\n","  documentoSemStopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documentoSemStopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"]},{"cell_type":"markdown","metadata":{"id":"cv3sJJolDd0Q"},"source":["# 4 Resultado do Classificador Binário usando o Método Kfold"]},{"cell_type":"markdown","metadata":{"id":"o078EpzsDd0Q"},"source":["## 4.1 Carrega o resultado e parâmetros da melhor classificação"]},{"cell_type":"markdown","metadata":{"id":"etn_-IHMDd0Q"},"source":["### 4.1.1 Função que encontra a melhor classificação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_XN2v1QDd0Q"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import pandas as pd\n","\n","def getResultadosClassificacaoKFold(DIRETORIO_COHEBERT, \n","                                    _DOCUMENTOS_PERTURBADOS, \n","                                    _TOP_K_PREDICAO):\n","  \n","  # Numero de Folds\n","  KFOLDS = 10\n","\n","  # Quantidade de documentos a serem perturbados a partir do original.    \n","  DOCUMENTOS_PERTURBADOS = _DOCUMENTOS_PERTURBADOS\n","\n","  # Quantidade de palavras a serem recuperadas mais próximas da máscara. \n","  TOP_K_PREDICAO = _TOP_K_PREDICAO\n","\n","  # MCL a serem avaliados\n","  #MODELO_BERT = ['_BERTimbau','_BERTmultilingual']\n","  MODELO_BERT = ['_BERTimbau']\n","\n","  #TAMANHO_BERT = ['_base','_large']\n","  TAMANHO_BERT = ['_large']\n","  \n","  # Taxa de aprendizagem do nome do arquivo\n","  TAXAS_DE_APRENDIZAGEM = [1, 2, 3, 4, 5]\n","\n","  # Tamanho dos lotes\n","  TAMANHO_LOTE = [16, 32]\n","\n","  # Salva resultados intermediários\n","  EPOCA = [2, 3, 4]\n","\n","  # Diretório para salvar o arquivo.\n","  DIRETORIO_AVALIACAO = \"/content/drive/My Drive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/kfold/Avaliacao/\"  \n","\n","  MELHOR_DOCUMENTOS_PERTURBADOS = 0\n","  MELHOR_TOP_K_PREDICAO = 0\n","  MELHOR_TAXAS_DE_APRENDIZAGEM = 0\n","  MELHOR_TAMANHO_LOTE = 0\n","  MELHOR_EPOCA_EXECUCA = 0\n","  MELHOR_ACURACIA = 0\n","  MELHOR_TEMPO = 0\n","\n","  lista_resultados = []\n","\n","  lista_tempo_total = []  \n","  \n","  # Verifica se o diretório dos resultados existe.\n","  if os.path.exists(DIRETORIO_AVALIACAO):    \n","    for modelo in MODELO_BERT:    \n","      for tamanho in TAMANHO_BERT:\n","        if modelo != '_BERTmultilingual' or tamanho != '_large':                  \n","          for documentos_perturbados in DOCUMENTOS_PERTURBADOS:\n","            for top_k_predicao in TOP_K_PREDICAO: \n","              if documentos_perturbados ==  top_k_predicao:\n","                DIRETORIO_AVALIACAO_PK = DIRETORIO_AVALIACAO + \"P_\" + str(documentos_perturbados) + \"_K_\" + str(top_k_predicao) + \"/\"              \n","                # Verifica se o diretório dos resultados existe.\n","                if os.path.exists(DIRETORIO_AVALIACAO_PK):\n","                  arquivos = os.listdir(DIRETORIO_AVALIACAO_PK) \n","                  conta_regR = 0\n","                  for lote in TAMANHO_LOTE:\n","                    for taxa_de_aprendizagem in TAXAS_DE_APRENDIZAGEM:                      \n","                      for epoca in EPOCA:  \n","                          # Acumuladores.\n","                          soma_acuracia = 0\n","                          lista_tempo = []\n","                          conta_folds = 0 \n","                          conta_reg = 0\n","                          \n","                          for i in range(len(arquivos)):\n","                            for fold in range(1,11):\n","                              # Filtra o nome do arquivo a ser avaliado                                                     \n","                              if (((\"_P_\" + str(documentos_perturbados)+\"_\") in arquivos[i]) \n","                                    and ((\"_K_\" + str(top_k_predicao)+\"_\") in arquivos[i]) \n","                                    and ((\"_b_\" + str(lote)) in arquivos[i]) \n","                                    and (modelo in arquivos[i]) \n","                                    and (tamanho in arquivos[i]) \n","                                    and (('_f' + str(fold) + '_') in arquivos[i]) \n","                                    and ((\"e_\" + str(epoca)) in arquivos[i]) \n","                                    and ((\"lr_\" + str(taxa_de_aprendizagem)) in arquivos[i])):                           \n","\n","                                  NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO_PK + arquivos[i]                              \n","                                  # Verifica se o arquivo existe.\n","                                  if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","                                    # Carrega os dados do arquivo  \n","                                    dados = pd.read_csv(NOME_ARQUIVO_AVALIACAO_COMPLETO, sep=';')\n","                        \n","                                    # Conta o número de folds.\n","                                    conta_folds = conta_folds + 1\n","                                    \n","                                    # Mostra os dados do teste do fold.\n","                                    for index, linha in dados.iterrows():        \n","                                      # Cálculo das estatísticas\n","                                      acc = (linha['vp']+linha['vn'])/(linha['vp']+linha['vn']+linha['fp']+linha['fn'])                         \n","                                      #print('{};{};{};{:.8f};{}'.format(fold, index, arquivos[i],acc,linha['tempo']))\n","                                      # Guarda o tempo.\n","                                      lista_tempo.append(str(linha['tempo']))\n","                                      # Conta o número de registros.\n","                                      conta_reg = conta_reg + 1\n","                                      \n","                                    # Realiza a soma da acurácia do arquivo.\n","                                    soma_acuracia = soma_acuracia + dados['acuracia'].sum()\n","                                          \n","                          if conta_folds != 0:\n","                            # Calcula a média.                          \n","                            media_acuracia = soma_acuracia/conta_reg\n","\n","                            # Guarda os resultados de todos os folds  \n","                            lista_resultados.append([documentos_perturbados,top_k_predicao,taxa_de_aprendizagem,lote,epoca, media_acuracia, somaTempo(lista_tempo)])\n","                            \n","                            if media_acuracia \u003e MELHOR_ACURACIA:\n","                                MELHOR_DOCUMENTOS_PERTURBADOS = documentos_perturbados\n","                                MELHOR_TOP_K_PREDICAO = top_k_predicao\n","                                MELHOR_TAXAS_DE_APRENDIZAGEM = taxa_de_aprendizagem\n","                                MELHOR_TAMANHO_LOTE = lote\n","                                MELHOR_EPOCA_EXECUCAO = epoca\n","                                MELHOR_ACURACIA = media_acuracia\n","                                MELHOR_TEMPO = somaTempo(lista_tempo)\n","                        \n","                          else:                          \n","                              print('Nenhum arquivo de avaliação encontrado')\n","                  \n","                else:\n","                  print('Diretório ' + 'P_' + str(documentos_perturbados) + '_K_' + str(top_k_predicao) + ' não encontrado')                        \n","    \n","    # Retorno do melhor valor\n","    lista_resultado_ordenado = sorted(lista_resultados, key=lambda x: x[5], reverse=True)\n","    return MELHOR_DOCUMENTOS_PERTURBADOS, MELHOR_TOP_K_PREDICAO, MELHOR_TAXAS_DE_APRENDIZAGEM, MELHOR_TAMANHO_LOTE, MELHOR_EPOCA_EXECUCAO, MELHOR_ACURACIA, MELHOR_TEMPO, lista_resultado_ordenado\n","  else:\n","    print('Diretório com os resultados não encontrado')"]},{"cell_type":"markdown","metadata":{"id":"rtweMBA2Dd0Q"},"source":["Recupera os melhores resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZPhVu4bDd0Q"},"outputs":[],"source":["DOCUMENTOS_PERTURBADOS = [1, 20, 100]\n","TOP_K_PREDICAO = [1, 20, 100]\n","\n","# Recupera os melhores parâmetros\n","MELHOR_DOCUMENTOS_PERTURBADOS, MELHOR_TOP_K_PREDICAO, MELHOR_TAXAS_DE_APRENDIZAGEM, MELHOR_TAMANHO_LOTE, MELHOR_EPOCA_EXECUCAO, MELHOR_ACURACIA, MELHOR_TEMPO, lista_resultados = getResultadosClassificacaoKFold(DIRETORIO_COHEBERT, DOCUMENTOS_PERTURBADOS, TOP_K_PREDICAO)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bQQ8FQ1Dd0R"},"outputs":[],"source":["print(\"Parâmetros da melhor acurácia do classificador\")\n","print(\"\\n  Documentos Perturbados:\", MELHOR_DOCUMENTOS_PERTURBADOS, \n","      \"\\n  Top k predição        :\", MELHOR_TOP_K_PREDICAO, \n","      \"\\n  Taxa de aprendizagem  :\", MELHOR_TAXAS_DE_APRENDIZAGEM, \n","      \"\\n  Lote                  :\", MELHOR_TAMANHO_LOTE, \n","      \"\\n  Epoca execução        :\", MELHOR_EPOCA_EXECUCAO, \n","      \"\\n  Acurácia              :\", MELHOR_ACURACIA, \n","      \"\\n  Tempo execução        :\", MELHOR_TEMPO)\n","\n","print(\"\\nLista das acurácias ranqueadas\")\n","for i, linha in enumerate(lista_resultados):\n","    print((i+1),\"=\", linha)"]},{"cell_type":"markdown","metadata":{"id":"1cW6cgtYDd0R"},"source":["### Escolhendo um resultado diferente do melhor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SO3ye0lRDd0R"},"outputs":[],"source":["# Parametros para melhor de 100\n","# MELHOR_DOCUMENTOS_PERTURBADOS = 100\n","# MELHOR_TOP_K_PREDICAO = 100\n","# MELHOR_TAXAS_DE_APRENDIZAGEM = 1\n","# MELHOR_TAMANHO_LOTE = 16\n","# MELHOR_EPOCA_EXECUCAO = 3\n","# MELHOR_ACURACIA = 0.9876333333333334\n","# MELHOR_TEMPO = '19:59:18'\n","# lista_resultados= []\n","\n","# Parametros para melhor de 20\n","MELHOR_DOCUMENTOS_PERTURBADOS = 20\n","MELHOR_TOP_K_PREDICAO = 20\n","MELHOR_TAXAS_DE_APRENDIZAGEM = 1\n","MELHOR_TAMANHO_LOTE = 16\n","MELHOR_EPOCA_EXECUCAO = 4\n","MELHOR_ACURACIA =  0.9564722222222223\n","MELHOR_TEMPO = '05:01:57'\n","lista_resultados= []\n","\n","#Parametros para melhor de 1\n","# MELHOR_DOCUMENTOS_PERTURBADOS = 1\n","# MELHOR_TOP_K_PREDICAO = 1\n","# MELHOR_TAXAS_DE_APRENDIZAGEM = 2\n","# MELHOR_TAMANHO_LOTE = 16\n","# MELHOR_EPOCA_EXECUCAO = 3\n","# MELHOR_ACURACIA = 0.6488888888888888\n","# MELHOR_TEMPO = '00:18:54'\n","# lista_resultados= []"]},{"cell_type":"markdown","metadata":{"id":"1w0Ry5oMDd0R"},"source":["### 4.1.2 Função que carrega e calcula a média da acurácia dos folds\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBPnCqQeDd0S"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import pandas as pd\n","\n","def relatorioResultados(DIRETORIO_COHEBERT, \n","                        TEXTO_PURO, \n","                        _DOCUMENTOS_PERTURBADOS, \n","                        _TOP_K_PREDICAO,\n","                        _TAXAS_DE_APRENDIZAGEM,\n","                        _TAMANHO_LOTE,\n","                        _EPOCA_EXECUCAO\n","                        ):\n","  \n","  # Numero de Folds\n","  KFOLDS = 10\n","\n","  # Quantidade de documentos a serem perturbados a partir do original.    \n","  DOCUMENTOS_PERTURBADOS = _DOCUMENTOS_PERTURBADOS\n","\n","  # Quantidade de palavras a serem recuperadas mais próximas da máscara. \n","  TOP_K_PREDICAO = _TOP_K_PREDICAO\n","\n","  # MCL a serem avaliados\n","  #MODELO_BERT = ['_BERTimbau','_BERTmultilingual']\n","  MODELO_BERT = ['_BERTimbau']\n","\n","  #TAMANHO_BERT = ['_base','_large']\n","  TAMANHO_BERT = ['_large']\n","\n","  # Taxa de aprendizagem do nome do arquivo\n","  TAXAS_DE_APRENDIZAGEM = _TAXAS_DE_APRENDIZAGEM\n","\n","  # Tamanho dos lotes\n","  TAMANHO_LOTE = _TAMANHO_LOTE\n","\n","  # Salva resultados intermediários\n","  EPOCA = _EPOCA_EXECUCAO\n","  \n","  # Diretório para salvar o arquivo.\n","  DIRETORIO_AVALIACAO = \"/content/drive/My Drive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/kfold/Avaliacao/\"  \n","\n","  lista_tempo_total = []  \n","  total_geral_folds = 0\n","  total_geral_registros = 0\n","  total_arquivos = (len(MODELO_BERT) * len(TAMANHO_BERT) *\n","                   len(DOCUMENTOS_PERTURBADOS) *  len(TOP_K_PREDICAO) * \n","                   len(TAMANHO_LOTE) * len(EPOCA) * len(TAXAS_DE_APRENDIZAGEM) * KFOLDS)\n","  #total_arquivos = 400  \n","  if TEXTO_PURO == False:\n","    print(\"total_arquivos =\", total_arquivos) \n","\n","  # Verifica se o diretório dos resultados existe.\n","  if os.path.exists(DIRETORIO_AVALIACAO):    \n","    for modelo in MODELO_BERT:\n","      for tamanho in TAMANHO_BERT:        \n","        if modelo != '_BERTmultilingual' or tamanho != '_large':  \n","          for documentos_perturbados in DOCUMENTOS_PERTURBADOS:\n","            for top_k_predicao in TOP_K_PREDICAO:        \n","              if documentos_perturbados ==  top_k_predicao:\n","                DIRETORIO_AVALIACAO_PK = DIRETORIO_AVALIACAO + \"P_\" + str(documentos_perturbados) + \"_K_\" + str(top_k_predicao) + \"/\"\n","          \n","                # Verifica se o diretório dos resultados existe.\n","                if os.path.exists(DIRETORIO_AVALIACAO_PK):\n","                  arquivos = os.listdir(DIRETORIO_AVALIACAO_PK) \n","                  for lote in TAMANHO_LOTE:\n","                    for taxa_de_aprendizagem in TAXAS_DE_APRENDIZAGEM:\n","                      for epoca in EPOCA:                    \n","                          # Acumuladores.\n","                          soma_acuracia = 0\n","                          lista_tempo = []\n","                          conta_folds = 0 \n","                          conta_reg = 0\n","                          if TEXTO_PURO == False:\n","                            print(\"\\nModelo:\", modelo, \" Tamanho:\", tamanho, \" N Doc:\",documentos_perturbados,\n","                                  \" Top k:\", top_k_predicao, \" Lote:\", lote, \" Taxa Apred.:\", taxa_de_aprendizagem, \" Época:\", epoca)\n","        \n","                          for i in range(len(arquivos)):                                    \n","                            for fold in range(1,11):                                                         \n","                              if (((\"_P_\" + str(documentos_perturbados)+\"_\") in arquivos[i]) \n","                                  and ((\"_K_\" + str(top_k_predicao)+\"_\") in arquivos[i]) \n","                                  and ((\"_b_\" + str(lote)) in arquivos[i]) \n","                                  and (modelo in arquivos[i]) \n","                                  and (tamanho in arquivos[i]) \n","                                  and ((\"_b_\" + str(lote)) in arquivos[i]) \n","                                  and (('_f' + str(fold) + '_') in arquivos[i]) \n","                                  and ((\"e_\" + str(epoca)) in arquivos[i]) \n","                                  and ((\"lr_\" + str(taxa_de_aprendizagem)) in arquivos[i])):\n","                              \n","                                  NOME_ARQUIVO_AVALIACAO_COMPLETO = DIRETORIO_AVALIACAO_PK + arquivos[i]                              \n","                                  # Verifica se o arquivo existe.\n","                                  if os.path.isfile(NOME_ARQUIVO_AVALIACAO_COMPLETO):\n","                                    # Carrega os dados do arquivo  \n","                                    dados = pd.read_csv(NOME_ARQUIVO_AVALIACAO_COMPLETO, sep=';')\n","                        \n","                                    # Conta o número de folds.\n","                                    conta_folds = conta_folds + 1\n","                                    # Conta o número geral de folds\n","                                    total_geral_folds = total_geral_folds + 1\n","\n","                                    # Mostra os dados do teste do fold.\n","                                    for index, linha in dados.iterrows():        \n","                                      # Cálculo das estatísticas\n","                                      acc = (linha['vp']+linha['vn'])/(linha['vp']+linha['vn']+linha['fp']+linha['fn'])                         \n","                                      print('{};{};{};{};{}'.format(fold, index, arquivos[i],str(acc).replace(\".\", \",\"),linha['tempo']))\n","                                      #print('{};{};{};{:.8f};{}'.format(fold, index, arquivos[i],acc,linha['tempo']))\n","                                      # Guarda o tempo.\n","                                      lista_tempo.append(str(linha['tempo']))\n","\n","                                      # Conta o número de registros.\n","                                      conta_reg = conta_reg + 1\n","                                      # Conta o número geral de registros.\n","                                      total_geral_registros = total_geral_registros + 1\n","\n","                                    # Realiza a soma da acurácia do arquivo.\n","                                    soma_acuracia = soma_acuracia + dados['acuracia'].sum()\n","\n","                          \n","                          if conta_folds != 0:\n","                              # Mostra a soma da acurácia . \n","                              if TEXTO_PURO == False:\n","                                print('Total acurácia                                           : {:.8f}'.format(soma_acuracia))\n","                              # Mostra a quantidade de folds.\n","                              if TEXTO_PURO == False:\n","                                print('Quantidade de folds                                      : {}'.format(conta_folds))  \n","                              # Mostra a quantidade de registros.\n","                              if TEXTO_PURO == False:\n","                                print('Quantidade de registros                                  : {}'.format(conta_reg))  \n","                              # Calcula a média.\n","                              if TEXTO_PURO == False:\n","                                media_acuracia = soma_acuracia/conta_reg\n","                                print('A média da acurácia de {:2d} registros é                    : {:.8f}'.format(conta_reg, media_acuracia))\n","                                print('O tempo gasto na execução do treinamento {:2d} registros é  : {}'.format(conta_reg, somaTempo(lista_tempo)))\n","                                print('A média de tempo de execução de {:2d} registros é           : {}\\n'.format(conta_reg, mediaTempo(lista_tempo)))\n","                              \n","                              if epoca == 4:\n","                                # Guarda o tempo total\n","                                lista_tempo_total.append(somaTempo(lista_tempo))\n","                          else:\n","                              if TEXTO_PURO == False:\n","                                print('Nenhum arquivo de avaliação encontrado')\n","                                      \n","                else:\n","                  print('Diretório ' + 'P_' + str(documentos_perturbados) + '_K_' + str(top_k_predicao) + ' não encontrado')\n","    \n","  else:\n","      print('Diretório com os resultados não encontrado')        "]},{"cell_type":"markdown","metadata":{"id":"7b0OdJTODd0S"},"source":["Recupera os dados dos melhores resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20uS1MtdDd0S"},"outputs":[],"source":["# Diretório do cohebert\n","DOCUMENTOS_PERTURBADOS = [MELHOR_DOCUMENTOS_PERTURBADOS]\n","TOP_K_PREDICAO = [MELHOR_TOP_K_PREDICAO]\n","TAXAS_DE_APRENDIZAGEM = [MELHOR_TAXAS_DE_APRENDIZAGEM]\n","TAMANHO_LOTE = [MELHOR_TAMANHO_LOTE]\n","EPOCA_EXECUCAO = [MELHOR_EPOCA_EXECUCAO]\n","TEXTO_PURO = False\n","\n","relatorioResultados(DIRETORIO_COHEBERT, \n","                    TEXTO_PURO, \n","                    DOCUMENTOS_PERTURBADOS, \n","                    TOP_K_PREDICAO, \n","                    TAXAS_DE_APRENDIZAGEM, \n","                    TAMANHO_LOTE, \n","                    EPOCA_EXECUCAO)"]},{"cell_type":"markdown","metadata":{"id":"Uq_76xUCDd0S"},"source":["## 4.2 Carregamento dos arquivos de dados originais e perturbados"]},{"cell_type":"markdown","metadata":{"id":"PJukCVLQDd0S"},"source":["### 4.2.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tb0m95cSDd0S"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(MELHOR_DOCUMENTOS_PERTURBADOS) + \"_k\" + str(MELHOR_TOP_K_PREDICAO) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(MELHOR_DOCUMENTOS_PERTURBADOS) + \"_k\" + str(MELHOR_TOP_K_PREDICAO) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(MELHOR_DOCUMENTOS_PERTURBADOS) + \"_k\" + str(MELHOR_TOP_K_PREDICAO) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(MELHOR_DOCUMENTOS_PERTURBADOS) + \"_k\" + str(MELHOR_TOP_K_PREDICAO) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"PhR8vZEmDd0T"},"source":["### 4.2.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aLUcqBxMDd0T"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Perturbados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"4z3C13kxDd0T"},"source":["### 4.2.3 Copia e descompacta os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zhsBwoPcDd0T"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a cópia!\")"]},{"cell_type":"markdown","metadata":{"id":"tORqjdvlDd0T"},"source":["Descompacta os arquivos.\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_ZYjLCdDd0T"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação!\")"]},{"cell_type":"markdown","metadata":{"id":"txCMqCa-Dd0T"},"source":["### 4.2.4 Carregamento das lista com os dados dos arquivos originais e perturbados"]},{"cell_type":"markdown","metadata":{"id":"MTZKZrktDd0U"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7mQE_IRyDd0U"},"outputs":[],"source":["#Biblioteca\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0TzHz_MDd0U"},"outputs":[],"source":["lista_documentos_originais.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9FTcUoHDd0U"},"outputs":[],"source":["lista_documentos_originais_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"quWxoc6EDd0U"},"source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCSI3QskDd0U"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","def corrigirTipoDadosColunasOriginais(lista_documentos_originais, lista_documentos_originais_pos):\n","\n","  # Corrige os tipos dos dados \n","  tipos = {\"id\": str}\n","  lista_documentos_originais = lista_documentos_originais.astype(tipos)\n","  lista_documentos_originais_pos = lista_documentos_originais_pos.astype(tipos)\n","\n","  # Verifica se o tipo da coluna não é list e converte\n","  lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","  lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","  logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","  logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))\n","\n","  return lista_documentos_originais, lista_documentos_originais_pos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euuNfgpeDd0U"},"outputs":[],"source":["lista_documentos_originais, lista_documentos_originais_pos = corrigirTipoDadosColunasOriginais(lista_documentos_originais, lista_documentos_originais_pos)"]},{"cell_type":"markdown","metadata":{"id":"5vAI9s7nDd0U"},"source":["#### Criando dados indexados originais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ovn1VWN8Dd0V"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iyNKlccRDd0V"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"apMwBFk3Dd0V"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGN4_vKADd0V"},"outputs":[],"source":["# Abre o arquivo e retorna o DataFrame\n","lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))"]},{"cell_type":"markdown","metadata":{"id":"SW56YY0vDd0V"},"source":["AlgUns csv estão com os nomes das colunas errados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztxxEjMYDd0V"},"outputs":[],"source":["lista_documentos_perturbados = lista_documentos_perturbados.rename(columns={'documentoPerturbado': 'documento_perturbado'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9JF1Qh-Dd0V"},"outputs":[],"source":["lista_documentos_perturbados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWLcw8teDd0W"},"outputs":[],"source":["lista_documentos_perturbados_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"z0jpPb2PDd0W"},"source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3CZzQ6EDd0W"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","def corrigirTipoDadosColunasPerturbados(lista_documentos_perturbados, lista_documentos_perturbados_pos):\n","\n","  # Corrige os tipos dos dados \n","  tipos = {\"id\": str}\n","  lista_documentos_perturbados = lista_documentos_perturbados.astype(tipos)\n","  lista_documentos_perturbados_pos = lista_documentos_perturbados_pos.astype(tipos)\n","\n","  # Verifica se o tipo da coluna não é list e converte\n","  lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","  lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","  lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","  logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","  logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))\n","\n","  return lista_documentos_perturbados, lista_documentos_perturbados_pos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gLyE16xXDd0W"},"outputs":[],"source":["lista_documentos_perturbados, lista_documentos_perturbados_pos = corrigirTipoDadosColunasPerturbados(lista_documentos_perturbados, lista_documentos_perturbados_pos)"]},{"cell_type":"markdown","metadata":{"id":"roSDH_rDDd0W"},"source":["#### Criando dados indexados perturbados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJtV-3GUDd0W"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UsY-Af9nDd0W"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados_pos.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"FcA-KmznDd0X"},"source":["### 4.2.5 Agrupar os dados originais e perturbados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S2-_0MF2Dd0X"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def agruparDadosOriginaisPerturbados(lista_documentos_originais, lista_documentos_perturbados_indexado):\n","\n","  print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","  lista_documentos_agrupados = []\n","\n","  # Barra de progresso dos documentos\n","  lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","  # Percorre os documentos\n","  for i, linha_documento in lista_documentos_originais_bar: \n","    #if i \u003c 2:\n","      #print(\"linha_documento:\",linha_documento)\n","      # Recupera o id do documento\n","      id_documento = linha_documento[0]     \n","      #print(\"id_documento:\",id_documento)     \n","  \n","      # Carrega a lista das sentenças do documento\n","      lista_sentenca_documento = linha_documento[1]    \n","      #print(\"\\nlista_sentenca_documento:\",lista_sentenca_documento)\n","      #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento)) \n","\n","      # Adiciona o original a lista dos dados agrupados, considerando como coerente(1)\n","      lista_documentos_agrupados.append([id_documento, lista_sentenca_documento, linha_documento[2], 1])\n","    \n","      # Percorre os documentos perturbados apartir do original\n","      for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","        # Id do documento perturbado\n","        id_perturbado = str(id_documento) + \"_pert_\" + str(j)\n","\n","        # localiza o documento perturbado \n","        #documento_perturbado = lista_documentos_perturbados.loc[lista_documentos_perturbados['id']==id_perturbado].values[0]\n","        documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","        # Recupera a sentença do documento perturbado\n","        lista_perturbado = documento_perturbado[0]\n","            \n","        # Adiciona o perturbado a lista dos dados agrupados considerando como incoerente(0)\n","        lista_documentos_agrupados.append([id_perturbado, lista_perturbado, documento_perturbado[1], 0])    \n","\n","  logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))\n","\n","  # Cria o dataframe da lista\n","  lista_documentos_agrupados = pd.DataFrame(lista_documentos_agrupados, columns = [\"id\",\"sentencas\",\"documento\",\"classe\"])\n","\n","  # Corrige os tipos dos dados da lista agrupada\n","  tipos = {\"id\": str, \"sentencas\": object, \"documento\": str, \"classe\": int}\n","\n","  lista_documentos_agrupados = lista_documentos_agrupados.astype(tipos)\n","\n","  return lista_documentos_agrupados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wRQRjFnDd0X"},"outputs":[],"source":["# Importa das bibliotecas\n","import pandas as pd\n","\n","print(\"Analisando documentos originais e perturbados\")\n","# Concatena as listas de documentos originais e perturbados\n","lista_documentos_agrupados = agruparDadosOriginaisPerturbados(lista_documentos_originais, lista_documentos_perturbados_indexado)\n","lista_documentos_agrupados_pos = pd.concat([lista_documentos_originais_pos, lista_documentos_perturbados_pos])\n","\n","# Corrige o tipo de dado da coluna id da lista\n","tipos = {\"id\": str}\n","lista_documentos_agrupados_pos = lista_documentos_agrupados_pos.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SNSl4CLZDd0X"},"outputs":[],"source":["logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Owsae8hiDd0X"},"outputs":[],"source":["lista_documentos_agrupados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTZEOaGxDd0X"},"outputs":[],"source":["logging.info(\"TERMINADO AGRUPAMENTO POS: {}.\".format(len(lista_documentos_agrupados_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aS59DdafDd0X"},"outputs":[],"source":["lista_documentos_agrupados_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"CGIbIgqIDd0Y"},"source":["#### Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBymLeD5Dd0Y"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_indexado = lista_documentos_agrupados.set_index([\"id\"])\n","lista_documentos_agrupados_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NVKs7qO4Dd0Y"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_pos_indexado = lista_documentos_agrupados_pos.set_index([\"id\"])\n","lista_documentos_agrupados_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"-38l8opVDd0Y"},"source":["## 4.3 Carrega os dados da classificação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1IM-799zDd0Y"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","import pandas as pd\n","\n","def getDadosClassificacaoCompactado(DIRETORIO_COHEBERT,                           \n","                          _DOCUMENTOS_PERTURBADOS, \n","                          _TOP_K_PREDICAO,\n","                          _EPOCA,\n","                          _TAXAS_DE_APRENDIZAGEM,\n","                          _TAMANHO_LOTE,\n","                          _EPOCA_EXECUCAO,\n","                          _MODELO_BERT = '_BERTimbau',\n","                          _TAMANHO_BERT = '_large'\n","                          ):\n","\n","  # Diretório para carregar o arquivo.\n","  DIRETORIO_CLASSIFICACAO_DRIVE = DIRETORIO_DRIVE + \"validacao_classificacao_palavra/kfold/Classificacao/\" + \"P_\" + str(_DOCUMENTOS_PERTURBADOS) + \"_K_\" + str(_TOP_K_PREDICAO) + \"/\"\n","\n","  # Diretório local para carregar o arquivo\n","  DIRETORIO_CLASSIFICACAO_LOCAL = DIRETORIO_LOCAL + \"Classificacao/\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_CLASSIFICACAO_LOCAL):  \n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_CLASSIFICACAO_LOCAL)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_CLASSIFICACAO_LOCAL))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_CLASSIFICACAO_LOCAL))\n","    \n","  # Dataframe que será retornado após o preenchimento\n","  df_dados_classificacao = pd.DataFrame()\n","\n","  # Verifica se o diretório das classificações existem.\n","  if os.path.exists(DIRETORIO_CLASSIFICACAO_DRIVE):\n","    \n","    # Carrega o nome dos arquivos do drive\n","    arquivos = os.listdir(DIRETORIO_CLASSIFICACAO_DRIVE)     \n","\n","    print('\\nModelo:', _MODELO_BERT, \n","          ' Tamanho:', _TAMANHO_BERT, \n","          ' Np:', str(_DOCUMENTOS_PERTURBADOS), \n","          ' Topk:', str(_TOP_K_PREDICAO), \n","          ' Lote:', str(_TAMANHO_LOTE), \n","          ' Taxa Apr.: ', str(_TAXAS_DE_APRENDIZAGEM),\n","          ' Epoca:', str(_EPOCA_EXECUCAO))\n","    \n","    # Acumuladores.\n","    conta_folds = 0 \n","    conta_reg = 0\n","\n","    # Percorre os folds \n","    for fold in range(1,11): \n","      # Nome do arquivo\n","      NOME_ARQUIVO_CLASSIFICACAO = (NOME_BASE_SAIDA + \"_P_\" +  str(_DOCUMENTOS_PERTURBADOS) \n","                                  + \"_K_\" + str(_TOP_K_PREDICAO) \n","                                  + \"_E_\" + str(_EPOCA) \n","                                  + \"_e_\" + str(_EPOCA_EXECUCAO) \n","                                  + \"_lr_\" + str(_TAXAS_DE_APRENDIZAGEM) \n","                                  + \"_b_\" +  str(_TAMANHO_LOTE)  \n","                                  + \"_\" +  str(_TAMANHO_LOTE)  \n","                                  + \"_f\" + str(fold) \n","                                  + _MODELO_BERT \n","                                  + _TAMANHO_BERT)\n","      \n","      # Caminho completo do arquivo compactado no drive\n","      NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO = DIRETORIO_CLASSIFICACAO_DRIVE + NOME_ARQUIVO_CLASSIFICACAO + \".zip\"\n","      # print(\"NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO:\", NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO)\n","\n","      # Caminho completo do arquivo compactado no local\n","      NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO = DIRETORIO_CLASSIFICACAO_LOCAL + NOME_ARQUIVO_CLASSIFICACAO + \".zip\"\n","      # print(\"NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO:\", NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO)\n","\n","      # Caminho completo do arquivo no local\n","      NOME_ARQUIVO_CLASSIFICACAO_LOCAL = DIRETORIO_CLASSIFICACAO_LOCAL + NOME_ARQUIVO_CLASSIFICACAO + \".csv\"\n","      # print(\"NOME_ARQUIVO_CLASSIFICACAO_LOCAL:\", NOME_ARQUIVO_CLASSIFICACAO_LOCAL)\n","\n","      # Verifica se o arquivo existe.\n","      if os.path.isfile(NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO):\n","\n","          # Copia arquivo da classificação compactado do google drive para o drive local\n","          !cp \"$NOME_ARQUIVO_CLASSIFICACAO_DRIVE_COMPACTADO\" \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO\"  \n","                        \n","          # Descompacta arquivo da classificação compactado no drive local\n","          !unzip -o -j -q \"$NOME_ARQUIVO_CLASSIFICACAO_LOCAL_COMPACTADO\" -d \"$DIRETORIO_CLASSIFICACAO_LOCAL\"\n","\n","          # Carrega os dados do arquivo  \n","          dados = pd.read_csv(NOME_ARQUIVO_CLASSIFICACAO_LOCAL, sep=';')\n","          \n","          # Concatena com os dados lidos anteriormente\n","          df_dados_classificacao = pd.concat([df_dados_classificacao, dados], ignore_index=True)\n","            \n","          # Conta o número de folds.\n","          conta_folds = conta_folds + 1\n","\n","          conta_reg = conta_reg + len(dados)\n","      else:\n","          print('Arquivo não encontrado')\n","              \n","    print('Folds:', conta_folds, ' Regs:', conta_reg)\n","  else:\n","      print('Diretório com os resultados não encontrado')\n","\n","  # Corrige os tipos dos dados \n","  tipos = {\"id\": str}\n","  df_dados_classificacao = df_dados_classificacao.astype(tipos)      \n","\n","  print('Registros:', len(df_dados_classificacao))   \n","\n","  return df_dados_classificacao "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MX5lSdClDd0Y"},"outputs":[],"source":["DOCUMENTOS_PERTURBADOS = MELHOR_DOCUMENTOS_PERTURBADOS\n","TOP_K_PREDICAO = MELHOR_TOP_K_PREDICAO\n","EPOCA = 4\n","TAXAS_DE_APRENDIZAGEM = MELHOR_TAXAS_DE_APRENDIZAGEM\n","TAMANHO_LOTE = MELHOR_TAMANHO_LOTE\n","EPOCA_EXECUCAO = MELHOR_EPOCA_EXECUCAO\n","\n","# Recupera os dados da melhor classificação\n","df_dados_classificacao = getDadosClassificacaoCompactado(DIRETORIO_COHEBERT, \n","                                             DOCUMENTOS_PERTURBADOS, \n","                                             TOP_K_PREDICAO,\n","                                             EPOCA,\n","                                             TAXAS_DE_APRENDIZAGEM,\n","                                             TAMANHO_LOTE,\n","                                             EPOCA_EXECUCAO)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dg1-IcymDd0Z"},"outputs":[],"source":["df_dados_classificacao.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"ejchPeIPyR59"},"source":["## 4.4 Carregamento dos arquivos de comparação"]},{"cell_type":"markdown","metadata":{"id":"TJAWS5bSyY_P"},"source":["### 4.4.1 Carregamento do arquivo de dado comparação entre palavras"]},{"cell_type":"markdown","metadata":{"id":"x-72P6oeZv3R"},"source":["#### 4.4.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJUJ1oxia6St"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_COMPARACAO_PALAVRA = \"comparacao_palavra_p\" + str(MELHOR_DOCUMENTOS_PERTURBADOS) + \"_k\" + str(MELHOR_TOP_K_PREDICAO) + \".csv\"\n","NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO = \"comparacao_palavra_p\" + str(MELHOR_DOCUMENTOS_PERTURBADOS) + \"_k\" + str(MELHOR_TOP_K_PREDICAO) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"yDpiZYl_aqBR"},"source":["#### 4.4.1.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94C4zeLdyY_Q"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"M_JasFe_Zv3S"},"source":["#### 4.4.1.3 Copia e descompacta os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rp1y9GNvZv3S"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  # Copia o arquivo de comparações do google drive para a diretório local\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\"\n","  \n","  logging.info(\"Terminei a cópia!\")"]},{"cell_type":"markdown","metadata":{"id":"ToYPuceZyY_R"},"source":["Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiodRQM4yY_R"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Descompactação realizada!\")"]},{"cell_type":"markdown","metadata":{"id":"SUa-E-R0a6Sv"},"source":["#### 4.4.1.4 Carregamento das lista com os dados do arquivo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie_cJJV9a6Sv"},"outputs":[],"source":["#Biblioteca\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_comparacao_palavra = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_PALAVRA, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_comparacao_palavra)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQwMLwaCef3f"},"outputs":[],"source":["lista_comparacao_palavra.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"08xModMIawfM"},"source":["#### 4.4.1.5 Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O0VlVLaJawfN"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_comparacao_palavra_indexado = lista_comparacao_palavra.set_index([\"id\", \"index_sentenca\", \"index_wi\", \"index_wj\"])\n","lista_comparacao_palavra_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"7vMFrBSyDd0b"},"source":["### 4.4.2 Carregamento do arquivo de dado comparação palavra e contexto"]},{"cell_type":"markdown","metadata":{"id":"0fqSA4o_Dd0b"},"source":["#### 4.4.2.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvkTkHA0Dd0b"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_COMPARACAO_CONTEXTO = \"comparacao_contexto_p\" + str(MELHOR_DOCUMENTOS_PERTURBADOS) + \"_k\" + str(MELHOR_TOP_K_PREDICAO) + \".csv\"\n","NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO = \"comparacao_contexto_p\" + str(MELHOR_DOCUMENTOS_PERTURBADOS) + \"_k\" + str(MELHOR_TOP_K_PREDICAO) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"cgSC-U39Dd0b"},"source":["#### 4.4.2.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUCHuhK9Dd0c"},"outputs":[],"source":["# Import das bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"9V4vmTEyDd0c"},"source":["#### 4.4.2.3 Copia e descompacta os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3qfuUc8Dd0c"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  # Copia o arquivo de comparações do google drive para a diretório local\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO\"\n","  \n","  logging.info(\"Terminei a cópia!\")"]},{"cell_type":"markdown","metadata":{"id":"RqmZEtq_Dd0c"},"source":["Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FDCL4bKPDd0c"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_CONTEXTO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Descompactação realizada!\")"]},{"cell_type":"markdown","metadata":{"id":"ya9W7EHxDd0c"},"source":["#### 4.4.2.4 Carregamento das lista com os dados do arquivo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nADTewNDd0c"},"outputs":[],"source":["#Biblioteca\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_comparacao_contexto = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_CONTEXTO, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_comparacao_contexto))) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xod_DzoEDd0d"},"outputs":[],"source":["lista_comparacao_contexto.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"IJc0AsmhDd0d"},"source":["#### 4.4.2.5 Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVngLksFDd0d"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_comparacao_contexto_indexado = lista_comparacao_contexto.set_index([\"id\", \"index_sentenca\", \"index_wi\"])\n","lista_comparacao_contexto_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"TTuaeGLUDd0d"},"source":["## 4.5 Analisa os dados das classificações"]},{"cell_type":"markdown","metadata":{"id":"mAAJv_rIDd0d"},"source":["### Acurácia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smLohfCFDd0d"},"outputs":[],"source":["def calculoClassificacao(df_dados_classificacao):\n","  vp_s = 0\n","  vn_s = 0\n","  fp_s = 0\n","  fn_s = 0\n","  for i, linha in df_dados_classificacao.iterrows():\n","    #if i \u003c 20:\n","    if linha['classe'] == 1 and linha['predicao'] == 1:\n","        vp_s = vp_s + 1\n","    if linha['classe'] == 0 and linha['predicao'] == 0:\n","        vn_s = vn_s + 1        \n","    if linha['classe'] == 1 and linha['predicao'] == 0:\n","        fp_s = fp_s + 1        \n","    if linha['classe'] == 0 and linha['predicao'] == 1:\n","        fn_s = fn_s + 1        \n","\n","  # Acurácia indica uma performance geral do modelo. \n","  # Dentre todas as classificações, quantas o modelo classificou corretamente(vp=1 e vn=0).\n","  if (vp_s+vn_s+fp_s+fn_s) != 0:\n","    acc = (vp_s+vn_s)/(vp_s+vn_s+fp_s+fn_s)\n","  else:\n","    acc  = 0\n","    \n","  # Recall(Revocação) avalia todas as situações da classe Positivo(vp=1) com o valor esperado e quantas estão corretas.\n","  if (vp_s+fn_s) != 0:\n","      rec = (vp_s)/(vp_s+fn_s)\n","  else:\n","      rec = 0\n","  \n","  # Precisão avalia as classificações da classe positivo(vp=1 e fp=0) que o modelo fez e quantas estão corretas.\n","  if (vp_s+fp_s) != 0:\n","      pre = (vp_s)/(vp_s+fp_s)\n","  else:\n","      pre = 0  \n","\n","  # F1 é a média harmônica entre precisão e recall.\n","  if (pre + rec) != 0:  \n","    f1 = 2 * ((pre * rec)/(pre + rec))\n","  else:\n","    f1 = 0\n","\n","  return acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDK78RJLDd0d"},"outputs":[],"source":["acc, rec, pre, f1, vp_s, vn_s, fp_s, fn_s = calculoClassificacao(df_dados_classificacao)\n","\n","print(\"Acurácia: {0:.2%}\".format(acc))\n","print(\"Recall  : {0:.2%}\".format(rec))\n","print(\"Precisão: {0:.2%}\".format(pre))\n","print(\"F1      : {0:.2%}\".format(f1))\n","\n","total = vp_s + vn_s + fp_s + fn_s\n","print(\"Total   :\", total)\n","print(\"vp      : {0:.2%} de {1:1d}\".format((vp_s/total), vp_s))\n","print(\"vn      : {0:.2%} de {1:1d}\".format((vn_s/total), vn_s))\n","print(\"fp      : {0:.2%} de {1:1d}\".format((fp_s/total), fp_s))\n","print(\"fn      : {0:.2%} de {1:1d}\".format((fn_s/total), fn_s))"]},{"cell_type":"markdown","metadata":{"id":"jJeZx0qfDd0d"},"source":["#### Matriz de confusão"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIIqPRORDd0e"},"outputs":[],"source":["# Import das bibliotecas.\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","TAMANHO_FONTE = 38\n","matplotlib.rc('font', size=TAMANHO_FONTE)          # Controla o tamanho do do texto default\n","matplotlib.rc('axes', titlesize=TAMANHO_FONTE)     # Tamanho da fonte do eixo do título\n","matplotlib.rc('axes', labelsize=TAMANHO_FONTE)     # Tamanho da fonte dos rótulos do eixo x e y\n","matplotlib.rc('xtick', labelsize=TAMANHO_FONTE)    # Tamanho da fonte das marcações do eixo y\n","matplotlib.rc('ytick', labelsize=TAMANHO_FONTE)    # Tamanho da fonte dos marcações do eixo x\n","matplotlib.rc('legend', fontsize=TAMANHO_FONTE)    # Tamanho da fonte da legenda\n","matplotlib.rc('figure', titlesize=TAMANHO_FONTE+2)   # Tamanho da fonte do título da figura\n","\n","# Aumenta o tamanho da plotagem e o tamanho da fonte.\n","plt.rcParams['figure.figsize'] = (15,8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GWaeCXayDd0e"},"outputs":[],"source":["# Import das bibliotecas.\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","x_alvo =     df_dados_classificacao['classe'].tolist()\n","y_predicao = df_dados_classificacao['predicao'].tolist()\n","\n","print(classification_report(x_alvo, y_predicao))\n","\n","# Insere os dados no gráfico\n","cf_matrix = confusion_matrix(x_alvo, y_predicao)\n","quantidade_grupos = [\"{0:0.0f}\".format(valor) for valor in cf_matrix.flatten()]\n","percentual_grupos = [\"{0:.2%}\".format(valor) for valor in cf_matrix.flatten()/np.sum(cf_matrix)]\n","rotulos = [f\"{v1}\\n{v2}\" for v1, v2 in zip(quantidade_grupos,percentual_grupos)]\n","rotulos = np.asarray(rotulos).reshape(2,2)\n","ax = sns.heatmap(cf_matrix, annot=rotulos, fmt='', cmap='Blues_r')\n","\n","# Texto do eixo x\n","ax.set_xlabel('Rótulos preditos')\n","# Texto do eixo y\n","ax.set_ylabel('Rótulos verdadeiros')\n","# Rótulos adicionais\n","ax.xaxis.set_ticklabels(['pertDOs','DOs'])\n","ax.yaxis.set_ticklabels(['pertDOs','DOs'])\n","\n","# Mostra o gráfico\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"SIl1RnsIDd0e"},"source":["### Listas em pares"]},{"cell_type":"markdown","metadata":{"id":"HSI2el9lDd0f"},"source":["#### Listas de pares de documentos originais e perturbados classificados corretamente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSYi-0ApDd0g"},"outputs":[],"source":["def listaClassificadoCorretamente(df_dados_classificacao):\n","  lista_retorno = []  \n","  lista_retorno_DO = []\n","  lista_retorno_pertDO = []\n","  for i, linha in df_dados_classificacao.iterrows():\n","    #if i \u003c 20:    \n","    # 1 - Documento Original\n","    if linha['classe'] == 1 and linha['predicao'] == 1:\n","        lista_retorno_DO.append([linha['id'],linha['classe'],linha['predicao']])\n","        lista_retorno.append([linha['id'],linha['classe'],linha['predicao']])\n","    # 0 - Documento perturbado \n","    if linha['classe'] == 0 and linha['predicao'] == 0:\n","        lista_retorno_pertDO.append([linha['id'],linha['classe'],linha['predicao']])\n","        lista_retorno.append([linha['id'],linha['classe'],linha['predicao']])\n","\n","  tipos = {\"id\": str} \n","  df_lista_retorno = pd.DataFrame(lista_retorno, columns = [\"id\",\"classe\",\"predicao\"]) \n","  df_lista_retorno = df_lista_retorno.astype(tipos)\n","\n","  df_lista_retorno_DO = pd.DataFrame(lista_retorno_DO, columns = [\"id\",\"classe\",\"predicao\"])\n","  df_lista_retorno_DO = df_lista_retorno_DO.astype(tipos)\n","\n","  df_lista_retorno_pertDO = pd.DataFrame(lista_retorno_pertDO, columns = [\"id\",\"classe\",\"predicao\"])\n","  df_lista_retorno_pertDO = df_lista_retorno_pertDO.astype(tipos)\n","  \n","  return df_lista_retorno, df_lista_retorno_DO, df_lista_retorno_pertDO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnjfmOS_Dd0g"},"outputs":[],"source":["lista_retorno_classificado_corretamente, lista_retorno_DO_correto, lista_retorno_pertDO_correto = listaClassificadoCorretamente(df_dados_classificacao)\n","print('DO e pertDO classificados corretamente:', len(lista_retorno_classificado_corretamente))\n","print('DO classificados corretamente(VP)     :', len(lista_retorno_DO_correto))\n","print('pertDO classificados corretamente(FP) :', len(lista_retorno_pertDO_correto))"]},{"cell_type":"markdown","metadata":{"id":"sMLTechfDd0g"},"source":["#### Listas de pares de documentos originais e perturbados classificados incorretamente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-BnGrZeDd0g"},"outputs":[],"source":["def listaClassificadoIncorretamente(df_dados_classificacao):\n","  lista_retorno = []  \n","  lista_retorno_DO = []\n","  lista_retorno_pertDO = []\n","  for i, linha in df_dados_classificacao.iterrows():\n","    # 1 - Documento Original\n","    if linha['classe'] == 1 and linha['predicao'] == 0:\n","        lista_retorno_DO.append([linha['id'],linha['classe'],linha['predicao']])\n","        lista_retorno.append([linha['id'],linha['classe'],linha['predicao']])        \n","    # 0 - Documento Perturbado\n","    if linha['classe'] == 0 and linha['predicao'] == 1:\n","        lista_retorno_pertDO.append([linha['id'],linha['classe'],linha['predicao']])\n","        lista_retorno.append([linha['id'],linha['classe'],linha['predicao']])\n","  \n","  tipos = {\"id\": str} \n","  df_lista_retorno = pd.DataFrame(lista_retorno, columns = [\"id\",\"classe\",\"predicao\"])     \n","  df_lista_retorno = df_lista_retorno.astype(tipos)\n","\n","  df_lista_retorno_DO = pd.DataFrame(lista_retorno_DO, columns = [\"id\",\"classe\",\"predicao\"])\n","  df_lista_retorno_DO = df_lista_retorno_DO.astype(tipos)\n","\n","  df_lista_retorno_pertDO = pd.DataFrame(lista_retorno_pertDO, columns = [\"id\",\"classe\",\"predicao\"])\n","  df_lista_retorno_pertDO = df_lista_retorno_pertDO.astype(tipos)\n","\n","  return df_lista_retorno, df_lista_retorno_DO, df_lista_retorno_pertDO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KPplI6oUDd0g"},"outputs":[],"source":["lista_retorno_classificado_incorretamente, lista_retorno_DO_incorreto, lista_retorno_pertDO_incorreto = listaClassificadoIncorretamente(df_dados_classificacao)\n","print('DO e pertDO classificados incorretamente:', len(lista_retorno_classificado_incorretamente))\n","print('DO classificados incorretamente(VN)     :', len(lista_retorno_DO_incorreto))\n","print('pertDO classificados incorretamente(FN) :', len(lista_retorno_pertDO_incorreto))"]},{"cell_type":"markdown","metadata":{"id":"5lXP9YwzDd0g"},"source":["#### Acurácia das listas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0_cx0GaMDd0g"},"outputs":[],"source":["total = len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente)\n","print(\"Total de documentos                 :\", total)\n","print(\"  Total de documentos originais     :\", (len(lista_retorno_DO_correto)+len(lista_retorno_DO_incorreto)))\n","print(\"  Total de documentos perturbados   :\", (len(lista_retorno_pertDO_correto)+len(lista_retorno_pertDO_incorreto)))\n","print(\"Total de acertos                    :\", len(lista_retorno_classificado_corretamente))\n","print(\"Total de erros                      :\", len(lista_retorno_classificado_incorretamente))\n","print()\n","print(\"Acurácia                                        : {0:.2%}\".format(len(lista_retorno_classificado_corretamente)/total))\n","print(\"  DO coerentes       = Verdadeiros positivos(VP): {0:.2%}\".format(len(lista_retorno_DO_correto)/total))\n","print(\"  pertDO incoerentes = Falsos positivos(FP)     : {0:.2%}\".format(len(lista_retorno_pertDO_correto)/total))\n","print(\"  DO incoerentes     = Verdadeiro negativos(VN) : {0:.2%}\".format(len(lista_retorno_DO_incorreto)/total))\n","print(\"  pertDO coerentes   = Falsos negativos(FN)     : {0:.2%}\".format(len(lista_retorno_pertDO_incorreto)/total))"]},{"cell_type":"markdown","metadata":{"id":"VonHrEmkDd0h"},"source":["#### Listas documentos originais e perturbados e suas classificações sem repetições"]},{"cell_type":"markdown","metadata":{"id":"izvyu6mrDd0h"},"source":["Remove a duplicidade dos documentos originais classificados corretamente(VP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTizpFqWDd0h"},"outputs":[],"source":["print(\"Com repetição:\",len(lista_retorno_DO_correto))\n","lista_retorno_DO_classificado_corretamente_sem_repeticao = lista_retorno_DO_correto.drop_duplicates(subset=['id'])\n","print(\"Sem repetição:\", len(lista_retorno_DO_classificado_corretamente_sem_repeticao))"]},{"cell_type":"markdown","metadata":{"id":"GKE123U2Dd0h"},"source":["Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Es98NOnzDd0h"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_retorno_DO_classificado_corretamente_sem_repeticao_indexado = lista_retorno_DO_classificado_corretamente_sem_repeticao.set_index([\"id\"])\n","lista_retorno_DO_classificado_corretamente_sem_repeticao_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"nHCFrSwSDd0i"},"source":["Remove a duplicidade dos documentos originais classificados incorretamente(VN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JnPWJ_zDd0i"},"outputs":[],"source":["print(\"Com repetição:\",len(lista_retorno_DO_incorreto))\n","lista_retorno_DO_classificado_incorretamente_sem_repeticao = lista_retorno_DO_incorreto.drop_duplicates(subset=['id'])\n","print(\"Sem repetição:\", len(lista_retorno_DO_classificado_incorretamente_sem_repeticao))"]},{"cell_type":"markdown","metadata":{"id":"MG2tcgPNDd0i"},"source":["Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4V4bNLJuDd0i"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_retorno_DO_classificado_incorretamente_sem_repeticao_indexado = lista_retorno_DO_classificado_incorretamente_sem_repeticao.set_index([\"id\"])\n","lista_retorno_DO_classificado_incorretamente_sem_repeticao_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"lvrRMqXnDd0i"},"source":["Remove a duplicidade dos documentos perturbados classificados corretamente(FP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILFohPAdDd0i"},"outputs":[],"source":["print(\"Com repetição:\",len(lista_retorno_pertDO_correto))\n","lista_retorno_pertDO_classificado_corretamente_sem_repeticao = lista_retorno_pertDO_correto.drop_duplicates(subset=['id'])\n","print(\"Sem repetição:\", len(lista_retorno_pertDO_classificado_corretamente_sem_repeticao))"]},{"cell_type":"markdown","metadata":{"id":"0UD1oWu5Dd0j"},"source":["Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmlHwk4yDd0j"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_retorno_pertDO_classificado_corretamente_sem_repeticao_indexado = lista_retorno_pertDO_classificado_corretamente_sem_repeticao.set_index([\"id\"])\n","lista_retorno_pertDO_classificado_corretamente_sem_repeticao_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"9uwszYgFDd0j"},"source":["Remove a duplicidade dos documentos perturbados classificados incorretamente(FN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YtYr4wADd0j"},"outputs":[],"source":["print(\"Com repetição:\",len(lista_retorno_pertDO_incorreto))\n","lista_retorno_pertDO_classificado_incorretamente_sem_repeticao = lista_retorno_pertDO_incorreto.drop_duplicates(subset=['id'])\n","print(\"Sem repetição:\", len(lista_retorno_pertDO_classificado_incorretamente_sem_repeticao))"]},{"cell_type":"markdown","metadata":{"id":"sqDvOz0ADd0j"},"source":["Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zeYhz2RMDd0j"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_retorno_pertDO_classificado_incorretamente_sem_repeticao_indexado = lista_retorno_pertDO_classificado_incorretamente_sem_repeticao.set_index([\"id\"])\n","lista_retorno_pertDO_classificado_incorretamente_sem_repeticao_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"ColsmtdhDd0k"},"source":["Remove as duplicidades dos documentos classificados corretamente."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUPjynmNDd0k"},"outputs":[],"source":["print(\"Com repetição:\",len(lista_retorno_classificado_corretamente))\n","lista_retorno_classificado_corretamente_sem_repeticao = lista_retorno_classificado_corretamente.drop_duplicates(subset=['id'])\n","print(\"Sem repetição:\", len(lista_retorno_classificado_corretamente_sem_repeticao))"]},{"cell_type":"markdown","metadata":{"id":"byP7bjwRDd0k"},"source":["Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qZiZR8tEDd0k"},"outputs":[],"source":["lista_retorno_classificado_corretamente_sem_repeticao.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39rB5whiDd0k"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_retorno_classificado_corretamente_sem_repeticao_indexado = lista_retorno_classificado_corretamente_sem_repeticao.set_index([\"id\"])\n","lista_retorno_classificado_corretamente_sem_repeticao_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"1ty0hLdiDd0k"},"source":["Remove as duplicidades dos documentos perturbados classificados incorretamente."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNhQhEZzDd0k"},"outputs":[],"source":["print(\"Com repetição:\",len(lista_retorno_classificado_incorretamente))\n","lista_retorno_classificado_incorretamente_sem_repeticao = lista_retorno_classificado_incorretamente.drop_duplicates(subset=['id'])\n","print(\"Sem repetição:\", len(lista_retorno_classificado_incorretamente_sem_repeticao))"]},{"cell_type":"markdown","metadata":{"id":"E0yMwOMHDd0l"},"source":["Criando dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bOUh3rjWDd0l"},"outputs":[],"source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_retorno_classificado_incorretamente_sem_repeticao_indexado = lista_retorno_classificado_incorretamente_sem_repeticao.set_index([\"id\"])\n","lista_retorno_classificado_incorretamente_sem_repeticao_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"0O_BJEDbDd0l"},"source":["### Medidas de DO e pertDO"]},{"cell_type":"markdown","metadata":{"id":"kw0qQ6zoQhkq"},"source":["#### Função quer realiza a medição dos documentos\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PDHaHnU-5yXx"},"source":["##### getMedidasComparacaoPalavra"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6u_Srfdt09a1"},"outputs":[],"source":["import sys\n","\n","def getMedidasComparacaoPalavra(id_documento, \n","                                index_sentenca,\n","                                index_wi,\n","                                index_wj,\n","                                estrategia_medida=0):\n","\n","  # Pesquisa a medida de comparação das palavras wi e wj\n","  # pelo id do documento, índice da sentença, índice da palavra wi e índice da palavra wj\n","  medidas = lista_comparacao_palavra_indexado.loc[str(id_documento),\n","                                                  index_sentenca,\n","                                                  index_wi,\n","                                                  index_wj]\n","\n","  if len(medidas) != 0:\n","    # print(\"\u003e\u003e\u003e\u003emedidas:\",medidas)\n","    # Seleciona a estratégia de pooling\n","    pooling = \"_mean\"\n","    if estrategia_medida == 1:\n","      pooling = \"_max\"\n","\n","    cos = medidas[\"cos\" + pooling]\n","    euc = medidas[\"euc\" + pooling]\n","    man = medidas[\"man\" + pooling]\n","\n","    return cos, euc, man\n","\n","  else:\n","   print(\"Problemas comparação palavras:\", medidas)\n","   return 0, float(sys.maxsize), float(sys.maxsize)"]},{"cell_type":"markdown","metadata":{"id":"SN5lpgdUBLbp"},"source":["##### Palavras Adjacentes"]},{"cell_type":"markdown","metadata":{"id":"DgQ6ZKylpC5y"},"source":["###### getMedidasCoerenciaPalavrasAdjacentesDocumentoTodasPalavras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1JvCjMA84Xp"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasAdjacentesDocumentoTodasPalavras(id_documento,\n","                                                                documento, \n","                                                                lista_sentenca_documento, \n","                                                                lista_tokens_documento,\n","                                                                lista_pos_documento,\n","                                                                estrategia_medida):\n","  '''\n","    Percorre as sentenças de um documento para calcular as medidas\n","  '''\n","  \n","  #print(\"lista_sentenca_documento:\", lista_sentenca_documento)\n","  #print(\"lista_tokens_documento:\", lista_tokens_documento)\n","  #print(\"lista_pos_documento:\", lista_pos_documento)\n","  \n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    # print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    # print(\"sentenca_pos:\",sentenca_pos)\n","    #print(\"Quantidade de palavras:\",len(sentenca_token))\n","\n","    # Quantidade de palavras da sentença\n","    k = len(sentenca_token)\n","  \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","    #Percorre as palavras do documento    \n","    for ix in range(0,k-1):\n","\n","      # Seleciona as palavras do documento  \n","      wi = sentenca_token[ix]\n","      wj = sentenca_token[ix+1]\n","      # Seleciona as POS-Tagging das palavras\n","      pos_i = sentenca_pos[ix]\n","      pos_j = sentenca_pos[ix+1]\n","\n","      # print(\"\\nwi:\", wi, ix)\n","      # print(\"wj:\", wj, ix+1)\n","\n","      # Recupera as medidas entre wi e wj             \n","      cos, euc, man = getMedidasComparacaoPalavra(id_documento, i, ix, ix+1, estrategia_medida)\n","  \n","      # Acumula as medidas do par de palavras\n","      soma_Wcos = soma_Wcos + abs(cos)\n","      soma_Weuc = soma_Weuc + abs(euc)\n","      soma_Wman = soma_Wman + abs(man)\n","\n","    # Calcula a média das medidas para as k-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k-1) != 0:\n","      \n","      MWcos = float(soma_Wcos)/float(k-1)\n","      MWeuc = float(soma_Weuc)/float(k-1)\n","      MWman = float(soma_Wman)/float(k-1)\n","    \n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","\n","  # Calcula a média das medidas para o documento\n","  MScos = float(soma_Scos)/float(n)\n","  MSeuc = float(soma_Seuc)/float(n)\n","  MSman = float(soma_Sman)/float(n)\n","  \n","  return MScos, MSeuc, MSman"]},{"cell_type":"markdown","metadata":{"id":"0AV690tOo-Cd"},"source":["###### getMedidasCoerenciaPalavrasAdjacentesDocumentoSemStopWord"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0MjO8nGV5fG"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasAdjacentesDocumentoSemStopWord(id_documento,\n","                                                              documento, \n","                                                              lista_sentenca_documento, \n","                                                              lista_tokens_documento, \n","                                                              lista_pos_documento,\n","                                                              estrategia_medida):\n","  \n","  '''\n","    Percorre as sentenças de um documento para calcular as medidas\n","  '''\n","  \n","  #print(\"lista_sentenca_documento:\", lista_sentenca_documento)\n","  #print(\"lista_tokens_documento:\", lista_tokens_documento)\n","  #print(\"lista_pos_documento:\", lista_pos_documento)\n","\n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    #print(\"sentenca:\",sentenca)  \n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    #print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    #print(\"sentenca_pos:\",sentenca_pos)\n","    #print(\"Quantidade de palavras:\",len(sentenca_token))\n","   \n","    # Seleciona as palavras e POS-Tagging sem as Stopwords\n","    lista_tokens_nova = []\n","    lista_pos_nova = []    \n","    # Percorre as postagging das palavras\n","    for ix, palavra in enumerate(sentenca_token):\n","        # Se o token estiver não lista de stopwords\n","        if palavra.lower() not in getStopwords(nlp):\n","          # Guarda os elementos utilizados\n","          lista_tokens_nova.append(sentenca_token[ix])\n","          lista_pos_nova.append(sentenca_pos[ix])              \n","   \n","    #print(\"Depois\")\n","    #print(\"lista_tokens_nova:\",lista_tokens_nova)\n","    #print(\"POS Tagging:\",lista_pos_nova)\n","    #print(\"Quantidade de palavras:\",len(lista_tokens_nova))\n","\n","    # Quantidade de palavras na sentença\n","    k = len(lista_tokens_nova)\n","      \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","    #Percorre as palavras do documento    \n","    for ix in range(0,k-1):\n","\n","      # Seleciona as palavras do documento  \n","      wi = lista_tokens_nova[ix]\n","      wj = lista_tokens_nova[ix+1]\n","      # Seleciona as POS-Tagging das palavras\n","      pos_i = lista_pos_nova[ix]\n","      pos_j = lista_pos_nova[ix+1]\n","\n","      # print(\"\\nwi:\", wi, ix)\n","      # print(\"wj:\", wj, ix+1)                    \n","\n","      # Recupera as medidas entre wi e wj             \n","      cos, euc, man = getMedidasComparacaoPalavra(id_documento, i, ix, ix+1, estrategia_medida)\n","     \n","      # Acumula as medidas do par de palavras\n","      soma_Wcos = soma_Wcos + abs(cos)\n","      soma_Weuc = soma_Weuc + abs(euc)\n","      soma_Wman = soma_Wman + abs(man)\n","   \n","    # Calcula a média das medidas para as m-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k-1) != 0:\n","      MWcos = float(soma_Wcos)/float(k-1)\n","      MWeuc = float(soma_Weuc)/float(k-1)\n","      MWman = float(soma_Wman)/float(k-1)\n","\n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","    \n","    del lista_tokens_nova\n","    del lista_pos_nova    \n","    \n","  # Calcula a média das medidas para o documento\n","  MScos = float(soma_Scos)/float(n)\n","  MSeuc = float(soma_Seuc)/float(n)\n","  MSman = float(soma_Sman)/float(n)\n","  \n","  return MScos, MSeuc, MSman"]},{"cell_type":"markdown","metadata":{"id":"qJdWB9t_pGxr"},"source":["###### getMedidasCoerenciaPalavrasAdjacentesDocumentoPalavrasSalientes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LP7gKQ7Oe5KP"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasAdjacentesDocumentoPalavrasSalientes(id_documento,\n","                                                                    documento, \n","                                                                    lista_sentenca_documento, \n","                                                                    lista_tokens_documento, \n","                                                                    lista_pos_documento,\n","                                                                    estrategia_medida,\n","                                                                    classe_saliente=[\"NOUN\",\"VERB\",\"AUX\"]):\n","  \n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    # print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    # print(\"sentenca_pos:\",sentenca_pos)\n","    # print(\"Quantidade de palavras:\",len(sentenca_token))\n","\n","    # Seleciona somente palavras saliente \n","    lista_tokens_nova = []\n","    lista_pos_nova = []    \n","    # Percorre as postagging das palavras\n","    for ix, pos in enumerate(sentenca_pos):\n","        # Se a postagging da palavra estiver na lista das classes das salientes\n","        if pos in classe_saliente:\n","          # Guarda os elementos utilizados\n","          lista_tokens_nova.append(sentenca_token[ix])\n","          lista_pos_nova.append(sentenca_pos[ix])    \n","       \n","    #print(\"Depois\")\n","    #print(\"lista_tokens_nova:\",lista_tokens_nova)\n","    #print(\"POS Tagging:\",lista_pos_nova)\n","    #print(\"Quantidade de palavras:\",len(lista_tokens_nova))\n","\n","    # Quantidade de palavras na sentença\n","    k = len(lista_tokens_nova)\n","  \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","    #Percorre as palavras do documento    \n","    for ix in range(0,k-1):\n","\n","      # Seleciona as palavras do documento  \n","      wi = lista_tokens_nova[ix]\n","      wj = lista_tokens_nova[ix+1]\n","      # Seleciona as POS-Tagging das palavras\n","      pos_i = lista_pos_nova[ix]\n","      pos_j = lista_pos_nova[ix+1]\n","\n","      # print(\"\\nwi:\", wi, ix)\n","      # print(\"wj:\", wj, ix+1)                  \n","\n","      # Recupera as medidas entre wi e wj             \n","      cos, euc, man = getMedidasComparacaoPalavra(id_documento, i, ix, ix+1, estrategia_medida)\n","     \n","      # Acumula as medidas do par de palavras\n","      soma_Wcos = soma_Wcos + abs(cos)\n","      soma_Weuc = soma_Weuc + abs(euc)\n","      soma_Wman = soma_Wman + abs(man)\n","\n","    # Calcula a média das medidas para as m-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k-1) != 0:\n","      MWcos = float(soma_Wcos)/float(k-1)\n","      MWeuc = float(soma_Weuc)/float(k-1)\n","      MWman = float(soma_Wman)/float(k-1)\n","\n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","\n","    del lista_tokens_nova\n","    del lista_pos_nova\n","\n","  # Calcula a média das medidas para o documento\n","  MScos = float(soma_Scos)/float(n)\n","  MSeuc = float(soma_Seuc)/float(n)\n","  MSman = float(soma_Sman)/float(n)\n","    \n","  return MScos, MSeuc, MSman"]},{"cell_type":"markdown","metadata":{"id":"BwqpQb8MpMu-"},"source":["###### getMedidasCoerenciaPalavrasAdjacentes\n","\n","Recupera as medidas da coerência das palavras adjacentes de acordo com o filtro de palavras a ser utilizado nos documentos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQs-1sCxiHyt"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasAdjacentes(id_documento,\n","                                          documento, \n","                                          lista_sentenca_documento, \n","                                          lista_tokens_documento, \n","                                          lista_pos_documento, \n","                                          estrategia_medida = 0,\n","                                          filtro_palavra = 0,\n","                                          classe_saliente=[\"NOUN\",\"VERB\",\"AUX\"]):\n","\n","  \"\"\"\n","    Recupera as medidas da coerência das palavras adjacentes de acordo com o filtro de palavras a ser utilizado nos documentos.\n","  \"\"\"    \n","  \n","  if filtro_palavra == 0: # Todas as palavras\n","    return getMedidasCoerenciaPalavrasAdjacentesDocumentoTodasPalavras(id_documento, \n","                                                                       documento, \n","                                                                       lista_sentenca_documento, \n","                                                                       lista_tokens_documento, \n","                                                                       lista_pos_documento,\n","                                                                       estrategia_medida)\n","  else:\n","    if filtro_palavra == 1: # Sem stopwords\n","        return getMedidasCoerenciaPalavrasAdjacentesDocumentoSemStopWord(id_documento, \n","                                                                         documento, \n","                                                                         lista_sentenca_documento, \n","                                                                         lista_tokens_documento, \n","                                                                         lista_pos_documento,\n","                                                                         estrategia_medida)\n","    else: \n","        if filtro_palavra == 2: # Somente verbos(e auxiliares) substantivos          \n","          return getMedidasCoerenciaPalavrasAdjacentesDocumentoPalavrasSalientes(id_documento, \n","                                                                                 documento, \n","                                                                                 lista_sentenca_documento, \n","                                                                                 lista_tokens_documento, \n","                                                                                 lista_pos_documento,\n","                                                                                 estrategia_medida,\n","                                                                                 classe_saliente=classe_saliente) "]},{"cell_type":"markdown","metadata":{"id":"q6nOFPOXBVhM"},"source":["##### Palavras Combinação"]},{"cell_type":"markdown","metadata":{"id":"4SQfIUuUBlIJ"},"source":["###### getMedidasCoerenciaPalavrasCombinacaoDocumentoTodasPalavras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uK_WZntYBlIJ"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasCombinacaoDocumentoTodasPalavras(id_documento,\n","                                                                documento, \n","                                                                lista_sentenca_documento, \n","                                                                lista_tokens_documento, \n","                                                                lista_pos_documento,\n","                                                                estrategia_medida):\n","  '''\n","    Percorre as sentenças de um documento para calcular as medidas\n","  '''\n","  \n","  #print(\"lista_sentenca_documento:\", lista_sentenca_documento)\n","  #print(\"lista_tokens_documento:\", lista_tokens_documento)\n","  #print(\"lista_pos_documento:\", lista_pos_documento)\n","  \n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    # print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    # print(\"sentenca_pos:\",sentenca_pos)\n","    #print(\"Quantidade de palavras:\",len(sentenca_token))\n","\n","    # Quantidade de palavras da sentença\n","    k = len(sentenca_token)\n","  \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","\n","    contaComparacoes = 0\n","    \n","    # Seleciona os pares de sentença a serem avaliados\n","    for ix in range(0,k-1):\n","\n","      # Seleciona as palavras do documento  \n","      wi = sentenca_token[ix]      \n","      pos_i = sentenca_pos[ix]\n","        \n","      # Percorre as palavras da sentença\n","      for jx in range(ix+1,k):\n","\n","        # Seleciona as palavras do documento  \n","        wj = sentenca_token[jx]\n","        pos_j = sentenca_pos[jx]\n","\n","        # print(\"\\nwi:\", wi, pos_i)                          \n","        # print(\"wj:\", wj, pos_j)                    \n","\n","        # Recupera as medidas entre wi e wj             \n","        cos, euc, man = getMedidasComparacaoPalavra(id_documento, i, ix, jx, estrategia_medida)\n","  \n","        # Acumula as medidas do par de palavras\n","        soma_Wcos = soma_Wcos + abs(cos)\n","        soma_Weuc = soma_Weuc + euc\n","        soma_Wman = soma_Wman + man\n","\n","        contaComparacoes = contaComparacoes + 1\n","      \n","    # Calcula a média das medidas para as m-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k-1) != 0:\n","      MWcos = float(soma_Wcos)/float(contaComparacoes)\n","      MWeuc = float(soma_Weuc)/float(contaComparacoes)\n","      MWman = float(soma_Wman)/float(contaComparacoes)\n","    \n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","\n","  # Calcula a média das medidas para o documento\n","  MScos = float(soma_Scos)/float(n)\n","  MSeuc = float(soma_Seuc)/float(n)\n","  MSman = float(soma_Sman)/float(n)\n","  \n","  return MScos, MSeuc, MSman"]},{"cell_type":"markdown","metadata":{"id":"oaE6vQb1EDtO"},"source":["###### getMedidasCoerenciaPalavrasCombinacaoDocumentoSemStopWord\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-whkXrm4EDtP"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasCombinacaoDocumentoSemStopWord(id_documento,\n","                                                              documento, \n","                                                              lista_sentenca_documento, \n","                                                              lista_tokens_documento, \n","                                                              lista_pos_documento,\n","                                                              estrategia_medida):\n","  \n","  '''\n","    Percorre as sentenças de um documento para calcular as medidas\n","  '''\n","  \n","  #print(\"lista_sentenca_documento:\", lista_sentenca_documento)\n","  #print(\"lista_tokens_documento:\", lista_tokens_documento)\n","  #print(\"lista_pos_documento:\", lista_pos_documento)\n","\n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    #print(\"sentenca:\",sentenca)  \n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    #print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    #print(\"sentenca_pos:\",sentenca_pos)\n","    #print(\"Quantidade de palavras:\",len(sentenca_token))\n","   \n","    # Seleciona as palavras e POS-Tagging sem as Stopwords\n","    lista_tokens_nova = []\n","    lista_pos_nova = []    \n","    # Percorre as postagging das palavras\n","    for ix, palavra in enumerate(sentenca_token):\n","        # Se o token estiver não lista de stopwords\n","        if palavra.lower() not in getStopwords(nlp):\n","          # Guarda os elementos utilizados\n","          lista_tokens_nova.append(sentenca_token[ix])\n","          lista_pos_nova.append(sentenca_pos[ix])              \n","\n","    #print(\"Depois\")\n","    #print(\"lista_tokens_nova:\",lista_tokens_nova)\n","    #print(\"POS Tagging:\",lista_pos_nova)\n","    #print(\"Quantidade de palavras:\",len(lista_tokens_nova))\n","\n","    # Quantidade de palavras na sentença\n","    k = len(lista_tokens_nova)\n","  \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","    # Seleciona os pares de sentença a serem avaliados\n","    for ix in range(0,k-1):\n","      # Seleciona as palavras do documento  \n","      wi = lista_tokens_nova[ix]      \n","      pos_i = lista_pos_nova[ix]\n","        \n","      # Percorre as palavras da sentença\n","      for jx in range(ix+1,k):\n","        # Seleciona as palavras do documento  \n","        wj = lista_tokens_nova[jx]\n","        pos_j = lista_pos_nova[jx]\n","\n","        # print(\"\\nwi:\", wi, pos_i)                          \n","        # print(\"wj:\", wj, pos_j)                    \n","\n","        # Recupera as medidas entre wi e wj             \n","        cos, euc, man = getMedidasComparacaoPalavra(id_documento, i, ix, jx, estrategia_medida)\n","  \n","        # Acumula as medidas do par de palavras\n","        soma_Wcos = soma_Wcos + abs(cos)\n","        soma_Weuc = soma_Weuc + euc\n","        soma_Wman = soma_Wman + man\n","      \n","    # Calcula a média das medidas para as m-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k-1) != 0:\n","      MWcos = float(soma_Wcos)/float(k-1)\n","      MWeuc = float(soma_Weuc)/float(k-1)\n","      MWman = float(soma_Wman)/float(k-1)\n","    \n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","\n","    del lista_tokens_nova\n","    del lista_pos_nova    \n","\n","  # Calcula a média das medidas para o documento\n","  Scos = float(soma_Scos)/float(n)\n","  Seuc = float(soma_Seuc)/float(n)\n","  Sman = float(soma_Sman)/float(n)\n","    \n","  return Scos, Seuc, Sman"]},{"cell_type":"markdown","metadata":{"id":"x1W8AGEbFL_P"},"source":["###### getMedidasCoerenciaPalavrasCombinacaoDocumentoPalavrasSalientes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4VFXSd1FL_P"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasCombinacaoDocumentoPalavrasSalientes(id_documento,\n","                                                                    documento, \n","                                                                    lista_sentenca_documento, \n","                                                                    lista_tokens_documento, \n","                                                                    lista_pos_documento,\n","                                                                    estrategia_medida,\n","                                                                    classe_saliente=[\"NOUN\",\"VERB\",\"AUX\"]):\n","  \n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    # print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    # print(\"sentenca_pos:\",sentenca_pos)\n","    # print(\"Quantidade de palavras:\",len(sentenca_token))\n","\n","    # Somente palavras saliente \n","    lista_tokens_nova = []\n","    lista_pos_nova = []    \n","    # Percorre as postagging das palavras\n","    for ix, pos in enumerate(sentenca_pos):\n","        # Se a postagging da palavra estiver na lista das classes das salientes\n","        if pos in classe_saliente:\n","          # Guarda os elementos utilizados\n","          lista_tokens_nova.append(sentenca_token[ix])\n","          lista_pos_nova.append(sentenca_pos[ix])\n","    \n","    #print(\"Depois\")\n","    #print(\"lista_tokens_nova:\",lista_tokens_nova)\n","    #print(\"POS Tagging:\",lista_pos_nova)\n","    #print(\"Quantidade de palavras:\",len(lista_tokens_nova))\n","\n","    # Quantidade de palavras na sentença\n","    k = len(lista_tokens_nova)\n","  \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","     # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","    # Seleciona os pares de sentença a serem avaliados\n","    for ix in range(0,k-1):\n","      # Seleciona as palavras do documento  \n","      wi = lista_tokens_nova[ix]      \n","      pos_i = lista_pos_nova[ix]\n","        \n","      # Percorre as palavras da sentença\n","      for jx in range(ix+1,k):\n","        # Seleciona as palavras do documento  \n","        wj = lista_tokens_nova[jx]\n","        pos_j = lista_pos_nova[jx]\n","\n","        # print(\"\\nwi:\", wi, pos_i)                          \n","        # print(\"wj:\", wj, pos_j)                    \n","\n","        # Recupera as medidas entre wi e wj             \n","        cos, euc, man = getMedidasComparacaoPalavra(id_documento, i, ix, jx, estrategia_medida)\n","  \n","        # Acumula as medidas do par de palavras\n","        soma_Wcos = soma_Wcos + abs(cos)\n","        soma_Weuc = soma_Weuc + euc\n","        soma_Wman = soma_Wman + man\n","\n","    # Calcula a média das medidas para as m-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k-1) != 0:\n","      MWcos = float(soma_Wcos)/float(k-1)\n","      MWeuc = float(soma_Weuc)/float(k-1)\n","      MWman = float(soma_Wman)/float(k-1)\n","\n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","\n","    del lista_tokens_nova\n","    del lista_pos_nova\n","\n","  # Calcula a média das medidas para o documento\n","  MScos = float(soma_Scos)/float(n)\n","  MSeuc = float(soma_Seuc)/float(n)\n","  MSman = float(soma_Sman)/float(n)\n","  \n","  return MScos, MSeuc, MSman"]},{"cell_type":"markdown","metadata":{"id":"Yc29kGMvAtpu"},"source":["###### getMedidasCoerenciaPalavrasCombinacao\n","\n","Recupera as medidas da coerência da combinação de palavras de acordo com o filtro de palavras a ser utilizado nos documentos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gt5UWCkLAtpv"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasCombinacao(id_documento,\n","                                          documento, \n","                                          lista_sentenca_documento, \n","                                          lista_tokens_documento, \n","                                          lista_pos_documento,\n","                                          estrategia_medida,                                \n","                                          filtro_palavra = 0,\n","                                          classe_saliente=[\"NOUN\",\"VERB\",\"AUX\"]):\n","  \"\"\"\n","    Recupera as medidas da coerência da combinação de palavras de acordo com o filtro de palavras a ser utilizado nos documentos.\n","  \"\"\"  \n","  \n","  if filtro_palavra == 0: # Todas as palavras\n","    return getMedidasCoerenciaPalavrasCombinacaoDocumentoTodasPalavras(id_documento, \n","                                                                       documento, \n","                                                                       lista_sentenca_documento, \n","                                                                       lista_tokens_documento, \n","                                                                       lista_pos_documento,\n","                                                                       estrategia_medida)\n","  else:\n","    if filtro_palavra == 1: # Sem stopwords\n","        return getMedidasCoerenciaPalavrasCombinacaoDocumentoSemStopWord(id_documento, documento, \n","                                                                         lista_sentenca_documento, \n","                                                                         lista_tokens_documento, \n","                                                                         lista_pos_documento,\n","                                                                         estrategia_medida)\n","    else: \n","        if filtro_palavra == 2: # Somente verbos(e auxiliares) substantivos          \n","          return getMedidasCoerenciaPalavrasCombinacaoDocumentoPalavrasSalientes(id_documento, \n","                                                                                 documento, \n","                                                                                 lista_sentenca_documento, \n","                                                                                 lista_tokens_documento, \n","                                                                                 lista_pos_documento,\n","                                                                                 estrategia_medida,\n","                                                                                 classe_saliente=classe_saliente)"]},{"cell_type":"markdown","metadata":{"id":"YqvGKY8YBaTf"},"source":["##### Contexto"]},{"cell_type":"markdown","metadata":{"id":"H7RBtWbXMnY-"},"source":["###### getMedidasComparacaoPalavrasGlobal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CFGWLNvMnY-"},"outputs":[],"source":["import sys\n","\n","def getMedidasComparacaoPalavrasGlobal(id_documento, \n","                                       index_sentenca, \n","                                       index_wi,                                       \n","                                       estrategia_medida=0,\n","                                       filtro_palavra=0):\n","  \n","  # Pesquisa a medida palavra wi e o contexto\n","  # pelo id do documento, índice da sentença, índice da palavra wi\n","  medidas = lista_comparacao_contexto_indexado.loc[str(id_documento),\n","                                                   index_sentenca,\n","                                                   index_wi]\n","\n","  if len(medidas) != 0:\n","    # print(\"\u003e\u003e\u003e\u003emedidas:\",medidas)\n","    # Seleciona a estratégia de pooling\n","    pooling = \"_mean\"\n","    if estrategia_medida == 1:\n","      pooling = \"_max\"\n","\n","    # Seleciona o filtro de palavra\n","    if filtro_palavra == 0: # Todas as palavras\n","      cos = medidas[\"cos_ctxall\" + pooling]\n","      euc = medidas[\"euc_ctxall\" + pooling]\n","      man = medidas[\"man_ctxall\" + pooling]\n","    else:\n","      if filtro_palavra == 1: # Sem as stopwords\n","        cos = medidas[\"cos_ctxclean\" + pooling]\n","        euc = medidas[\"euc_ctxclean\" + pooling]\n","        man = medidas[\"man_ctxclean\" + pooling]\n","      else:\n","        if filtro_palavra == 2: # Somente verbos, auxiliar e substantivo\n","          cos = medidas[\"cos_ctxverbnoun\" + pooling]\n","          euc = medidas[\"euc_ctxverbnoun\" + pooling]\n","          man = medidas[\"man_ctxverbnoun\" + pooling]\n","\n","    return cos, euc, man\n","\n","  else:\n","    print(\"Problemas comparação contexto:\", medidas)\n","    return 0, float(sys.maxsize), float(sys.maxsize)"]},{"cell_type":"markdown","metadata":{"id":"JgMZljA1LpSN"},"source":["###### getMedidasCoerenciaPalavrasGlobalDocumentoTodasPalavras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0OFZzlnLpSN"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasGlobalDocumentoTodasPalavras(id_documento,\n","                                                            documento, \n","                                                            lista_sentenca_documento, \n","                                                            lista_tokens_documento, \n","                                                            lista_pos_documento,\n","                                                            estrategia_medida,\n","                                                            filtro_palavra):\n","  '''\n","    Percorre as sentenças de um documento para calcular as medidas\n","  '''\n","  \n","  #print(\"lista_sentenca_documento:\", lista_sentenca_documento)\n","  #print(\"lista_tokens_documento:\", lista_tokens_documento)\n","  #print(\"lista_pos_documento:\", lista_pos_documento)\n","  \n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    # print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    # print(\"sentenca_pos:\",sentenca_pos)\n","    #print(\"Quantidade de palavras:\",len(sentenca_token))\n","\n","    # Quantidade de palavras da sentença\n","    k = len(sentenca_token)\n","  \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","    # Seleciona os pares de sentença a serem avaliados\n","    for ix in range(0,k):\n","\n","      # Seleciona as palavras do documento  \n","      wi = sentenca_token[ix]      \n","      pos_i = sentenca_pos[ix]\n","        \n","      # print(\"\\nwi:\", wi, pos_i)      \n","\n","      # Recupera as medidas entre wi com o contexto\n","      cos, euc, man = getMedidasComparacaoPalavrasGlobal(id_documento, \n","                                                         i,\n","                                                         ix,\n","                                                         estrategia_medida,\n","                                                         filtro_palavra)\n","  \n","      # Acumula as medidas do par de palavras\n","      soma_Wcos = soma_Wcos + abs(cos)\n","      soma_Weuc = soma_Weuc + abs(euc)\n","      soma_Wman = soma_Wman + abs(man)\n","      \n","    # Calcula a média das medidas para as m-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k) != 0:\n","      MWcos = float(soma_Wcos)/float(k)\n","      MWeuc = float(soma_Weuc)/float(k)\n","      MWman = float(soma_Wman)/float(k)\n","    \n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","\n","  # Calcula a média das medidas para o documento\n","  MScos = float(soma_Scos)/float(n)\n","  MSeuc = float(soma_Seuc)/float(n)\n","  MSman = float(soma_Sman)/float(n)\n","  \n","  return MScos, MSeuc, MSman"]},{"cell_type":"markdown","metadata":{"id":"XY7Yzx-2PLVP"},"source":["###### getMedidasCoerenciaPalavrasGlobalDocumentoSemStopWord"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smcB5n-9PLVP"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasGlobalDocumentoSemStopWord(id_documento,\n","                                                          documento, \n","                                                          lista_sentenca_documento, \n","                                                          lista_tokens_documento, \n","                                                          lista_pos_documento,\n","                                                          estrategia_medida,\n","                                                          filtro_palavra):\n","  \n","  '''\n","    Percorre as sentenças de um documento para calcular as medidas\n","  '''\n","  \n","  #print(\"lista_sentenca_documento:\", lista_sentenca_documento)\n","  #print(\"lista_tokens_documento:\", lista_tokens_documento)\n","  #print(\"lista_pos_documento:\", lista_pos_documento)\n","\n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    #print(\"sentenca:\",sentenca)  \n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    #print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    #print(\"sentenca_pos:\",sentenca_pos)\n","    #print(\"Quantidade de palavras:\",len(sentenca_token))\n","   \n","    # Seleciona as palavras e POS-Tagging sem as Stopwords\n","    lista_tokens_nova = []\n","    lista_pos_nova = []    \n","    # Percorre as postagging das palavras\n","    for ix, palavra in enumerate(sentenca_token):\n","        # Se o token estiver não lista de stopwords\n","        if palavra.lower() not in getStopwords(nlp):\n","          # Guarda os elementos utilizados\n","          lista_tokens_nova.append(sentenca_token[ix])\n","          lista_pos_nova.append(sentenca_pos[ix])              \n","\n","    #print(\"Depois\")\n","    #print(\"lista_tokens_nova:\",lista_tokens_nova)\n","    #print(\"POS Tagging:\",lista_pos_nova)\n","    #print(\"Quantidade de palavras:\",len(lista_tokens_nova))\n","\n","    # Quantidade de palavras na sentença\n","    k = len(lista_tokens_nova)\n","  \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","    # Seleciona os pares de sentença a serem avaliados\n","    for ix in range(0,k):\n","\n","      # Seleciona as palavras do documento  \n","      wi = lista_tokens_nova[ix]      \n","      pos_i = lista_pos_nova[ix]\n","        \n","      # print(\"\\nwi:\", wi, pos_i)      \n","\n","      # Recupera as medidas entre wi com o contexto\n","      cos, euc, man = getMedidasComparacaoPalavrasGlobal(id_documento, \n","                                                         i,\n","                                                         ix,\n","                                                         estrategia_medida,\n","                                                         filtro_palavra)\n","      \n","      # Acumula as medidas do par de palavras\n","      soma_Wcos = soma_Wcos + abs(cos)\n","      soma_Weuc = soma_Weuc + abs(euc)\n","      soma_Wman = soma_Wman + abs(man)\n","      \n","    # Calcula a média das medidas para as m-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k) != 0:\n","      MWcos = float(soma_Wcos)/float(k)\n","      MWeuc = float(soma_Weuc)/float(k)\n","      MWman = float(soma_Wman)/float(k)\n","    \n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","\n","    del lista_tokens_nova\n","    del lista_pos_nova\n","\n","  # Calcula a média das medidas para o documento\n","  Scos = float(soma_Scos)/float(n)\n","  Seuc = float(soma_Seuc)/float(n)\n","  Sman = float(soma_Sman)/float(n)\n","    \n","  return Scos, Seuc, Sman"]},{"cell_type":"markdown","metadata":{"id":"F2hovTgKPykV"},"source":["###### getMedidasCoerenciaPalavrasGlobalDocumentoPalavrasSalientes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1TRBnO7bPykW"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasGlobalDocumentoPalavrasSalientes(id_documento,\n","                                                                documento, \n","                                                                lista_sentenca_documento, \n","                                                                lista_tokens_documento, \n","                                                                lista_pos_documento,\n","                                                                estrategia_medida,\n","                                                                filtro_palavra,\n","                                                                classe_saliente=[\"NOUN\",\"VERB\",\"AUX\"]):\n","\n","  # Acumuladores das medidas entre as sentenças    \n","  soma_Scos = 0\n","  soma_Seuc = 0\n","  soma_Sman = 0\n","\n","  # Quantidade de sentenças no documento\n","  n = len(lista_sentenca_documento)\n","\n","  # Percorre as sentenças do documento\n","  for i, sentenca in enumerate(lista_sentenca_documento):    \n","\n","    # Carrega as POSTagging da sentença\n","    sentenca_token = lista_tokens_documento[i]\n","    # print(\"sentenca_token:\",sentenca_token)\n","    sentenca_pos = lista_pos_documento[i]\n","    # print(\"sentenca_pos:\",sentenca_pos)\n","    # print(\"Quantidade de palavras:\",len(sentenca_token))\n","\n","    # Somente palavras saliente \n","    lista_tokens_nova = []\n","    lista_pos_nova = []    \n","    # Percorre as postagging das palavras\n","    for ix, pos in enumerate(sentenca_pos):\n","        # Se a postagging da palavra estiver na lista das classes das salientes\n","        if pos in classe_saliente:\n","          # Guarda os elementos utilizados\n","          lista_tokens_nova.append(sentenca_token[ix])\n","          lista_pos_nova.append(sentenca_pos[ix])\n","    \n","    #print(\"Depois\")\n","    #print(\"lista_tokens_nova:\",lista_tokens_nova)\n","    #print(\"POS Tagging:\",lista_pos_nova)\n","    #print(\"Quantidade de palavras:\",len(lista_tokens_nova))\n","\n","    # Quantidade de palavras na sentença\n","    k = len(lista_tokens_nova)\n","  \n","    # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","     # Acumuladores das medidas entre as palavras  \n","    soma_Wcos = 0\n","    soma_Weuc = 0\n","    soma_Wman = 0\n","    \n","    # Seleciona os pares de sentença a serem avaliados\n","    for ix in range(0,k):\n","\n","      # Seleciona as palavras do documento  \n","      wi = lista_tokens_nova[ix]      \n","      pos_i = lista_pos_nova[ix]\n","        \n","      # print(\"\\nwi:\", wi, pos_i)      \n","\n","      # Recupera as medidas entre wi com o contexto\n","      cos, euc, man = getMedidasComparacaoPalavrasGlobal(id_documento, \n","                                                         i,\n","                                                         ix,                                                          \n","                                                         estrategia_medida,\n","                                                         filtro_palavra)\n","  \n","      # Acumula as medidas do par de palavras\n","      soma_Wcos = soma_Wcos + abs(cos)\n","      soma_Weuc = soma_Weuc + abs(euc)\n","      soma_Wman = soma_Wman + abs(man)\n","\n","    # Calcula a média das medidas para as m-1 palavras da sentença   \n","    MWcos = 0\n","    MWeuc = 0\n","    MWman = 0\n","\n","    # Se existe palavras\n","    if float(k) != 0:\n","      MWcos = float(soma_Wcos)/float(k)\n","      MWeuc = float(soma_Weuc)/float(k)\n","      MWman = float(soma_Wman)/float(k)\n","\n","    # Acumula a média das medidas das palavras da sentença\n","    soma_Scos = soma_Scos + MWcos\n","    soma_Seuc = soma_Seuc + MWeuc\n","    soma_Sman = soma_Sman + MWman\n","\n","    del lista_tokens_nova\n","    del lista_pos_nova\n","\n","  # Calcula a média das medidas para o documento\n","  MScos = float(soma_Scos)/float(n)\n","  MSeuc = float(soma_Seuc)/float(n)\n","  MSman = float(soma_Sman)/float(n)\n","  \n","  return MScos, MSeuc, MSman"]},{"cell_type":"markdown","metadata":{"id":"y3384CNiAy_h"},"source":["###### getMedidasCoerenciaPalavrasGlobal\n","\n","Recupera as medidas da palavra com o contexto global de acordo com o filtro de palavras a ser utilizado nos documentos.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ed_5nggCAy_h"},"outputs":[],"source":["def getMedidasCoerenciaPalavrasGlobal(id_documento, \n","                                      documento, \n","                                      lista_sentenca_documento, \n","                                      lista_tokens_documento, \n","                                      lista_pos_documento,\n","                                      estrategia_medida,                             \n","                                      filtro_palavra = 0,\n","                                      classe_saliente=[\"NOUN\",\"VERB\",\"AUX\"]):\n","  \n","  \"\"\"\n","    Recupera as medidas da palavra com o contexto global de acordo com o filtro de palavras a ser utilizado nos documentos.\n","  \"\"\"\n","  \n","  if filtro_palavra == 0: # Todas as palavras\n","    return getMedidasCoerenciaPalavrasGlobalDocumentoTodasPalavras(id_documento, \n","                                                                   documento, \n","                                                                   lista_sentenca_documento, \n","                                                                   lista_tokens_documento, \n","                                                                   lista_pos_documento,\n","                                                                   estrategia_medida,\n","                                                                   filtro_palavra)\n","  else:\n","    if filtro_palavra == 1: # Sem stopwords\n","        return getMedidasCoerenciaPalavrasGlobalDocumentoSemStopWord(id_documento, documento, \n","                                                                     lista_sentenca_documento, \n","                                                                     lista_tokens_documento, \n","                                                                     lista_pos_documento,\n","                                                                     estrategia_medida,\n","                                                                     filtro_palavra)\n","    else: \n","        if filtro_palavra == 2: # Somente verbos(e auxiliares) substantivos          \n","          return getMedidasCoerenciaPalavrasGlobalDocumentoPalavrasSalientes(id_documento, \n","                                                                             documento, \n","                                                                             lista_sentenca_documento, \n","                                                                             lista_tokens_documento, \n","                                                                             lista_pos_documento,\n","                                                                             estrategia_medida,\n","                                                                             filtro_palavra,\n","                                                                             classe_saliente=classe_saliente)          "]},{"cell_type":"markdown","metadata":{"id":"vP5UKzaF_y2q"},"source":["###### getMedidasCoerenciaDocumento\n","\n","Recupera as medidas de coerência de acordo com a equação a ser utilizado nos documentos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Or-9aAHS_yEa"},"outputs":[],"source":["def getMedidasCoerenciaDocumento(id_documento,                                  \n","                                 documento, \n","                                 lista_sentenca_documento, \n","                                 lista_tokens_documento, \n","                                 lista_pos_documento,\n","                                 equacao_medida = 0,\n","                                 estrategia_medida = 0,\n","                                 filtro_palavra = 0,\n","                                 classe_saliente=[\"NOUN\",\"VERB\",\"AUX\"]):\n","  \n","  \"\"\"\n","    Recupera as medidas de coerência de acordo com a equação a ser utilizado nos documentos.\n","  \"\"\"\n","  \n","  if equacao_medida == 0: # Compara palavras adjacentes\n","    # print(\"Calculando para palavra adjacentes\")\n","    return getMedidasCoerenciaPalavrasAdjacentes(id_documento, \n","                                                 documento, \n","                                                 lista_sentenca_documento, \n","                                                 lista_tokens_documento, \n","                                                 lista_pos_documento, \n","                                                 estrategia_medida,\n","                                                 filtro_palavra,\n","                                                 classe_saliente=classe_saliente)\n","  else:\n","    if equacao_medida == 1: # Compara todas as palavras\n","        # print(\"Calculando para todas as palavras\")\n","        return getMedidasCoerenciaPalavrasCombinacao(id_documento, \n","                                                     documento, \n","                                                     lista_sentenca_documento, \n","                                                     lista_tokens_documento, \n","                                                     lista_pos_documento, \n","                                                     estrategia_medida,\n","                                                     filtro_palavra,\n","                                                     classe_saliente=classe_saliente)\n","    else:         \n","        if equacao_medida == 2: # Somente verbos(e auxiliares) substantivos          \n","          # print(\"Calculando para o contexto\")  \n","          return getMedidasCoerenciaPalavrasGlobal(id_documento, \n","                                                   documento, \n","                                                   lista_sentenca_documento, \n","                                                   lista_tokens_documento, \n","                                                   lista_pos_documento,\n","                                                   estrategia_medida,\n","                                                   filtro_palavra, \n","                                                   classe_saliente=classe_saliente) "]},{"cell_type":"markdown","metadata":{"id":"vTZBIaw7z8yk"},"source":["##### Auxiliares"]},{"cell_type":"markdown","metadata":{"id":"cgzcSAEQhpiq"},"source":["###### getDadosDocumento\n","\n","Recuperar os dados de documentos originais ou perturbados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_a7MNqv-izdj"},"outputs":[],"source":["def getDadosDocumento(_id_documento):\n","  \"\"\"\n","    Recupera os dados de um documento. Procura na lista de documentos originais e documentos perturbados.\n","    \n","    Parâmetros:\n","      `_id_documento` - Um id de documento original o perturbado.\n","      \n","    Retorno:\n","      `documento_original` - Um texto com o documento. \n","      `lista_sentenca_documento_original` - Uma lista com as sentenças do documento.\n","      `lista_tokens_documento_original` - Uma lista com os tokens do documento.\n","      `lista_pos_documento_original` - Uma lista com os PoS-Tagging do documento.\n","  \n","  \"\"\"\n","\n","  # print(\"_id_documento:\",_id_documento)\n","  # Procurar nos documentos perturbados\n","  if \"_pert_\" in str(_id_documento):\n","    # localiza os dados do documento perturbado \n","    reg_documento_perturbado = lista_documentos_perturbados_indexado.loc[_id_documento]\n","        \n","    # Recupera as sentenças do documento perturbado\n","    lista_sentenca_documento_perturbado = reg_documento_perturbado[\"perturbado\"]\n","    # Recupera o documento perturbado\n","    documento_perturbado = reg_documento_perturbado[\"documento_perturbado\"]  \n","\n","    # Recupera as POS Tagging do documento perturbado\n","    tokens_perturbado = []\n","    tokens_perturbado_pos = []        \n","    reg_perturbado_pos = lista_documentos_perturbados_pos_indexado.loc[_id_documento]\n","    #print(\"reg_perturbado_pos:\",reg_perturbado_pos)\n","    pos_documento_perturbado = reg_perturbado_pos['pos_documento']\n","    for i, linha2 in enumerate(pos_documento_perturbado):\n","      tokens_perturbado.append(linha2[0])\n","      tokens_perturbado_pos.append(linha2[1])\n","\n","    # Recupera os tokens e pos do documento perturbado\n","    lista_tokens_documento_perturbado = tokens_perturbado\n","    lista_pos_documento_perturbado = tokens_perturbado_pos\n","\n","    return documento_perturbado, lista_sentenca_documento_perturbado, lista_tokens_documento_perturbado, lista_pos_documento_perturbado\n","  else:\n","    # Procurar nos documentos originais\n","    # localiza os dados do documento original                                     \n","    reg_documento_original = lista_documentos_originais_indexado.loc[_id_documento]\n","\n","    # Recupera as sentenças do documento orriginal    \n","    lista_sentenca_documento_original = reg_documento_original[\"sentencas\"]     \n","    #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","    #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","    # Recupera o documento Original\n","    documento_original = reg_documento_original[\"documento\"]    \n","          \n","    # Recupera as POS Tagging do documento original\n","    documentos_originais_pos = lista_documentos_originais_pos_indexado.loc[_id_documento]\n","    # print(\"documentos_originais_pos:\", documentos_originais_pos)\n","    # print(\"len(documentos_originais_pos):\", len(documentos_originais_pos))\n","\n","    # Recupera os tokens e POS do documento original\n","    tokens_original = []\n","    tokens_original_pos = []    \n","    reg_original_pos = lista_documentos_originais_pos_indexado.loc[_id_documento] \n","    # print(\"reg_original_pos:\",reg_original_pos)    \n","    pos_documento_original = reg_original_pos['pos_documento']\n","    for i, linha2 in enumerate(pos_documento_original):      \n","      tokens_original.append(linha2[0])\n","      tokens_original_pos.append(linha2[1])\n","              \n","    # Recupera os tokens e pos do documento original\n","    lista_tokens_documento_original = tokens_original\n","    lista_pos_documento_original = tokens_original_pos\n","\n","    return documento_original, lista_sentenca_documento_original, lista_tokens_documento_original, lista_pos_documento_original"]},{"cell_type":"markdown","metadata":{"id":"JbqeNjN_laaU"},"source":["###### getMedidasCoerenciaDocumentoId"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0r0GSHXOhp7p"},"outputs":[],"source":["def getMedidasCoerenciaDocumentoId(id_documento,\n","                                   equacao_medida = 0,\n","                                   estrategia_medida = 0,\n","                                   filtro_palavra = 0):\n","  \"\"\"\n","    Recupera as medidas das equações de documento original ou perturbado.\n","    \n","    Parâmetros:\n","      `id_documento` - Um id de documento original o perturbado.\n","      `equacao_medida` - Um id equação de medida (0 - CAW, 1 - CWP, 2 - CG). \n","      `estrategia_medida` - Um id de estratégia de medida (0 - MEAN, 1 - MAX).\n","      `filtro_palavra` - Um id de filtro de palavra (0 - ALL, 1 - CLEAN, 2 - REL).\n","      \n","    Retorno:\n","      `medida_cos` - A medida do documento segundo os parâmetros usando similaridade do cosseno.\n","      `medida_euc` - A medida do documento segundo os parâmetros usando distância Euclidiana.\n","      `medida_man` - A medida do documento segundo os parâmetros usando distância de Manhattan.\n","  \n","  \"\"\"\n","  \n","  # Localiza os dados do documento\n","  documento, lista_sentenca_documento, lista_tokens_documento, lista_pos_documento = getDadosDocumento(id_documento)\n","\n","  # Retorna as medidas de acorrdo com os parâmetros\n","  return getMedidasCoerenciaDocumento(id_documento,                                  \n","                                 documento, \n","                                 lista_sentenca_documento, \n","                                 lista_tokens_documento, \n","                                 lista_pos_documento,\n","                                 equacao_medida = equacao_medida,\n","                                 estrategia_medida = estrategia_medida,\n","                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"markdown","metadata":{"id":"wj8uVkEk9BQq"},"source":["###### getDadosPerturbacao"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MvTqlDk9Bf3"},"outputs":[],"source":["def getDadosPerturbacao(_id_perturbado):\n","  \n","  # localiza os dados do documento perturbado mascarado\n","  reg_documento_perturbado = lista_documentos_perturbados_indexado.loc[_id_perturbado]\n","\n","  # Recupera a lista das sentenças perturbadas\n","  lista_sentencas_mascarada = reg_documento_perturbado[2]\n","\n","  # Índice da sentença perturbada\n","  index_sentenca = -1\n","\n","  # Percorre as sentenças para encontrar a sentença perturbada\n","  for i, linha in enumerate(lista_sentencas_mascarada):\n","\n","    # Identifica a sentença mascarada que foi perturbada\n","    if 'MASK' in linha[0] :\n","      # Recupera a palavra mascarada sentença do documento perturbado\n","      index_sentenca = i\n","      sentenca_mascarada = linha[0]\n","      palavra_mascarada = linha[1]\n","      token_predito = linha[2]\n","      peso_predito = linha[3] \n","\n","  return index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito"]},{"cell_type":"markdown","metadata":{"id":"LK4-bX439Cno"},"source":["###### getPosPalavraSentenca"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lz3JHkLDd0u"},"outputs":[],"source":["def getPosPalavraSentenca(sentenca_token, sentenca_pos, token_procura):\n","\n","  pos_token_procura = \"\" \n","  # print(\"token_procura:\",token_procura)\n","  # print(\"sentenca_token:\", sentenca_token)\n","  # print(\"sentenca_pos:\",sentenca_pos)\n","    \n","  for i, sentenca in enumerate(sentenca_token):\n","    # print(\"sentenca:\", sentenca)\n","    for j, token_sentenca in enumerate(sentenca):\n","        # print(\"token_sentenca:\", token_sentenca)        \n","        if token_sentenca == token_procura:\n","          # print(\"sentenca_pos[i][j]:\", sentenca_pos[i][j])\n","          pos_token_procura = sentenca_pos[i][j]\n","  \n","  return pos_token_procura"]},{"cell_type":"markdown","metadata":{"id":"yA4-6_c79ItH"},"source":["###### getIndicePalavraMascarada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ok0UV6xpDd0u"},"outputs":[],"source":["def getIndicePalavraMascarada(sentenca_mascarada):\n","\n","  palavras = sentenca_mascarada.split()\n","  indice_token_procura = -1  \n","    \n","  for i, palavra in enumerate(palavras):\n","    # print(\"palavra:\", palavra)\n","    if palavra == '[MASK]':\n","       indice_token_procura = i      \n","  \n","  return indice_token_procura"]},{"cell_type":"markdown","metadata":{"id":"pZ922pAs9MQN"},"source":["###### trataNumero"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQuqPsozDd0u"},"outputs":[],"source":["def trataNumero(numero, casas_decimais=10):\n","    # Converte o número para string\n","    # Troca \".\" por vírgula\n","    # Especifica o número de casas decimais\n","    return str(format(numero, \".\" + str(casas_decimais) + \"f\")).replace(\".\", \",\")"]},{"cell_type":"markdown","metadata":{"id":"pE2NGp2bMBS8"},"source":["###### getLinhaMedida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iB05LTz7MAqx"},"outputs":[],"source":["def getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida):\n","  \n","  linha = str(x[1] \n","              + \" [\" \n","              + x[2] \n","              + \"(\" \n","              + melhorDO \n","              + trataNumero(x[indice_palavra_selecionada]) \n","              + \") -\u003e \"  \n","              + x[4] \n","              + \"(\" \n","              + melhor_pertDO \n","              + trataNumero(x[indice_palavra_substituida]) \n","              + \")\" \n","              + \" - \" \n","              + trataNumero(x[6]) \n","              + \"] - \" \n","              + str(x[7]))\n","  return linha"]},{"cell_type":"markdown","metadata":{"id":"gJvY32Z2MwID"},"source":["###### getLinhaMedidaExibicao"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bv6wGZ_rMwWf"},"outputs":[],"source":["def getLinhaMedidaExibicao(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida):\n","\n","  linha = str(x[1] + \n","              \" [\" + \n","              x[2] + \n","              \"(\" + \n","              melhorDO + \n","              trataNumero(x[indice_palavra_selecionada]) + \n","              \") -\u003e \" + \n","              x[4] +\n","              \"(\" + \n","              melhor_pertDO + \n","              trataNumero(x[indice_palavra_substituida]) + \n","              \")\" + \n","              \" - \" + \n","              trataNumero(x[6]) + \n","              \"] - \" + \n","              str(x[7]) + \n","              \" - \" + \n","              x[3] + \n","              \"/\" + \n","              x[5])\n","  return linha"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uKgzsj9f9N8"},"outputs":[],"source":["def getEstrategiaMedidaStr(estrategia_medida):\n","  if estrategia_medida == 0:\n","    return \"MEAN - Média dos tokens\"\n","  else:\n","    if estrategia_medida == 1:\n","      return \"MAX - Máximo dos tokens\"\n","    else:\n","      return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrPvlIKbefoj"},"outputs":[],"source":["def getFiltroPalavraStr(filtro_palavra):\n","  if filtro_palavra == 0:\n","    return \"ALL - Todas as palavras\"\n","  else:\n","    if filtro_palavra == 1:\n","      return \"CLEAN - Sem as stopwords\"\n","    else:\n","      if filtro_palavra == 2:\n","        return \"REL - Somente verbos(aux) e substantivos\"\n","      else:\n","        return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FkmiSUKed6Gm"},"outputs":[],"source":["def getEquacaoMedidaStr(equacao_medida):\n","  if equacao_medida == 0:\n","    return \"CAW - Palavras adjacentes\"\n","  else:\n","    if equacao_medida == 1:\n","      return \"CPW - Todos os pares de palavras\"\n","    else:\n","      if equacao_medida == 2:\n","        return \"CG - Contexto global\"\n","      else:\n","        return None     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDPLWLPJYpcM"},"outputs":[],"source":["def getEquacaoMedidaStrCurto(equacao_medida):\n","  if equacao_medida == 0:\n","    return \"CAW\"\n","  else:\n","    if equacao_medida == 1:\n","      return \"CPW\"\n","    else:\n","      if equacao_medida == 2:\n","        return \"CG\"\n","      else:\n","        return None   "]},{"cell_type":"markdown","metadata":{"id":"NJrA8OH-mTd3"},"source":["#### Função gera as medidas das palavras entre DO e pertDO usando a equação CG\n","\n","Compara a palavra com a medida global(CG) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9S4kjanmTd4"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def getListaMedidasPerturbadoCG(_id_documento_original,\n","                              estrategia_medida = 0,\n","                              filtro_palavra = 0):\n","\n","  lista_perturbado_classificado_medida = []\n","\n","  # Barra de progresso dos documentos\n","  lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","  # Percorre os documentos\n","  for i, linha in lista_documentos_originais_bar:   \n","    \n","    # Recupera o id do documento original\n","    id_documento_original = linha['id']\n","\n","    if id_documento_original == _id_documento_original:\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(_id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Verifica se o documento original foi classificado corretamente    \n","      documento_id_original = id_documento_original in lista_retorno_classificado_corretamente_sem_repeticao_indexado.index\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente    \n","      if documento_id_original == True:             \n","        documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'])        \n","      else:\n","        classe = \"0\"\n","\n","      # Guarda o maior ranking  \n","      maior_ranking = 0\n","\n","      # Lista dos documentos perturbados classificados\n","      lista_perturbado_classificado = []\n","\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","        # Id do documento perturbado\n","        id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","        #id_perturbado = linha['id'] + 1\n","        #print(\"id_perturbado:\",id_perturbado)\n","\n","        # Localiza os dados do documento perturbado\n","        documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","        # Recupera o documento perturrbado\n","        #print(\"documento_perturbado:\",documento_perturbado)\n","        #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","        #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","        #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","        #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","        #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","        #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","        # Recupera a sentença mascarada e seus dados do documento perturbado\n","        index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","\n","        # Encontrar o índice da palavra mascarada\n","        index_wi = getIndicePalavraMascarada(sentenca_mascarada)       \n","        \n","        palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","        # print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","        token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos,token_predito)\n","        # print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","        # Não realiza nenhum tipo de filtragem\n","        cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO = getMedidasComparacaoPalavrasGlobal(id_documento_original,\n","                                                                                        index_sentenca, \n","                                                                                        index_wi,\n","                                                                                        estrategia_medida, #Estratégia 0 = MEAN\n","                                                                                        filtro_palavra) #Filtro palavra 0 = All\n","        #print(\"    Ctx DO     :\", palavra_mascarada, \" - \", cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO)\n","\n","        cos_ctxall_pertDO, euc_ctxall_pertDO, man_ctxall_pertDO = getMedidasComparacaoPalavrasGlobal(id_perturbado,\n","                                                                                        index_sentenca, \n","                                                                                        index_wi,\n","                                                                                        estrategia_medida, #Estratégia 0 = MEAN\n","                                                                                        filtro_palavra) #Filtro palavra 0 = All\n","        # print(\"    Ctx pertDO :\", token_predito, \" - \", cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO)\n","\n","        # Recupera o id documento perturbado se ele foi classificado corretamente\n","        documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]\n","        #print(\"documento_id_perturbado_correto:\",id_perturbado,documento_id_perturbado_correto)\n","        \n","        # Localiza a classificação do documento perturbado  \n","        classe = 1\n","        # Se foi encontrado foi classificado corretamente        \n","        if len(documento_id_perturbado_correto) != 0:\n","          classe = 0        \n","          documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","        else:\n","          # Recupera o id documento perturbado se ele foi classificado incorretamente\n","          documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]\n","          \n","          # Se foi encontrado foi classificado incorretamente          \n","          if len(documento_id_perturbado_incorreto) != 0:            \n","            #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","            documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","            #print(\"documento:\",documento)\n","        \n","        if j == 0:\n","          maior_ranking = peso_predito \n","        else:\n","          if peso_predito \u003e maior_ranking:\n","            maior_ranking = peso_predito \n","\n","        # Guarda os dados\n","        lista_perturbado_classificado.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                              str(documento['documento']),            #1\n","                                              palavra_mascarada,                      #2\n","                                              palavra_mascarada_classe,               #3                                   \n","                                              token_predito,                          #4\n","                                              token_predito_classe,                   #5\n","                                              peso_predito,                           #6\n","                                              classe,                                 #7\n","                                              cos_ctxall_DO,                          #8\n","                                              euc_ctxall_DO,                          #9\n","                                              man_ctxall_DO,                          #10\n","                                              cos_ctxall_pertDO,                      #11\n","                                              euc_ctxall_pertDO,                      #12\n","                                              man_ctxall_pertDO,                      #13\n","                                              ])\n","\n","      # Calcula os percentuais das medidas do documento perturbado    \n","      for i, x in enumerate(lista_perturbado_classificado):      \n","        # print(\"x:\",x)\n","        ranking_percentual = x[6] / maior_ranking\n","        # calcula as diferenças\n","        if x[8] != 0:\n","          dcos = (x[11]-x[8])/x[8] * 10\n","        else:\n","          dcos = x[11] * 10\n","        if x[9] != 0:\n","          deuc = (x[9]-x[12])/x[9]\n","        else:\n","          deuc = -x[12]\n","        if x[10] != 0:\n","          dman = (x[10]-x[13])/x[10]\n","        else:\n","          dman = -x[13]\n","\n","        # POS Tagging iguais entre selecionada e perturbada  \n","        pos_igual = 1\n","        if x[3] == x[5]:\n","          pos_igual = 0         \n","            \n","        # Verifica se as palavras são iguais\n","        palavra_igual = 0\n","        if x[2] == x[4]:\n","          palavra_igual = 1        \n","        \n","        # Guarda a medida calculada do documento\n","        lista_perturbado_classificado_medida.append([x[0],\n","                                                    x[1],\n","                                                    x[2],\n","                                                    x[3],\n","                                                    x[4],\n","                                                    x[5],\n","                                                    x[6],\n","                                                    x[7],\n","                                                    x[8],\n","                                                    x[9],\n","                                                    x[10],\n","                                                    x[11],\n","                                                    x[12],\n","                                                    x[13],\n","                                                    ranking_percentual,  #14\n","                                                    dcos,                #15\n","                                                    deuc,                #16\n","                                                    dman,                #17\n","                                                    pos_igual,           #18\n","                                                    palavra_igual])      #19\n","\n","  # Ordena a lista das medidas pela plausabilidade\n","  lista_perturbado_classificado_medida = sorted(lista_perturbado_classificado_medida, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","  print(\"TERMINADO MEDIDAS PERTURBADOS:\", len(lista_perturbado_classificado_medida))\n","\n","  return lista_perturbado_classificado_medida"]},{"cell_type":"markdown","metadata":{"id":"FikrxNtyqUrf"},"source":["#### Função gera as medidas de uma equação entre DO e pertDO\n","\n","Gera todas as medidas usando medidas de distância e similaridade(cos,euc,man) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUMe79-OqUrf"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def getListaMedidasEquacaoPerturbado(_id_documento_original,\n","                                      equacao_medida = 0,\n","                                      estrategia_medida = 0,\n","                                      filtro_palavra = 0,):\n","\n","  lista_perturbado_classificado_medida = []\n","\n","  # Barra de progresso dos documentos\n","  lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","  # Percorre os documentos\n","  for i, linha in lista_documentos_originais_bar:   \n","    \n","    # Recupera o id do documento original\n","    id_documento_original = linha['id']\n","\n","    if id_documento_original == _id_documento_original:\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(_id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Verifica se o documento original foi classificado corretamente    \n","      documento_id_original = id_documento_original in lista_retorno_classificado_corretamente_sem_repeticao_indexado.index\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente    \n","      if documento_id_original == True:             \n","        documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'])        \n","      else:\n","        classe = \"0\"\n","        \n","      maior_ranking = 0\n","\n","      lista_perturbado_classificado = []\n","\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","        # Id do documento perturbado\n","        id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","        #id_perturbado = linha['id'] + 1\n","        #print(\"id_perturbado:\",id_perturbado)\n","\n","        # Localiza os dados do documento perturbado\n","        documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","        # Recupera o documento perturrbado\n","        #print(\"documento_perturbado:\",documento_perturbado)\n","        #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","        #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","        #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","        #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","        #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","        #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","        # Recupera a sentença mascarada e seus dados do documento perturbado\n","        index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","\n","        # Encontrar o índice da palavra mascarada\n","        index_wi = getIndicePalavraMascarada(sentenca_mascarada)       \n","        \n","        palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","        # print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","        token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos,token_predito)\n","        # print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","        cos_DO, euc_DO, man_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                              documento_original, \n","                                                              lista_sentenca_documento_original, \n","                                                              documento_original_tokens, \n","                                                              documento_original_pos,\n","                                                              equacao_medida = equacao_medida,\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","\n","        #print(\"     DO     :\", palavra_mascarada, \" - \", cos_DO, euc_DO, man_DO)\n","\n","\n","        cos_pertDO, euc_pertDO, man_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                              documento_perturbado, \n","                                                              lista_sentenca_documento_perturbado, \n","                                                              documento_perturbado_tokens, \n","                                                              documento_perturbado_pos,\n","                                                              equacao_medida = equacao_medida,\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","\n","        # print(\"    pertDO :\", token_predito, \" - \", cos_pertDO, euc_pertDO, man_pertDO)\n","\n","        # Recupera o id documento perturbado se ele foi classificado corretamente\n","        documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]\n","\n","        #print(\"documento_id_perturbado_correto:\",id_perturbado,documento_id_perturbado_correto)\n","        #print(\"verifica:\", id_perturbado in lista_retorno_classificado_corretamente_sem_repeticao.index)\n","        \n","        # Localiza a classificação do documento perturbado  \n","        classe = 1\n","        # Se foi encontrado foi classificado corretamente\n","        #if documento_id_perturbado_correto == True:\n","        if len(documento_id_perturbado_correto) != 0:\n","          classe = 0        \n","          documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","        else:\n","          # Recupera o id documento perturbado se ele foi classificado incorretamente\n","          documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]\n","          \n","          # Se foi encontrado foi classificado incorretamente          \n","          if len(documento_id_perturbado_incorreto) != 0:            \n","            #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","            documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","            #print(\"documento:\",documento)\n","        \n","        if j == 0:\n","          maior_ranking = peso_predito \n","        else:\n","          if peso_predito \u003e maior_ranking:\n","            maior_ranking = peso_predito \n","\n","        # Guarda os dados\n","        lista_perturbado_classificado.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                              str(documento['documento']),            #1\n","                                              palavra_mascarada,                      #2\n","                                              palavra_mascarada_classe,               #3                                   \n","                                              token_predito,                          #4\n","                                              token_predito_classe,                   #5\n","                                              peso_predito,                           #6\n","                                              classe,                                 #7\n","                                              cos_DO,                                 #8\n","                                              euc_DO,                                 #9\n","                                              man_DO,                                 #10\n","                                              cos_pertDO,                             #11\n","                                              euc_pertDO,                             #12\n","                                              man_pertDO,                             #13\n","                                              ])\n","\n","      # Calcula os percentuais das medidas do documento perturbado    \n","      for i, x in enumerate(lista_perturbado_classificado):      \n","        # print(\"x:\",x)\n","        ranking_percentual = x[6] / maior_ranking\n","        # calcula as diferenças        \n","        if x[8] != 0:\n","          dcos = (x[11]-x[8])/x[8] * 10\n","        else:\n","          dcos = x[11] * 10\n","        if x[9] != 0:\n","          deuc = (x[9]-x[12])/x[9]\n","        else:\n","          deuc = -x[12]\n","        if x[10] != 0:\n","          dman = (x[10]-x[13])/x[10]\n","        else:\n","          dman = -x[13]\n","\n","        # POS Tagging iguais entre selecionada e perturbada  \n","        pos_igual = 1\n","        if x[3] == x[5]:\n","          pos_igual = 0         \n","            \n","        # Verifica se as palavras são iguais\n","        palavra_igual = 0\n","        if x[2] == x[4]:\n","          palavra_igual = 1        \n","        \n","        lista_perturbado_classificado_medida.append([x[0],\n","                                                    x[1],\n","                                                    x[2],\n","                                                    x[3],\n","                                                    x[4],\n","                                                    x[5],\n","                                                    x[6],\n","                                                    x[7],\n","                                                    x[8],\n","                                                    x[9],\n","                                                    x[10],\n","                                                    x[11],\n","                                                    x[12],\n","                                                    x[13],\n","                                                    ranking_percentual,  #14\n","                                                    dcos,                #15\n","                                                    deuc,                #16\n","                                                    dman,                #17\n","                                                    pos_igual,           #18\n","                                                    palavra_igual])      #19\n","\n","  # Ordena a lista das medidas pela plausabilidade\n","  lista_perturbado_classificado_medida = sorted(lista_perturbado_classificado_medida, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","  print(\"TERMINADO MEDIDAS PERTURBADOS:\", len(lista_perturbado_classificado_medida))\n","\n","  return lista_perturbado_classificado_medida"]},{"cell_type":"markdown","metadata":{"id":"YZkvxm2p1Z4p"},"source":["#### Função gera as medidas das equações entre DO e pertDO\n","\n","Gera todas as medidas das equações de (in)coerrência(CAW,CWP,CG) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGzLPpeqqFTd"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def getListaMedidasEquacoesPerturbado(_id_documento_original,\n","                                      medida = 'cos',\n","                                      estrategia_medida = 0,\n","                                      filtro_palavra = 0,):\n","\n","  lista_perturbado_classificado_medida = []\n","\n","  # Barra de progresso dos documentos\n","  lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","  # Percorre os documentos\n","  for i, linha in lista_documentos_originais_bar:   \n","    \n","    # Recupera o id do documento ooriginal\n","    id_documento_original = linha['id']\n","\n","    if id_documento_original == _id_documento_original:\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(_id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Verifica se o documento original foi classificado corretamente    \n","      documento_id_original = id_documento_original in lista_retorno_classificado_corretamente_sem_repeticao_indexado.index\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente    \n","      if documento_id_original == True:             \n","        documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'])        \n","      else:\n","        classe = \"0\"\n","        \n","      maior_ranking = 0\n","\n","      lista_perturbado_classificado = []\n","\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","        # Id do documento perturbado\n","        id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","        #id_perturbado = linha['id'] + 1\n","        #print(\"id_perturbado:\",id_perturbado)\n","\n","        # Localiza os dados do documento perturbado\n","        documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","        # Recupera o documento perturrbado\n","        #print(\"documento_perturbado:\",documento_perturbado)\n","        #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","        #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","        #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","        #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","        #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","        #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","        # Recupera a sentença mascarada e seus dados do documento perturbado\n","        index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","\n","        # Encontrar o índice da palavra mascarada\n","        index_wi = getIndicePalavraMascarada(sentenca_mascarada)       \n","        \n","        palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","        # print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","        token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos,token_predito)\n","        # print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","        CAWcos_DO, CAWeuc_DO, CAWman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                              documento_original, \n","                                                              lista_sentenca_documento_original, \n","                                                              documento_original_tokens, \n","                                                              documento_original_pos,\n","                                                              equacao_medida = 0, #CAW\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","        #print(\"     DO     :\", palavra_mascarada, \" - \", CAWcos_DO, CAWeuc_DO, CAWman_DO)\n","\n","\n","        CAWcos_pertDO, CAWeuc_pertDO, CAWman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                              documento_perturbado, \n","                                                              lista_sentenca_documento_perturbado, \n","                                                              documento_perturbado_tokens, \n","                                                              documento_perturbado_pos,\n","                                                              equacao_medida = 0, #CAW\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","        # print(\"    pertDO :\", token_predito, \" - \", CAWcos_pertDO, CAWeuc_pertDO, CAWman_pertDO)\n","\n","\n","        CWPcos_DO, CWPeuc_DO, CWPman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                              documento_original, \n","                                                              lista_sentenca_documento_original, \n","                                                              documento_original_tokens, \n","                                                              documento_original_pos,\n","                                                              equacao_medida = 1, #CWP\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)     \n","        #print(\"     DO     :\", palavra_mascarada, \" - \", CWPcos_DO, CWPeuc_DO, CWPman_DO)\n","\n","\n","        CWPcos_pertDO, CWPeuc_pertDO, CWPman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                              documento_perturbado, \n","                                                              lista_sentenca_documento_perturbado, \n","                                                              documento_perturbado_tokens, \n","                                                              documento_perturbado_pos,\n","                                                              equacao_medida = 1, #CWP\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","        # print(\"    pertDO :\", token_predito, \" - \", CWPcos_pertDO, CWPeuc_pertDO, CWPman_pertDO)\n","\n","\n","        CGcos_DO, CGeuc_DO, CGman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                              documento_original, \n","                                                              lista_sentenca_documento_original, \n","                                                              documento_original_tokens, \n","                                                              documento_original_pos,\n","                                                              equacao_medida = 2, #CG\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)     \n","        #print(\"     DO     :\", palavra_mascarada, \" - \", CGcos_DO, CGeuc_DO, CGman_DO)\n","\n","\n","        CGcos_pertDO, CGeuc_pertDO, CGman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                              documento_perturbado, \n","                                                              lista_sentenca_documento_perturbado, \n","                                                              documento_perturbado_tokens, \n","                                                              documento_perturbado_pos,\n","                                                              equacao_medida = 2, #CG\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","        # print(\"    pertDO :\", token_predito, \" - \", CGcos_pertDO, CGeuc_pertDO, CGman_pertDO)\n","\n","        if medida == 'cos':\n","          CAW_DO = CAWcos_DO\n","          CWP_DO = CWPcos_DO\n","          CG_DO = CGcos_DO\n","          CAW_pertDO = CAWcos_pertDO\n","          CWP_pertDO = CWPcos_pertDO\n","          CG_pertDO = CGcos_pertDO\n","        else:\n","          if medida == 'euc':\n","            CAW_DO = CAWeuc_DO\n","            CWP_DO = CWPeuc_DO\n","            CG_DO = CGeuc_DO\n","            CAW_pertDO = CAWeuc_pertDO\n","            CWP_pertDO = CWPeuc_pertDO\n","            CG_pertDO = CGeuc_pertDO\n","          else:\n","             if medida == 'man':\n","              CAW_DO = CAWman_DO\n","              CWP_DO = CWPman_DO\n","              CG_DO = CGman_DO\n","              CAW_pertDO = CAWman_pertDO\n","              CWP_pertDO = CWPman_pertDO\n","              CG_pertDO = CGman_pertDO\n","\n","\n","        # Recupera o id documento perturbado se ele foi classificado corretamente\n","        documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]\n","        #print(\"documento_id_perturbado_correto:\",id_perturbado,documento_id_perturbado_correto)\n","        \n","        # Localiza a classificação do documento perturbado  \n","        classe = 1\n","        # Se foi encontrado foi classificado corretamente        \n","        if len(documento_id_perturbado_correto) != 0:\n","          classe = 0        \n","          documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","        else:\n","          # Recupera o id documento perturbado se ele foi classificado incorretamente\n","          documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]\n","          \n","          # Se foi encontrado foi classificado incorretamente          \n","          if len(documento_id_perturbado_incorreto) != 0:            \n","            #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","            documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","            #print(\"documento:\",documento)\n","        \n","        if j == 0:\n","          maior_ranking = peso_predito \n","        else:\n","          if peso_predito \u003e maior_ranking:\n","            maior_ranking = peso_predito \n","\n","        # Guarda os dados\n","        lista_perturbado_classificado.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                              str(documento['documento']),            #1\n","                                              palavra_mascarada,                      #2\n","                                              palavra_mascarada_classe,               #3                                   \n","                                              token_predito,                          #4\n","                                              token_predito_classe,                   #5\n","                                              peso_predito,                           #6\n","                                              classe,                                 #7\n","                                              CAW_DO,                                 #8\n","                                              CWP_DO,                                 #9\n","                                              CG_DO,                                  #10\n","                                              CAW_pertDO,                             #11\n","                                              CWP_pertDO,                             #12\n","                                              CG_pertDO,                              #13\n","                                              ])\n","\n","      # Calcula as medidas do documento perturbado    \n","      for i, x in enumerate(lista_perturbado_classificado):      \n","        # print(\"x:\",x)\n","        ranking_percentual = x[6] / maior_ranking\n","        # calcula as diferenças\n","        if medida == 'cos':\n","          CAW = (x[11]-x[8])/x[8]\n","          CWP = (x[12]-x[9])/x[9]\n","          CG = (x[13]-x[10])/x[10]\n","        else:\n","          CAW = (x[8]-x[11])/x[8]\n","          CWP = (x[9]-x[12])/x[9]\n","          CG = (x[10]-x[13])/x[10]\n","\n","        # POS Tagging iguais entre selecionada e perturbada  \n","        pos_igual = 1\n","        if x[3] == x[5]:\n","          pos_igual = 0         \n","            \n","        # Verifica se as palavras são iguais\n","        palavra_igual = 0\n","        if x[2] == x[4]:\n","          palavra_igual = 1        \n","        \n","        lista_perturbado_classificado_medida.append([x[0],\n","                                                    x[1],\n","                                                    x[2],\n","                                                    x[3],\n","                                                    x[4],\n","                                                    x[5],\n","                                                    x[6],\n","                                                    x[7],\n","                                                    x[8],\n","                                                    x[9],\n","                                                    x[10],\n","                                                    x[11],\n","                                                    x[12],\n","                                                    x[13],\n","                                                    ranking_percentual,  #14\n","                                                    CAW,                 #15\n","                                                    CWP,                 #16\n","                                                    CG,                  #17\n","                                                    pos_igual,           #18\n","                                                    palavra_igual])      #19\n","\n","  # Ordena a lista das medidas pela plausabilidade\n","  lista_perturbado_classificado_medida = sorted(lista_perturbado_classificado_medida, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","  print(\"TERMINADO MEDIDAS PERTURBADOS:\", len(lista_perturbado_classificado_medida))\n","\n","  return lista_perturbado_classificado_medida"]},{"cell_type":"markdown","metadata":{"id":"1FyDEfsIDd00"},"source":["#### Função de visualização das medidas das palavras entre DO e pertDO usando a equação CG\n","\n","Visualização das medidas da palavra com a medida global(CG) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q2rSzu3Ubk1Z"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def visualizaMedidasCG(_id_documento_original,\n","                     medida = 'cos',\n","                     estrategia_medida = 0,\n","                     filtro_palavra = 0,\n","                     _exibir_dados = True):\n","  \n","  print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","  print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","  print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","  print(\"Medida           :\", medida)\n","  print(\"Estratégia medida:\", getEstrategiaMedidaStr(estrategia_medida))\n","  print(\"Filtro palavra   :\", getFiltroPalavraStr(filtro_palavra))\n","  \n","  exibir_dados = _exibir_dados\n","\n","  lista_melhor_DO_correto = []\n","  lista_melhor_pertDO_correto = []\n","  lista_melhor_DO_incorreto = []\n","  lista_melhor_pertDO_incorreto = []\n","\n","  # Lista as medidas de um documento ou de todos se o Id igual a None\n","  if _id_documento_original == None:    \n","    lista_documentos = lista_documentos_originais\n","    #print(\"Todos\")\n","  else:\n","    #print(\"Somente o id = \", id)\n","    lista_documentos = lista_documentos_originais.loc[lista_documentos_originais['id']==_id_documento_original]\n","\n","  # Barra de progresso dos documentos\n","  lista_documentos_originais_bar = tqdm_notebook(lista_documentos.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos))\n","\n","  # Percorre os documentos\n","  for i, linha in lista_documentos_originais_bar:   \n","\n","    # Limita a quantidade de dados a serem exibidas\n","    #if i \u003c 2:    \n","    \n","      # Recupera o id do documento original\n","      id_documento_original = linha['id']\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Recupera o documento original se ele foi classificado corretamente    \n","      documento_id_original = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == linha['id']]\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente\n","      if len(documento_id_original) != 0:\n","        #print(\"documento_id_original:\",len(documento_id_original))          \n","        documento = lista_documentos_agrupados.loc[lista_documentos_agrupados[\"id\"] == str(documento_id_original['id'].values[0])]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'].values[0])      \n","      else:\n","        classe = \"0\"\n","    \n","      if exibir_dados == True:\n","        #Mostra o documento original e sua classificação\n","        print(\"\\nDO: \" + linha[\"documento\"] + \" - \" + classe)    \n","        pos_concatenado = \"\"\n","        # Concatena as pos do documento\n","        for doc_pos1 in documento_original_pos:\n","            # print(\"doc_pos1\",doc_pos1)\n","            for doc_pos2 in doc_pos1:\n","              pos_concatenado = pos_concatenado + doc_pos2 + \" \"\n","        print(\"    \" + \" \" + pos_concatenado)\n","      \n","      # Lista com documentos perturbados e sua classificacao para o DO\n","      lista_perturbado_classificado_correto = []\n","      lista_perturbado_classificado_incorreto = []\n","\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","          # Id do documento perturbado\n","          id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","          #id_perturbado = linha['id'] + 1\n","          #print(\"id_perturbado:\",id_perturbado)\n","\n","          # Localiza os dados do documento perturbado\n","          documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","          # Recupera o documento perturrbado\n","          #print(\"documento_perturbado:\",documento_perturbado)\n","          #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","          #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","          #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","          #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","          #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","          #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","          # Recupera a sentença mascarada e seus dados do documento perturbado\n","          index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","          \n","          # Encontrar o índice da palavra mascarada\n","          index_wi = getIndicePalavraMascarada(sentenca_mascarada)\n","\n","          palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","          #print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","          token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos, token_predito)\n","          #print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","          cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO = getMedidasComparacaoPalavrasGlobal(id_documento_original, \n","                                                                                           index_sentenca, \n","                                                                                           index_wi,\n","                                                                                           estrategia_medida = estrategia_medida, #Estratégia 0 = MEAN, 1 - MAX\n","                                                                                           filtro_palavra = filtro_palavra) #Filtro palavra 0 = All, 1 - CLEAN, 2 - REL\n","          # print(\"    Ctx DO     :\", palavra_mascarada, \" - \", cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO)\n","\n","          cos_ctxall_pertDO, euc_ctxall_pertDO, man_ctxall_pertDO = getMedidasComparacaoPalavrasGlobal(id_perturbado, \n","                                                                                           index_sentenca, \n","                                                                                           index_wi,\n","                                                                                           estrategia_medida = estrategia_medida, #Estratégia 0 = MEAN, 1 - MAX\n","                                                                                           filtro_palavra = filtro_palavra) #Filtro palavra 0 = All, 1 - CLEAN, 2 - REL\n","          # print(\"    Ctx pertDO :\", token_predito, \" - \", cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO)\n","\n","          # Recupera o id documento perturbado se ele foi classificado corretamente\n","          documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]        \n","          \n","          # Se foi encontrado foi classificado corretamente          \n","          if len(documento_id_perturbado_correto) != 0:\n","            \n","            versaoPerturbadaClassificada = True\n","            #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","            documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","            #print(\"documento:\",documento)\n","            lista_perturbado_classificado_correto.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                                          str(documento[\"documento\"]),            #1\n","                                                          palavra_mascarada,                      #2\n","                                                          palavra_mascarada_classe,               #3\n","                                                          token_predito,                          #4\n","                                                          token_predito_classe,                   #5\n","                                                          peso_predito,                           #6\n","                                                          0,                                      #7\n","                                                          cos_ctxall_DO,                          #8\n","                                                          euc_ctxall_DO,                          #9\n","                                                          man_ctxall_DO,                          #10\n","                                                          cos_ctxall_pertDO,                      #11\n","                                                          euc_ctxall_pertDO,                      #12\n","                                                          man_ctxall_pertDO,                      #13\n","                                                          ])          \n","\n","          else:\n","            # Recupera o id documento perturbado se ele foi classificado incorretamente\n","            documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]            \n","\n","            # Se foi encontrado foi classificado incorretamente            \n","            if len(documento_id_perturbado_incorreto) != 0:                        \n","              #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))                        \n","              documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","              #print(\"documento:\",documento)\n","              lista_perturbado_classificado_incorreto.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                                              str(documento[\"documento\"]),  #1\n","                                                              palavra_mascarada,                      #2\n","                                                              palavra_mascarada_classe,               #3\n","                                                              token_predito,                          #4\n","                                                              token_predito_classe,                   #5\n","                                                              peso_predito,                           #6\n","                                                              1,                                      #7\n","                                                              cos_ctxall_DO,                          #8\n","                                                              euc_ctxall_DO,                          #9\n","                                                              man_ctxall_DO,                          #10\n","                                                              cos_ctxall_pertDO,                      #11\n","                                                              euc_ctxall_pertDO,                      #12\n","                                                              man_ctxall_pertDO,                      #13\n","                                                              ])                                  \n","                  \n","      # Ordena as listas\n","      lista_perturbado_classificado_correto = sorted(lista_perturbado_classificado_correto, key=lambda x: (x[2], x[6]), reverse=True)\n","      lista_perturbado_classificado_incorreto = sorted(lista_perturbado_classificado_incorreto, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","      # Cosseno\n","      if medida == 'cos':\n","        indice_palavra_selecionada = 8 # índice palavra original selecionada\n","        indice_palavra_substituida = 11 # índice palavra substiuída\n","      else:        \n","        # Euclidiana\n","        if medida == 'euc':\n","          indice_palavra_selecionada = 9 # índice palavra original selecionada\n","          indice_palavra_substituida = 12 # índice palavra substituída\n","        else:          \n","          # Manhatan\n","          if medida == 'man':\n","            indice_palavra_selecionada = 10 # índice palavra original selecionada\n","            indice_palavra_substituida = 13 # índice palavra substituída\n","      \n","      if exibir_dados == True:\n","        # Mostra a saída das classificações    \n","        print(\"  Classificações corretas (classe = predição): \" + str(len(lista_perturbado_classificado_correto)))\n","\n","      if len(lista_perturbado_classificado_correto) != 0:           \n","        conta_melhor_DO = 0 \n","        conta_melhor_pertDO = 0\n","        classes_iguais = 0\n","                \n","        for i, x in enumerate(lista_perturbado_classificado_correto):\n","          # Classes morfosintáticas iguais\n","          if x[3] == x[5]:\n","            classes_iguais = classes_iguais + 1\n","    \n","          # similaridade do cosseno euclidiana(busca a maior distância)\n","          if medida == 'cos':\n","            if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos\n","              # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento      \n","              melhorDO = \"\u003e\"\n","              melhor_pertDO = \"\"\n","              conta_melhor_DO = conta_melhor_DO + 1            \n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_DO_correto.append(linha)            \n","            else:\n","              # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","              melhorDO = \"\"\n","              melhor_pertDO = \"\u003e\"\n","              conta_melhor_pertDO = conta_melhor_pertDO + 1\n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_pertDO_correto.append(linha)\n","          else:\n","            # distância euclidiana(busca a menor distância)          \n","            if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man  \n","              # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento      \n","              melhorDO = \"\u003e\"\n","              melhor_pertDO = \"\"\n","              conta_melhor_DO = conta_melhor_DO + 1            \n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_DO_correto.append(linha)             \n","            else:\n","              # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","              melhorDO = \"\"\n","              melhor_pertDO = \"\u003e\"\n","              conta_melhor_pertDO = conta_melhor_pertDO + 1\n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_pertDO_correto.append(linha)\n","              \n","          if exibir_dados == True:\n","            linha = getLinhaMedidaExibicao(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            print(\"  \" + str(i+1), \"-\" + linha)            \n","\n","        if exibir_dados == True:\n","          print(\"       DO melhor      :\",conta_melhor_DO, \" pertDOMelhor:\",conta_melhor_pertDO)\n","          print(\"       Classes iguais :\",classes_iguais)\n","\n","      if exibir_dados == True:\n","        print(\"  Classificações incorretas(classe != predição): \" + str(len(lista_perturbado_classificado_incorreto)))\n","        \n","      if len(lista_perturbado_classificado_incorreto) != 0:           \n","        conta_melhor_DO = 0 \n","        conta_melhor_pertDO = 0\n","        classes_iguais = 0\n","          \n","        for i, x in enumerate(lista_perturbado_classificado_incorreto):\n","\n","            # Classes morfosintáticas iguais\n","            if x[3] == x[5]:\n","              classes_iguais = classes_iguais  + 1\n","\n","            if medida == 'cos':\n","              if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos                \n","                # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","                melhorDO = \"\u003e\"\n","                melhor_pertDO = \"\"              \n","                conta_melhor_DO = conta_melhor_DO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_DO_incorreto.append(linha)\n","               \n","              else:\n","                # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","                melhorDO = \"\"\n","                melhor_pertDO = \"\u003e\"\n","                conta_melhor_pertDO = conta_melhor_pertDO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_pertDO_incorreto.append(linha)                \n","\n","            else:            \n","              if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man\n","                # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","                melhorDO = \"\u003e\"\n","                melhor_pertDO = \"\"              \n","                conta_melhor_DO = conta_melhor_DO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_DO_incorreto.append(linha)\n","                \n","              else:\n","                # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","                melhorDO = \"\"\n","                melhor_pertDO = \"\u003e\"\n","                conta_melhor_pertDO = conta_melhor_pertDO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_pertDO_incorreto.append(linha)\n","                \n","            if exibir_dados == True:    \n","              linha = getLinhaMedidaExibicao(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              print(\"  \" + str(i+1), \"-\" + linha)              \n","        \n","        if exibir_dados == True:  \n","          print(\"       DO melhor      :\",conta_melhor_DO, \" pertDOMelhor:\",conta_melhor_pertDO)\n","          print(\"       Classes iguais :\",classes_iguais)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3K0bp7nDd02"},"outputs":[],"source":["visualizaMedidasCG(\"1\")"]},{"cell_type":"markdown","metadata":{"id":"ALf4upAFGbsj"},"source":["#### Função de visualização das medidas de uma equação entre DO e pertDO\n","\n","Visualização das medidas usando medidas de distância e similaridade(cos,euc,man) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqB-vt3PGbsk"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def visualizaMedidasEquacao(_id_documento_original,\n","                             equacao_medida = 0,\n","                             medida = 'cos',\n","                             estrategia_medida = 0,\n","                             filtro_palavra = 0,\n","                             _exibir_dados = True):\n","  \n","  print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","  print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","  print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","  print(\"Equação medida   :\", getEquacaoMedidaStr(equacao_medida))\n","  print(\"Medida           :\", medida)\n","  print(\"Estratégia medida:\", getEstrategiaMedidaStr(estrategia_medida))\n","  print(\"Filtro palavra   :\", getFiltroPalavraStr(filtro_palavra))\n","\n","  exibir_dados = _exibir_dados\n","\n","  lista_melhor_DO_correto = []\n","  lista_melhor_pertDO_correto = []\n","  lista_melhor_DO_incorreto = []\n","  lista_melhor_pertDO_incorreto = []\n","\n","  # Lista as medidas de um documento ou de todos\n","  if _id_documento_original == None:\n","    lista_documentos = lista_documentos_originais\n","    #print(\"Todos\")\n","  else:\n","    #print(\"Somente o id = \", id)\n","    lista_documentos = lista_documentos_originais.loc[lista_documentos_originais['id']==_id_documento_original]\n","        \n","  # Barra de progresso dos documentos\n","  lista_documentos_originais_bar = tqdm_notebook(lista_documentos.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos))\n","\n","  # Percorre os documentos\n","  for i, linha in lista_documentos_originais_bar:   \n","\n","    # Limita a quantidade de dados a serem exibidas\n","    #if i \u003c 2:    \n","    # Procura um documento específico\n","    #if \"Em uma fila a operação de enfileirar ocorre em qual extremidade\" in linha['documento']:\n","\n","      # Recupera o id do documento original\n","      id_documento_original = linha['id']\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Recupera o documento original se ele foi classificado corretamente    \n","      documento_id_original = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == linha['id']]\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente\n","      if len(documento_id_original) != 0:\n","        #print(\"documento_id_original:\",len(documento_id_original))          \n","        documento = lista_documentos_agrupados.loc[lista_documentos_agrupados[\"id\"] == str(documento_id_original['id'].values[0])]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'].values[0])      \n","      else:\n","        classe = \"0\"\n","    \n","      if exibir_dados == True:\n","        #Mostra o documento original e sua classificação\n","        print(\"\\nDO: \" + linha[\"documento\"] + \" - \" + classe)    \n","        pos_concatenado = \"\"\n","        # Concatena as pos do documento\n","        for doc_pos1 in documento_original_pos:\n","            # print(\"doc_pos1\",doc_pos1)\n","            for doc_pos2 in doc_pos1:\n","              pos_concatenado = pos_concatenado + doc_pos2 + \" \"\n","        print(\"    \" + \" \" + pos_concatenado)\n","      \n","      # Lista com documentos perturbados e sua classificacao para o DO\n","      lista_perturbado_classificado_correto = []\n","      lista_perturbado_classificado_incorreto = []\n","\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","          # Id do documento perturbado\n","          id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","          #id_perturbado = linha['id'] + 1\n","          #print(\"id_perturbado:\",id_perturbado)\n","\n","          # Localiza os dados do documento perturbado\n","          documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","          # Recupera o documento perturrbado\n","          #print(\"documento_perturbado:\",documento_perturbado)\n","          #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","          #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","          #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","          #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","          #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","          #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","          # Recupera a sentença mascarada e seus dados do documento perturbado\n","          index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","          \n","          # Encontrar o índice da palavra mascarada\n","          index_wi = getIndicePalavraMascarada(sentenca_mascarada)\n","\n","          palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","          #print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","          token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos, token_predito)\n","          #print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","          CAWcos_DO, CAWeuc_DO, CAWman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                              documento_original, \n","                                                              lista_sentenca_documento_original, \n","                                                              documento_original_tokens, \n","                                                              documento_original_pos,\n","                                                              equacao_medida = 0, #CAW\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","          #print(\"     DO     :\", palavra_mascarada, \" - \", CAWcos_DO, CAWeuc_DO, CAWman_DO)\n","\n","\n","          CAWcos_pertDO, CAWeuc_pertDO, CAWman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                                documento_perturbado, \n","                                                                lista_sentenca_documento_perturbado, \n","                                                                documento_perturbado_tokens, \n","                                                                documento_perturbado_pos,\n","                                                                equacao_medida = 0, #CAW\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)\n","          # print(\"    pertDO :\", token_predito, \" - \", CAWcos_pertDO, CAWeuc_pertDO, CAWman_pertDO)\n","\n","\n","          CWPcos_DO, CWPeuc_DO, CWPman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                                documento_original, \n","                                                                lista_sentenca_documento_original, \n","                                                                documento_original_tokens, \n","                                                                documento_original_pos,\n","                                                                equacao_medida = 1, #CWP\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)     \n","          #print(\"     DO     :\", palavra_mascarada, \" - \", CWPcos_DO, CWPeuc_DO, CWPman_DO)\n","\n","\n","          CWPcos_pertDO, CWPeuc_pertDO, CWPman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                                documento_perturbado, \n","                                                                lista_sentenca_documento_perturbado, \n","                                                                documento_perturbado_tokens, \n","                                                                documento_perturbado_pos,\n","                                                                equacao_medida = 1, #CWP\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)\n","          # print(\"    pertDO :\", token_predito, \" - \", CWPcos_pertDO, CWPeuc_pertDO, CWPman_pertDO)\n","\n","\n","          CGcos_DO, CGeuc_DO, CGman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                                documento_original, \n","                                                                lista_sentenca_documento_original, \n","                                                                documento_original_tokens, \n","                                                                documento_original_pos,\n","                                                                equacao_medida = 2, #CG\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)     \n","          #print(\"     DO     :\", palavra_mascarada, \" - \", CGcos_DO, CGeuc_DO, CGman_DO)\n","\n","\n","          CGcos_pertDO, CGeuc_pertDO, CGman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                                documento_perturbado, \n","                                                                lista_sentenca_documento_perturbado, \n","                                                                documento_perturbado_tokens, \n","                                                                documento_perturbado_pos,\n","                                                                equacao_medida = 2, #CG\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)\n","          # print(\"    pertDO :\", token_predito, \" - \", CGcos_pertDO, CGeuc_pertDO, CGman_pertDO)\n","\n","          if medida == 'cos':\n","            CAW_DO = CAWcos_DO\n","            CWP_DO = CWPcos_DO\n","            CG_DO = CGcos_DO\n","            CAW_pertDO = CAWcos_pertDO\n","            CWP_pertDO = CWPcos_pertDO\n","            CG_pertDO = CGcos_pertDO\n","          else:\n","            if medida == 'euc':\n","              CAW_DO = CAWeuc_DO\n","              CWP_DO = CWPeuc_DO\n","              CG_DO = CGeuc_DO\n","              CAW_pertDO = CAWeuc_pertDO\n","              CWP_pertDO = CWPeuc_pertDO\n","              CG_pertDO = CGeuc_pertDO\n","            else:\n","              if medida == 'man':\n","                CAW_DO = CAWman_DO\n","                CWP_DO = CWPman_DO\n","                CG_DO = CGman_DO\n","                CAW_pertDO = CAWman_pertDO\n","                CWP_pertDO = CWPman_pertDO\n","                CG_pertDO = CGman_pertDO\n","\n","          # Recupera o id documento perturbado se ele foi classificado corretamente\n","          documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]        \n","          \n","          # Se foi encontrado foi classificado corretamente\n","          #if documento_id_perturbado_correto == True:\n","          if len(documento_id_perturbado_correto) != 0:\n","            \n","            versaoPerturbadaClassificada = True\n","            #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","            documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","            #print(\"documento:\",documento)\n","            lista_perturbado_classificado_correto.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                                          str(documento[\"documento\"]),            #1\n","                                                          palavra_mascarada,                      #2\n","                                                          palavra_mascarada_classe,               #3\n","                                                          token_predito,                          #4\n","                                                          token_predito_classe,                   #5\n","                                                          peso_predito,                           #6\n","                                                          0,                                      #7\n","                                                          CAW_DO,                                 #8\n","                                                          CWP_DO,                                 #9\n","                                                          CG_DO,                                  #10\n","                                                          CAW_pertDO,                             #11\n","                                                          CWP_pertDO,                             #12\n","                                                          CG_pertDO,                              #13\n","                                                          ])          \n","\n","          else:\n","            # Recupera o id documento perturbado se ele foi classificado incorretamente\n","            documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]            \n","\n","            # Se foi encontrado foi classificado incorretamente            \n","            if len(documento_id_perturbado_incorreto) != 0:                        \n","              #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))                        \n","              documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","              #print(\"documento:\",documento)\n","              lista_perturbado_classificado_incorreto.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                                              str(documento[\"documento\"]),  #1\n","                                                              palavra_mascarada,                      #2\n","                                                              palavra_mascarada_classe,               #3\n","                                                              token_predito,                          #4\n","                                                              token_predito_classe,                   #5\n","                                                              peso_predito,                           #6\n","                                                              1,                                      #7\n","                                                              CAW_DO,                                 #8\n","                                                              CWP_DO,                                 #9\n","                                                              CG_DO,                                  #10\n","                                                              CAW_pertDO,                             #11\n","                                                              CWP_pertDO,                             #12\n","                                                              CG_pertDO,                              #13\n","                                                              ])                                  \n","                  \n","      # Ordena as listas\n","      lista_perturbado_classificado_correto = sorted(lista_perturbado_classificado_correto, key=lambda x: (x[2], x[6]), reverse=True)\n","      lista_perturbado_classificado_incorreto = sorted(lista_perturbado_classificado_incorreto, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","      # CAW\n","      if equacao_medida == 0:\n","        indice_palavra_selecionada = 8 # índice palavra original selecionada\n","        indice_palavra_substituida = 11 # índice palavra substiuída\n","      else:        \n","        # CWP\n","        if equacao_medida == 1:\n","          indice_palavra_selecionada = 9 # índice palavra original selecionada\n","          indice_palavra_substituida = 12 # índice palavra substituída\n","        else:          \n","          # CG\n","          if equacao_medida == 2:\n","            indice_palavra_selecionada = 10 # índice palavra original selecionada\n","            indice_palavra_substituida = 13 # índice palavra substituída\n","      \n","      if exibir_dados == True:\n","        # Mostra a saída das classificações    \n","        print(\"  Classificações corretas (classe = predição): \" + str(len(lista_perturbado_classificado_correto)))\n","\n","      if len(lista_perturbado_classificado_correto) != 0:           \n","        conta_melhor_DO = 0 \n","        conta_melhor_pertDO = 0\n","        classes_iguais = 0\n","                \n","        for i, x in enumerate(lista_perturbado_classificado_correto):\n","          # Classes morfosintáticas iguais\n","          if x[3] == x[5]:\n","            classes_iguais = classes_iguais + 1\n","    \n","          # similaridade do cosseno euclidiana(busca a maior distância)\n","          if medida == 'cos':\n","            if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos\n","              # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento      \n","              melhorDO = \"\u003e\"\n","              melhor_pertDO = \"\"\n","              conta_melhor_DO = conta_melhor_DO + 1  \n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_DO_correto.append(linha)\n","              \n","            else:\n","              # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","              melhorDO = \"\"\n","              melhor_pertDO = \"\u003e\"\n","              conta_melhor_pertDO = conta_melhor_pertDO + 1\n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_pertDO_correto.append(linha)\n","             \n","          else:\n","            # distância euclidiana(busca a menor distância)          \n","            if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man  \n","              # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento      \n","              melhorDO = \"\u003e\"\n","              melhor_pertDO = \"\"\n","              conta_melhor_DO = conta_melhor_DO + 1\n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_DO_correto.append(linha)\n","              \n","            else:\n","              # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","              melhorDO = \"\"\n","              melhor_pertDO = \"\u003e\"\n","              conta_melhor_pertDO = conta_melhor_pertDO + 1\n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_pertDO_correto.append(linha)\n","             \n","          if exibir_dados == True:\n","            linha = getLinhaMedidaExibicao(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            print(\"  \" + str(i+1), \"-\" + linha)    \n","            \n","        if exibir_dados == True:\n","          print(\"       DO melhor      :\",conta_melhor_DO, \" pertDOMelhor:\",conta_melhor_pertDO)\n","          print(\"       Classes iguais :\",classes_iguais)\n","\n","      if exibir_dados == True:\n","        print(\"  Classificações incorretas(classe != predição): \" + str(len(lista_perturbado_classificado_incorreto)))\n","        \n","      if len(lista_perturbado_classificado_incorreto) != 0:           \n","        conta_melhor_DO = 0 \n","        conta_melhor_pertDO = 0\n","        classes_iguais = 0\n","          \n","        for i, x in enumerate(lista_perturbado_classificado_incorreto):\n","\n","            # Classes morfosintáticas iguais\n","            if x[3] == x[5]:\n","              classes_iguais = classes_iguais  + 1\n","\n","            if medida == 'cos':\n","              if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos                \n","                # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","                melhorDO = \"\u003e\"\n","                melhor_pertDO = \"\"              \n","                conta_melhor_DO = conta_melhor_DO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_DO_incorreto.append(linha)\n","                \n","              else:\n","                # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","                melhorDO = \"\"\n","                melhor_pertDO = \"\u003e\"\n","                conta_melhor_pertDO = conta_melhor_pertDO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_pertDO_incorreto.append(linha)                \n","\n","            else:            \n","              if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man\n","                # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","                melhorDO = \"\u003e\"\n","                melhor_pertDO = \"\"              \n","                conta_melhor_DO = conta_melhor_DO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_DO_incorreto.append(linha)\n","                \n","              else:\n","                # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","                melhorDO = \"\"\n","                melhor_pertDO = \"\u003e\"\n","                conta_melhor_pertDO = conta_melhor_pertDO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_pertDO_incorreto.append(linha)                \n","                \n","            if exibir_dados == True: \n","              linha = getLinhaMedidaExibicao(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              print(\"  \" + str(i+1), \"-\" + linha)                         \n","        \n","        if exibir_dados == True:  \n","          print(\"       DO melhor      :\",conta_melhor_DO, \" pertDOMelhor:\",conta_melhor_pertDO)\n","          print(\"       Classes iguais :\",classes_iguais)"]},{"cell_type":"markdown","metadata":{"id":"rPZt7Poslpe9"},"source":["#### Função de visualização das medidas das equações entre DO e pertD\n","\n","Visualização das medidas das equações de (in)coerrência(CAW,CWP,CG) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWitLmLAl0Bf"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def visualizaMedidasEquacoes(_id_documento_original,\n","                             equacao_medida = 0,\n","                             medida = 'euc',\n","                             estrategia_medida = 0,\n","                             filtro_palavra = 0,\n","                             _exibir_dados = True):\n","  \n","  print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","  print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","  print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","  print(\"Equação medida   :\", getEquacaoMedidaStr(equacao_medida))\n","  print(\"Medida           :\", medida)\n","  print(\"Estratégia medida:\", getEstrategiaMedidaStr(estrategia_medida))\n","  print(\"Filtro palavra   :\", getFiltroPalavraStr(filtro_palavra))\n","\n","  exibir_dados = _exibir_dados\n","\n","  lista_melhor_DO_correto = []\n","  lista_melhor_pertDO_correto = []\n","  lista_melhor_DO_incorreto = []\n","  lista_melhor_pertDO_incorreto = []\n","\n","  # Lista as medidas de um documento ou de todos\n","  if _id_documento_original == None:\n","    lista_documentos = lista_documentos_originais\n","    #print(\"Todos\")\n","  else:\n","    #print(\"Somente o id = \", id)\n","    lista_documentos = lista_documentos_originais.loc[lista_documentos_originais['id']==_id_documento_original]\n","        \n","  # Barra de progresso dos documentos\n","  lista_documentos_originais_bar = tqdm_notebook(lista_documentos.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos))\n","\n","  # Percorre os documentos\n","  for i, linha in lista_documentos_originais_bar:   \n","\n","    # Limita a quantidade de dados a serem exibidas\n","    #if i \u003c 2:    \n","    # Procura um documento específico\n","    #if \"Em uma fila a operação de enfileirar ocorre em qual extremidade\" in linha['documento']:\n","\n","      # Recupera o id do documento original\n","      id_documento_original = linha['id']\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Recupera o documento original se ele foi classificado corretamente    \n","      documento_id_original = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == linha['id']]\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente\n","      if len(documento_id_original) != 0:\n","        #print(\"documento_id_original:\",len(documento_id_original))          \n","        documento = lista_documentos_agrupados.loc[lista_documentos_agrupados[\"id\"] == str(documento_id_original['id'].values[0])]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'].values[0])      \n","      else:\n","        classe = \"0\"\n","    \n","      if exibir_dados == True:\n","        #Mostra o documento original e sua classificação\n","        print(\"\\nDO: \" + linha[\"documento\"] + \" - \" + classe)    \n","        pos_concatenado = \"\"\n","        # Concatena as pos do documento\n","        for doc_pos1 in documento_original_pos:\n","            # print(\"doc_pos1\",doc_pos1)\n","            for doc_pos2 in doc_pos1:\n","              pos_concatenado = pos_concatenado + doc_pos2 + \" \"\n","        print(\"    \" + \" \" + pos_concatenado)\n","      \n","      # Lista com documentos perturbados e sua classificacao para o DO\n","      lista_perturbado_classificado_correto = []\n","      lista_perturbado_classificado_incorreto = []\n","\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","          # Id do documento perturbado\n","          id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","          #id_perturbado = linha['id'] + 1\n","          #print(\"id_perturbado:\",id_perturbado)\n","\n","          # Localiza os dados do documento perturbado\n","          documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","          # Recupera o documento perturrbado\n","          #print(\"documento_perturbado:\",documento_perturbado)\n","          #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","          #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","          #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","          #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","          #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","          #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","          # Recupera a sentença mascarada e seus dados do documento perturbado\n","          index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","          \n","          # Encontrar o índice da palavra mascarada\n","          index_wi = getIndicePalavraMascarada(sentenca_mascarada)\n","\n","          palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","          #print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","          token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos, token_predito)\n","          #print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","          CAWcos_DO, CAWeuc_DO, CAWman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                              documento_original, \n","                                                              lista_sentenca_documento_original, \n","                                                              documento_original_tokens, \n","                                                              documento_original_pos,\n","                                                              equacao_medida = 0, #CAW\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","          #print(\"     DO     :\", palavra_mascarada, \" - \", CAWcos_DO, CAWeuc_DO, CAWman_DO)\n","\n","\n","          CAWcos_pertDO, CAWeuc_pertDO, CAWman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                                documento_perturbado, \n","                                                                lista_sentenca_documento_perturbado, \n","                                                                documento_perturbado_tokens, \n","                                                                documento_perturbado_pos,\n","                                                                equacao_medida = 0, #CAW\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)\n","          # print(\"    pertDO :\", token_predito, \" - \", CAWcos_pertDO, CAWeuc_pertDO, CAWman_pertDO)\n","\n","\n","          CWPcos_DO, CWPeuc_DO, CWPman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                                documento_original, \n","                                                                lista_sentenca_documento_original, \n","                                                                documento_original_tokens, \n","                                                                documento_original_pos,\n","                                                                equacao_medida = 1, #CWP\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)     \n","          #print(\"     DO     :\", palavra_mascarada, \" - \", CWPcos_DO, CWPeuc_DO, CWPman_DO)\n","\n","\n","          CWPcos_pertDO, CWPeuc_pertDO, CWPman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                                documento_perturbado, \n","                                                                lista_sentenca_documento_perturbado, \n","                                                                documento_perturbado_tokens, \n","                                                                documento_perturbado_pos,\n","                                                                equacao_medida = 1, #CWP\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)\n","          # print(\"    pertDO :\", token_predito, \" - \", CWPcos_pertDO, CWPeuc_pertDO, CWPman_pertDO)\n","\n","\n","          CGcos_DO, CGeuc_DO, CGman_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                                documento_original, \n","                                                                lista_sentenca_documento_original, \n","                                                                documento_original_tokens, \n","                                                                documento_original_pos,\n","                                                                equacao_medida = 2, #CG\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)     \n","          #print(\"     DO     :\", palavra_mascarada, \" - \", CGcos_DO, CGeuc_DO, CGman_DO)\n","\n","\n","          CGcos_pertDO, CGeuc_pertDO, CGman_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                                documento_perturbado, \n","                                                                lista_sentenca_documento_perturbado, \n","                                                                documento_perturbado_tokens, \n","                                                                documento_perturbado_pos,\n","                                                                equacao_medida = 2, #CG\n","                                                                estrategia_medida = estrategia_medida,\n","                                                                filtro_palavra = filtro_palavra)\n","          # print(\"    pertDO :\", token_predito, \" - \", CGcos_pertDO, CGeuc_pertDO, CGman_pertDO)\n","\n","          if medida == 'cos':\n","            CAW_DO = CAWcos_DO\n","            CWP_DO = CWPcos_DO\n","            CG_DO = CGcos_DO\n","            CAW_pertDO = CAWcos_pertDO\n","            CWP_pertDO = CWPcos_pertDO\n","            CG_pertDO = CGcos_pertDO\n","          else:\n","            if medida == 'euc':\n","              CAW_DO = CAWeuc_DO\n","              CWP_DO = CWPeuc_DO\n","              CG_DO = CGeuc_DO\n","              CAW_pertDO = CAWeuc_pertDO\n","              CWP_pertDO = CWPeuc_pertDO\n","              CG_pertDO = CGeuc_pertDO\n","            else:\n","              if medida == 'man':\n","                CAW_DO = CAWman_DO\n","                CWP_DO = CWPman_DO\n","                CG_DO = CGman_DO\n","                CAW_pertDO = CAWman_pertDO\n","                CWP_pertDO = CWPman_pertDO\n","                CG_pertDO = CGman_pertDO\n","\n","          # Recupera o id documento perturbado se ele foi classificado corretamente\n","          documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]        \n","          \n","          # Se foi encontrado foi classificado corretamente\n","          #if documento_id_perturbado_correto == True:\n","          if len(documento_id_perturbado_correto) != 0:\n","            \n","            versaoPerturbadaClassificada = True\n","            #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","            documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","            #print(\"documento:\",documento)\n","            lista_perturbado_classificado_correto.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                                          str(documento[\"documento\"]),            #1\n","                                                          palavra_mascarada,                      #2\n","                                                          palavra_mascarada_classe,               #3\n","                                                          token_predito,                          #4\n","                                                          token_predito_classe,                   #5\n","                                                          peso_predito,                           #6\n","                                                          0,                                      #7\n","                                                          CAW_DO,                                 #8\n","                                                          CWP_DO,                                 #9\n","                                                          CG_DO,                                  #10\n","                                                          CAW_pertDO,                             #11\n","                                                          CWP_pertDO,                             #12\n","                                                          CG_pertDO,                              #13\n","                                                          ])          \n","\n","          else:\n","            # Recupera o id documento perturbado se ele foi classificado incorretamente\n","            documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]            \n","\n","            # Se foi encontrado foi classificado incorretamente            \n","            if len(documento_id_perturbado_incorreto) != 0:                        \n","              #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))                        \n","              documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","              #print(\"documento:\",documento)\n","              lista_perturbado_classificado_incorreto.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                                              str(documento[\"documento\"]),  #1\n","                                                              palavra_mascarada,                      #2\n","                                                              palavra_mascarada_classe,               #3\n","                                                              token_predito,                          #4\n","                                                              token_predito_classe,                   #5\n","                                                              peso_predito,                           #6\n","                                                              1,                                      #7\n","                                                              CAW_DO,                                 #8\n","                                                              CWP_DO,                                 #9\n","                                                              CG_DO,                                  #10\n","                                                              CAW_pertDO,                             #11\n","                                                              CWP_pertDO,                             #12\n","                                                              CG_pertDO,                              #13\n","                                                              ])                                  \n","                  \n","      # Ordena as listas\n","      lista_perturbado_classificado_correto = sorted(lista_perturbado_classificado_correto, key=lambda x: (x[2], x[6]), reverse=True)\n","      lista_perturbado_classificado_incorreto = sorted(lista_perturbado_classificado_incorreto, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","      # CAW\n","      if equacao_medida == 0:\n","        indice_palavra_selecionada = 8 # índice palavra original selecionada\n","        indice_palavra_substituida = 11 # índice palavra substiuída\n","      else:        \n","        # CWP\n","        if equacao_medida == 1:\n","          indice_palavra_selecionada = 9 # índice palavra original selecionada\n","          indice_palavra_substituida = 12 # índice palavra substituída\n","        else:          \n","          # CG\n","          if equacao_medida == 2:\n","            indice_palavra_selecionada = 10 # índice palavra original selecionada\n","            indice_palavra_substituida = 13 # índice palavra substituída\n","      \n","      if exibir_dados == True:\n","        # Mostra a saída das classificações    \n","        print(\"  Classificações corretas (classe = predição): \" + str(len(lista_perturbado_classificado_correto)))\n","\n","      if len(lista_perturbado_classificado_correto) != 0:           \n","        conta_melhor_DO = 0 \n","        conta_melhor_pertDO = 0\n","        classes_iguais = 0\n","                \n","        for i, x in enumerate(lista_perturbado_classificado_correto):\n","          # Classes morfosintáticas iguais\n","          if x[3] == x[5]:\n","            classes_iguais = classes_iguais + 1\n","    \n","          # similaridade do cosseno euclidiana(busca a maior distância)\n","          if medida == 'cos':\n","            if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos\n","              # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento      \n","              melhorDO = \"\u003e\"\n","              melhor_pertDO = \"\"\n","              conta_melhor_DO = conta_melhor_DO + 1            \n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_DO_correto.append(linha)\n","            \n","            else:\n","              # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","              melhorDO = \"\"\n","              melhor_pertDO = \"\u003e\"\n","              conta_melhor_pertDO = conta_melhor_pertDO + 1\n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_pertDO_correto.append(linha)\n","              \n","          else:\n","            # distância euclidiana(busca a menor distância)          \n","            if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man  \n","              # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento      \n","              melhorDO = \"\u003e\"\n","              melhor_pertDO = \"\"\n","              conta_melhor_DO = conta_melhor_DO + 1\n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_DO_correto.append(linha)\n","             \n","            else:\n","              # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","              melhorDO = \"\"\n","              melhor_pertDO = \"\u003e\"\n","              conta_melhor_pertDO = conta_melhor_pertDO + 1\n","              linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              lista_melhor_pertDO_correto.append(linha)             \n","\n","          if exibir_dados == True:\n","            linha = getLinhaMedidaExibicao(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            print(\"  \" + str(i+1), \"-\" + linha)            \n","\n","        if exibir_dados == True:\n","          print(\"       DO melhor      :\",conta_melhor_DO, \" pertDOMelhor:\",conta_melhor_pertDO)\n","          print(\"       Classes iguais :\",classes_iguais)\n","\n","      if exibir_dados == True:\n","        print(\"  Classificações incorretas(classe != predição): \" + str(len(lista_perturbado_classificado_incorreto)))\n","        \n","      if len(lista_perturbado_classificado_incorreto) != 0:           \n","        conta_melhor_DO = 0 \n","        conta_melhor_pertDO = 0\n","        classes_iguais = 0\n","          \n","        for i, x in enumerate(lista_perturbado_classificado_incorreto):\n","\n","            # Classes morfosintáticas iguais\n","            if x[3] == x[5]:\n","              classes_iguais = classes_iguais  + 1\n","\n","            if medida == 'cos':\n","              if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos                \n","                # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","                melhorDO = \"\u003e\"\n","                melhor_pertDO = \"\"              \n","                conta_melhor_DO = conta_melhor_DO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_DO_incorreto.append(linha)\n","                \n","              else:\n","                # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","                melhorDO = \"\"\n","                melhor_pertDO = \"\u003e\"\n","                conta_melhor_pertDO = conta_melhor_pertDO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_pertDO_incorreto.append(linha)\n","                \n","            else:            \n","              if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man\n","                # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","                melhorDO = \"\u003e\"\n","                melhor_pertDO = \"\"              \n","                conta_melhor_DO = conta_melhor_DO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_DO_incorreto.append(linha)\n","                \n","              else:\n","                # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","                melhorDO = \"\"\n","                melhor_pertDO = \"\u003e\"\n","                conta_melhor_pertDO = conta_melhor_pertDO + 1\n","                linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","                lista_melhor_pertDO_incorreto.append(linha)                \n","\n","            if exibir_dados == True: \n","              linha = getLinhaMedidaExibicao(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","              print(\"  \" + str(i+1), \"-\" + linha)\n","              \n","        if exibir_dados == True:  \n","          print(\"       DO melhor      :\",conta_melhor_DO, \" pertDOMelhor:\",conta_melhor_pertDO)\n","          print(\"       Classes iguais :\",classes_iguais)"]},{"cell_type":"markdown","metadata":{"id":"S4fIQOaUDd04"},"source":["#### Função que mostra os dados das medidas das palavras entre DO e pertDO usando a equação CG\n","\n","\n","Gera CSV das medidas da palavra com a medida global(CG) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebOpWQ5xDd04"},"outputs":[],"source":["def mostrarMedidasCSV(lista_perturbado_classificado_medida,\n","                      _id_documento):\n","\n","  print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","  print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","  print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","  \n","  # Lista as medidas de um documento ou de todos\n","  if _id_documento == None:\n","    lista_documentos = lista_documentos_originais\n","    #print(\"Todos\")\n","  else:\n","    #print(\"Somente o id = \", id)\n","    lista_documentos = lista_documentos_originais.loc[lista_documentos_originais['id']==_id_documento]\n","\n","  # Percorre a lista dos documentos originais\n","  for i, linha in lista_documentos.iterrows():\n","    \n","    # Limita a quantidade de dados a serem exibidas\n","    #if i \u003c 2:    \n","    # Procura um documento específico\n","    #if id != none and id in linha['documento']:\n","    \n","      # Recupera o id do documento original\n","      id_documento_original = str(linha['id'])\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Recupera o documento original se ele foi classificado corretamente    \n","      documento_id_original = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == str(linha['id'])]\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente\n","      if len(documento_id_original) != 0:\n","        #print(\"documento_id_original:\",len(documento_id_original))          \n","        #documento = lista_documentos_agrupados.loc[lista_documentos_agrupados[\"id\"] == str(documento_id_original['id'].values[0])]\n","        documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'])\n","      else:\n","        classe = \"0\"\n","            \n","      print(\"\\nDO;classificacao(1-DO, 0-pertDO)\")    \n","      print(linha[\"documento\"] + \";\" + classe)          \n","      # Concatena as pos do documento\n","      pos_concatenado = \"\"      \n","      for doc_pos1 in documento_original_pos:\n","        # print(\"doc_pos1\",doc_pos1)\n","        for doc_pos2 in doc_pos1:\n","          pos_concatenado = pos_concatenado + doc_pos2 + \" \"\n","      print(pos_concatenado)\n","      print()\n","\n","      # Cabeçalho dos documentos perturbados    \n","      print(\"pertDO;\" +                                   #0\n","            \"classificacao(1-DO,0-pertDO);\" +             #1\n","            \"palavra selecionada;\" +                      #2\n","            \"classe palavra selecionada;\" +               #3\n","            \"CGcos(selecionada,DO);\" +                    #4\n","            \"CGeuc(selecionada,DO);\" +                    #5\n","            \"CGman(selecionada,DO);\" +                    #6\n","            \"palavra perturbada;\" +                       #7\n","            \"classe palavra perturbada;\" +                #8\n","            \"CGcos(perturbada, pertDO);\" +                #9\n","            \"CGeuc(perturbada, pertDO);\" +                #10\n","            \"CGman(perturbada, pertDO);\"+                 #11\n","            \"ranking de plausabilidade;\" +                #12\n","            \"dcos;\" +                                     #13\n","            \"deuc;\" +                                     #14\n","            \"dman;\" +                                     #15\n","            \"posigual;\" +                                 #16\n","            \"palavra_igual\")                              #17\n","      \n","      # Id do documento perturbado\n","      id_perturbado_parcial = id_documento_original + \"_pert_\"\n","      #print(\"id_perturbado_parcial:\",id_perturbado_parcial)  \n","\n","      conta = 0\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for i, x in enumerate(lista_perturbado_classificado_medida):        \n","        if  x[0].startswith(id_perturbado_parcial): \n","          print(x[1],\";\",               #0\n","                x[7],\";\",               #1\n","                x[2],\";\",               #2\n","                x[3],\";\",               #3\n","                trataNumero(x[8]),\";\",  #4\n","                trataNumero(x[9]),\";\",  #5\n","                trataNumero(x[10]),\";\", #6\n","                x[4],\";\",               #7\n","                x[5],\";\",               #8\n","                trataNumero(x[11]),\";\", #9\n","                trataNumero(x[12]),\";\", #10\n","                trataNumero(x[13]),\";\", #11              \n","                trataNumero(x[14]),\";\", #12              \n","                trataNumero(x[15]),\";\", #13\n","                trataNumero(x[16]),\";\", #14\n","                trataNumero(x[17]),\";\", #15\n","                trataNumero(x[18]),\";\", #16\n","                trataNumero(x[19])      #17\n","                ) \n","          conta = conta + 1\n","      print(\"Documentos perturbados:\", conta)    "]},{"cell_type":"markdown","metadata":{"id":"z6mjn-EX1V2V"},"source":["#### Função que mostra os dados das medidas de uma equação das perturbações em CSV\n","\n","Visualização das medidas usando medidas de distância e similaridade(cos,euc,man) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwdAqBxA1V2W"},"outputs":[],"source":["def mostrarMedidasEquacaoCSV(lista_perturbado_classificado_medida,\n","                             _id_documento,\n","                             equacao_medida = 0):\n","\n","  print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","  print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","  print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","  print(\"Equação medida   :\", getEquacaoMedidaStr(equacao_medida))\n","  \n","  # Lista as medidas de um documento ou de todos\n","  if _id_documento == None:\n","    lista_documentos = lista_documentos_originais\n","    #print(\"Todos\")\n","  else:\n","    #print(\"Somente o id = \", id)\n","    lista_documentos = lista_documentos_originais.loc[lista_documentos_originais['id']==_id_documento]\n","\n","  # Percorre a lista dos documentos originais\n","  for i, linha in lista_documentos.iterrows():\n","    \n","    # Limita a quantidade de dados a serem exibidas\n","    #if i \u003c 2:    \n","    # Procura um documento específico\n","    #if id != none and id in linha['documento']:\n","    \n","      # Recupera o id do documento original\n","      id_documento_original = str(linha['id'])\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Recupera o documento original se ele foi classificado corretamente    \n","      documento_id_original = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == str(linha['id'])]\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente\n","      if len(documento_id_original) != 0:\n","        #print(\"documento_id_original:\",len(documento_id_original))          \n","        #documento = lista_documentos_agrupados.loc[lista_documentos_agrupados[\"id\"] == str(documento_id_original['id'].values[0])]\n","        documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'])\n","      else:\n","        classe = \"0\"\n","            \n","      print(\"\\nDO;classificacao(1-DO, 0-pertDO)\")    \n","      print(linha[\"documento\"] + \";\" + classe)          \n","      # Concatena as pos do documento\n","      pos_concatenado = \"\"      \n","      for doc_pos1 in documento_original_pos:\n","        # print(\"doc_pos1\",doc_pos1)\n","        for doc_pos2 in doc_pos1:\n","          pos_concatenado = pos_concatenado + doc_pos2 + \" \"\n","      print(pos_concatenado)\n","      print()\n","\n","      eq = getEquacaoMedidaStrCurto(equacao_medida)\n","      # Cabeçalho dos documentos perturbados    \n","      print(\"pertDO;\" +                                   #0\n","            \"classificacao(1-DO,0-pertDO);\" +   #1\n","            \"palavra selecionada;\" +                      #2\n","            \"classe palavra selecionada;\" +               #3            \n","            eq + \"cos(selecionada,DO);\" +                 #4\n","            eq + \"euc(selecionada,DO);\" +                 #5\n","            eq + \"man(selecionada,DO);\" +                 #6\n","            \"palavra perturbada;\" +                       #7\n","            \"classe palavra perturbada;\" +                #8\n","            eq + \"cos(perturbada, pertDO);\" +             #9\n","            eq + \"euc(perturbada, pertDO);\" +             #10\n","            eq + \"man(perturbada, pertDO);\"+              #11\n","            \"ranking de plausabilidade;\" +                #12\n","            eq + \"dcos;\" +                                #13\n","            eq + \"deuc;\" +                                #14\n","            eq + \"dman;\" +                                #15\n","            \"posigual;\" +                                 #16\n","            \"palavra_igual\")                              #17\n","      \n","      # Id do documento perturbado\n","      id_perturbado_parcial = id_documento_original + \"_pert_\"\n","      #print(\"id_perturbado_parcial:\",id_perturbado_parcial)  \n","\n","      conta = 0\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for i, x in enumerate(lista_perturbado_classificado_medida):        \n","        if  x[0].startswith(id_perturbado_parcial): \n","          print(x[1],\";\",               #0\n","                x[7],\";\",               #1\n","                x[2],\";\",               #2\n","                x[3],\";\",               #3\n","                trataNumero(x[8]),\";\",  #4\n","                trataNumero(x[9]),\";\",  #5\n","                trataNumero(x[10]),\";\", #6\n","                x[4],\";\",               #7\n","                x[5],\";\",               #8\n","                trataNumero(x[11]),\";\", #9\n","                trataNumero(x[12]),\";\", #10\n","                trataNumero(x[13]),\";\", #11              \n","                trataNumero(x[14]),\";\", #12              \n","                trataNumero(x[15]),\";\", #13\n","                trataNumero(x[16]),\";\", #14\n","                trataNumero(x[17]),\";\", #15\n","                trataNumero(x[18]),\";\", #16\n","                trataNumero(x[19])      #17\n","                ) \n","          conta = conta + 1\n","      print(\"Documentos perturbados:\", conta)    "]},{"cell_type":"markdown","metadata":{"id":"3kTwPNdX49Jr"},"source":["#### Função que mostra os dados das medidas das equações dos documento perturbados em CSV\n","\n","Visualização das medidas das equações de (in)coerrência(CAW,CWP,CG) de DO as versões de pertDO."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4G_SK70249Js"},"outputs":[],"source":["def mostrarMedidasEquacoesCSV(lista_perturbado_classificado_medida,\n","                             _id_documento,\n","                             medida = 'euc'):\n","\n","  print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","  print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","  print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","  print(\"Medida           :\", medida)\n","  \n","  # Lista as medidas de um documento ou de todos\n","  if _id_documento == None:\n","    lista_documentos = lista_documentos_originais\n","    #print(\"Todos\")\n","  else:\n","    #print(\"Somente o id = \", id)\n","    lista_documentos = lista_documentos_originais.loc[lista_documentos_originais['id']==_id_documento]\n","\n","  # Percorre a lista dos documentos originais\n","  for i, linha in lista_documentos.iterrows():\n","    \n","    # Limita a quantidade de dados a serem exibidas\n","    #if i \u003c 2:    \n","    # Procura um documento específico\n","    #if id != none and id in linha['documento']:\n","    \n","      # Recupera o id do documento original\n","      id_documento_original = str(linha['id'])\n","\n","      # print(\"id_documento_original:\",id_documento_original) \n","      # Localiza os dados do documento original\n","      documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","      # Recupera o documento Original\n","      #print(\"documento_original:\",documento_original)\n","      #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","      #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","      #print(\"documento_original_tokens:\",documento_original_tokens)\n","      #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","      #print(\"documento_original_pos:\",documento_original_pos)\n","      #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","      \n","      # Recupera o documento original se ele foi classificado corretamente    \n","      documento_id_original = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == str(linha['id'])]\n","      #print(\"documento_id_original:\", documento_id_original)\n","\n","      # Recupera a classificação do original\n","      classe = \"\"\n","      # Se o documento original foi encontrado foi classificado corretamente\n","      if len(documento_id_original) != 0:\n","        #print(\"documento_id_original:\",len(documento_id_original))          \n","        #documento = lista_documentos_agrupados.loc[lista_documentos_agrupados[\"id\"] == str(documento_id_original['id'].values[0])]\n","        documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","        #print(\"documento:\",documento)\n","        classe =  str(documento['classe'])\n","      else:\n","        classe = \"0\"\n","            \n","      print(\"\\nDO;classificacao(1-DO, 0-pertDO)\")    \n","      print(linha[\"documento\"] + \";\" + classe)          \n","      # Concatena as pos do documento\n","      pos_concatenado = \"\"      \n","      for doc_pos1 in documento_original_pos:\n","        # print(\"doc_pos1\",doc_pos1)\n","        for doc_pos2 in doc_pos1:\n","          pos_concatenado = pos_concatenado + doc_pos2 + \" \"\n","      print(pos_concatenado)\n","      print()\n","      \n","      # Cabeçalho dos documentos perturbados    \n","      print(\"pertDO;\" +                                     #0\n","            \"classificacao(1-DO,0-pertDO);\" +               #1\n","            \"palavra selecionada;\" +                        #2\n","            \"classe palavra selecionada;\" +                 #3            \n","            \"CAW\" + medida + \"(selecionada,DO);\" +          #4\n","            \"CWP\" + medida + \"(selecionada,DO);\" +          #5\n","            \"CG\"  + medida + \"(selecionada,DO);\" +          #6\n","            \"palavra perturbada;\" +                         #7\n","            \"classe palavra perturbada;\" +                  #8\n","            \"CAW\" + medida + \"(perturbada, pertDO);\" +      #9\n","            \"CWP\" + medida + \"(perturbada, pertDO);\" +      #10\n","            \"CG\"  + medida + \"(perturbada, pertDO);\"+       #11\n","            \"ranking de plausabilidade;\" +                  #12\n","            \"CAWd\" + medida + \";\" +                         #13\n","            \"CWP\"  + medida + \";\" +                         #14\n","            \"CGd\"  + medida + \";\"+                          #15\n","            \"posigual;\" +                                   #16\n","            \"palavra_igual\")                                #17\n","      \n","      # Id do documento perturbado\n","      id_perturbado_parcial = id_documento_original + \"_pert_\"\n","      #print(\"id_perturbado_parcial:\",id_perturbado_parcial)  \n","\n","      conta = 0\n","      # Percorre os documentos perturbados e suas classificações a partir do original\n","      for i, x in enumerate(lista_perturbado_classificado_medida):        \n","        if  x[0].startswith(id_perturbado_parcial): \n","          print(x[1],\";\",               #0\n","                x[7],\";\",               #1\n","                x[2],\";\",               #2\n","                x[3],\";\",               #3\n","                trataNumero(x[8]),\";\",  #4\n","                trataNumero(x[9]),\";\",  #5\n","                trataNumero(x[10]),\";\", #6\n","                x[4],\";\",               #7\n","                x[5],\";\",               #8\n","                trataNumero(x[11]),\";\", #9\n","                trataNumero(x[12]),\";\", #10\n","                trataNumero(x[13]),\";\", #11              \n","                trataNumero(x[14]),\";\", #12              \n","                trataNumero(x[15]),\";\", #13\n","                trataNumero(x[16]),\";\", #14\n","                trataNumero(x[17]),\";\", #15\n","                trataNumero(x[18]),\";\", #16\n","                trataNumero(x[19])      #17\n","                ) \n","          conta = conta + 1\n","      print(\"Documentos perturbados:\", conta)    "]},{"cell_type":"markdown","metadata":{"id":"ARd5Salbck5s"},"source":["#### Funções de gráfico das diferenças de um DO e suas perturbações classificadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVcQkZ25Dd05"},"outputs":[],"source":["# Import das bibliotecas.\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","TAMANHO_FONTE = 18\n","matplotlib.rc('font', size=TAMANHO_FONTE)          # Controla o tamanho do do texto default\n","matplotlib.rc('axes', titlesize=TAMANHO_FONTE)     # Tamanho da fonte do eixo do título\n","matplotlib.rc('axes', labelsize=TAMANHO_FONTE)     # Tamanho da fonte dos rótulos do eixo x e y\n","matplotlib.rc('xtick', labelsize=TAMANHO_FONTE)    # Tamanho da fonte das marcações do eixo y\n","matplotlib.rc('ytick', labelsize=TAMANHO_FONTE)    # Tamanho da fonte dos marcações do eixo x\n","matplotlib.rc('legend', fontsize=TAMANHO_FONTE)    # Tamanho da fonte da legenda\n","matplotlib.rc('figure', titlesize=TAMANHO_FONTE+2) # Tamanho da fonte do título da figura\n","\n","# Aumenta o tamanho da plotagem e o tamanho da fonte.\n","plt.rcParams['figure.figsize'] = (15,8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYNEIminGUYx"},"outputs":[],"source":["# Import da biblioteca\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import StrMethodFormatter\n","\n","def graficoMedidaPerturbado(lista_perturbado_classificado_medida,\n","                            _id_documento):\n","  # Dados do gráfico\n","  lista = [x for x in lista_perturbado_classificado_medida if x[0].startswith(str(_id_documento)+\"_pert_\")]\n","\n","  # Recupera o documento original\n","  documentos_original = lista_documentos_originais_indexado.loc[_id_documento]\n","  print(\"DO:\",documentos_original[1])\n","\n","  lista_ranking = [x[14]*100 for x in lista]\n","  lista_dcos = [x[15]*50 for x in lista]\n","  lista_deuc = [x[16]*100 for x in lista]\n","  lista_dman = [x[17]*100 for x in lista]\n","  lista_pos_igual = [x[18]*100 for x in lista]\n","  lista_classe = [x[7]*100 for x in lista]\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x1 = list(range(1, len(lista_ranking)+1))\n","  eixo_y1 = lista_ranking\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x2 = list(range(1, len(lista_dcos)+1))\n","  eixo_y2 = lista_dcos\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x3 = list(range(1, len(lista_deuc)+1))\n","  eixo_y3 = lista_deuc\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x4 = list(range(1, len(lista_dman)+1))\n","  eixo_y4 = lista_dman\n","    \n","  # Eixo x e y de Pertubado\n","  eixo_x5 = list(range(1, len(lista_pos_igual)+1))\n","  eixo_y5 = lista_pos_igual\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x6 = list(range(1, len(lista_classe)+1))\n","  eixo_y6 = lista_classe\n","\n","  # Título do gráfico\n","  plt.title('Diferenças de 1 DO e suas ' + str(MELHOR_DOCUMENTOS_PERTURBADOS) + ' versões perturbadas\\nordenadas pelo ranking de plausabilidade')\n","  # Texto do eixo x\n","  plt.xlabel('pertDO')\n","  # Texto do eixo y\n","  plt.ylabel('Percentual')\n","\n","  # Aumenta o tamanho da plotagem e o tamanho da fonte.\n","  plt.rcParams['figure.figsize'] = (20,8)\n","\n","  # Insere os dados no gráfico\n","  plt.plot(eixo_x1, eixo_y1, 'b'+'-', marker=\"8\", label='Ranking plausabilidade')\n","  plt.plot(eixo_x2, eixo_y2, 'r'+'-', marker=\"s\", label='Diferença de coerência Ccos')\n","  plt.plot(eixo_x3, eixo_y3, 'y'+'-', marker=\"v\", label='Diferença de coerência Ceuc')\n","  plt.plot(eixo_x4, eixo_y4, 'g'+'-', marker=\"d\", label='Diferença de coerência Cman')\n","  plt.plot(eixo_x5, eixo_y5, 'm'+'-', marker=\"P\", label='Muda POS-Tagging')\n","  plt.plot(eixo_x6, eixo_y6, 'c'+'-', marker=\"*\", label='BERTimbau (0-DO, 1-pertDO)')\n","\n","  # Plota a linha do eixo y em 0\n","  plt.axhline(y=0, color='black', linestyle='-')\n","\n","  # Desenha linha da grade\n","  plt.grid(color='gray', linestyle='solid')\n","\n","  # Configura o eixo x e y para conter somente números inteiros\n","  plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n","  plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n","\n","  # Insere a legenda e por padrão usa o label de cada gráfico em colunas na parte inferior do gráfico\n","  plt.legend(title='Legenda:', loc=(0.0, -0.32), ncol=3)._legend_box.align='left'\n","\n","  # Valores para o eixo x\n","  x_ticks = list(range(1,MELHOR_DOCUMENTOS_PERTURBADOS+1))\n","\n","  # Adiciona os valores do x para o gráfico\n","  plt.xticks(ticks=x_ticks, labels=x_ticks)\n","\n","  # Mostra o gráfico\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"O8FMI6xS0aGC"},"source":["#### Funções de gráfico das diferenças medidas equações de um DO e suas perturbações classificadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_DvjLGk0acW"},"outputs":[],"source":["# Import da biblioteca\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import StrMethodFormatter\n","\n","def graficoMedidaEquacoesPerturbado(lista_perturbado_classificado_medida,\n","                            _id_documento,\n","                            legenda = ['Ranking plausabilidade',\n","                                       'Diferença de coerência Ccos',\n","                                       'Diferença de coerência Ceuc',\n","                                       'Diferença de coerência Cman',\n","                                       'Muda POS-Tagging',\n","                                       'BERTimbau (0-DO, 1-pertDO)']):\n","  # Dados do gráfico\n","  lista = [x for x in lista_perturbado_classificado_medida if x[0].startswith(str(_id_documento)+\"_pert_\")]\n","\n","  # Recupera o documento original\n","  documentos_original = lista_documentos_originais_indexado.loc[_id_documento]\n","  print(\"DO:\",documentos_original[1])\n","\n","  lista_ranking = [x[14]*100 for x in lista]\n","  lista_dcos = [x[15]*200 for x in lista]\n","  lista_deuc = [x[16]*300 for x in lista]\n","  lista_dman = [x[17]*300 for x in lista]\n","  lista_pos_igual = [x[18]*100 for x in lista]\n","  lista_classe = [x[7]*100 for x in lista]\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x1 = list(range(1, len(lista_ranking)+1))\n","  eixo_y1 = lista_ranking\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x2 = list(range(1, len(lista_dcos)+1))\n","  eixo_y2 = lista_dcos\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x3 = list(range(1, len(lista_deuc)+1))\n","  eixo_y3 = lista_deuc\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x4 = list(range(1, len(lista_dman)+1))\n","  eixo_y4 = lista_dman\n","    \n","  # Eixo x e y de Pertubado\n","  eixo_x5 = list(range(1, len(lista_pos_igual)+1))\n","  eixo_y5 = lista_pos_igual\n","\n","  # Eixo x e y de Pertubado\n","  eixo_x6 = list(range(1, len(lista_classe)+1))\n","  eixo_y6 = lista_classe\n","\n","  # Título do gráfico\n","  plt.title('Diferenças de 1 DO e suas ' + str(MELHOR_DOCUMENTOS_PERTURBADOS) + ' versões perturbadas\\nordenadas pelo ranking de plausabilidade')\n","  # Texto do eixo x\n","  plt.xlabel('pertDO')\n","  # Texto do eixo y\n","  plt.ylabel('Percentual')\n","\n","  # Aumenta o tamanho da plotagem e o tamanho da fonte.\n","  plt.rcParams['figure.figsize'] = (20,5)\n","\n","  # Insere os dados no gráfico\n","  plt.plot(eixo_x1, eixo_y1, 'b'+'-', marker=\"8\", label=legenda[0])\n","  plt.plot(eixo_x2, eixo_y2, 'r'+'-', marker=\"s\", label=legenda[1])\n","  plt.plot(eixo_x3, eixo_y3, 'y'+'-', marker=\"v\", label=legenda[2])\n","  plt.plot(eixo_x4, eixo_y4, 'g'+'-', marker=\"d\", label=legenda[3])\n","  plt.plot(eixo_x5, eixo_y5, 'm'+'-', marker=\"P\", label=legenda[4])\n","  plt.plot(eixo_x6, eixo_y6, 'c'+'-', marker=\"*\", label=legenda[5])\n","\n","  # Plota a linha do eixo y em 0\n","  plt.axhline(y=0, color='black', linestyle='-')\n","\n","  # Desenha linha da grade\n","  plt.grid(color='gray', linestyle='solid')\n","\n","  # Configura o eixo x e y para conter somente números inteiros\n","  plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n","  plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n","\n","  # Insere a legenda e por padrão usa o label de cada gráfico em colunas na parte inferior do gráfico\n","  plt.legend(title='Legenda:', loc=(0.0, -0.32), ncol=3)._legend_box.align='left'\n","\n","  # Valores para o eixo x\n","  x_ticks = list(range(1,MELHOR_DOCUMENTOS_PERTURBADOS+1))\n","\n","  # Adiciona os valores do x para o gráfico\n","  plt.xticks(ticks=x_ticks, labels=x_ticks)\n","\n","  # Mostra o gráfico\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"unO6OOd8yUCI"},"source":["#### Gráfico das diferenças da equação CG de um DO e suas perturbações classificadas com filtros de palavras 0 - ALL\n","\n","Utiliza os parâmetros com melhor resultado do mensurador parar Np = 20."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sw3LJSX2ye6A"},"outputs":[],"source":["estrategia_medida = 0 # 0 - MEAN\n","filtro_palavra = 0    # 0 - ALL, 1 - CLEAN, 2 - REL\n","equacao_medida = 0    # 0 - CAW, 1 - CWP, 2 - CG\n","\n","# Medida base\n","medida = \"man\""]},{"cell_type":"markdown","metadata":{"id":"FAUIFoQ6z9-d"},"source":["##### Exemplo DO 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vwuVj22Oyh4e"},"outputs":[],"source":["id_documento = \"483b327d3f80408fa56ffa3e3778aabf\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUmZ2fcVK38j"},"outputs":[],"source":["visualizaMedidasEquacoes(id_documento,\n","                         medida = medida,\n","                         equacao_medida = equacao_medida,\n","                         estrategia_medida = estrategia_medida,\n","                         filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCvi0w05tLrX"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasEquacaoPerturbado(id_documento,\n","                                      equacao_medida = equacao_medida, \n","                                      estrategia_medida = estrategia_medida,\n","                                      filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIZrA3eStSLP"},"outputs":[],"source":["graficoMedidaEquacoesPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento,\n","                        legenda = ['Ranking plausabilidade',\n","                                   'Diferença de coerência CGcos',\n","                                   'Diferença de coerência CGeuc',\n","                                   'Diferença de coerência CGman',\n","                                   'Muda POS-Tagging',\n","                                   'BERTimbau (0-DO, 1-pertDO)'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ew-hfot0FEc"},"outputs":[],"source":["mostrarMedidasEquacaoCSV(lista_perturbado_classificado_medida1,\n","                         id_documento,\n","                         equacao_medida = equacao_medida)"]},{"cell_type":"markdown","metadata":{"id":"lHs0WfJp1ER1"},"source":["##### Exemplo DO 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gDrK8bSa1ER1"},"outputs":[],"source":["id_documento = \"559dc36ec1b448e1922a84a7bd14cb27\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-13O4I-fkPXv"},"outputs":[],"source":["visualizaMedidasEquacoes(id_documento,\n","                         medida = medida,\n","                         equacao_medida = equacao_medida,\n","                         estrategia_medida = estrategia_medida,\n","                         filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uy0vrKGa1ER1"},"outputs":[],"source":["lista_perturbado_classificado_medida2 = getListaMedidasEquacaoPerturbado(id_documento,\n","                                      equacao_medida = equacao_medida, \n","                                      estrategia_medida = estrategia_medida,\n","                                      filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxClOBEf1ER2"},"outputs":[],"source":["graficoMedidaEquacoesPerturbado(lista_perturbado_classificado_medida2,\n","                        id_documento,\n","                        legenda = ['Ranking plausabilidade',\n","                                       'Diferença de coerência CGcos',\n","                                       'Diferença de coerência CGeuc',\n","                                       'Diferença de coerência CGman',\n","                                       'Muda POS-Tagging',\n","                                       'BERTimbau (0-DO, 1-pertDO)'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TeXpsVTC0GgY"},"outputs":[],"source":["mostrarMedidasEquacaoCSV(lista_perturbado_classificado_medida1,\n","                         id_documento,\n","                         equacao_medida = equacao_medida,\n","                         )"]},{"cell_type":"markdown","metadata":{"id":"J4BMCRAf1NvO"},"source":["##### Exemplo DO 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nc2Z33HQ1NvO"},"outputs":[],"source":["id_documento = \"559dc36ec1b448e1922a84a7bd14cb27\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVEuyUPrkb78"},"outputs":[],"source":["visualizaMedidasEquacoes(id_documento,\n","                         medida = medida,\n","                         equacao_medida = equacao_medida,\n","                         estrategia_medida = estrategia_medida,\n","                         filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7OdZzSR1NvO"},"outputs":[],"source":["lista_perturbado_classificado_medida2 = getListaMedidasEquacaoPerturbado(id_documento,\n","                                      equacao_medida = equacao_medida, \n","                                      estrategia_medida = estrategia_medida,\n","                                      filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aj4JgqcT1NvP"},"outputs":[],"source":["graficoMedidaEquacoesPerturbado(lista_perturbado_classificado_medida2,\n","                        id_documento,\n","                        legenda = ['Ranking plausabilidade',\n","                                       'Diferença de coerência CGcos',\n","                                       'Diferença de coerência CGeuc',\n","                                       'Diferença de coerência CGman',\n","                                       'Muda POS-Tagging',\n","                                       'BERTimbau (0-DO, 1-pertDO)'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_MmX3kM0H9D"},"outputs":[],"source":["mostrarMedidasEquacaoCSV(lista_perturbado_classificado_medida1,\n","                         id_documento,\n","                         equacao_medida = equacao_medida,\n","                         )"]},{"cell_type":"markdown","metadata":{"id":"_pAlW0wdK0Ph"},"source":["##### Exemplo DO 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hskFHUA9Ky64"},"outputs":[],"source":["id_documento = \"3f8ee2355e1f4745a10f55a9cc41396f\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRrbQp0oK5GX"},"outputs":[],"source":["visualizaMedidasEquacoes(id_documento,\n","                         medida = medida,\n","                         equacao_medida = equacao_medida,\n","                         estrategia_medida = estrategia_medida,\n","                         filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mlsRBoXPK5GY"},"outputs":[],"source":["lista_perturbado_classificado_medida2 = getListaMedidasEquacaoPerturbado(id_documento,\n","                                      equacao_medida = equacao_medida, \n","                                      estrategia_medida = estrategia_medida,\n","                                      filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnQo8aSgK5GY"},"outputs":[],"source":["graficoMedidaEquacoesPerturbado(lista_perturbado_classificado_medida2,\n","                        id_documento,\n","                        legenda = ['Ranking plausabilidade',\n","                                       'Diferença de coerência CGcos',\n","                                       'Diferença de coerência CGeuc',\n","                                       'Diferença de coerência CGman',\n","                                       'Muda POS-Tagging',\n","                                       'BERTimbau (0-DO, 1-pertDO)'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUG100v9K5GY"},"outputs":[],"source":["mostrarMedidasEquacaoCSV(lista_perturbado_classificado_medida1,\n","                         id_documento,\n","                         equacao_medida = equacao_medida,\n","                         )"]},{"cell_type":"markdown","metadata":{"id":"onWBOVzrkXjM"},"source":["#### Gráfico das diferenças das palavras de um DO e suas versões perturbadas classificadas com equação CG e filtros de palavras = 0 - ALL e medida = \"euc\"\n","\n","Não calcula a medida de coerência do documento.\n","Compara as medidas das palavras com a medida CG( média do documento)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2oC6A7h9es8F"},"outputs":[],"source":["estrategia_medida = 0 # 0 - MEAN 1 - MAX\n","filtro_palavra = 0    # 0 - ALL, 1 - CLEAN, 2 - REL\n","\n","# Medida base\n","medida = \"euc\""]},{"cell_type":"markdown","metadata":{"id":"OBbuQPrCDd08"},"source":["##### Exemplo DO 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kugsBUaADd09"},"outputs":[],"source":["id_documento = \"483b327d3f80408fa56ffa3e3778aabf\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EEBpSg3Dd09"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grHvabVQdced"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hyN9uImZHi66"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkWFbyavgBdn"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"FuiM40N1Dd09"},"source":["##### Exemplo DO 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bttXNBAkDd09"},"outputs":[],"source":["id_documento = \"559dc36ec1b448e1922a84a7bd14cb27\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-jlwoB2fK0u"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvFhNzhkfK0u"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njRrfP-jfK0v"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5NAWEZghFpp"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"4hR7nrQqDd0-"},"source":["##### Exemplo DO 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FftrAn8UDd0-"},"outputs":[],"source":["id_documento = \"559dc36ec1b448e1922a84a7bd14cb27\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLVTUKyVfMVO"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKObViJTfMVO"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rN3t2iQQfMVO"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yj3pFOZGhGp0"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"KCaHGcYVDd0_"},"source":["##### Exemplo DO 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzFDC_Y1Dd0_"},"outputs":[],"source":["id_documento = \"3f8ee2355e1f4745a10f55a9cc41396f\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNP6_-bzfN1S"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CmWA_7IfN1S"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5zfH8iJfN1T"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87pxqgwqhI99"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"0fovEpaXbsQP"},"source":["#### Gráfico das diferenças das palavras de um DO e suas versões perturbadas classificadas com equação CG e filtros de palavras = 1 - CLEAN e medida = \"euc\"\n","\n","Não calcula a medida de coerência do documento.\n","Compara as medidas das palavras com a medida CG( média do documento)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YsydAbj0bsQP"},"outputs":[],"source":["estrategia_medida = 0 # 0 - MEAN 1 - MAX\n","filtro_palavra = 1    # 0 - ALL, 1 - CLEAN, 2 - REL\n","\n","# Medida base\n","medida = \"euc\""]},{"cell_type":"markdown","metadata":{"id":"HqZPlDeXbsQP"},"source":["##### Exemplo DO 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"li_jz6ZFbsQQ"},"outputs":[],"source":["id_documento = \"483b327d3f80408fa56ffa3e3778aabf\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCsP9lHjbsQQ"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6wXSNzzQbsQQ"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P2Cj9RHibsQQ"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cij0vcRLbsQQ"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"0mi7MxjtbsQR"},"source":["##### Exemplo DO 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2IXyCkDjbsQR"},"outputs":[],"source":["id_documento = \"559dc36ec1b448e1922a84a7bd14cb27\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fS8BLmfcbsQR"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HlmBwZtobsQS"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87rhrLTDbsQS"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16tM8uXCbsQS"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"DK39IF23bsQS"},"source":["##### Exemplo DO 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tk1gowsObsQS"},"outputs":[],"source":["id_documento = \"559dc36ec1b448e1922a84a7bd14cb27\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdH-p_OxbsQT"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91Vld8jObsQT"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JINJ4g38bsQT"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVVuQ85sbsQT"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"lH37T3cqbsQT"},"source":["##### Exemplo DO 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zL4mJSuSbsQT"},"outputs":[],"source":["id_documento = \"3f8ee2355e1f4745a10f55a9cc41396f\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJNdEqrUbsQT"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crVNzBEvbsQW"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-QfYy0XbsQW"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DmQrlJxGbsQX"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"neSlO-zNbyQ4"},"source":["#### Gráfico das diferenças das palavras de um DO e suas versões perturbadas classificadas com equação CG e filtros de palavras = 2 - REL e medida = \"euc\"\n","\n","Não calcula a medida de coerência do documento.\n","Compara as medidas das palavras com a medida CG( média do documento)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJ4Yb7B-byQ5"},"outputs":[],"source":["estrategia_medida = 0 # 0 - MEAN 1 - MAX\n","filtro_palavra = 2    # 0 - ALL, 1 - CLEAN, 2 - REL\n","\n","# Medida base\n","medida = \"euc\""]},{"cell_type":"markdown","metadata":{"id":"wKQ5aN9DbyQ5"},"source":["##### Exemplo DO 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lGkWGOFNbyQ5"},"outputs":[],"source":["id_documento = \"483b327d3f80408fa56ffa3e3778aabf\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SF3VGa8rbyQ5"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_Jek2rmbyQ6"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrwyQVG4byQ6"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rm6_W12nbyQ6"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"DRoFhcLPbyQ6"},"source":["##### Exemplo DO 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1ltnbTibyQ6"},"outputs":[],"source":["id_documento = \"559dc36ec1b448e1922a84a7bd14cb27\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSD6EpE0byQ6"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FHNiko7sbyQ7"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZ0Fzd7xbyQ7"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbMBKPYybyQ7"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"TVl3r3--byQ7"},"source":["##### Exemplo DO 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E3MI1wKTbyQ7"},"outputs":[],"source":["id_documento = \"559dc36ec1b448e1922a84a7bd14cb27\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgKiWxKwbyQ7"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34BfL0Q6byQ8"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnYYmLHXbyQ8"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6QcyJMtbyQ8"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"t4s4As0TbyQ8"},"source":["##### Exemplo DO 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dG6c0JmbyQ8"},"outputs":[],"source":["id_documento = \"3f8ee2355e1f4745a10f55a9cc41396f\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LgpIe6ThbyQ8"},"outputs":[],"source":["visualizaMedidasCG(id_documento,\n","                 medida = medida,\n","                 estrategia_medida = estrategia_medida,\n","                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjlGO9LtbyQ9"},"outputs":[],"source":["lista_perturbado_classificado_medida1 = getListaMedidasPerturbadoCG(id_documento,\n","                                                                 estrategia_medida = estrategia_medida,\n","                                                                 filtro_palavra = filtro_palavra)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbPfFzggbyQ9"},"outputs":[],"source":["graficoMedidaPerturbado(lista_perturbado_classificado_medida1,\n","                        id_documento)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUinjs6_byQ-"},"outputs":[],"source":["mostrarMedidasCSV(lista_perturbado_classificado_medida1,\n","                  id_documento)"]},{"cell_type":"markdown","metadata":{"id":"xebzxNPL2urI"},"source":["#### Gera a medida de coerência CG(2) de DO e suas versões perturbadas classificads e com filtro de palavras igual a REL(2) \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1i2X-WC2urI"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","\n","medida = 'euc'\n","equacao_medida = 2 # 0 - CAW, 1 - CWP, 2 - CG\n","estrategia_medida = 0 # 0 - MEAN 1 - MAX\n","filtro_palavra = 2    # 0 - ALL, 1 - CLEAN, 2 - REL\n","\n","lista_perturbado_classificado_medida = []\n","\n","conta_pertDO_correto = 0\n","conta_pertDO_incorreto = 0\n","conta_DO_correto = 0\n","conta_DO_incorreto = 0\n","\n","conta_melhor_DO_correto = 0\n","conta_melhor_pertDO_correto = 0\n","conta_melhor_DO_incorreto = 0\n","conta_melhor_pertDO_incorreto = 0\n","\n","classe_iguais_pertDO_correto = 0\n","classe_iguais_pertDO_incorreto = 0\n","\n","pertDO_igual_DO_correto = 0\n","pertDO_igual_DO_incorreto = 0\n","pertDO_diferente_DO_correto = 0\n","pertDO_diferente_DO_incorreto = 0\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha in lista_documentos_originais_bar:   \n","  # Limita a quantidade de dados a serem processados\n","  #if i \u003c 2:    \n","    # Recupera o id do documento original\n","    id_documento_original = linha['id']\n","    \n","    # print(\"id_documento_original:\",id_documento_original) \n","    # Localiza os dados do documento original\n","    documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","    # Recupera o documento Original\n","    #print(\"documento_original:\",documento_original)\n","    #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","    #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","    #print(\"documento_original_tokens:\",documento_original_tokens)\n","    #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","    #print(\"documento_original_pos:\",documento_original_pos)\n","    #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","    \n","    # Verifica se o documento original foi classificado corretamente    \n","    documento_id_original = id_documento_original in lista_retorno_classificado_corretamente_sem_repeticao_indexado.index\n","    #print(\"documento_id_original:\", documento_id_original)\n","\n","    # Recupera a classificação do original\n","    classe = \"\"\n","    # Se o documento original foi encontrado foi classificado corretamente    \n","    if documento_id_original == True:             \n","      documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","      #print(\"documento:\",documento)\n","      classe =  str(documento['classe'])\n","      conta_DO_correto = conta_DO_correto + 1\n","    else:\n","      classe = \"0\"\n","      conta_DO_incorreto = conta_DO_incorreto + 1\n","\n","    maior_ranking = 0\n","\n","    lista_perturbado_classificado = []\n","\n","    # Percorre os documentos perturbados e suas classificações a partir do original\n","    for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","      # Id do documento perturbado\n","      id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","      #id_perturbado = linha['id'] + 1\n","      #print(\"id_perturbado:\",id_perturbado)\n","\n","      # Localiza os dados do documento perturbado\n","      documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","      # Recupera o documento perturrbado\n","      #print(\"documento_perturbado:\",documento_perturbado)\n","      #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","      #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","      #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","      #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","      #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","      #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","      # Recupera a sentença mascarada e seus dados do documento perturbado\n","      index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","\n","      # Encontrar o índice da palavra mascarada\n","      index_wi = getIndicePalavraMascarada(sentenca_mascarada)       \n","      \n","      palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","      # print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","      token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos,token_predito)\n","      # print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","      cos_DO, euc_DO, man_DO = getMedidasCoerenciaDocumento(id_documento_original,\n","                                                              documento_original, \n","                                                              lista_sentenca_documento_original, \n","                                                              documento_original_tokens, \n","                                                              documento_original_pos,\n","                                                              equacao_medida = equacao_medida,\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","\n","        #print(\"     DO     :\", palavra_mascarada, \" - \", cos_DO, euc_DO, man_DO)\n","\n","      cos_pertDO, euc_pertDO, man_pertDO = getMedidasCoerenciaDocumento(id_perturbado,\n","                                                              documento_perturbado, \n","                                                              lista_sentenca_documento_perturbado, \n","                                                              documento_perturbado_tokens, \n","                                                              documento_perturbado_pos,\n","                                                              equacao_medida = equacao_medida,\n","                                                              estrategia_medida = estrategia_medida,\n","                                                              filtro_palavra = filtro_palavra)\n","\n","      # print(\"    pertDO :\", token_predito, \" - \", cos_pertDO, euc_pertDO, man_pertDO)\n","\n","      # Recupera o id documento perturbado se ele foi classificado corretamente\n","      documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]\n","      #print(\"documento_id_perturbado_correto:\",id_perturbado,documento_id_perturbado_correto)\n","            \n","      # Localiza a classificação do documento perturbado  \n","      classe = 1\n","      # Se foi encontrado foi classificado corretamente\n","      #if documento_id_perturbado_correto == True:\n","      if len(documento_id_perturbado_correto) != 0:\n","        classe = 0        \n","        documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","        conta_pertDO_correto = conta_pertDO_correto + 1\n","      else:\n","        # Recupera o id documento perturbado se ele foi classificado incorretamente        \n","        documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]\n","        \n","        # Se foi encontrado foi classificado incorretamente\n","        #if documento_id_perturbado_incorreto == True:\n","        if len(documento_id_perturbado_incorreto) != 0:\n","          conta_pertDO_incorreto = conta_pertDO_incorreto + 1\n","          #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","          documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","          #print(\"documento:\",documento)\n","      \n","      # Guarda o maior rankin do peso\n","      if j == 0:\n","        maior_ranking = peso_predito \n","      else:\n","        if peso_predito \u003e maior_ranking:\n","           maior_ranking = peso_predito \n","\n","      # Guarda os dados\n","      lista_perturbado_classificado.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                              str(documento['documento']),            #1\n","                                              palavra_mascarada,                      #2\n","                                              palavra_mascarada_classe,               #3                                   \n","                                              token_predito,                          #4\n","                                              token_predito_classe,                   #5\n","                                              peso_predito,                           #6\n","                                              classe,                                 #7\n","                                              cos_DO,                                 #8\n","                                              euc_DO,                                 #9\n","                                              man_DO,                                 #10\n","                                              cos_pertDO,                             #11\n","                                              euc_pertDO,                             #12\n","                                              man_pertDO,                             #13\n","                                              ])\n","    \n","    # Cosseno\n","    if medida == 'cos':\n","      indice_palavra_selecionada = 8 # índice palavra original selecionada\n","      indice_palavra_substituida = 11 # índice palavra substituída\n","    else:\n","      # Euclidiana\n","      if medida == 'euc':\n","        indice_palavra_selecionada = 9 # índice palavra original selecionada\n","        indice_palavra_substituida = 12 # índice palavra substituída\n","      else:\n","        # Manhatan\n","        if medida == 'man':\n","          indice_palavra_selecionada = 10 # índice palavra original selecionada\n","          indice_palavra_substituida = 13 # índice palavra substituída\n","\n","    # Calcula as medidas do documento perturbado    \n","    for i, x in enumerate(lista_perturbado_classificado):      \n","      # print(\"x:\",x)\n","      ranking_percentual = x[6] / maior_ranking\n","      # calcula as diferenças\n","      if x[8] != 0:\n","        dcos = (x[11]-x[8])/x[8] * 10\n","      else:\n","        dcos = x[11] * 10\n","      if x[9] != 0:\n","        deuc = (x[9]-x[12])/x[9]\n","      else:\n","        deuc = -x[12]\n","      if x[10] != 0:\n","        dman = (x[10]-x[13])/x[10]\n","      else:\n","        dman = -x[13]\n","\n","      # POS Tagging iguais entre selecionada e perturbada  \n","      pos_igual = 1\n","      if x[3] == x[5]:\n","        pos_igual = 0\n","        if x[7] == 0:\n","          classe_iguais_pertDO_correto = classe_iguais_pertDO_correto +  1\n","        else:\n","          classe_iguais_pertDO_incorreto = classe_iguais_pertDO_incorreto + 1\n","\n","      # Avalia a medida para o cosseno\n","      if medida == 'cos':\n","        # Similaridade do cosseno(busca a maior distância) da palavra original e modificada(substituta) com o documento\n","        if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos        \n","          # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","          if x[7] == 0:\n","            conta_melhor_DO_correto = conta_melhor_DO_correto + 1\n","          else:  \n","            conta_melhor_DO_incorreto = conta_melhor_DO_incorreto + 1      \n","        else:\n","          # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","          if x[7] == 0:\n","            conta_melhor_pertDO_correto = conta_melhor_pertDO_correto + 1\n","          else:  \n","            conta_melhor_pertDO_incorreto = conta_melhor_pertDO_incorreto + 1      \n","      else:\n","        # distância Euclidiana(busca a menor distância) da palavra original e modificada(substituta) com o documento\n","        if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man        \n","            # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","            if x[7] == 0:\n","              conta_melhor_DO_correto = conta_melhor_DO_correto + 1\n","            else:  \n","              conta_melhor_DO_incorreto = conta_melhor_DO_incorreto + 1      \n","        else:\n","            # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","            if x[7] == 0:\n","              conta_melhor_pertDO_correto = conta_melhor_pertDO_correto + 1\n","            else:  \n","              conta_melhor_pertDO_incorreto = conta_melhor_pertDO_incorreto + 1\n","          \n","      # Verifica se as palavras são iguais\n","      palavra_igual = 0\n","      if x[2] == x[4]:\n","        palavra_igual = 1        \n","        # Classificados como incoerente\n","        if x[7] == 0:\n","          pertDO_igual_DO_correto = pertDO_igual_DO_correto + 1\n","        else:\n","          pertDO_igual_DO_incorreto = pertDO_igual_DO_incorreto + 1\n","      # Palavras diferentes\n","      else:        \n","        # Classificados como incoerente\n","        if x[7] == 0:\n","          pertDO_diferente_DO_correto = pertDO_diferente_DO_correto + 1\n","        else:\n","          pertDO_diferente_DO_incorreto = pertDO_diferente_DO_incorreto + 1\n","\n","      lista_perturbado_classificado_medida.append([x[0],\n","                                                   x[1],\n","                                                   x[2],\n","                                                   x[3],\n","                                                   x[4],\n","                                                   x[5],\n","                                                   x[6],\n","                                                   x[7],\n","                                                   x[8],\n","                                                   x[9],\n","                                                   x[10],\n","                                                   x[11],\n","                                                   x[12],\n","                                                   x[13],\n","                                                   ranking_percentual,  #14\n","                                                   dcos,                #15\n","                                                   deuc,                #16\n","                                                   dman,                #17\n","                                                   pos_igual,           #18\n","                                                   palavra_igual])      #19\n","\n","# Ordena a lista das medidas pela plausabilidade\n","lista_perturbado_classificado_medida = sorted(lista_perturbado_classificado_medida, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","print(\"TERMINADO MEDIDAS PERTURBADOS:\", len(lista_perturbado_classificado_medida))"]},{"cell_type":"markdown","metadata":{"id":"j3iwhR1S2urK"},"source":["##### Geral"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSIyEmRL2urK"},"outputs":[],"source":["total_DO = conta_DO_correto + conta_DO_incorreto\n","total_pertDO = conta_pertDO_correto + conta_pertDO_incorreto\n","\n","print(\"Documentos Originais:\", total_DO)\n","print(\"Documentos originais classificados corretamente com repetição   :\", len(lista_retorno_DO_correto))\n","print(\"Documentos originais classificados incorretamente com repetição :\", len(lista_retorno_DO_incorreto))\n","\n","print(\"Documentos originais classificados corretamente sem repetição   :\", conta_DO_correto)\n","print(\"Documentos originais classificados incorretamente sem repetição :\", conta_DO_incorreto)\n","print()\n","print(\"Documentos perturbados:\", total_pertDO)\n","print(\"Documentos perturbados classificados corretamente               :\", conta_pertDO_correto)\n","print(\"Documentos perturbados classificados incorretamente             :\", conta_pertDO_incorreto)\n"]},{"cell_type":"markdown","metadata":{"id":"OWhYiS_W2urK"},"source":["##### Classe morfossintática"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YfyN-veI2urK"},"outputs":[],"source":["total_pertDO = conta_pertDO_correto + conta_pertDO_incorreto\n","total_classes_iguais = classe_iguais_pertDO_correto + classe_iguais_pertDO_incorreto\n","\n","print(\"Documentos perturbados:\", total_pertDO)\n","print(\"     classe da palavra perturbada é igual a classe da palavra em DO      :\", total_classes_iguais, \" / {0:.2%} do total\".format(total_classes_iguais/total_pertDO))\n","print(\"     classe da palavra perturbada é diferente da classe da palavra em DO :\", total_pertDO-total_classes_iguais, \" / {0:.2%} do total\".format((total_pertDO-total_classes_iguais)/total_pertDO))\n","print()\n","print(\"Documentos perturbados(pertDO) classificados corretamente                :\", conta_pertDO_correto, \" / {0:.2%} do total\".format( conta_pertDO_correto/total_pertDO))\n","\n","print(\"Quantidade de documentos perturbados classificados corretamente onde a \")\n","print(\"     classe da palavra perturbada é igual a classe da palavra em DO      :\", classe_iguais_pertDO_correto, \" / {0:.2%} do total\".format( classe_iguais_pertDO_correto/conta_pertDO_correto))\n","print(\"Quantidade de documentos perturbados classificados corretamente onde a \")\n","print(\"     classe da palavra perturbada é diferente a classe da palavra em DO  :\", conta_pertDO_correto-classe_iguais_pertDO_correto, \" / {0:.2%} do total\".format((conta_pertDO_correto-classe_iguais_pertDO_correto)/conta_pertDO_correto))\n","print()\n","print(\"Documentos perturbados(pertDO) classificados incorretamente              :\", conta_pertDO_incorreto, \" / {0:.2%} do total\".format(conta_pertDO_incorreto/total_pertDO))\n","print(\"Quantidade de documentos perturbados classificados incorretamente onde a \")\n","if conta_pertDO_incorreto != 0:\n","  percentual = classe_iguais_pertDO_incorreto/conta_pertDO_incorreto\n","else:\n","  percentual = 0\n","print(\"     classe da palavra perturbada é igual a classe da palavra em DO      :\", classe_iguais_pertDO_incorreto, \" / {0:.2%} do total\".format(percentual))\n","print(\"Quantidade de documentos perturbados classificados incorretamente onde a \")\n","if conta_pertDO_incorreto != 0:\n","  percentual = (conta_pertDO_incorreto-classe_iguais_pertDO_incorreto)/conta_pertDO_incorreto\n","else:\n","  percentual = 0\n","print(\"     classe da palavra perturbada é diferente a classe da palavra em DO  :\", conta_pertDO_incorreto-classe_iguais_pertDO_incorreto, \" / {0:.2%} do total\".format(percentual))"]},{"cell_type":"markdown","metadata":{"id":"dGzGXtXB2urL"},"source":["##### Medida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOA1E9lI2urL"},"outputs":[],"source":["total_pertDO = conta_pertDO_correto + conta_pertDO_incorreto\n","\n","print(\"Documentos perturbados:\", total_pertDO)\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","print(\"   maior que a medida da palavra selecionada comparada comparada os embeddings do DO :\", (conta_melhor_DO_correto+conta_melhor_DO_incorreto), \" / {0:.2%} do total\".format((conta_melhor_DO_correto+conta_melhor_DO_incorreto)/total_pertDO))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","print(\"   menor que a medida da palavra selecionada comparada comparada os embeddings do DO :\", total_pertDO-(conta_melhor_DO_correto+conta_melhor_DO_incorreto), \" / {0:.2%} do total\".format((total_pertDO-(conta_melhor_DO_correto+conta_melhor_DO_incorreto))/total_pertDO))\n","print()\n","print(\"Documentos perturbados(pertDO) classificados corretamente                            :\", conta_pertDO_correto, \" / {0:.2%} do total\".format(conta_pertDO_correto/total_pertDO))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","print(\"   maior que a medida da palavra selecionada comparada comparada os embeddings do DO :\", conta_melhor_DO_correto, \" / {0:.2%} do total\".format(conta_melhor_DO_correto/conta_pertDO_correto))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","print(\"   menor que a medida da palavra selecionada comparada com os embeddings de DO       :\", conta_melhor_pertDO_correto, \" / {0:.2%} do total\".format(conta_melhor_pertDO_correto/conta_pertDO_correto))\n","\n","print()\n","print(\"Documentos perturbados(pertDO) classificados incorretamente                          :\", conta_pertDO_incorreto, \" / {0:.2%} do total\".format(conta_pertDO_incorreto/total_pertDO))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","if conta_pertDO_incorreto != 0:\n","  percentual = conta_melhor_DO_incorreto/conta_pertDO_incorreto\n","else:\n","  percentual = 0\n","print(\"   maior que a medida da palavra selecionada comparada comparada os embeddings de DO :\", conta_melhor_DO_incorreto, \" / {0:.2%} do total\".format(percentual))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","if conta_pertDO_incorreto != 0:\n","  percentual = conta_melhor_pertDO_incorreto/conta_pertDO_incorreto\n","else:\n","  percentual = 0\n","print(\"   menor que a medida da palavra selecionada comparada com os embeddings de DO    :\", conta_melhor_pertDO_incorreto, \" / {0:.2%} do total\".format(percentual))"]},{"cell_type":"markdown","metadata":{"id":"W7f1n4MK2urL"},"source":["##### Palavra selecionada igual a perturbada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8a0td3j2urL"},"outputs":[],"source":["total_pertDO = conta_pertDO_correto + conta_pertDO_incorreto\n","\n","print(\"Documentos perturbados:\", total_pertDO)\n","print(\"     palavra perturbada é igual a palavra selecionada em DO            :\", (pertDO_igual_DO_correto + pertDO_igual_DO_incorreto), \" / {0:.2%} do total\".format((pertDO_igual_DO_correto + pertDO_igual_DO_incorreto)/total_pertDO))\n","if (pertDO_igual_DO_correto + pertDO_igual_DO_incorreto) != 0:\n","  print(\"       Classificado corretamente(menos coerente)                         :\", pertDO_igual_DO_correto , \" / {0:.2%} do total\".format((pertDO_igual_DO_correto)/(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto)))\n","else:\n","  print(\"       Classificado corretamente(menos coerente)                         :\", pertDO_igual_DO_correto , \" / 0.00% do total\")  \n","if (pertDO_igual_DO_correto + pertDO_igual_DO_incorreto) != 0:\n","  print(\"       Classificado incorretamente(coerente)                             :\", pertDO_igual_DO_incorreto, \" / {0:.2%} do total\".format((pertDO_igual_DO_incorreto)/(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto)))\n","else:  \n","  print(\"       Classificado incorretamente(coerente)                             :\", pertDO_igual_DO_incorreto, \" / 0.00% do total\")\n","print(\"     palavra perturbada é diferente da palavra selecionada em DO       :\", total_pertDO-(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto), \" / {0:.2%} do total\".format((total_pertDO-(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto))/total_pertDO))\n","print(\"       Classificado corretamente(menos coerente)                         :\", pertDO_diferente_DO_correto , \" / {0:.2%} do total\".format((pertDO_diferente_DO_correto)/(total_pertDO-(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto))))\n","print(\"       Classificado incorretamente(coerente)                             :\", pertDO_diferente_DO_incorreto, \" / {0:.2%} do total\".format((pertDO_diferente_DO_incorreto)/(total_pertDO-(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto))))\n","print()\n","print(\"Documentos perturbados(pertDO) classificados corretamente              :\", conta_pertDO_correto, \" / {0:.2%} do total\".format(conta_pertDO_correto/total_pertDO))\n","print(\"Quantidade de documentos perturbados classificados corretamente onde a \")\n","print(\"     palavra perturbada é igual a palavra selecionada em DO            :\", pertDO_igual_DO_correto, \" / {0:.2%} do total\".format((pertDO_igual_DO_correto)/conta_pertDO_correto))\n","print(\"Quantidade de documentos perturbados classificados corretamente onde a \")\n","print(\"     palavra perturbada é diferente a palavra selecionada em DO        :\", conta_pertDO_correto-pertDO_igual_DO_correto, \" / {0:.2%} do total\".format((conta_pertDO_correto-pertDO_igual_DO_correto)/conta_pertDO_correto))\n","\n","print()\n","print(\"Documentos perturbados(pertDO) classificados incorretamente            :\", conta_pertDO_incorreto, \" / {0:.2%} do total\".format(conta_pertDO_incorreto/total_pertDO))\n","print(\"Quantidade de documentos perturbados classificados incorretamente onde a \")\n","print(\"     palavra perturbada é igual da palavra em DO                       :\", pertDO_igual_DO_incorreto, \" / {0:.2%} do total\".format(pertDO_igual_DO_incorreto/conta_pertDO_incorreto))\n","print(\"Quantidade de documentos perturbados classificados incorretamente onde a \")\n","print(\"     palavra perturbada é diferente da palavra selecionada em DO       :\", conta_pertDO_incorreto-pertDO_igual_DO_incorreto, \" / {0:.2%} do total\".format((conta_pertDO_incorreto-pertDO_igual_DO_incorreto)/conta_pertDO_incorreto))"]},{"cell_type":"markdown","metadata":{"id":"L5Y2CQvF6bVA"},"source":["#### Gera a medida de distância Euclidina(euc) da palavra perturbada e a média dos embeddings do seu documento(CG) classificado com filtro de palavras igual a 0(ALL) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I40PeMZZDd1N"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","\n","medida = 'euc'\n","\n","lista_perturbado_classificado_medida = []\n","\n","conta_pertDO_correto = 0\n","conta_pertDO_incorreto = 0\n","conta_DO_correto = 0\n","conta_DO_incorreto = 0\n","\n","conta_melhor_DO_correto = 0\n","conta_melhor_pertDO_correto = 0\n","conta_melhor_DO_incorreto = 0\n","conta_melhor_pertDO_incorreto = 0\n","\n","classe_iguais_pertDO_correto = 0\n","classe_iguais_pertDO_incorreto = 0\n","\n","pertDO_igual_DO_correto = 0\n","pertDO_igual_DO_incorreto = 0\n","pertDO_diferente_DO_correto = 0\n","pertDO_diferente_DO_incorreto = 0\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha in lista_documentos_originais_bar:   \n","  # Limita a quantidade de dados a serem processados\n","  #if i \u003c 2:    \n","    # Recupera o id do documento original\n","    id_documento_original = linha['id']\n","    \n","    # print(\"id_documento_original:\",id_documento_original) \n","    # Localiza os dados do documento original\n","    documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","    # Recupera o documento Original\n","    #print(\"documento_original:\",documento_original)\n","    #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","    #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","    #print(\"documento_original_tokens:\",documento_original_tokens)\n","    #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","    #print(\"documento_original_pos:\",documento_original_pos)\n","    #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","    \n","    # Verifica se o documento original foi classificado corretamente    \n","    documento_id_original = id_documento_original in lista_retorno_classificado_corretamente_sem_repeticao_indexado.index\n","    #print(\"documento_id_original:\", documento_id_original)\n","\n","    # Recupera a classificação do original\n","    classe = \"\"\n","    # Se o documento original foi encontrado foi classificado corretamente    \n","    if documento_id_original == True:             \n","      documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","      #print(\"documento:\",documento)\n","      classe =  str(documento['classe'])\n","      conta_DO_correto = conta_DO_correto + 1\n","    else:\n","      classe = \"0\"\n","      conta_DO_incorreto = conta_DO_incorreto + 1\n","\n","    maior_ranking = 0\n","\n","    lista_perturbado_classificado = []\n","\n","    # Percorre os documentos perturbados e suas classificações a partir do original\n","    for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","      # Id do documento perturbado\n","      id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","      #id_perturbado = linha['id'] + 1\n","      #print(\"id_perturbado:\",id_perturbado)\n","\n","      # Localiza os dados do documento perturbado\n","      documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","      # Recupera o documento perturrbado\n","      #print(\"documento_perturbado:\",documento_perturbado)\n","      #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","      #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","      #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","      #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","      #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","      #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","      # Recupera a sentença mascarada e seus dados do documento perturbado\n","      index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","\n","      # Encontrar o índice da palavra mascarada\n","      index_wi = getIndicePalavraMascarada(sentenca_mascarada)       \n","      \n","      palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","      # print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","      token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos,token_predito)\n","      # print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","      cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO = getMedidasComparacaoPalavrasGlobal(id_documento_original,\n","                                                                                       index_sentenca, \n","                                                                                       index_wi,\n","                                                                                       0, #Estratégia 0 = MEAN\n","                                                                                       0) #Filtro palavra 0 = All\n","      #print(\"    Ctx DO     :\", palavra_mascarada, \" - \", cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO)\n","\n","      cos_ctxall_pertDO, euc_ctxall_pertDO, man_ctxall_pertDO = getMedidasComparacaoPalavrasGlobal(id_perturbado,\n","                                                                                       index_sentenca, \n","                                                                                       index_wi,\n","                                                                                       0, #Estratégia 0 = MEAN\n","                                                                                       0) #Filtro palavra 0 = All\n","      # print(\"    Ctx pertDO :\", token_predito, \" - \", cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO)\n","\n","      # Recupera o id documento perturbado se ele foi classificado corretamente\n","      documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]\n","      #print(\"documento_id_perturbado_correto:\",id_perturbado,documento_id_perturbado_correto)\n","            \n","      # Localiza a classificação do documento perturbado  \n","      classe = 1\n","      # Se foi encontrado foi classificado corretamente\n","      #if documento_id_perturbado_correto == True:\n","      if len(documento_id_perturbado_correto) != 0:\n","        classe = 0        \n","        documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","        conta_pertDO_correto = conta_pertDO_correto + 1\n","      else:\n","        # Recupera o id documento perturbado se ele foi classificado incorretamente        \n","        documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]\n","        \n","        # Se foi encontrado foi classificado incorretamente\n","        #if documento_id_perturbado_incorreto == True:\n","        if len(documento_id_perturbado_incorreto) != 0:\n","          conta_pertDO_incorreto = conta_pertDO_incorreto + 1\n","          #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","          documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","          #print(\"documento:\",documento)\n","      \n","      # Guarda o maior rankin do peso\n","      if j == 0:\n","        maior_ranking = peso_predito \n","      else:\n","        if peso_predito \u003e maior_ranking:\n","           maior_ranking = peso_predito \n","\n","      # Guarda os dados\n","      lista_perturbado_classificado.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                            str(documento['documento']),            #1\n","                                            palavra_mascarada,                      #2\n","                                            palavra_mascarada_classe,               #3                                   \n","                                            token_predito,                          #4\n","                                            token_predito_classe,                   #5\n","                                            peso_predito,                           #6\n","                                            classe,                                 #7\n","                                            cos_ctxall_DO,                          #8\n","                                            euc_ctxall_DO,                          #9\n","                                            man_ctxall_DO,                          #10\n","                                            cos_ctxall_pertDO,                      #11\n","                                            euc_ctxall_pertDO,                      #12\n","                                            man_ctxall_pertDO,                      #13\n","                                            ])\n","    \n","    # Cosseno\n","    if medida == 'cos':\n","      indice_palavra_selecionada = 8 # índice palavra original selecionada\n","      indice_palavra_substituida = 11 # índice palavra substituída\n","    else:\n","      # Euclidiana\n","      if medida == 'euc':\n","        indice_palavra_selecionada = 9 # índice palavra original selecionada\n","        indice_palavra_substituida = 12 # índice palavra substituída\n","      else:\n","        # Manhatan\n","        if medida == 'man':\n","          indice_palavra_selecionada = 10 # índice palavra original selecionada\n","          indice_palavra_substituida = 13 # índice palavra substituída\n","\n","    # Calcula as medidas do documento perturbado    \n","    for i, x in enumerate(lista_perturbado_classificado):      \n","      # print(\"x:\",x)\n","      ranking_percentual = x[6] / maior_ranking\n","      # calcula as diferenças\n","      if x[8] != 0:\n","        dcos = (x[11]-x[8])/x[8] * 10\n","      else:\n","        dcos = x[11] * 10\n","      if x[9] != 0:\n","        deuc = (x[9]-x[12])/x[9]\n","      else:\n","        deuc = -x[12]\n","      if x[10] != 0:\n","        dman = (x[10]-x[13])/x[10]\n","      else:\n","        dman = -x[13]\n","\n","      # POS Tagging iguais entre selecionada e perturbada  \n","      pos_igual = 1\n","      if x[3] == x[5]:\n","        pos_igual = 0\n","        if x[7] == 0:\n","          classe_iguais_pertDO_correto = classe_iguais_pertDO_correto +  1\n","        else:\n","          classe_iguais_pertDO_incorreto = classe_iguais_pertDO_incorreto + 1\n","\n","      # Avalia a medida para o cosseno\n","      if medida == 'cos':\n","        # Similaridade do cosseno(busca a maior distância) da palavra original e modificada(substituta) com o documento\n","        if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos        \n","          # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","          if x[7] == 0:\n","            conta_melhor_DO_correto = conta_melhor_DO_correto + 1\n","          else:  \n","            conta_melhor_DO_incorreto = conta_melhor_DO_incorreto + 1      \n","        else:\n","          # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","          if x[7] == 0:\n","            conta_melhor_pertDO_correto = conta_melhor_pertDO_correto + 1\n","          else:  \n","            conta_melhor_pertDO_incorreto = conta_melhor_pertDO_incorreto + 1      \n","      else:\n","        # distância euclidiana(busca a menor distância) da palavra original e modificada(substituta) com o documento\n","        if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man        \n","            # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento\n","            if x[7] == 0:\n","              conta_melhor_DO_correto = conta_melhor_DO_correto + 1\n","            else:  \n","              conta_melhor_DO_incorreto = conta_melhor_DO_incorreto + 1      \n","        else:\n","            # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","            if x[7] == 0:\n","              conta_melhor_pertDO_correto = conta_melhor_pertDO_correto + 1\n","            else:  \n","              conta_melhor_pertDO_incorreto = conta_melhor_pertDO_incorreto + 1\n","          \n","      # Verifica se as palavras são iguais\n","      palavra_igual = 0\n","      if x[2] == x[4]:\n","        palavra_igual = 1        \n","        # Classificados como incoerente\n","        if x[7] == 0:\n","          pertDO_igual_DO_correto = pertDO_igual_DO_correto + 1\n","        else:\n","          pertDO_igual_DO_incorreto = pertDO_igual_DO_incorreto + 1\n","      # Palavras diferentes\n","      else:        \n","        # Classificados como incoerente\n","        if x[7] == 0:\n","          pertDO_diferente_DO_correto = pertDO_diferente_DO_correto + 1\n","        else:\n","          pertDO_diferente_DO_incorreto = pertDO_diferente_DO_incorreto + 1\n","\n","      lista_perturbado_classificado_medida.append([x[0],\n","                                                   x[1],\n","                                                   x[2],\n","                                                   x[3],\n","                                                   x[4],\n","                                                   x[5],\n","                                                   x[6],\n","                                                   x[7],\n","                                                   x[8],\n","                                                   x[9],\n","                                                   x[10],\n","                                                   x[11],\n","                                                   x[12],\n","                                                   x[13],\n","                                                   ranking_percentual,  #14\n","                                                   dcos,                #15\n","                                                   deuc,                #16\n","                                                   dman,                #17\n","                                                   pos_igual,           #18\n","                                                   palavra_igual])      #19\n","\n","# Ordena a lista das medidas pela plausabilidade\n","lista_perturbado_classificado_medida = sorted(lista_perturbado_classificado_medida, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","print(\"TERMINADO MEDIDAS PERTURBADOS:\", len(lista_perturbado_classificado_medida))"]},{"cell_type":"markdown","metadata":{"id":"jD3TPqu9Dd1N"},"source":["##### Geral"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nwi_-UxjDd1N"},"outputs":[],"source":["total_DO = conta_DO_correto + conta_DO_incorreto\n","total_pertDO = conta_pertDO_correto + conta_pertDO_incorreto\n","\n","print(\"Documentos Originais:\", total_DO)\n","print(\"Documentos originais classificados corretamente com repetição   :\", len(lista_retorno_DO_correto))\n","print(\"Documentos originais classificados incorretamente com repetição :\", len(lista_retorno_DO_incorreto))\n","\n","print(\"Documentos originais classificados corretamente sem repetição   :\", conta_DO_correto)\n","print(\"Documentos originais classificados incorretamente sem repetição :\", conta_DO_incorreto)\n","print()\n","print(\"Documentos perturbados:\", total_pertDO)\n","print(\"Documentos perturbados classificados corretamente               :\", conta_pertDO_correto)\n","print(\"Documentos perturbados classificados incorretamente             :\", conta_pertDO_incorreto)\n"]},{"cell_type":"markdown","metadata":{"id":"h86wURkMDd1O"},"source":["##### Classe morfossintática"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAl58ZDADd1O"},"outputs":[],"source":["total_pertDO = conta_pertDO_correto + conta_pertDO_incorreto\n","total_classes_iguais = classe_iguais_pertDO_correto + classe_iguais_pertDO_incorreto\n","\n","print(\"Documentos perturbados:\", total_pertDO)\n","print(\"     classe da palavra perturbada é igual a classe da palavra em DO      :\", total_classes_iguais, \" / {0:.2%} do total\".format(total_classes_iguais/total_pertDO))\n","print(\"     classe da palavra perturbada é diferente da classe da palavra em DO :\", total_pertDO-total_classes_iguais, \" / {0:.2%} do total\".format((total_pertDO-total_classes_iguais)/total_pertDO))\n","print()\n","print(\"Documentos perturbados(pertDO) classificados corretamente                :\", conta_pertDO_correto, \" / {0:.2%} do total\".format( conta_pertDO_correto/total_pertDO))\n","\n","print(\"Quantidade de documentos perturbados classificados corretamente onde a \")\n","print(\"     classe da palavra perturbada é igual a classe da palavra em DO      :\", classe_iguais_pertDO_correto, \" / {0:.2%} do total\".format( classe_iguais_pertDO_correto/conta_pertDO_correto))\n","print(\"Quantidade de documentos perturbados classificados corretamente onde a \")\n","print(\"     classe da palavra perturbada é diferente a classe da palavra em DO  :\", conta_pertDO_correto-classe_iguais_pertDO_correto, \" / {0:.2%} do total\".format((conta_pertDO_correto-classe_iguais_pertDO_correto)/conta_pertDO_correto))\n","print()\n","print(\"Documentos perturbados(pertDO) classificados incorretamente              :\", conta_pertDO_incorreto, \" / {0:.2%} do total\".format(conta_pertDO_incorreto/total_pertDO))\n","print(\"Quantidade de documentos perturbados classificados incorretamente onde a \")\n","if conta_pertDO_incorreto != 0:\n","  percentual = classe_iguais_pertDO_incorreto/conta_pertDO_incorreto\n","else:\n","  percentual = 0\n","print(\"     classe da palavra perturbada é igual a classe da palavra em DO      :\", classe_iguais_pertDO_incorreto, \" / {0:.2%} do total\".format(percentual))\n","print(\"Quantidade de documentos perturbados classificados incorretamente onde a \")\n","if conta_pertDO_incorreto != 0:\n","  percentual = (conta_pertDO_incorreto-classe_iguais_pertDO_incorreto)/conta_pertDO_incorreto\n","else:\n","  percentual = 0\n","print(\"     classe da palavra perturbada é diferente a classe da palavra em DO  :\", conta_pertDO_incorreto-classe_iguais_pertDO_incorreto, \" / {0:.2%} do total\".format(percentual))"]},{"cell_type":"markdown","metadata":{"id":"cYBRWj7IDd1O"},"source":["##### Medida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Y7Mgu-mDd1O"},"outputs":[],"source":["total_pertDO = conta_pertDO_correto + conta_pertDO_incorreto\n","\n","print(\"Documentos perturbados:\", total_pertDO)\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","print(\"   maior que a medida da palavra selecionada comparada comparada os embeddings do DO :\", (conta_melhor_DO_correto+conta_melhor_DO_incorreto), \" / {0:.2%} do total\".format((conta_melhor_DO_correto+conta_melhor_DO_incorreto)/total_pertDO))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","print(\"   menor que a medida da palavra selecionada comparada comparada os embeddings do DO :\", total_pertDO-(conta_melhor_DO_correto+conta_melhor_DO_incorreto), \" / {0:.2%} do total\".format((total_pertDO-(conta_melhor_DO_correto+conta_melhor_DO_incorreto))/total_pertDO))\n","print()\n","print(\"Documentos perturbados(pertDO) classificados corretamente                            :\", conta_pertDO_correto, \" / {0:.2%} do total\".format(conta_pertDO_correto/total_pertDO))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","print(\"   maior que a medida da palavra selecionada comparada comparada os embeddings do DO :\", conta_melhor_DO_correto, \" / {0:.2%} do total\".format(conta_melhor_DO_correto/conta_pertDO_correto))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","print(\"   menor que a medida da palavra selecionada comparada com os embeddings de DO       :\", conta_melhor_pertDO_correto, \" / {0:.2%} do total\".format(conta_melhor_pertDO_correto/conta_pertDO_correto))\n","\n","print()\n","print(\"Documentos perturbados(pertDO) classificados incorretamente                          :\", conta_pertDO_incorreto, \" / {0:.2%} do total\".format(conta_pertDO_incorreto/total_pertDO))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","if conta_pertDO_incorreto != 0:\n","  percentual = conta_melhor_DO_incorreto/conta_pertDO_incorreto\n","else:\n","  percentual = 0\n","print(\"   maior que a medida da palavra selecionada comparada comparada os embeddings de DO :\", conta_melhor_DO_incorreto, \" / {0:.2%} do total\".format(percentual))\n","print(\"A distância Euclidiana dos embeddings da palavra que gera a perturbação comparada comparada com os embeddings de pertDO é\")\n","if conta_pertDO_incorreto != 0:\n","  percentual = conta_melhor_pertDO_incorreto/conta_pertDO_incorreto\n","else:\n","  percentual = 0\n","print(\"   menor que a medida da palavra selecionada comparada com os embeddings de DO    :\", conta_melhor_pertDO_incorreto, \" / {0:.2%} do total\".format(percentual))"]},{"cell_type":"markdown","metadata":{"id":"iz8XQe-TDd1O"},"source":["##### Palavra selecionada igual a perturbada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9L9mM2kDd1O"},"outputs":[],"source":["total_pertDO = conta_pertDO_correto + conta_pertDO_incorreto\n","\n","print(\"Documentos perturbados:\", total_pertDO)\n","print(\"     palavra perturbada é igual a palavra selecionada em DO            :\", (pertDO_igual_DO_correto + pertDO_igual_DO_incorreto), \" / {0:.2%} do total\".format((pertDO_igual_DO_correto + pertDO_igual_DO_incorreto)/total_pertDO))\n","if (pertDO_igual_DO_correto + pertDO_igual_DO_incorreto) != 0:\n","  print(\"       Classificado corretamente(menos coerente)                         :\", pertDO_igual_DO_correto , \" / {0:.2%} do total\".format((pertDO_igual_DO_correto)/(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto)))\n","else:\n","  print(\"       Classificado corretamente(menos coerente)                         :\", pertDO_igual_DO_correto , \" / 0.00% do total\")  \n","if (pertDO_igual_DO_correto + pertDO_igual_DO_incorreto) != 0:\n","  print(\"       Classificado incorretamente(coerente)                             :\", pertDO_igual_DO_incorreto, \" / {0:.2%} do total\".format((pertDO_igual_DO_incorreto)/(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto)))\n","else:  \n","  print(\"       Classificado incorretamente(coerente)                             :\", pertDO_igual_DO_incorreto, \" / 0.00% do total\")\n","print(\"     palavra perturbada é diferente da palavra selecionada em DO       :\", total_pertDO-(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto), \" / {0:.2%} do total\".format((total_pertDO-(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto))/total_pertDO))\n","print(\"       Classificado corretamente(menos coerente)                         :\", pertDO_diferente_DO_correto , \" / {0:.2%} do total\".format((pertDO_diferente_DO_correto)/(total_pertDO-(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto))))\n","print(\"       Classificado incorretamente(coerente)                             :\", pertDO_diferente_DO_incorreto, \" / {0:.2%} do total\".format((pertDO_diferente_DO_incorreto)/(total_pertDO-(pertDO_igual_DO_correto + pertDO_igual_DO_incorreto))))\n","print()\n","print(\"Documentos perturbados(pertDO) classificados corretamente              :\", conta_pertDO_correto, \" / {0:.2%} do total\".format(conta_pertDO_correto/total_pertDO))\n","print(\"Quantidade de documentos perturbados classificados corretamente onde a \")\n","print(\"     palavra perturbada é igual a palavra selecionada em DO            :\", pertDO_igual_DO_correto, \" / {0:.2%} do total\".format((pertDO_igual_DO_correto)/conta_pertDO_correto))\n","print(\"Quantidade de documentos perturbados classificados corretamente onde a \")\n","print(\"     palavra perturbada é diferente a palavra selecionada em DO        :\", conta_pertDO_correto-pertDO_igual_DO_correto, \" / {0:.2%} do total\".format((conta_pertDO_correto-pertDO_igual_DO_correto)/conta_pertDO_correto))\n","\n","print()\n","print(\"Documentos perturbados(pertDO) classificados incorretamente            :\", conta_pertDO_incorreto, \" / {0:.2%} do total\".format(conta_pertDO_incorreto/total_pertDO))\n","print(\"Quantidade de documentos perturbados classificados incorretamente onde a \")\n","print(\"     palavra perturbada é igual da palavra em DO                       :\", pertDO_igual_DO_incorreto, \" / {0:.2%} do total\".format(pertDO_igual_DO_incorreto/conta_pertDO_incorreto))\n","print(\"Quantidade de documentos perturbados classificados incorretamente onde a \")\n","print(\"     palavra perturbada é diferente da palavra selecionada em DO       :\", conta_pertDO_incorreto-pertDO_igual_DO_incorreto, \" / {0:.2%} do total\".format((conta_pertDO_incorreto-pertDO_igual_DO_incorreto)/conta_pertDO_incorreto))"]},{"cell_type":"markdown","metadata":{"id":"ewOXnnHeDd1P"},"source":["#### Gráfico das medidas dos documentos perturbados classificados incorretamente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCYEOP2KDd1P"},"outputs":[],"source":["# Import da biblioteca\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import StrMethodFormatter\n","\n","# Dados do gráfico\n","lista = [x for x in lista_perturbado_classificado_medida if x[7] ==1]\n","lista = sorted(lista, key=lambda x: (x[6]), reverse=True)\n","\n","lista_ranking = [x[14]*100 for x in lista]\n","lista_dcos = [x[15]*50 for x in lista]\n","lista_deuc = [x[16]*100 for x in lista]\n","lista_dman = [x[17]*100 for x in lista]\n","lista_pos_igual = [x[18]*100 for x in lista]\n","listapertDOigualDO = [x[19]*100 for x in lista]\n","\n","# Eixo x e y de Pertubado\n","eixo_x1 = list(range(1, len(lista_ranking)+1))\n","eixo_y1 = lista_ranking\n","\n","# Eixo x e y de Pertubado\n","eixo_x2 = list(range(1, len(lista_dcos)+1))\n","eixo_y2 = lista_dcos\n","\n","# Eixo x e y de Pertubado\n","eixo_x3 = list(range(1, len(lista_deuc)+1))\n","eixo_y3 = lista_deuc\n","\n","# Eixo x e y de Pertubado\n","eixo_x4 = list(range(1, len(lista_dman)+1))\n","eixo_y4 = lista_dman\n","  \n","# Eixo x e y de Pertubado\n","eixo_x5 = list(range(1, len(lista_pos_igual)+1))\n","eixo_y5 = lista_pos_igual\n","\n","# Eixo x e y de Pertubado\n","eixo_x6 = list(range(1, len(listapertDOigualDO)+1))\n","eixo_y6 = listapertDOigualDO\n","\n","# Título do gráfico\n","plt.title('Diferenças entre pertDO e DO em que pertDO foi classificado como coerente \\nordenados pelo ranking de plausabilidade')\n","# Texto do eixo x\n","plt.xlabel('pertDO')\n","# Texto do eixo y\n","plt.ylabel('Percentual')\n","\n","# Aumenta o tamanho da plotagem e o tamanho da fonte.\n","plt.rcParams['figure.figsize'] = (15,8)\n","\n","# Insere os dados no gráfico\n","plt.plot(eixo_x1, eixo_y1, 'b'+'-', marker=\"8\", label='Ranking plausabilidade')\n","plt.plot(eixo_x2, eixo_y2, 'r'+'-', marker=\"s\", label='Diferença de coerência Ccos')\n","plt.plot(eixo_x3, eixo_y3, 'y'+'-', marker=\"v\", label='Diferença de coerência Ceuc')\n","plt.plot(eixo_x4, eixo_y4, 'g'+'-', marker=\"d\", label='Diferença de coerência Cman')\n","plt.plot(eixo_x5, eixo_y5, 'm'+'-', marker=\"P\", label='Muda POS-Tagging')\n","plt.plot(eixo_x6, eixo_y6, 'c'+'-', marker=\"P\", label='pertDO == DO')\n","\n","# Plota a linha do eixo y em 0\n","plt.axhline(y=0, color='black', linestyle='-')\n","\n","# Desenha linha da grade\n","plt.grid(color='gray', linestyle='solid')\n","\n","# Configura o eixo x e y para conter somente números inteiros\n","#plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n","#plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n","\n","# Insere a legenda e por padrão usa o label de cada gráfico em colunas na parte inferior do gráfico\n","plt.legend(title='Legenda:', loc=(0.0, -0.35), ncol=3)._legend_box.align='left'\n","\n","# Mostra o gráfico\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dEVR4vSiDd1P"},"source":["#### Mostra os dados das medidas das perturbações em CSV para documentos perturbados classificados incorretamente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mSptYZkJDd1P"},"outputs":[],"source":["# Cabeçalho dos documentos perturbados    \n","print(\"pertDO;\" +                                   #0\n","      \"classificacao(1-DO,0-pertDO);\" +   #1\n","      \"palavra selecionada;\" +                      #2\n","      \"classe palavra selecionada;\" +               #3\n","      \"cos(selecionada,DO);\" +                      #4\n","      \"euc(selecionada,DO);\" +                      #5\n","      \"man(selecionada,DO);\" +                      #6\n","      \"palavra perturbada;\" +                       #7\n","      \"classe palavra perturbada;\" +                #8\n","      \"cos(perturbada, pertDO);\" +                  #9\n","      \"euc(perturbada, pertDO);\" +                  #10\n","      \"man(perturbada, pertDO);\"+                   #11\n","      \"ranking de plausabilidade;\" +                #12\n","      \"dcos;\" +                                     #13\n","      \"deuc;\" +                                     #14\n","      \"dman;\" +                                     #15\n","      \"posigual;\" +                                 #16\n","      \"palavra_igual\")                              #17\n","\n","# Percorre os documentos perturbados e suas classificações a partir do original\n","for i, x in enumerate(lista_perturbado_classificado_medida):\n","  if x[7] == 1: \n","    print(x[1],\";\",               #0\n","          x[7],\";\",               #1\n","          x[2],\";\",               #2\n","          x[3],\";\",               #3\n","          trataNumero(x[8]),\";\",  #4\n","          trataNumero(x[9]),\";\",  #5\n","          trataNumero(x[10]),\";\", #6\n","          x[4],\";\",               #7\n","          x[5],\";\",               #8\n","          trataNumero(x[11]),\";\", #9\n","          trataNumero(x[12]),\";\", #10\n","          trataNumero(x[13]),\";\", #11              \n","          trataNumero(x[14]),\";\", #12              \n","          trataNumero(x[15]),\";\", #13\n","          trataNumero(x[16]),\";\", #14\n","          trataNumero(x[17]),\";\", #15\n","          trataNumero(x[18]),\";\", #16\n","          trataNumero(x[19])      #17\n","          )        "]},{"cell_type":"markdown","metadata":{"id":"zNpRpr2WDd1P"},"source":["#### Visualização das medidas dos documentos perturbados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLH7vP90Dd1P"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Documentos originais e perturados e suas classificações:\", len(lista_retorno_classificado_corretamente) + len(lista_retorno_classificado_incorretamente))\n","print(\"  Classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","print(\"  Classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","\n","medida =  'euc'\n","\n","exibir_dados = False\n","\n","lista_melhor_DO_correto = []\n","lista_melhor_pertDO_correto = []\n","lista_melhor_DO_incorreto = []\n","lista_melhor_pertDO_incorreto = []\n","      \n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha in lista_documentos_originais_bar:   \n","\n","  # Limita a quantidade de dados a serem exibidas\n","  if i \u003c 2:    \n","  # Procura um documento específico\n","  #if \"Em uma fila a operação de enfileirar ocorre em qual extremidade\" in linha['documento']:\n","\n","    # Recupera o id do documento original\n","    id_documento_original = linha['id']\n","\n","    # print(\"id_documento_original:\",id_documento_original) \n","    # Localiza os dados do documento original\n","    documento_original, lista_sentenca_documento_original, documento_original_tokens, documento_original_pos = getDadosDocumento(id_documento_original)\n","    # Recupera o documento Original\n","    #print(\"documento_original:\",documento_original)\n","    #print(\"lista_sentenca_documento_original:\",lista_sentenca_documento_original)\n","    #print(\"len(lista_sentenca_documento_original):\",len(lista_sentenca_documento_original))\n","    #print(\"documento_original_tokens:\",documento_original_tokens)\n","    #print(\"len(documento_original_tokens):\",len(documento_original_tokens))\n","    #print(\"documento_original_pos:\",documento_original_pos)\n","    #print(\"len(documento_original_pos):\",len(documento_original_pos))\n","    \n","    # Recupera o documento original se ele foi classificado corretamente    \n","    documento_id_original = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == str(linha['id'])]\n","    #print(\"documento_id_original:\", documento_id_original)\n","\n","    # Recupera a classificação do original\n","    classe = \"\"\n","    # Se o documento original foi encontrado foi classificado corretamente\n","    if len(documento_id_original) != 0:\n","      #print(\"documento_id_original:\",len(documento_id_original))          \n","      documento = lista_documentos_agrupados_indexado.loc[id_documento_original]\n","      #print(\"documento:\",documento)\n","      classe =  str(documento['classe'])      \n","    else:\n","      classe = \"0\"\n","   \n","    if exibir_dados == True:\n","      #Mostra o documento original e sua classificação\n","      print(\"\\nDO: \" + linha[\"documento\"] + \" - \" + classe)          \n","      # Concatena as pos do documento\n","      pos_concatenado = \"\"\n","      for doc_pos1 in documento_original_pos:\n","        # print(\"doc_pos1\",doc_pos1)\n","        for doc_pos2 in doc_pos1:\n","          pos_concatenado = pos_concatenado + doc_pos2 + \" \"\n","      print(\"    \" + \" \" + pos_concatenado)\n","      \n","    # Lista com documentos perturbados e sua classificacao para o DO\n","    lista_perturbado_classificado_correto = []\n","    lista_perturbado_classificado_incorreto = []\n","\n","    # Percorre os documentos perturbados e suas classificações a partir do original\n","    for j in range(0, MELHOR_DOCUMENTOS_PERTURBADOS):\n","\n","        # Id do documento perturbado\n","        id_perturbado = str(linha['id']) + \"_pert_\" + str(j)\n","        #id_perturbado = linha['id'] + 1\n","        #print(\"id_perturbado:\",id_perturbado)\n","\n","        # Localiza os dados do documento perturbado\n","        documento_perturbado, lista_sentenca_documento_perturbado, documento_perturbado_tokens, documento_perturbado_pos = getDadosDocumento(id_perturbado)\n","        # Recupera o documento perturrbado\n","        #print(\"documento_perturbado:\",documento_perturbado)\n","        #print(\"lista_sentenca_documento_perturbado:\",lista_sentenca_documento_perturbado)\n","        #print(\"len(lista_sentenca_documento_perturbado):\",len(lista_sentenca_documento_perturbado))\n","        #print(\"documento_perturbado_tokens:\",documento_perturbado_tokens)\n","        #print(\"len(documento_perturbado_tokens):\",len(documento_perturbado_tokens))\n","        #print(\"documento_perturbado_pos:\",documento_perturbado_pos)\n","        #print(\"len(documento_perturbado_pos):\",len(documento_perturbado_pos))\n","\n","        # Recupera a sentença mascarada e seus dados do documento perturbado\n","        index_sentenca, sentenca_mascarada, palavra_mascarada, token_predito, peso_predito = getDadosPerturbacao(id_perturbado)\n","          \n","        # Encontrar o índice da palavra mascarada\n","        index_wi = getIndicePalavraMascarada(sentenca_mascarada)\n","\n","        palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","        #print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","        token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos, token_predito)\n","        #print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","        # Encontrar o índice da palavra mascarada\n","        index_wi = getIndicePalavraMascarada(sentenca_mascarada) \n","        \n","        palavra_mascarada_classe = getPosPalavraSentenca(documento_original_tokens, documento_original_pos, palavra_mascarada)\n","        # print(\"palavra_mascarada:\", palavra_mascarada, \" /palavra_mascarada_classe:\",palavra_mascarada_classe)          \n","        token_predito_classe = getPosPalavraSentenca(documento_perturbado_tokens, documento_perturbado_pos,token_predito)\n","        # print(\"token_predito:\", token_predito, \" /token_predito_classe:\",token_predito_classe)\n","\n","        cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO = getMedidasComparacaoPalavrasGlobal(id_documento_original,\n","                                                                                       index_sentenca, \n","                                                                                       index_wi,\n","                                                                                       0, #Estratégia 0 = MEAN\n","                                                                                       0) #Filtro palavra 0 = All\n","\t\n","        #print(\"    Ctx DO     :\", palavra_mascarada, \" - \", cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO)\n","        cos_ctxall_pertDO, euc_ctxall_pertDO, man_ctxall_pertDO = getMedidasComparacaoPalavrasGlobal(id_perturbado,\n","                                                                                       index_sentenca, \n","                                                                                       index_wi,\n","                                                                                       0, #Estratégia 0 = MEAN\n","                                                                                       0) #Filtro palavra 0 = All\n","\n","        # print(\"    Ctx pertDO :\", token_predito, \" - \", cos_ctxall_DO, euc_ctxall_DO, man_ctxall_DO)\n","\n","        # Recupera o id documento perturbado se ele foi classificado corretamente\n","        documento_id_perturbado_correto = lista_retorno_classificado_corretamente_sem_repeticao.loc[lista_retorno_classificado_corretamente_sem_repeticao[\"id\"] == id_perturbado]        \n","        \n","        # Se foi encontrado foi classificado corretamente\n","        if len(documento_id_perturbado_correto) != 0:\n","          \n","          versaoPerturbadaClassificada = True\n","          #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))                    \n","          documento = lista_documentos_agrupados_indexado.loc[id_perturbado]\n","          #print(\"documento:\",documento)\n","          lista_perturbado_classificado_correto.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                    str(documento['documento']),            #1\n","                                    palavra_mascarada,                      #2\n","                                    palavra_mascarada_classe,               #3                                   \n","                                    token_predito,                          #4\n","                                    token_predito_classe,                   #5\n","                                    peso_predito,                           #6\n","                                    0,                                      #7 #0 = classe documento original\n","                                    cos_ctxall_DO,                          #8\n","                                    euc_ctxall_DO,                          #9\n","                                    man_ctxall_DO,                          #10\n","                                    cos_ctxall_pertDO,                      #11\n","                                    euc_ctxall_pertDO,                      #12\n","                                    man_ctxall_pertDO,                      #13\n","                                    ])          \n","\n","        else:\n","          # Recupera o id documento perturbado se ele foi classificado incorretamente\n","          documento_id_perturbado_incorreto = lista_retorno_classificado_incorretamente_sem_repeticao.loc[lista_retorno_classificado_incorretamente_sem_repeticao[\"id\"] == id_perturbado]\n","\n","          # Se foi encontrado foi classificado incorretamente\n","          if len(documento_id_perturbado_incorreto) != 0:            \n","            #print(\"documento_id_perturbado_correto:\",len(documento_id_perturbado_correto))          \n","            documento = lista_documentos_agrupados.loc[lista_documentos_agrupados[\"id\"] == str(documento_id_perturbado_incorreto['id'].values[0])]\n","            #print(\"documento:\",documento)\n","            lista_perturbado_classificado_incorreto.append([str(id_documento_original) + \"_pert_\" + str(j), #0\n","                                    str(documento['documento'].values[0]),  #1\n","                                    palavra_mascarada,                      #2\n","                                    palavra_mascarada_classe,               #3                                   \n","                                    token_predito,                          #4\n","                                    token_predito_classe,                   #5\n","                                    peso_predito,                           #6\n","                                    1,                                      #7 #1 = classe documento perturbado\n","                                    cos_ctxall_DO,                          #8\n","                                    euc_ctxall_DO,                          #9\n","                                    man_ctxall_DO,                          #10\n","                                    cos_ctxall_pertDO,                      #11\n","                                    euc_ctxall_pertDO,                      #12\n","                                    man_ctxall_pertDO,                      #13\n","                                    ])                                  \n","                \n","    # Ordena as listas\n","    lista_perturbado_classificado_correto = sorted(lista_perturbado_classificado_correto, key=lambda x: (x[2], x[6]), reverse=True)\n","    lista_perturbado_classificado_incorreto = sorted(lista_perturbado_classificado_incorreto, key=lambda x: (x[2], x[6]), reverse=True)\n","\n","    # Cosseno\n","    if medida == 'cos':\n","      indice_palavra_selecionada = 8 # índice palavra original selecionada\n","      indice_palavra_substituida = 11 # índice palavra substiuída\n","    else:        \n","      # Euclidiana\n","      if medida == 'euc':\n","        indice_palavra_selecionada = 9 # índice palavra original selecionada\n","        indice_palavra_substituida = 12 # índice palavra substituída\n","      else:          \n","        # Manhatan\n","        if medida == 'man':\n","          indice_palavra_selecionada = 10 # índice palavra original selecionada\n","          indice_palavra_substituida = 13 # índice palavra substituída\n","    \n","    if exibir_dados == True:\n","      # Mostra a saída das classificações    \n","      print(\"  Classificações corretas (classe = predição): \" + str(len(lista_perturbado_classificado_correto)))\n","\n","    if len(lista_perturbado_classificado_correto) != 0:           \n","      conta_melhor_DO = 0 \n","      conta_melhor_pertDO = 0\n","      classes_iguais = 0\n","              \n","      for i, x in enumerate(lista_perturbado_classificado_correto):\n","        melhorDO = \"\u003e\"\n","        melhor_pertDO = \"\"\n","\n","        # Classes morfosintáticas iguais\n","        if x[3] == x[5]:\n","          classes_iguais = classes_iguais + 1\n","  \n","        # similaridade do cosseno euclidiana(busca a maior distância)\n","        if medida == 'cos':\n","          if x[indice_palavra_selecionada] \u003e= x[indice_palavra_substituida]: #cos\n","            # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento      \n","            melhorDO = \"\u003e\"\n","            melhor_pertDO = \"\"\n","            conta_melhor_DO = conta_melhor_DO + 1            \n","            linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            lista_melhor_DO_correto.append(linha)\n","                 \n","          else:\n","            # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","            melhorDO = \"\"\n","            melhor_pertDO = \"\u003e\"\n","            conta_melhor_pertDO = conta_melhor_pertDO + 1\n","            \n","            linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            lista_melhor_pertDO_correto.append(linha)\n","                        \n","        else:\n","          # distância euclidiana(busca a menor distância)          \n","          if x[indice_palavra_selecionada] \u003c= x[indice_palavra_substituida]: #euc e man  \n","            # Palavra selecionada possui medida melhor que a modificada(substituta) em relação ao documento      \n","            melhorDO = \"\u003e\"\n","            melhor_pertDO = \"\"\n","            conta_melhor_DO = conta_melhor_DO + 1\n","            \n","            linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            lista_melhor_DO_correto.append(linha)            \n","            \n","          else:\n","            # Palavra modificada(substituta) possui medida melhor que a palavra selecionada em relação ao documento.\n","            melhorDO = \"\"\n","            melhor_pertDO = \"\u003e\"\n","            conta_melhor_pertDO = conta_melhor_pertDO + 1\n","            linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            lista_melhor_pertDO_correto.append(linha)\n","\n","        if exibir_dados == True:\n","          linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","          print(\"   \" + linha)\n","         \n","      if exibir_dados == True:\n","        print(\"       DO melhor      :\",conta_melhor_DO, \" pertDOMelhor:\",conta_melhor_pertDO)\n","        print(\"       Classes iguais :\",classes_iguais)\n","\n","    if exibir_dados == True:\n","      print(\"  Classificações incorretas(classe != predição): \" + str(len(lista_perturbado_classificado_incorreto)))\n","      \n","    if len(lista_perturbado_classificado_incorreto) != 0:           \n","      conta_melhor_DO = 0 \n","      conta_melhor_pertDO = 0\n","      classes_iguais = 0\n","        \n","      for i, x in enumerate(lista_perturbado_classificado_incorreto):\n","          melhorDO = \"\u003e\"\n","          melhor_pertDO = \"\"\n","\n","          # Classes morfosintáticas iguais\n","          if x[3] == x[5]:\n","            classes_iguais = classes_iguais  + 1\n","\n","          #if x[indice_palavra_selecionada] \u003c x[indice_palavra_substituida]: #cos\n","          if x[indice_palavra_selecionada] \u003e x[indice_palavra_substituida]: #euc e man\n","            melhorDO = \"\"\n","            melhor_pertDO = \"\u003e\"          \n","            conta_melhor_pertDO = conta_melhor_pertDO + 1\n","            linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            lista_melhor_pertDO_incorreto.append(linha)\n","            \n","          else:\n","            conta_melhor_DO = conta_melhor_DO + 1\n","            linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            lista_melhor_DO_incorreto.append(linha)\n","           \n","          if exibir_dados == True: \n","            linha = getLinhaMedida(x, melhorDO, melhor_pertDO, indice_palavra_selecionada, indice_palavra_substituida)\n","            print(\"   \" + linha)\n","                  \n","      if exibir_dados == True:  \n","        print(\"       DO melhor      :\",conta_melhor_DO, \" pertDOMelhor:\",conta_melhor_pertDO)\n","        print(\"       Classes iguais :\",classes_iguais)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXP0ClKfDd1Q"},"outputs":[],"source":["print(\"Documentos perturbados(pertDO) classificados corretamente\")\n","print(\"  A distância Euclidiana da palavra selecionada em DO com o seu contexto(media palavras da sentença) é melhor do que de sua versão perturbada\")\n","print(\"  lista_melhor_DO_correto:\",len(lista_melhor_DO_correto))\n","for i, x in enumerate(lista_melhor_DO_correto):\n","  if i \u003c 10:\n","    print(\"     \", x)\n","print()\n","\n","print(\"  A distância Euclidiana da palavra selecionada em DO com o seu contexto(media palavras da sentença) é pior do que de sua versão perturbada\")\n","print(\"  lista_melhor_pertDO_correto\", len(lista_melhor_pertDO_correto))\n","for i, x in enumerate(lista_melhor_pertDO_correto):\n","  #if i \u003c 10:\n","    print(\"     \", x)\n","print()\n","\n","print(\"Documentos perturbados(pertDO) classificados incorretamente\")\n","print(\"  A distância Euclidiana da palavra selecionada em DO com o seu contexto(media palavras da sentença) é melhor do que de sua versão perturbada\")\n","print(\"  lista_melhor_DO_incorreto:\", len(lista_melhor_DO_incorreto))\n","for i, x in enumerate(lista_melhor_DO_incorreto):\n","  if i \u003c 10:\n","    print(\"     \", x)\n","print()\n","\n","print(\"  A distância Euclidiana da palavra selecionada em DO com o seu contexto(media palavras da sentença) é pior do que de sua versão perturbada\")\n","print(\"  lista_melhor_pertDO_incorreto:\", len(lista_melhor_pertDO_incorreto))\n","for i, x in enumerate(lista_melhor_pertDO_incorreto):\n","  if i \u003c 10:\n","    print(\"     \", x)"]},{"cell_type":"markdown","metadata":{"id":"VbHRQXxLDd1Q"},"source":["#### Listas documentos originais e perturbados classificados corretamente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9BNrusmDd1Q"},"outputs":[],"source":["print(\"Documentos originais e perturbados classificados corretamente(classe=previsão):\", len(lista_retorno_classificado_corretamente))\n","conta = 0\n","for i, linha in lista_retorno_classificado_corretamente.iterrows():\n","  conta = conta + 1\n","  if i \u003c 2000:    \n","    documento = lista_documentos_agrupados_indexado.loc[linha[\"id\"]]       \n","    if len(documento) != 0:    \n","      print(\"   \", conta, documento['documento'], documento['classe'])"]},{"cell_type":"markdown","metadata":{"id":"ViXuTy4JDd1Q"},"source":["#### Listas documentos originais e perturbados classificados incorretamente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PyzHjlqDd1Q"},"outputs":[],"source":["print(\"Documentos originais e perturbados classificados incorretamente(classe!=previsão):\", len(lista_retorno_classificado_incorretamente))\n","conta = 0\n","for i, linha in lista_retorno_classificado_incorretamente.iterrows():\n","  conta = conta + 1\n","  if i \u003c 2000:    \n","    documento = lista_documentos_agrupados_indexado.loc[linha[\"id\"]]       \n","    if len(documento) != 0:    \n","      print(\"   \", conta, documento['documento'], documento['classe'])"]},{"cell_type":"markdown","metadata":{"id":"4N_JACE-Dd1R"},"source":["#### Listas documentos perturbados com palavra selecionada igual a perturbada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CurP5fCcDd1R"},"outputs":[],"source":["for i, x in enumerate(lista_perturbado_classificado_medida):\n","  if i \u003c 20:\n","      # Verifica se as palavras são iguais\n","      if x[2] == x[4]:        \n","        print(x[0], x[1], x[7])        "]},{"cell_type":"markdown","metadata":{"id":"jw0cyOLRDd1R"},"source":["### Listas"]},{"cell_type":"markdown","metadata":{"id":"R3fxBHuTDd1R"},"source":["#### Lista de documentos originais(1) classificados corretamente(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YX4QaBdKDd1R"},"outputs":[],"source":["def listaOriginalClassificadoCorretamente(df_dados_classificacao):\n","  lista_retorno = []  \n","  for i, linha in df_dados_classificacao.iterrows():\n","    if linha['classe'] == 1 and linha['predicao'] == 1:\n","        lista_retorno.append(linha['id'])\n","\n","  df_lista_retorno = pd.DataFrame(lista_retorno, columns = [\"id\"])        \n","  return df_lista_retorno"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-W6XUHzIDd1R"},"outputs":[],"source":["lista_documento_original_classificado_corretamente = listaOriginalClassificadoCorretamente(df_dados_classificacao)\n","print('lista_documento_original_classificado_corretamente:', len(lista_documento_original_classificado_corretamente))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fpCcT7fDd1R"},"outputs":[],"source":["print(\"Lista de documentos originais classificados corretamente(coerentes)(classe=1 \u0026 previsão=1):\", len(lista_documento_original_classificado_corretamente))\n","for i, documento in lista_documento_original_classificado_corretamente.iterrows():\n","  if i \u003c 20:\n","    # Recupera o documento a ser exibido       \n","    documento = lista_documentos_agrupados_indexado.loc[linha[\"id\"]]       \n","    print(\"  \",i, \"-\", documento['documento'], documento['classe'])"]},{"cell_type":"markdown","metadata":{"id":"DFYglvL9Dd1R"},"source":["#### Lista de documento originais(1) classificados incorretamente(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NBAzjqFVDd1R"},"outputs":[],"source":["def listaOriginalClassificadoIncorretamente(df_dados_classificacao):\n","  lista_retorno = []  \n","  for i, linha in df_dados_classificacao.iterrows():\n","    if linha['classe'] == 1 and linha['predicao'] == 0:\n","        lista_retorno.append(linha['id'])\n","  df_lista_retorno = pd.DataFrame(lista_retorno, columns = [\"id\"])\n","  return df_lista_retorno"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BsPDhOYDd1R"},"outputs":[],"source":["lista_documento_original_classificado_incorretamente = listaOriginalClassificadoIncorretamente(df_dados_classificacao)\n","\n","print(\"Lista de documentos originais classificados incorretamente:\",len(lista_documento_original_classificado_incorretamente))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLUZ-NzIDd1S"},"outputs":[],"source":["print(\"Lista de documentos originais classificados incorretamente(incoerentes)(classe=1 \u0026 previsão=0):\", len(lista_documento_original_classificado_incorretamente))\n","for i, documento in lista_documento_original_classificado_incorretamente.iterrows():\n","    # Recupera o documento a ser exibido   \n","    documento = lista_documentos_agrupados_indexado.loc[linha[\"id\"]]       \n","    print(\"  \",i, \"-\", documento['documento'], documento['classe'])"]},{"cell_type":"markdown","metadata":{"id":"MmI3jtCjDd1S"},"source":["#### Lista Documentos Perturbados(0) Classificados corretamente(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxfxe5phDd1S"},"outputs":[],"source":["def listaPerturbadoClassificadoCorretamente(df_dados_classificacao):\n","  lista_retorno = []  \n","  for i, linha in df_dados_classificacao.iterrows():\n","    if linha['classe'] == 0 and linha['predicao'] == 0:\n","        lista_retorno.append(linha['id'])\n","  df_lista_retorno = pd.DataFrame(lista_retorno, columns = [\"id\"])\n","  return df_lista_retorno"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gIDReKmQDd1S"},"outputs":[],"source":["lista_documento_perturbado_classificado_corretamente = listaPerturbadoClassificadoCorretamente(df_dados_classificacao)\n","print('lista_documento_perturbado_classificado_corretamente:', len(lista_documento_perturbado_classificado_corretamente))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfhOysiVDd1S"},"outputs":[],"source":["print(\"Lista de documentos perturbados classificados corretamente(incoerentes)(classe=0 \u0026 previsão=0):\", len(lista_documento_perturbado_classificado_corretamente))\n","for i, documento in lista_documento_perturbado_classificado_corretamente.iterrows():\n","    # Recupera o documento a ser exibido   \n","    documento = lista_documentos_agrupados_indexado.loc[linha[\"id\"]]       \n","    print(\"  \",i, \"-\", documento['documento'], documento['classe'])"]},{"cell_type":"markdown","metadata":{"id":"iN5IoroxDd1S"},"source":["#### Lista Documentos Perturbados(0) Classificados incorretamente(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XrWsQ1raDd1S"},"outputs":[],"source":["def listaPerturbadoClassificadoIncorretamente(df_dados_classificacao):\n","  lista_retorno = []  \n","  for i, linha in df_dados_classificacao.iterrows():\n","    if linha['classe'] == 0 and linha['predicao'] == 1:\n","        lista_retorno.append(linha['id'])\n","        \n","  df_lista_retorno = pd.DataFrame(lista_retorno, columns = [\"id\"])\n","  return df_lista_retorno"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D8CWTEORDd1S"},"outputs":[],"source":["lista_documento_perturbado_classificado_incorretamente = listaPerturbadoClassificadoIncorretamente(df_dados_classificacao)\n","print('lista_documento_perturbado_classificado_incorretamente:', len(lista_documento_perturbado_classificado_incorretamente))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3tcTpNpDd1S"},"outputs":[],"source":["print(\"Lista de documentos perturbados classificados incorretamente(coerente)(classe=0 \u0026 previsão=1):\", len(lista_documento_perturbado_classificado_incorretamente))\n","for i, documento in lista_documento_perturbado_classificado_incorretamente.iterrows():\n","    # Recupera o documento a ser exibido   \n","    documento = lista_documentos_agrupados_indexado.loc[linha[\"id\"]]         \n","    print(\"  \",i, \"-\", documento['documento'], documento['classe'])"]},{"cell_type":"markdown","metadata":{"id":"Ii0r8pfDDd1T"},"source":["# 4 Finalização"]},{"cell_type":"markdown","metadata":{"id":"gGwFIFwnDd1T"},"source":["## 4.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4iL9Qxe0Dd1T"},"outputs":[],"source":[" # Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print('')\n","print('  Tempo processamento:  {:} (h:mm:ss)'.format(tempo_total_processamento))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"06.3.2 - AnaliseClassificadorKFold_FAQUAD_P_20_v1.ipynb","provenance":[{"file_id":"1Er23iD96x_SzmRG8md1kVggbmz0su_Q5","timestamp":1602332127662}],"toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}