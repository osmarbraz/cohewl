{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPXSuZl5rRAgdloKLSq4YIO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"85aeccb614b74c6983dbb1ee21f6a045":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59d9499bd6974ab981e6edf9495d2ebb","IPY_MODEL_429ec1dec6ed49d28056f7179c160086","IPY_MODEL_ca29e82bb519412186157f00420279f2"],"layout":"IPY_MODEL_fac17fbebeb14000b06129839eba9eb4"}},"59d9499bd6974ab981e6edf9495d2ebb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27e108c119b845f58a9d0f79d007a095","placeholder":"​","style":"IPY_MODEL_60e17dfdfca44238a359108850eb829a","value":"Documentos: 100%"}},"429ec1dec6ed49d28056f7179c160086":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4eadfb7243044e46a1d35af9a50001f8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_848eef1562da4d91b6643ddf9a38e1bf","value":1}},"ca29e82bb519412186157f00420279f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca7d7273cc034aadb4ce24e69969a577","placeholder":"​","style":"IPY_MODEL_d715f4d4814d47e28d16303755f354cd","value":" 1/1 [00:00&lt;00:00, 14.39 documento/s]"}},"fac17fbebeb14000b06129839eba9eb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27e108c119b845f58a9d0f79d007a095":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e17dfdfca44238a359108850eb829a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4eadfb7243044e46a1d35af9a50001f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"848eef1562da4d91b6643ddf9a38e1bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca7d7273cc034aadb4ce24e69969a577":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d715f4d4814d47e28d16303755f354cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52db2976e12540869081eba2c48b44c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b13134ae39ee42ea841435693c07a500","IPY_MODEL_15f480af9da24be7b080601dec75b55e","IPY_MODEL_da926fd2a0d54683adb0a00879b4dfe0"],"layout":"IPY_MODEL_b80f33fc3a604d0fb4a35d9dfd070e67"}},"b13134ae39ee42ea841435693c07a500":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9e7589c46d540858c5ecd1c352b438e","placeholder":"​","style":"IPY_MODEL_5d531d053bf7426fb0b9ff84fd4d219d","value":"Documentos:  71%"}},"15f480af9da24be7b080601dec75b55e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfdef08811024a1f86be4804d41958af","max":21,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c061b1e3a53c477ba66e388b82fb14e3","value":15}},"da926fd2a0d54683adb0a00879b4dfe0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c49b9b6b16e442a1b0159a3f6a391b08","placeholder":"​","style":"IPY_MODEL_0fd24aec536d4ffeb0b4d165d0b21112","value":" 15/21 [00:05&lt;00:02,  2.71 documento/s]"}},"b80f33fc3a604d0fb4a35d9dfd070e67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9e7589c46d540858c5ecd1c352b438e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d531d053bf7426fb0b9ff84fd4d219d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfdef08811024a1f86be4804d41958af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c061b1e3a53c477ba66e388b82fb14e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c49b9b6b16e442a1b0159a3f6a391b08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fd24aec536d4ffeb0b4d165d0b21112":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"78HE8FLsKN9Q"},"source":["# Gera os arquivos para o Embedding Projector das palavras do conjunto de dados CohQuAD In pt-br  com BERT Transformers by HuggingFace.\n","\n","Gera os arquivos para Embedding Projector(https://projector.tensorflow.org/).\n","\n","Pode ser configurado para utilizar o BERTimbau **Large** e **Base**.\n","\n","Gera arquivos **records_token_sentenca.tsv** com:\n","- Com e sem pooling dos embeddings das palavras fora do vocabulário.\n","- Gera embeddings da concatenação das 4 últimas camadas do BERT ou da última camada.\n","\n","O último registro de records é referente é a média dos embeddings dos tokens do documento consolidados.\n","\n","O arquivo **meta_token_sentenca.tsv** possui as seguindas colunas:\n","- Token ou Sentença\n","- POS-Tag\n","- OOV (1 - Não existe no vocabulário do **BERT** e combina os *embeddings* dos tokens para formar a palavra e 0 - Existe no vocabulário do **BERT**)\n","- Id (Id do documento)\n","- Origem (Id do documento de origem)\n","- Classe (1 - Original, 0 - Perturbado)\n","- Perturbada (1 - Perturbada, 0 - Não perturbada)\n","- Index (Índice da palavra na sentença)\n","- Próximo token da sentença\n","- Granularidade (0 - Token, 1 - Sentença)\n","- Tipo Texto (0 - Palavra perturbada, 1 Palavra Original, 2 - Sentença Perturbada, 3 - Sentença Original)\n","- Sentença\n","\n","\n","Exemplo de projeção dos arquivos gerados:\n","https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/osmarbraz/cohebertv1projecao/main/config_token.json\n","\n","Repositório dos arquivos no github.\n","https://github.com/osmarbraz/cohebertv1projecao\n","\n","---------------------------\n","\n","Artigos:\n","\n","- https://arxiv.org/pdf/1611.05469v1.pdf\n","\n","- https://towardsdatascience.com/visualizing-bias-in-data-using-embedding-projector-649bc65e7487\n","\n","- https://towardsdatascience.com/bert-visualization-in-embedding-projector-dfe4c9e18ca9\n","\n","- https://krishansubudhi.github.io/deeplearning/2020/08/27/bert-embeddings-visualization.html\n","\n","- https://amitness.com/interactive-sentence-embeddings/\n","\n","---------------------------\n","\n","**Utiliza o *projeto embeddings* projector para exibir os dados:**\n","https://projector.tensorflow.org/\n","\n","\n","**Link biblioteca Huggingface:**\n","https://github.com/huggingface/transformers\n","\n","\n","**Artigo original BERT Jacob Devlin:**\n","https://arxiv.org/pdf/1506.06724.pdf"]},{"cell_type":"markdown","metadata":{"id":"xyxb5Px3p1-e"},"source":["# 1 Preparação do ambiente\n","Preparação do ambiente para execução do exemplo."]},{"cell_type":"markdown","metadata":{"id":"cW_5CN8En7zl"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcTEKloUn-VK"},"outputs":[],"source":["# Import das bibliotecas\n","import time\n","import datetime\n","\n","#marca o tempo de início do processamento.\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj5TaAH_5-nB"},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================\n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.\n","    \"\"\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):\n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","\n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B1mvfAU5jZf"},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","\n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.\n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","\n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download\n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]\n","\n","    # Define o nome e caminho do arquivo temporário\n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","\n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","\n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:\n","        tamanho_conteudo = data.headers.get(\"Content-Length\")\n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)\n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):\n","            if chunk:\n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","\n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","\n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qwKjGvyLG4v"},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","\n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jirIzIstLea0"},"outputs":[],"source":["def carregar(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC9Xppq-_R0w"},"outputs":[],"source":["def carregarLista(nome_arquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nome_arquivo, \"r\", encoding= encoding)\n","\n","    sentencas = []\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkVk5LQT_G3f"},"outputs":[],"source":["def salvar(nome_arquivo, texto):\n","    \"\"\"\n","      Salva um texto em arquivo.\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.\n","    \"\"\"\n","\n","    arquivo = open(nome_arquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Guy6B4whsZFR"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempo_arredondado = int(round((tempo)))\n","\n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempo_arredondado))"]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModeloArgumentosMedida) de definição dos parâmetros do modelo para medida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgmN6RqDRDZS"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={'help': 'max seq len'},\n","    )\n","    pretrained_model_name_or_path: str = field(\n","        default='neuralmind/bert-base-portuguese-cased',\n","        metadata={'help': 'nome do modelo pré-treinado do BERT.'},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={'help': 'define se o texto do modelo deve ser todo em minúsculo.'},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita se o modelo retorna os pesos de atenção.'},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={'help': 'habilita gerar as camadas ocultas do modelo.'},\n","    )\n","    use_wandb : bool = field(\n","        default=True,\n","        metadata={'help': 'habilita o uso do wandb.'},\n","    )\n","    salvar_avaliacao : bool = field(\n","        default=True,\n","        metadata={'help': 'habilita o salvamento do resultado da avaliação.'},\n","    )\n","    salvar_medicao : bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o salvamento da medicao.'},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={'help': 'habilita o carragamento de mcl ajustado.'},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )\n","    estrategia_medida: int = field(\n","        default=0, # 0 - MEAN estratégia média / 1 - MAX  estratégia maior\n","        metadata={'help': 'Estratégia de cálculo da médida dos embeddings.'},\n","    )\n","    equacao_medida: int = field(\n","        default=0, # 0 - ADJACENTE / 1 - COMBINAÇÃO TODAS / 2 - CONTEXTO\n","        metadata={'help': 'Equação de cálculo da coerência.'},\n","    )\n","    filtro_palavra: int = field(\n","        default=0, # 0 - Considera todas as palavras das sentenças / 1 - Desconsidera as stopwords / 2 - Considera somente as palavras substantivas\n","        metadata={'help': 'Define o filtro de palavras das sentenças para gerar os embeddings.'},\n","    )"]},{"cell_type":"markdown","metadata":{"id":"HIN413rj50EI"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxV4-3Yg50EI"},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcopxbGZqDip"},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4  Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMiH0E3OnRa1"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory.\n","import sys\n","\n","# Retorna true ou false se estiver no Google Colaboratory.\n","IN_COLAB = 'google.colab' in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"RinFHFesVKis"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"MPngEboiVbfi"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"EjWE6WlvVbfj"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtaYZmc3Vbfj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664831209415,"user_tz":180,"elapsed":4227,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"1be74934-c7bb-45da-e224-239f6bb4f460"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Dispositivo GPU não encontrado\n"]}],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"iYRrUo2XWa8G"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrjqDO6nWa8J"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch\n","\n","def getDeviceGPU():\n","    \"\"\"\n","      Retorna um dispositivo de GPU se disponível ou CPU.\n","\n","      Retorno:\n","        `device` - Um device de GPU ou CPU.\n","    \"\"\"\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","\n","        # Diz ao PyTorch para usar GPU.\n","        device = torch.device(\"cuda\")\n","\n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:\n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","\n","    return device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChDxmtXsKwjf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664831212793,"user_tz":180,"elapsed":16,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"e283460b-7fd6-4eb0-e9eb-3d85e0d1af27"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Sem GPU disponível, usando CPU.\n"]}],"source":["# Recupera o device com GPU ou CPU\n","device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"fGf59D0yVNx9"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1iC5-pSAVh7_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664831213202,"user_tz":180,"elapsed":417,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"878258bf-342a-45fe-92c2-717661b3d5fb"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","INFO:root:Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","INFO:root:e selecione High-RAM. Então, execute novamente está célula\n"]}],"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysnDDapMQK8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664831248545,"user_tz":180,"elapsed":35346,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"a9e64c3a-3a91-4b8b-a0de-fd8af078d5dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejzpgGrFM0-j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664831259101,"user_tz":180,"elapsed":10561,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"3a90e6c3-9e56-48b4-b371-b4ca2167df2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 55.9 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 55.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 58.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 59.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 57.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 56.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 57.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 54.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 49.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 47.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 60.4 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 56.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=4b16c6f6e5b0b7568a6b1f081ab1289d8a9982bc9b2f330f1ea649086613f853\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.3\n"]}],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"oOd2MbBiDq93"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaMM4WdxgvQ7","colab":{"base_uri":"https://localhost:8080/","height":524},"executionInfo":{"status":"ok","timestamp":1664831274796,"user_tz":180,"elapsed":15702,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"c67cf933-8d3f-4840-e8d2-a3e7657f293a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.4.1-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 48.9 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","numba 0.56.2 requires setuptools<60, but you have setuptools 65.4.1 which is incompatible.\u001b[0m\n","Successfully installed pip-22.2.2 setuptools-65.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4p3Rz2qDq94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664831292326,"user_tz":180,"elapsed":17534,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4addd8ed-e98a-41c7-9f33-72bd33e488d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.8)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.10)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.7)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.4.1)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.9.2\n","    Uninstalling pydantic-1.9.2:\n","      Successfully uninstalled pydantic-1.9.2\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.0\n","    Uninstalling thinc-8.1.0:\n","      Successfully uninstalled thinc-8.1.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.1\n","    Uninstalling spacy-3.4.1:\n","      Successfully uninstalled spacy-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-1.8.2 spacy-3.2.0 thinc-8.0.17 typing-extensions-3.10.0.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.9 Instalação do BERT"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face.\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCVzCmy7pIOz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664831307224,"user_tz":180,"elapsed":14903,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"eec9cb01-06d3-4fc9-8fba-ddc373bfcae6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=c599b306c0709e250527c258c1cb2751a399a9cdee65f85244d3ae2c8ba3f1c4\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -U transformers==4.5.1"]},{"cell_type":"markdown","metadata":{"id":"giOsAS5v61go"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uiH9pNpwI6g"},"outputs":[],"source":["#Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 20\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 20\n","\n","#Realiza o pooling dos tokens de palavras fora do vocabulário do BERT\n","POOLING_TOKENS = 1 # 0 - Sem pooling / 1 - Com pooling\n","\n","#Utiliza somente documentos originais, perturbados ou ambos.\n","CLASSE_DOCUMENTO = 2 # 0 - Somente com a classe 0 (Perturbado) / 1 - Somente com classe 1 (Original), 2 - As duas classes 0 e 1\n","\n","#Estratégia de recuperação dos embeddings: (1 - Embeddings da última camada,\n","#                                           2 - Embeddings da concatenação das 4 últimas camadas)\n","ESTRATEGIA_EMBEDDING = 2\n","\n","# Estratégias a serem avaliadas (0 - Mean / 1 - Max) para as palavras formadas por mais de um token do BERT\n","ESTRATEGIA_MEDIDA_STR = [\"MEAN\", \"MAX\"]\n","ESTRATEGIA_MEDIDA = [0, 1]\n","\n","# Habilita a criação do rótulo \"__next__\" no projetor para gerar linhas entre os pontos de tokens de uma mesma origem em sequência.\n","LIGACAO_PROXIMO_TOKEN = True"]},{"cell_type":"markdown","source":["Permite filtrar os documentos a serem utilizados na geração dos arquivos da projeção."],"metadata":{"id":"BkttC-OgqSDP"}},{"cell_type":"code","source":["# Filtra um determinado conjunto de documentos originais e suas versões perturbadas\n","# FILTRO_DO = [] # Filtro vazio seleciona todos os documentos\n","FILTRO_DO = ['1p0']"],"metadata":{"id":"D40avaBwqQfq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"3V_ORR8Qyu1p"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Definição dos parâmetros do Modelo\n","model_args = ModeloArgumentosMedida(\n","    max_seq_len = 512,\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",\n","\n","    #pretrained_model_name_or_path = \"bert-large-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-cased\"\n","    pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","\n","    #modelo_spacy = \"en_core_web_lg\",\n","    #modelo_spacy = \"en_core_web_md\",\n","    #modelo_spacy = \"en_core_web_sm\",\n","    modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","\n","    versao_modelo_spacy = \"3.2.0\",\n","    do_lower_case = False,  # default True\n","    output_attentions = False,  # default False\n","    output_hidden_states = True, # default False\n","    use_wandb = True,\n","    salvar_medicao = True, #Salva o resultado da medição\n","    salvar_avaliacao = True, # Salva o resultado da avaliação das medições\n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100, 500 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path.\n","    estrategia_medida = 0, # Atributo usado para os logs do wandb. 0 - MEAN estratégia média / 1 - MAX  estratégia maior\n","    equacao_medida = 0, # Atributo usado para os logs do wandb. 0 - Palavras adjacentes / 1 - Todas as palavras / 2 - Palavra e contexto\n","    filtro_palavra = 0 # # Atributo usado para os logs do wandb. 0 - Considera todas as palavras das sentenças / 1 - Desconsidera as stopwords / 2 - Considera somente as palavras substantivas\n",")"]},{"cell_type":"markdown","metadata":{"id":"WlF4PKP6Iopi"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55PNP2s6Iopi"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHQUAD_IN_PTBR\""]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"tDgJTbPOZ8SW"},"source":["## Inicialização diretórios"]},{"cell_type":"markdown","metadata":{"id":"qpSERA9TC4WU"},"source":["Diretório base local"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edg7eW2cDflg"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","def criaDiretorioLocal():\n","\n","  # Cria o diretório para receber os arquivos Originais e Permutados\n","  # Diretório a ser criado\n","  dirbase = DIRETORIO_LOCAL[:-1]\n","\n","  if not os.path.exists(dirbase):\n","      # Cria o diretório\n","      os.makedirs(dirbase)\n","      logging.info(\"Diretório criado: {}.\".format(dirbase))\n","  else:\n","      logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xge0ar9MJoKy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833372404,"user_tz":180,"elapsed":27,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"a165516b-e61f-400f-ca4a-1806d8509aff"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_IN_PTBR.\n"]}],"source":["criaDiretorioLocal()"]},{"cell_type":"markdown","metadata":{"id":"4FmT9nhbaE3D"},"source":["Diretório para conter as os resultados das medidas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zO76uzj_C3zQ"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioMedidacao():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_medicao_palavra\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):\n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1Ot2h_bJuxy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833372406,"user_tz":180,"elapsed":21,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"cc7b98ee-4bc2-4ee5-f3c1-811870ac4359"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_IN_PTBR/validacao_medicao_palavra.\n"]}],"source":["criaDiretorioMedidacao()"]},{"cell_type":"markdown","metadata":{"id":"vIkT6ksqaQs3"},"source":["Diretório para conter os arquivos da avaliação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIV4xj6zDnb8"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioAvaliacao():\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_medicao_palavra/Avaliacao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):\n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiOVjJ5BJzE1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833372407,"user_tz":180,"elapsed":16,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"6403e4fa-60ed-4fdf-9617-64057b92789e"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_IN_PTBR/validacao_medicao_palavra/Avaliacao.\n"]}],"source":["criaDiretorioAvaliacao()"]},{"cell_type":"markdown","metadata":{"id":"cjP6v878aWR7"},"source":["Diretório para conter os arquivos das medidas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qf6UWAZYDsgm"},"outputs":[],"source":["# Import de bibliotecas.\n","import os\n","\n","def criaDiretorioMedicao():\n","\n","  DIRETORIO_BASE = DIRETORIO_DRIVE + \"validacao_medicao_palavra/Medicao\"\n","\n","  # Verifica se o diretório existe\n","  if not os.path.exists(DIRETORIO_BASE):\n","    # Cria o diretório\n","    os.makedirs(DIRETORIO_BASE)\n","    logging.info(\"Diretório criado: {}.\".format(DIRETORIO_BASE))\n","  else:\n","    logging.info(\"Diretório já existe: {}.\".format(DIRETORIO_BASE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IBBfHFuPJ3NM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833372407,"user_tz":180,"elapsed":12,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"38ac4c3d-7729-4b2a-9a9e-fd50846ee3e0"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/drive/MyDrive/Colab Notebooks/Data/COHQUAD_IN_PTBR/validacao_medicao_palavra/Medicao.\n"]}],"source":["criaDiretorioMedicao()"]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjWGu-9D5URZ"},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dq9PnXO77bPQ"},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","\n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivo_tar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")\n","    arquivo_tar.extractall(DIRETORIO_COHEBERT)\n","    arquivo_tar.close()\n","\n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):\n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePOccj0s8WMg"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","\n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp"]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbELnrpgA4T1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833378469,"user_tz":180,"elapsed":6070,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"f64520fc-7bbd-430b-d8ca-4e81d6974672"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:spaCy carregado.\n"]}],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","metadata":{"id":"AEzytjZi5Iw2"},"source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKg-_XyWoy8o"},"outputs":[],"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","\n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.\n","    \"\"\"\n","\n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords"]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1o8jevtoy8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833378470,"user_tz":180,"elapsed":41,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"8351ce9a-649f-418e-c4bc-281994ecf599"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Quantidade de stopwords: 416.\n"]},{"output_type":"stream","name":"stdout","text":["{'direita', 'aquele', 'do', 'estás', 'da', 'esta', 'nova', 'nível', 'quinze', 'este', 'maiorias', 'entre', 'cuja', 'grande', 'podem', 'saber', 'cima', 'todo', 'pelo', 'além', 'podia', 'sua', 'és', 'nesta', 'temos', 'tenho', 'nada', 'nos', 'oitavo', 'seus', 'maior', 'fazemos', 'ver', 'lhe', 'possível', 'qualquer', 'dão', 'poder', 'eventual', 'meu', 'oitava', 'ambas', 'fora', 'próxima', 'mês', 'ir', 'povo', 'vos', 'pois', 'custa', 'vinte', 'tentaram', 'vezes', 'logo', 'pela', 'área', 'estão', 'sexto', 'tente', 'sexta', 'conhecida', 'apoia', 'desde', 'des', 'grupo', 'baixo', 'mesmo', 'exemplo', 'ambos', 'apenas', 'conselho', 'terceiro', 'minha', 'até', 'quieto', 'partir', 'pouca', 'estiveram', 'de', 'ela', 'também', 'as', 'tuas', 'vez', 'bom', 'que', 'tiveste', 'tais', 'porque', 'deve', 'tua', 'posição', 'foram', 'dezassete', 'talvez', 'veja', 'porquê', 'uma', 'perto', 'cujo', 'daquele', 'todos', 'vindo', 'estar', 'tens', 'tempo', 'tendes', 'mal', 'possivelmente', 'estive', 'fazeis', 'aqui', 'algumas', 'por', 'se', 'quero', 'outros', 'dá', 'esteve', 'zero', 'qual', 'num', 'geral', 'atrás', 'apoio', 'querem', 'quieta', 'menor', 'aí', 'ao', 'quando', 'quanto', 'às', 'sob', 'três', 'muito', 'for', 'nosso', 'relação', 'com', 'te', 'demais', 'já', 'agora', 'dar', 'fomos', 'cedo', 'vai', 'somente', 'pegar', 'poderá', 'tive', 'vens', 'fazia', 'desta', 'último', 'está', 'nessa', 'sistema', 'dois', 'coisa', 'bem', 'iniciar', 'tivestes', 'como', 'tivemos', 'máximo', 'tipo', 'faz', 'os', 'lado', 'sem', 'foste', 'vais', 'na', 'nenhuma', 'vão', 'contudo', 'certeza', 'local', 'quem', 'puderam', 'vem', 'aquelas', 'sete', 'nuns', 'daquela', 'duas', 'era', 'muitos', 'põem', 'meses', 'tem', 'nesse', 'ali', 'comprida', 'fazer', 'fará', 'através', 'sei', 'tu', 'o', 'ontem', 'tão', 'parece', 'sétimo', 'obrigada', 'números', 'vossos', 'breve', 'longe', 'treze', 'me', 'umas', 'cá', 'neste', 'essas', 'posso', 'estará', 'são', 'fim', 'estiveste', 'tiveram', 'fostes', 'tanto', 'dentro', 'novo', 'naquela', 'parte', 'ter', 'vosso', 'mas', 'meus', 'nem', 'diante', 'tentar', 'tanta', 'estado', 'das', 'ou', 'esse', 'quer', 'outra', 'à', 'tal', 'quarta', 'aos', 'usa', 'numa', 'estivestes', 'próprio', 'portanto', 'outras', 'ora', 'tarde', 'fui', 'eu', 'forma', 'nossa', 'nossas', 'menos', 'estava', 'quarto', 'caminho', 'maioria', 'isso', 'e', 'nós', 'teus', 'você', 'meio', 'naquele', 'alguns', 'nas', 'adeus', 'favor', 'aquilo', 'enquanto', 'suas', 'catorze', 'sétima', 'onze', 'deverá', 'conhecido', 'disso', 'teu', 'ponto', 'aquela', 'depois', 'irá', 'sois', 'onde', 'porém', 'obrigado', 'pontos', 'não', 'devem', 'bastante', 'quinto', 'ligado', 'deste', 'estes', 'cinco', 'primeira', 'momento', 'têm', 'quatro', 'só', 'então', 'tentei', 'número', 'dezoito', 'eles', 'final', 'terceira', 'acerca', 'assim', 'vós', 'segunda', 'quinta', 'algo', 'desse', 'esses', 'vinda', 'nove', 'tudo', 'novas', 'sobre', 'pode', 'seu', 'dezasseis', 'doze', 'vêm', 'contra', 'vossas', 'todas', 'falta', 'boa', 'sim', 'estivemos', 'faço', 'no', 'um', 'mais', 'minhas', 'oito', 'certamente', 'aqueles', 'corrente', 'novos', 'pôde', 'fazem', 'uns', 'dezanove', 'toda', 'debaixo', 'elas', 'ainda', 'após', 'grandes', 'vários', 'antes', 'foi', 'dos', 'põe', 'embora', 'seria', 'fez', 'sabe', 'vocês', 'estas', 'quê', 'ele', 'lá', 'mil', 'quais', 'é', 'ademais', 'cada', 'comprido', 'dizem', 'questão', 'ser', 'valor', 'fazes', 'teve', 'cento', 'usar', 'inclusive', 'próximo', 'lugar', 'segundo', 'dez', 'apontar', 'essa', 'nunca', 'para', 'pelas', 'diz', 'nossos', 'sou', 'pouco', 'dessa', 'estou', 'dizer', 'em', 'primeiro', 'vossa', 'sempre', 'seis', 'porquanto', 'pelos', 'inicio', 'a', 'somos', 'isto'}\n"]}],"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6hdqVdfxm-_W"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy\n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ]\n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal\n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ]\n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},\n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar\n","               ]\n","\n","matcherv = Matcher(nlp.vocab)\n","\n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):\n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","\n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","\n","  return lista2"]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = dict()\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9SA61kD6sJY"},"outputs":[],"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","\n","  # Soma os dicionários da lista\n","  novodic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWxyAo54AOHU"},"outputs":[],"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.text)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gvd99wd_pwmt"},"outputs":[],"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista_tokens = []\n","  lista_pos = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:\n","    lista_tokens.append(token.text)\n","    lista_pos.append(token.pos_)\n","\n","  return lista_tokens, lista_pos"]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tadução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpCUpOs06sJY"},"outputs":[],"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","\n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\"\n","  return traduzido"]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMb0uDWzKZXP"},"outputs":[],"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxTCYFzcJZD6"},"outputs":[],"source":["def getSentencaSalientePOS(sentenca, pos, tipo_saliente=\"NOUN\"):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especeficado\n","    if pos[i] == tipo_saliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"_xaeX0oTVQ5t"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIaQ9bzBVQ5t"},"outputs":[],"source":["def removeStopWord(documento, stopwords):\n","\n","  # Remoção das stopwords do documento\n","  documento_sem_stopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documento_sem_stopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"]},{"cell_type":"markdown","metadata":{"id":"A7NAe8ogCf1y"},"source":["### retornaRelevante\n","\n","Retorna somente os palavras do documento ou sentença do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNNfykypChn-"},"outputs":[],"source":["def retornaRelevante(documento, classe_relevante=\"NOUN\"):\n","\n","  # Corrigir!\n","  # Utilizar o documento já tokenizado pelo spacy!!!!\n","  # Existe uma lista com o documento e a sentença tokenizada pelo spacy\n","\n","  # Realiza o parsing no spacy\n","  doc = nlp(documento)\n","\n","  # Retorna a lista das palavras relevantes\n","  documento_com_substantivos = []\n","  for token in doc:\n","    #print(\"token:\", token.pos_)\n","    if token.pos_ == classe_relevante:\n","      documento_com_substantivos.append(token.text)\n","\n","  # Concatena o documento com os substantivos\n","  documento_concatenado = \" \".join(documento_com_substantivos)\n","\n","  # Retorna o documento\n","  return documento_concatenado"]},{"cell_type":"markdown","metadata":{"id":"IBY7q_uH8JSE"},"source":["# 4 BERT"]},{"cell_type":"markdown","metadata":{"id":"MBGTMy8Ic7GK"},"source":["## 4.1 Modelo Pré-treinado BERT"]},{"cell_type":"markdown","metadata":{"id":"uiuxdXe9t1BX"},"source":["### Funções Auxiliares"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Huw0x5kt1Le"},"outputs":[],"source":["def getNomeModeloBERT(model_args):\n","    '''\n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","\n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"\n","\n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","\n","    return MODELO_BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYJB4ik7t5xe"},"outputs":[],"source":["def getTamanhoBERT(model_args):\n","    '''\n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","\n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","\n","    return TAMANHO_BERT"]},{"cell_type":"markdown","metadata":{"id":"rHt4e5pAcEMd"},"source":["### Função download Modelo Pre-treinado BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peDUrV2ccEXA"},"outputs":[],"source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","\n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","\n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo!\")\n","            # Apaga o diretório e os arquivos existentes\n","            shutil.rmtree(DIRETORIO_MODELO)\n","\n","        # Realiza o download do arquivo do modelo\n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.\n","        arquivo_zip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivo_zip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.\n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","\n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta!\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada!\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"V74WUpHqcfoI"},"source":["### Copia o modelo do BERT ajustado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQMpf9yycf8f"},"outputs":[],"source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\"\n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    logging.info(\"Modelo BERT ajustado copiado!\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"]},{"cell_type":"markdown","metadata":{"id":"eaneOhAKcO-3"},"source":["### Verifica de onde utilizar o modelo do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTy1TXz3cPKS"},"outputs":[],"source":["def verificaModelo(model_args):\n","    \"\"\"\n","    Verifica de onde utilizar o modelo.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    DIRETORIO_MODELO = None\n","\n","    if model_args.usar_mcl_ajustado == True:\n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","\n","        logging.info(\"Usando modelo BERT ajustado.\")\n","\n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"6tKcaIfReqdy"},"source":["## 4.2 Tokenizador BERT"]},{"cell_type":"markdown","metadata":{"id":"e8n7Z5s-QZF8"},"source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzAuptkwQZR3"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","\n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"]},{"cell_type":"markdown","metadata":{"id":"GYRV9KfHQE6v"},"source":["## 4.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"markdown","metadata":{"id":"-pZZrUKRhR3e"},"source":["### Função carrega modelo BERT medida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JUEyjCChUQh"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertModel # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:\n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertModel.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertModel.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"-uFDhRTZe2Js"},"source":["### Função carrega o BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVtAUbUBe2iS"},"outputs":[],"source":["def carregaBERT(model_args):\n","    \"\"\"\n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","        `tokenizer` - Um objeto tokenizador BERT carregado.\n","    \"\"\"\n","\n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","\n","    # Variável para conter o modelo\n","    model = None\n","\n","    # Carrega o modelo para cálculo da medida\n","    model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","\n","    # Carrega o tokenizador.\n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","\n","    return model, tokenizer"]},{"cell_type":"markdown","metadata":{"id":"x5NTxBRKfAcT"},"source":["### Carrega o BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYMLJJYSQHY3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833385722,"user_tz":180,"elapsed":7267,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"7ff320c6-4ef2-446e-a8fb-8c269b67622f"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Variável URL_MODELO não setada!\n","INFO:root:Usando modelo BERT pré-treinado.\n","INFO:root:Carregando o modelo BERT da comunidade neuralmind/bert-large-portuguese-cased para cálculo de medidas.\n","INFO:root:Carregando o tokenizador BERT do diretório neuralmind/bert-large-portuguese-cased.\n"]}],"source":["# Carrega o modelo e tokenizador do BERT\n","model, tokenizer = carregaBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"d7KprWqyZBQZ"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6sPjTQnuQV2"},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"khTFfBVbnsx9"},"source":["## 4.4 Funções auxiliares do BERT"]},{"cell_type":"markdown","metadata":{"id":"lCJzsw8T0I-5"},"source":["### concatenaListas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IpmDZ1mI0JHR"},"outputs":[],"source":["def concatenaListas(lista, pos=1):\n","  lista_concat = []\n","\n","  for x in lista:\n","      lista_concat = lista_concat + x[pos]\n","\n","  return lista_concat"]},{"cell_type":"markdown","metadata":{"id":"s42mgtmSZ8MR"},"source":["### getEmbeddingsCamadas\n","\n","Funções que recuperam os embeddings das camadas:\n","- Primeira camada;\n","- Penúltima camada;\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgo3EBTRZ9-3"},"outputs":[],"source":["def getEmbeddingPrimeiraCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][0]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingPenultimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-2]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingUltimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-1]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingSoma4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][-4:]\n","  # Saída: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado\n","\n","def getEmbeddingConcat4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Cria uma lista com os tensores a serem concatenados\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Lista com os tensores a serem concatenados\n","  lista_concat = []\n","\n","  # Percorre os 4 últimos\n","  for i in [-1,-2,-3,-4]:\n","      # Concatena da lista\n","      lista_concat.append(output[2][i])\n","\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Realiza a concatenação dos embeddings de todos as camadas\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  resultado = torch.cat(lista_concat, dim=-1)\n","\n","  # Saída: Entrada: (<1(lote)> x <qtde_tokens> x <3072 ou 4096>)\n","  return resultado\n","\n","def getEmbeddingSomaTodasAsCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas as camadas descontando a primeira(0)\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][1:]\n","  # Saída: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado"]},{"cell_type":"markdown","metadata":{"id":"q7nx_eZ8hSlr"},"source":["### getEmbeddingsVisual\n","\n","Função para gerar as coordenadas de plotagem a partir das sentenças de embeddings.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLdbOT8-g43V"},"outputs":[],"source":["def getEmbeddingsVisualUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAf9lJJ2hZbt"},"outputs":[],"source":["def getEmbeddingsVisualSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4XpwSN1ghpnz"},"outputs":[],"source":["def getEmbeddingsVisualConcat4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3KU1EFrnSPK"},"outputs":[],"source":["def getEmbeddingsVisualSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"Y8MjE0utzlZT"},"source":["### getEmbeddings\n","\n","Função para gerar os embeddings de sentenças.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QcqOuwS067Q"},"outputs":[],"source":["def getEmbeddingsUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BK1wDGBl067Y"},"outputs":[],"source":["def getEmbeddingsSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hym19Hxr067Y"},"outputs":[],"source":["def getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer):\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-PLZiUR067Z"},"outputs":[],"source":["def getEmbeddingsSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"zFd1rse11DpZ"},"source":["### getDocumentoTokenizado\n","\n","Retorna o documento tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvWIBFTLJ7z9"},"outputs":[],"source":["def getDocumentoTokenizado(documento, tokenizer):\n","    \"\"\"\n","      Retorna o documento tokenizado pelo BERT.\n","\n","      Parâmetros:\n","      `documento` - Documento a ser tokenizado.\n","      `tokenizer` - Tokenizador do BERT.\n","    \"\"\"\n","\n","    # Adiciona os tokens especiais.\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Documento tokenizado\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    del tokenizer\n","\n","    return documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"3wvgXwN81RCz"},"source":["### encontrarIndiceSubLista\n","\n","Retorna os índices de início e fim da sublista na lista"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abS44M4yvFxf"},"outputs":[],"source":["def encontrarIndiceSubLista(lista: List, sublista: List):\n","    \"\"\"\n","    Localiza os índices de início e fim de uma sublista em uma lista.\n","    Baseado no algoritmo de https://codereview.stackexchange.com/questions/19627/finding-sub-list\n","    de  https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n","\n","    Parâmetros:\n","      `lista` - Uma lista.\n","      `sublista` - Uma sublista a ser localizada na lista.\n","\n","    Retorno:\n","      Os índices de início e fim da sublista na lista.\n","    \"\"\"\n","    # Tamanho da lista\n","    h = len(lista)\n","    # Tamanho da sblista\n","    n = len(sublista)\n","    # Cria um dicionário com os saltos descrescentes dos elementos n-1 da sublista\n","    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n","    i = n - 1\n","    # Percorre a lista\n","    while i < h:\n","        # Percorre a sublista\n","        for j in range(n):\n","            # Se elemento da lista diferente da sublista pula a interação\n","            if lista[i - j] != sublista[-j - 1]:\n","              # Passa para o próximo elemento da lista saltando a sublista\n","              i += skip.get(lista[i], n)\n","              # Interrompe o for.\n","              break\n","        else:\n","            #Finalizando a pesquisa depois de executar todo o for(sem break)\n","            indice_inicio = i - n + 1\n","            indice_fim = indice_inicio + len(sublista)-1\n","\n","            # Retorna o início e fim da sublista na lista\n","            return indice_inicio, indice_fim\n","\n","    # Não encontrou a sublista na lista\n","    return -1, -1"]},{"cell_type":"markdown","metadata":{"id":"kGL37G6XFcwp"},"source":["### getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras\n","\n","A partir dos embeddings do documento, localiza o indíce de início e fim de uma sentença no documento e retorna os embeddings da sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uI07Y_M8__HG"},"outputs":[],"source":["def getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                           token_BERT_documento,\n","                                                           sentenca,\n","                                                           tokenizer):\n","\n","  # Tokeniza a sentença\n","  sentenca_tokenizada_BERT = getDocumentoTokenizado(sentenca, tokenizer)\n","  #print(sentenca_tokenizada_BERT)\n","\n","  # Remove os tokens de início e fim da sentença\n","  sentenca_tokenizada_BERT.remove(\"[CLS]\")\n","  sentenca_tokenizada_BERT.remove(\"[SEP]\")\n","  #print(len(sentenca_tokenizada_BERT))\n","\n","  # Localiza os índices dos tokens da sentença no documento\n","  inicio, fim = encontrarIndiceSubLista(token_BERT_documento, sentenca_tokenizada_BERT)\n","  #print(inicio,fim)\n","\n","  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do documento\n","  embedding_sentenca = embedding_documento[inicio:fim+1]\n","  #print(\"embedding_sentenca=\", embedding_sentenca.shape)\n","\n","  del tokenizer\n","  del token_BERT_documento\n","  del embedding_documento\n","\n","  # Retorna o embedding da sentença no documento\n","  return embedding_sentenca, sentenca_tokenizada_BERT"]},{"cell_type":"markdown","metadata":{"id":"THFhXGGmIO_r"},"source":["### getEmbeddingDocumentoComTodasPalavrasMean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhW_OiEsIPJI"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento excluindo os tokens\n","    especiais [CLS] do início e [SEP] do fim.\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embedding do documento.\n","  \"\"\"\n","\n","  # Calcula a média dos embeddings para os tokens de embedding_documento, removendo a primeira dimensão.\n","  # Entrada: <qtde_tokens> x <768 ou 1024>\n","  #print(\"embedding_documento1=\", embedding_documento.shape)\n","  media_embedding_documento = torch.mean(embedding_documento[1:-1], dim=0)\n","  # Saída: <768 ou 1024>\n","\n","  del embedding_documento\n","\n","  return media_embedding_documento"]},{"cell_type":"markdown","metadata":{"id":"1Ko_of60YuNd"},"source":["### getEmbeddingDocumentoRelevanteMean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDokSSODY0Sf"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                       index_sentenca,\n","                                       embedding_documento,\n","                                       token_BERT_documento,\n","                                       documento,\n","                                       token_documento,\n","                                       pos_documento,\n","                                       filtro):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento considerando tokens do tipo\n","    especificado no filtro\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","\n","  \"\"\"\n","\n","  # Recupera a lista de tokens do documento, a lista dos postagging e a lista dos seus embeddings com um mesmo tamanho\n","  lista_tokens, lista_postagging, lista_embeddings = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                    index_sentenca,\n","                                                                                    embedding_documento,\n","                                                                                    token_BERT_documento,\n","                                                                                    documento,\n","                                                                                    token_documento,\n","                                                                                    pos_documento)\n","\n","  #print(\"len(token_BERT_documento):\", len(token_BERT_documento))\n","  #print(\"token_BERT_documento:\", token_BERT_documento)\n","  #print(\"len(pos_documento):\", len(pos_documento))\n","  #print(\"pos_documento:\", pos_documento)\n","  #print(\"filtro:\", filtro)\n","  #print()\n","\n","  # Lista com os tensores selecionados\n","  lista_tokens_selecionados = []\n","  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word no documento\n","  for i, token_documento in enumerate(lista_tokens):\n","      if (lista_postagging[i] in filtro):\n","          #print(\"Adicionando palavra do embedding:\", lista_tokens[i])\n","          lista_tokens_selecionados.append(lista_embeddings[i])\n","\n","  if  len(lista_tokens_selecionados) != 0:\n","      # Empila os embeddings da lista pela dimensão 0\n","      embedding_relevante = torch.stack(lista_tokens_selecionados, dim=0)\n","      #print(\"embedding_relevante.shape:\",embedding_relevante.shape)\n","\n","      # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n","      # Entrada: <qtde_tokens> x <768 ou 1024>\n","      media_embedding_relevante = torch.mean(embedding_relevante, dim=0)\n","      # Saída: <768 ou 1024>\n","      #print(\"media_embedding_relevante.shape:\", media_embedding_relevante.shape)\n","  else:\n","      media_embedding_relevante = None\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del documento\n","  del token_documento\n","  del pos_documento\n","\n","  return media_embedding_relevante"]},{"cell_type":"markdown","metadata":{"id":"L_vknrk7YSpF"},"source":["### getEmbeddingDocumentoMean\n","\n","Filtros:\n","- ALL - Sentença com todas as palavras\n","- NOUN - Sentença somente com substantivos\n","- VERB - Sentença somente com verbos\n","- VERB,NOUN - Sentença somente com verbos e substantivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pd8B76YyYS02"},"outputs":[],"source":["def getEmbeddingDocumentoMean(id_documento,\n","                              index_sentenca,\n","                              embedding_documento,\n","                              token_BERT_documento,\n","                              documento,\n","                              tokenizer,\n","                              token_documento,\n","                              pos_documento,\n","                              filtro=[\"ALL\"]):\n","  \"\"\"\n","    Rediciona o cálculo da média dos embeddings de acordo com o filtro especificado.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","  \"\"\"\n","\n","  if \"ALL\" in filtro:\n","    return getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento)\n","  else:\n","    return getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                              index_sentenca,\n","                                              embedding_documento,\n","                                              token_BERT_documento,\n","                                              documento,\n","                                              token_documento,\n","                                              pos_documento,\n","                                              filtro)"]},{"cell_type":"markdown","metadata":{"id":"t1PgxcL01VfF"},"source":["### getTokensEmbeddingsPOSSentenca\n","Gera os tokens, POS e embeddings de cada sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBkcF2ve1VfG"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar mais tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera mais tokens que a tokenização das palavras do spaCy\n","dic_excecao_maior = {\"\":-1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXJk5Od51VfI"},"outputs":[],"source":["def getExcecaoDicMaior(token, dic_excecao_maior):\n","\n","  valor = dic_excecao_maior.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M6TSm62Y1VfI"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar menos tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera menos tokens que a tokenização das palavras do spaCy\n","dic_excecao_menor = {\"1°\":1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7OYmoFVk1VfJ"},"outputs":[],"source":["def getExcecaoDicMenor(token, dic_excecao_menor):\n","\n","  valor = dic_excecao_menor.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"markdown","metadata":{"id":"JzYA5pPE1VfJ"},"source":["Função que retorna os embeddings, tokens e POS da sentença com um mesmo tamanho."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9H1JlTt1VfK"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getTokensEmbeddingsPOSSentenca(embedding_documento,\n","                                   token_BERT_documento,\n","                                   sentenca):\n","    \"\"\"\n","      Retorna os tokens, as postagging e os embeddings dos tokens igualando a quantidade de tokens do spaCy com a tokenização do BERT de acordo com a estratégia.\n","      Usa a estratégia MEAN para calcular a média dos embeddings dos tokens que formam uma palavra.\n","      Usa a estratégia MAX para calcular o valor máximo dos embeddings dos tokens que formam uma palavra.\n","    \"\"\"\n","\n","    #Guarda os tokens e embeddings\n","    lista_tokens = []\n","    lista_tokens_OOV = []\n","    lista_embeddings_MEAN = []\n","    lista_embeddings_MAX = []\n","\n","    # Gera a tokenização e POS-Tagging da sentença\n","    sentenca_token, sentenca_pos = getListaTokensPOSSentenca(sentenca)\n","\n","    # print(\"\\nsentenca          :\",sentenca)\n","    # print(\"sentenca_token      :\",sentenca_token)\n","    # print(\"len(sentenca_token) :\",len(sentenca_token))\n","    # print(\"sentenca_pos        :\",sentenca_pos)\n","    # print(\"len(sentenca_pos)   :\",len(sentenca_pos))\n","\n","    # Recupera os embeddings da sentença dos embeddings do documento\n","    embedding_sentenca = embedding_documento\n","    sentenca_tokenizada_BERT = token_BERT_documento\n","\n","    # embedding <qtde_tokens x 4096>\n","    # print(\"embedding_sentenca          :\",embedding_sentenca.shape)\n","    # print(\"sentenca_tokenizada_BERT     :\",sentenca_tokenizada_BERT)\n","    # print(\"len(sentenca_tokenizada_BERT):\",len(sentenca_tokenizada_BERT))\n","\n","    # Seleciona os pares de palavra a serem avaliadas\n","    pos_wi = 0 # Posição do token da palavra gerado pelo spaCy\n","    pos_wj = pos_wi # Posição do token da palavra gerado pelo BERT\n","    pos2 = -1\n","\n","    # Enquanto o indíce da palavra pos_wj(2a palavra) não chegou ao final da quantidade de tokens do BERT\n","    while pos_wj < len(sentenca_tokenizada_BERT):\n","\n","      # Seleciona os tokens da sentença\n","      wi = sentenca_token[pos_wi] # Recupera o token da palavra gerado pelo spaCy\n","      wi1 = \"\"\n","      pos2 = -1\n","      if pos_wi+1 < len(sentenca_token):\n","        wi1 = sentenca_token[pos_wi+1] # Recupera o próximo token da palavra gerado pelo spaCy\n","\n","        # Localiza o deslocamento da exceção\n","        pos2 = getExcecaoDicMenor(wi+wi1, dic_excecao_menor)\n","        #print(\"Exceção pos2:\", pos2)\n","\n","      wj = sentenca_tokenizada_BERT[pos_wj] # Recupera o token da palavra gerado pelo BERT\n","      # print(\"wi[\",pos_wi,\"]=\", wi)\n","      # print(\"wj[\",pos_wj,\"]=\", wj)\n","\n","      # Tratando exceções\n","      # Localiza o deslocamento da exceção\n","      pos = getExcecaoDicMaior(wi, dic_excecao_maior)\n","      #print(\"Exceção pos:\", pos)\n","\n","      if pos != -1 or pos2 != -1:\n","        if pos != -1:\n","          #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","          lista_tokens.append(wi)\n","          # Marca como fora do vocabulário do BERT\n","          lista_tokens_OOV.append(1)\n","          # Verifica se tem mais de um token\n","          if pos != 1:\n","            indice_token = pos_wj + pos\n","            #print(\"Calcula a média de :\", pos_wj , \"até\", indice_token)\n","            embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","            #print(\"embeddings_tokens_palavra:\",embeddings_tokens_palavra.shape)\n","            # calcular a média dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_MEAN = torch.mean(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_MEAN:\",embedding_estrategia_MEAN.shape)\n","            lista_embeddings_MEAN.append(embedding_estrategia_MEAN)\n","\n","            # calcular o máximo dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_MAX, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_MAX:\",embedding_estrategia_MAX.shape)\n","            lista_embeddings_MAX.append(embedding_estrategia_MAX)\n","          else:\n","            # Adiciona o embedding do token a lista de embeddings\n","            lista_embeddings_MEAN.append(embedding_sentenca[pos_wj])\n","            lista_embeddings_MAX.append(embedding_sentenca[pos_wj])\n","\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + pos\n","          #print(\"Proxima:\")\n","          #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","          #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","        else:\n","          if pos2 != -1:\n","            #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","            lista_tokens.append(wi+wi1)\n","            # Marca como fora do vocabulário do BERT\n","            lista_tokens_OOV.append(1)\n","            # Verifica se tem mais de um token\n","            if pos2 == 1:\n","              # Adiciona o embedding do token a lista de embeddings\n","              lista_embeddings_MEAN.append(embedding_sentenca[pos_wj])\n","              lista_embeddings_MAX.append(embedding_sentenca[pos_wj])\n","\n","            # Avança para a próxima palavra e token do BERT\n","            pos_wi = pos_wi + 2\n","            pos_wj = pos_wj + pos2\n","            #print(\"Proxima:\")\n","            #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","            #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","      else:\n","        # Tokens iguais adiciona a lista, o token não possui subtoken\n","        if (wi == wj or wj==\"[UNK]\"):\n","          # Adiciona o token a lista de tokens\n","          #print(\"Adiciona 2 wi==wj or wj==[UNK]:\", wi )\n","          lista_tokens.append(wi)\n","          # Marca como dentro do vocabulário do BERT\n","          lista_tokens_OOV.append(0)\n","          # Adiciona o embedding do token a lista de embeddings\n","          lista_embeddings_MEAN.append(embedding_sentenca[pos_wj])\n","          lista_embeddings_MAX.append(embedding_sentenca[pos_wj])\n","          #print(\"embedding1[pos_wj]:\", embedding_sentenca[pos_wj].shape)\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + 1\n","\n","        else:\n","          # A palavra foi tokenizada pelo Wordpice com ## ou diferente do spaCy ou desconhecida\n","          # Inicializa a palavra a ser montada\n","          palavra_POS = wj\n","          indice_token = pos_wj + 1\n","          while  ((palavra_POS != wi) and indice_token < len(sentenca_tokenizada_BERT)):\n","              if \"##\" in sentenca_tokenizada_BERT[indice_token]:\n","                # Remove os caracteres \"##\" do token\n","                parte = sentenca_tokenizada_BERT[indice_token][2:]\n","              else:\n","                parte = sentenca_tokenizada_BERT[indice_token]\n","\n","              palavra_POS = palavra_POS + parte\n","              #print(\"palavra_POS:\",palavra_POS)\n","              # Avança para o próximo token do BERT\n","              indice_token = indice_token + 1\n","\n","          #print(\"\\nMontei palavra:\",palavra_POS)\n","          if (palavra_POS == wi or palavra_POS == \"[UNK]\"):\n","              # Adiciona o token a lista\n","              #print(\"Adiciona 3 palavra == wi or palavra_POS = [UNK]:\",wi)\n","              lista_tokens.append(wi)\n","              # Marca como fora do vocabulário do BERT\n","              lista_tokens_OOV.append(1)\n","              # Calcula a média dos tokens da palavra\n","              #print(\"Calcula o máximo :\", pos_wj , \"até\", indice_token)\n","              embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra)\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra.shape)\n","\n","              # calcular a média dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_MEAN = torch.mean(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_MEAN:\",embedding_estrategia_MEAN)\n","              #print(\"embedding_estrategia_MEAN.shape:\",embedding_estrategia_MEAN.shape)\n","              lista_embeddings_MEAN.append(embedding_estrategia_MEAN)\n","\n","              # calcular o valor máximo dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_MAX, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_MAX:\",embedding_estrategia_MAX)\n","              #print(\"embedding_estrategia_MAX.shape:\",embedding_estrategia_MAX.shape)\n","              lista_embeddings_MAX.append(embedding_estrategia_MAX)\n","\n","          # Avança para o próximo token do spaCy\n","          pos_wi = pos_wi + 1\n","          # Pula para o próximo token do BERT\n","          pos_wj = indice_token\n","\n","    # Verificação se as listas estão com o mesmo tamanho\n","    #if (len(lista_tokens) != len(sentenca_token)) or (len(lista_embeddings_MEAN) != len(sentenca_token)):\n","    if (len(lista_tokens) !=  len(lista_embeddings_MEAN)):\n","       print(\"\\nsentenca                  :\",sentenca)\n","       print(\"sentenca_pos              :\",sentenca_pos)\n","       print(\"sentenca_token            :\",sentenca_token)\n","       print(\"sentenca_tokenizada_BERT  :\",sentenca_tokenizada_BERT)\n","       print(\"lista_tokens              :\",lista_tokens)\n","       print(\"len(lista_tokens)         :\",len(lista_tokens))\n","       print(\"lista_embeddings_MEAN     :\",lista_embeddings_MEAN)\n","       print(\"len(lista_embeddings_MEAN):\",len(lista_embeddings_MEAN))\n","       print(\"lista_embeddings_MAX      :\",lista_embeddings_MAX)\n","       print(\"len(lista_embeddings_MAX) :\",len(lista_embeddings_MAX))\n","\n","    del embedding_sentenca\n","    del token_BERT_documento\n","    del sentenca_tokenizada_BERT\n","    del sentenca_token\n","\n","    return lista_tokens, sentenca_pos, lista_tokens_OOV, lista_embeddings_MEAN, lista_embeddings_MAX"]},{"cell_type":"markdown","metadata":{"id":"1qezcBkxnEdR"},"source":["# 5 - Projeção de embeddings\n","\n","Apresenta os tokens gerados pelo BERT e seus embeddings."]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 5.1 Carregamento dos arquivos de dados originais e permutados"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["### 5.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","metadata":{"id":"bNgwJRC2uGJb"},"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.1.2 Cria o diretório local para receber os dados"],"metadata":{"id":"I0LsmsBlJeeV"}},{"cell_type":"code","metadata":{"id":"gFYIHcIHE985","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833386152,"user_tz":180,"elapsed":9,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"2a9ea15e-b584-4df7-a67f-969a0408a6b8"},"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):\n","    # Cria o diretório\n","    os.makedirs(dirbase)\n","    logging.info(\"Diretório criado: {}\".format(dirbase))\n","else:\n","    logging.info(\"Diretório já existe: {}\".format(dirbase))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_IN_PTBR\n"]}]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","metadata":{"id":"pviuxToMCxQw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833387474,"user_tz":180,"elapsed":1329,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"5d90f1bf-cc4a-4e71-d506-0e91a3505a37"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a cópia.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a cópia.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos.\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens\n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","metadata":{"id":"dbHl3d88mouc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388588,"user_tz":180,"elapsed":1117,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"4385bd97-de0e-4db1-86ed-9cedba567818"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Terminei a descompactação.\n"]}]},{"cell_type":"markdown","metadata":{"id":"qzhYJNWJm1z4"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais, perturbados e permutados"]},{"cell_type":"markdown","metadata":{"id":"Usr1uRzQeJSb"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","metadata":{"id":"QRHlixdHEDTb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388588,"user_tz":180,"elapsed":25,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"11d64c49-d0a9-48a1-c9fc-508ccd66c31f"},"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO ORIGINAIS: 20.\n","INFO:root:TERMINADO ORIGINAIS POS: 20.\n"]}]},{"cell_type":"code","source":["#lista_documentos_originais = lista_documentos_originais[:5]"],"metadata":{"id":"mzl2SUe7N4QM"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJ5STBZPLlie","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388589,"user_tz":180,"elapsed":22,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"17bf5923-4227-41ff-a217-9c54079e8693"},"source":["lista_documentos_originais.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id                                          sentencas  \\\n","12  13p0  ['O que é uma pilha e como enfileirar um eleme...   \n","6    7p0        ['Como desempilhar elementos em uma fila?']   \n","2    3p0           ['Como empilhar elementos em uma fila?']   \n","18  19p0  ['Em uma pilha a operação de enfileirar ocorre...   \n","13  14p0  ['O que é uma fila e como empilhar um elemento...   \n","\n","                                            documento  \n","12  O que é uma pilha e como enfileirar um element...  \n","6             Como desempilhar elementos em uma fila?  \n","2                Como empilhar elementos em uma fila?  \n","18  Em uma pilha a operação de enfileirar ocorre e...  \n","13  O que é uma fila e como empilhar um elemento n...  "],"text/html":["\n","  <div id=\"df-64aa8ee0-8d7f-41bb-bb9c-59394c93435a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>12</th>\n","      <td>13p0</td>\n","      <td>['O que é uma pilha e como enfileirar um eleme...</td>\n","      <td>O que é uma pilha e como enfileirar um element...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7p0</td>\n","      <td>['Como desempilhar elementos em uma fila?']</td>\n","      <td>Como desempilhar elementos em uma fila?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3p0</td>\n","      <td>['Como empilhar elementos em uma fila?']</td>\n","      <td>Como empilhar elementos em uma fila?</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19p0</td>\n","      <td>['Em uma pilha a operação de enfileirar ocorre...</td>\n","      <td>Em uma pilha a operação de enfileirar ocorre e...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14p0</td>\n","      <td>['O que é uma fila e como empilhar um elemento...</td>\n","      <td>O que é uma fila e como empilhar um elemento n...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64aa8ee0-8d7f-41bb-bb9c-59394c93435a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-64aa8ee0-8d7f-41bb-bb9c-59394c93435a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-64aa8ee0-8d7f-41bb-bb9c-59394c93435a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1399}]},{"cell_type":"code","metadata":{"id":"4NVwIdXXDFn7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388589,"user_tz":180,"elapsed":21,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"dd4884a3-d47e-4dff-8bb8-7ee012aa063d"},"source":["lista_documentos_originais_pos.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id                                      pos_documento\n","9  10p0  [[['O', 'que', 'é', 'uma', 'pilha', 'e', 'como...\n","3   4p0  [[['Como', 'empilhar', 'e', 'desempilhar', 'el...\n","8   9p0  [[['O', 'que', 'é', 'uma', 'fila', 'e', 'como'...\n","6   7p0  [[['Como', 'desempilhar', 'elementos', 'em', '...\n","5   6p0  [[['Como', 'empilhar', 'e', 'desempilhar', 'el..."],"text/html":["\n","  <div id=\"df-d28bbbf8-8e51-4871-bd4b-2375b5b64767\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>10p0</td>\n","      <td>[[['O', 'que', 'é', 'uma', 'pilha', 'e', 'como...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4p0</td>\n","      <td>[[['Como', 'empilhar', 'e', 'desempilhar', 'el...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9p0</td>\n","      <td>[[['O', 'que', 'é', 'uma', 'fila', 'e', 'como'...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7p0</td>\n","      <td>[[['Como', 'desempilhar', 'elementos', 'em', '...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6p0</td>\n","      <td>[[['Como', 'empilhar', 'e', 'desempilhar', 'el...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d28bbbf8-8e51-4871-bd4b-2375b5b64767')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d28bbbf8-8e51-4871-bd4b-2375b5b64767 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d28bbbf8-8e51-4871-bd4b-2375b5b64767');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1400}]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"-hfUpvKqXoqe"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Corrige os tipos dos dados\n","tipos = {\"id\": str}\n","lista_documentos_originais = lista_documentos_originais.astype(tipos)\n","lista_documentos_originais_pos = lista_documentos_originais_pos.astype(tipos)\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"metadata":{"id":"lj9sJVavMccj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388589,"user_tz":180,"elapsed":21,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"29e1a4a8-3b56-45d6-976e-b450abbd7b2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO ORIGINAIS: 20.\n","INFO:root:TERMINADO CORREÇÃO ORIGINAIS POS: 20.\n"]}]},{"cell_type":"markdown","source":["#### Criando dados indexados originais"],"metadata":{"id":"8yyRt4jnYxsU"}},{"cell_type":"code","source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"],"metadata":{"id":"B9INo4nBS8aQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388589,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"038480ed-2958-4992-e40c-acf60eaf8084"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             sentencas  \\\n","id                                                       \n","1p0          [Como enfileirar elementos em uma pilha?]   \n","2p0       [Como desenfileirar elementos em uma pilha?]   \n","3p0             [Como empilhar elementos em uma fila?]   \n","4p0  [Como empilhar e desempilhar elementos em uma ...   \n","5p0  [Como empilhar elementos em uma estrutura de d...   \n","\n","                                             documento  \n","id                                                      \n","1p0            Como enfileirar elementos em uma pilha?  \n","2p0         Como desenfileirar elementos em uma pilha?  \n","3p0               Como empilhar elementos em uma fila?  \n","4p0  Como empilhar e desempilhar elementos em uma f...  \n","5p0  Como empilhar elementos em uma estrutura de da...  "],"text/html":["\n","  <div id=\"df-8d43cf76-3f4d-4c87-a0ad-7f9abb58b766\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0</th>\n","      <td>[Como enfileirar elementos em uma pilha?]</td>\n","      <td>Como enfileirar elementos em uma pilha?</td>\n","    </tr>\n","    <tr>\n","      <th>2p0</th>\n","      <td>[Como desenfileirar elementos em uma pilha?]</td>\n","      <td>Como desenfileirar elementos em uma pilha?</td>\n","    </tr>\n","    <tr>\n","      <th>3p0</th>\n","      <td>[Como empilhar elementos em uma fila?]</td>\n","      <td>Como empilhar elementos em uma fila?</td>\n","    </tr>\n","    <tr>\n","      <th>4p0</th>\n","      <td>[Como empilhar e desempilhar elementos em uma ...</td>\n","      <td>Como empilhar e desempilhar elementos em uma f...</td>\n","    </tr>\n","    <tr>\n","      <th>5p0</th>\n","      <td>[Como empilhar elementos em uma estrutura de d...</td>\n","      <td>Como empilhar elementos em uma estrutura de da...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d43cf76-3f4d-4c87-a0ad-7f9abb58b766')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8d43cf76-3f4d-4c87-a0ad-7f9abb58b766 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8d43cf76-3f4d-4c87-a0ad-7f9abb58b766');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1402}]},{"cell_type":"code","source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"],"metadata":{"id":"j70x_r30T_bx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388590,"user_tz":180,"elapsed":18,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"0fc706b6-f62d-4a5c-993b-17133d0b3f02"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         pos_documento\n","id                                                    \n","1p0  [[[Como, enfileirar, elementos, em, uma, pilha...\n","2p0  [[[Como, desenfileirar, elementos, em, uma, pi...\n","3p0  [[[Como, empilhar, elementos, em, uma, fila, ?...\n","4p0  [[[Como, empilhar, e, desempilhar, elementos, ...\n","5p0  [[[Como, empilhar, elementos, em, uma, estrutu..."],"text/html":["\n","  <div id=\"df-870d928e-2838-4a59-aad1-bc251d384cb0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0</th>\n","      <td>[[[Como, enfileirar, elementos, em, uma, pilha...</td>\n","    </tr>\n","    <tr>\n","      <th>2p0</th>\n","      <td>[[[Como, desenfileirar, elementos, em, uma, pi...</td>\n","    </tr>\n","    <tr>\n","      <th>3p0</th>\n","      <td>[[[Como, empilhar, elementos, em, uma, fila, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>4p0</th>\n","      <td>[[[Como, empilhar, e, desempilhar, elementos, ...</td>\n","    </tr>\n","    <tr>\n","      <th>5p0</th>\n","      <td>[[[Como, empilhar, elementos, em, uma, estrutu...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-870d928e-2838-4a59-aad1-bc251d384cb0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-870d928e-2838-4a59-aad1-bc251d384cb0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-870d928e-2838-4a59-aad1-bc251d384cb0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1403}]},{"cell_type":"markdown","metadata":{"id":"zJXcpioo7Bhn"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","metadata":{"id":"gB500dmd7Bho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388590,"user_tz":180,"elapsed":17,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"9f2a81c5-7463-41b8-e1a2-5d79a13f3e78"},"source":["# Abre o arquivo e retorna o DataFrame\n","lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO PERTURBADOS: 400.\n","INFO:root:TERMINADO PERTURBADOS POS: 400.\n"]}]},{"cell_type":"markdown","source":["AlgUns csv estão com os nomes das colunas errados"],"metadata":{"id":"qzTPk_BsFdzc"}},{"cell_type":"code","source":["lista_documentos_perturbados = lista_documentos_perturbados.rename(columns={'documentoPerturbado': 'documento_perturbado'})"],"metadata":{"id":"YlJ7P-kzFYmR"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQ9cgAz47Bhp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388590,"user_tz":180,"elapsed":13,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"149c393a-6873-4d5c-f2bc-e0f64f5a52db"},"source":["lista_documentos_perturbados.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id                                         perturbado  \\\n","121    7p0_pert_1    ['Como desempilhar elementos em uma pintura ?']   \n","374  19p0_pert_14  ['Em uma pilha a operação de carregar ocorre e...   \n","14    1p0_pert_14           ['Como reunir elementos em uma pilha ?']   \n","168    9p0_pert_8  ['O que é uma fila e como funciona seu element...   \n","197  10p0_pert_17  ['O que é uma pilha e como determinar seu elem...   \n","\n","                                  documento_perturbado  \\\n","121        Como desempilhar elementos em uma pintura ?   \n","374  Em uma pilha a operação de carregar ocorre em ...   \n","14                Como reunir elementos em uma pilha ?   \n","168    O que é uma fila e como funciona seu elemento ?   \n","197  O que é uma pilha e como determinar seu elemen...   \n","\n","                                             sentencas  \n","121  [['Como desempilhar elementos em uma [MASK] ?'...  \n","374  [['Em uma pilha a operação de [MASK] ocorre em...  \n","14   [['Como [MASK] elementos em uma pilha ?', 'enf...  \n","168  [['O que é uma fila e como [MASK] seu elemento...  \n","197  [['O que é uma pilha e como [MASK] seu element...  "],"text/html":["\n","  <div id=\"df-5bb4bcbe-a6de-4f00-838e-78d9954ea853\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>121</th>\n","      <td>7p0_pert_1</td>\n","      <td>['Como desempilhar elementos em uma pintura ?']</td>\n","      <td>Como desempilhar elementos em uma pintura ?</td>\n","      <td>[['Como desempilhar elementos em uma [MASK] ?'...</td>\n","    </tr>\n","    <tr>\n","      <th>374</th>\n","      <td>19p0_pert_14</td>\n","      <td>['Em uma pilha a operação de carregar ocorre e...</td>\n","      <td>Em uma pilha a operação de carregar ocorre em ...</td>\n","      <td>[['Em uma pilha a operação de [MASK] ocorre em...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1p0_pert_14</td>\n","      <td>['Como reunir elementos em uma pilha ?']</td>\n","      <td>Como reunir elementos em uma pilha ?</td>\n","      <td>[['Como [MASK] elementos em uma pilha ?', 'enf...</td>\n","    </tr>\n","    <tr>\n","      <th>168</th>\n","      <td>9p0_pert_8</td>\n","      <td>['O que é uma fila e como funciona seu element...</td>\n","      <td>O que é uma fila e como funciona seu elemento ?</td>\n","      <td>[['O que é uma fila e como [MASK] seu elemento...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>10p0_pert_17</td>\n","      <td>['O que é uma pilha e como determinar seu elem...</td>\n","      <td>O que é uma pilha e como determinar seu elemen...</td>\n","      <td>[['O que é uma pilha e como [MASK] seu element...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bb4bcbe-a6de-4f00-838e-78d9954ea853')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5bb4bcbe-a6de-4f00-838e-78d9954ea853 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5bb4bcbe-a6de-4f00-838e-78d9954ea853');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1406}]},{"cell_type":"code","source":["lista_documentos_perturbados_pos.sample(5)"],"metadata":{"id":"IE1xJdZWkc5I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833388591,"user_tz":180,"elapsed":14,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"055ebbd0-f0f6-431c-f7cc-cf12aaea8a2e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id                                      pos_documento\n","381   20p0_pert_1  [[['Em', 'uma', 'fila', 'a', 'operação', 'de',...\n","283   15p0_pert_3  [[['O', 'que', 'é', 'uma', 'fila', 'e', 'como'...\n","358  18p0_pert_18  [[['Como', 'são', 'implementadas', 'as', 'oper...\n","392  20p0_pert_12  [[['Em', 'uma', 'fila', 'a', 'operação', 'de',...\n","231  12p0_pert_11  [[['O', 'que', 'é', 'uma', 'fila', 'e', 'como'..."],"text/html":["\n","  <div id=\"df-d5a46ad2-cd0f-4c75-9557-f7bbc7985805\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>381</th>\n","      <td>20p0_pert_1</td>\n","      <td>[[['Em', 'uma', 'fila', 'a', 'operação', 'de',...</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>15p0_pert_3</td>\n","      <td>[[['O', 'que', 'é', 'uma', 'fila', 'e', 'como'...</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>18p0_pert_18</td>\n","      <td>[[['Como', 'são', 'implementadas', 'as', 'oper...</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>20p0_pert_12</td>\n","      <td>[[['Em', 'uma', 'fila', 'a', 'operação', 'de',...</td>\n","    </tr>\n","    <tr>\n","      <th>231</th>\n","      <td>12p0_pert_11</td>\n","      <td>[[['O', 'que', 'é', 'uma', 'fila', 'e', 'como'...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5a46ad2-cd0f-4c75-9557-f7bbc7985805')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d5a46ad2-cd0f-4c75-9557-f7bbc7985805 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d5a46ad2-cd0f-4c75-9557-f7bbc7985805');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1407}]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"VrfZzjjpsUOU"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Corrige os tipos dos dados\n","tipos = {\"id\": str}\n","lista_documentos_perturbados = lista_documentos_perturbados.astype(tipos)\n","lista_documentos_perturbados_pos = lista_documentos_perturbados_pos.astype(tipos)\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))"],"metadata":{"id":"ZHf-7dgSsUOU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833389158,"user_tz":180,"elapsed":580,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"63c1d08e-bce1-406c-d6a9-f936f124221c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO CORREÇÃO PERTURBADO: 400.\n","INFO:root:TERMINADO CORREÇÃO PERTURBADO POS: 400.\n"]}]},{"cell_type":"code","source":["lista_documentos_perturbados.sample(5)"],"metadata":{"id":"U-w5YwpbNqu8","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1664833389159,"user_tz":180,"elapsed":34,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"96f37190-125d-4542-db75-50f2888c13de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id                                         perturbado  \\\n","253  13p0_pert_13  [O que é uma pilha e como transformar um eleme...   \n","117   6p0_pert_17  [Como reunir e desempilhar elementos em uma es...   \n","168    9p0_pert_8  [O que é uma fila e como funciona seu elemento ?]   \n","269   14p0_pert_9  [O que é uma fila e como representar um elemen...   \n","135   7p0_pert_15        [Como desempilhar elementos em uma lista ?]   \n","\n","                                  documento_perturbado  \\\n","253  O que é uma pilha e como transformar um elemen...   \n","117  Como reunir e desempilhar elementos em uma est...   \n","168    O que é uma fila e como funciona seu elemento ?   \n","269  O que é uma fila e como representar um element...   \n","135          Como desempilhar elementos em uma lista ?   \n","\n","                                             sentencas  \n","253  [[O que é uma pilha e como [MASK] um elemento ...  \n","117  [[Como [MASK] e desempilhar elementos em uma e...  \n","168  [[O que é uma fila e como [MASK] seu elemento ...  \n","269  [[O que é uma fila e como [MASK] um elemento n...  \n","135  [[Como desempilhar elementos em uma [MASK] ?, ...  "],"text/html":["\n","  <div id=\"df-555b0fd9-009a-4ffb-99d9-d37bff05192c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>253</th>\n","      <td>13p0_pert_13</td>\n","      <td>[O que é uma pilha e como transformar um eleme...</td>\n","      <td>O que é uma pilha e como transformar um elemen...</td>\n","      <td>[[O que é uma pilha e como [MASK] um elemento ...</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>6p0_pert_17</td>\n","      <td>[Como reunir e desempilhar elementos em uma es...</td>\n","      <td>Como reunir e desempilhar elementos em uma est...</td>\n","      <td>[[Como [MASK] e desempilhar elementos em uma e...</td>\n","    </tr>\n","    <tr>\n","      <th>168</th>\n","      <td>9p0_pert_8</td>\n","      <td>[O que é uma fila e como funciona seu elemento ?]</td>\n","      <td>O que é uma fila e como funciona seu elemento ?</td>\n","      <td>[[O que é uma fila e como [MASK] seu elemento ...</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>14p0_pert_9</td>\n","      <td>[O que é uma fila e como representar um elemen...</td>\n","      <td>O que é uma fila e como representar um element...</td>\n","      <td>[[O que é uma fila e como [MASK] um elemento n...</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>7p0_pert_15</td>\n","      <td>[Como desempilhar elementos em uma lista ?]</td>\n","      <td>Como desempilhar elementos em uma lista ?</td>\n","      <td>[[Como desempilhar elementos em uma [MASK] ?, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-555b0fd9-009a-4ffb-99d9-d37bff05192c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-555b0fd9-009a-4ffb-99d9-d37bff05192c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-555b0fd9-009a-4ffb-99d9-d37bff05192c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1409}]},{"cell_type":"code","source":["lista_documentos_perturbados_pos.sample(5)"],"metadata":{"id":"1laR3W5hP6iu","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1664833389159,"user_tz":180,"elapsed":33,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"6da1bd86-6dfe-421e-a2db-206481d0c0d9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               id                                      pos_documento\n","124    7p0_pert_4  [[[Como, desempilhar, elementos, em, uma, peça...\n","155   8p0_pert_15  [[[Como, desempilhar, elementos, em, uma, estr...\n","149    8p0_pert_9  [[[Como, desempilhar, elementos, em, uma, estr...\n","332  17p0_pert_12  [[[Como, são, registradas, as, operações, de, ...\n","78    4p0_pert_18  [[[Como, empilhar, e, montar, elementos, em, u..."],"text/html":["\n","  <div id=\"df-eca7ba75-11cd-41dd-b39b-37e373656dfd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>124</th>\n","      <td>7p0_pert_4</td>\n","      <td>[[[Como, desempilhar, elementos, em, uma, peça...</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>8p0_pert_15</td>\n","      <td>[[[Como, desempilhar, elementos, em, uma, estr...</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>8p0_pert_9</td>\n","      <td>[[[Como, desempilhar, elementos, em, uma, estr...</td>\n","    </tr>\n","    <tr>\n","      <th>332</th>\n","      <td>17p0_pert_12</td>\n","      <td>[[[Como, são, registradas, as, operações, de, ...</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>4p0_pert_18</td>\n","      <td>[[[Como, empilhar, e, montar, elementos, em, u...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eca7ba75-11cd-41dd-b39b-37e373656dfd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-eca7ba75-11cd-41dd-b39b-37e373656dfd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-eca7ba75-11cd-41dd-b39b-37e373656dfd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1410}]},{"cell_type":"markdown","source":["#### Criando dados indexados perturbados"],"metadata":{"id":"Ix-Q5fZXY3HR"}},{"cell_type":"code","source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"],"metadata":{"id":"FqRQnYUtSxzB","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1664833389160,"user_tz":180,"elapsed":34,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"663e9744-877f-4eed-cd17-30db9e5065b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             perturbado  \\\n","id                                                        \n","1p0_pert_0      [Como colocar elementos em uma pilha ?]   \n","1p0_pert_1    [Como adicionar elementos em uma pilha ?]   \n","1p0_pert_2    [Como organizar elementos em uma pilha ?]   \n","1p0_pert_3  [Como identificar elementos em uma pilha ?]   \n","1p0_pert_4    [Como encontrar elementos em uma pilha ?]   \n","\n","                                 documento_perturbado  \\\n","id                                                      \n","1p0_pert_0      Como colocar elementos em uma pilha ?   \n","1p0_pert_1    Como adicionar elementos em uma pilha ?   \n","1p0_pert_2    Como organizar elementos em uma pilha ?   \n","1p0_pert_3  Como identificar elementos em uma pilha ?   \n","1p0_pert_4    Como encontrar elementos em uma pilha ?   \n","\n","                                                    sentencas  \n","id                                                             \n","1p0_pert_0  [[Como [MASK] elementos em uma pilha ?, enfile...  \n","1p0_pert_1  [[Como [MASK] elementos em uma pilha ?, enfile...  \n","1p0_pert_2  [[Como [MASK] elementos em uma pilha ?, enfile...  \n","1p0_pert_3  [[Como [MASK] elementos em uma pilha ?, enfile...  \n","1p0_pert_4  [[Como [MASK] elementos em uma pilha ?, enfile...  "],"text/html":["\n","  <div id=\"df-441019cb-ad73-4bba-9ea2-7b9b4f67904d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>perturbado</th>\n","      <th>documento_perturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0_pert_0</th>\n","      <td>[Como colocar elementos em uma pilha ?]</td>\n","      <td>Como colocar elementos em uma pilha ?</td>\n","      <td>[[Como [MASK] elementos em uma pilha ?, enfile...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_1</th>\n","      <td>[Como adicionar elementos em uma pilha ?]</td>\n","      <td>Como adicionar elementos em uma pilha ?</td>\n","      <td>[[Como [MASK] elementos em uma pilha ?, enfile...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_2</th>\n","      <td>[Como organizar elementos em uma pilha ?]</td>\n","      <td>Como organizar elementos em uma pilha ?</td>\n","      <td>[[Como [MASK] elementos em uma pilha ?, enfile...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_3</th>\n","      <td>[Como identificar elementos em uma pilha ?]</td>\n","      <td>Como identificar elementos em uma pilha ?</td>\n","      <td>[[Como [MASK] elementos em uma pilha ?, enfile...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_4</th>\n","      <td>[Como encontrar elementos em uma pilha ?]</td>\n","      <td>Como encontrar elementos em uma pilha ?</td>\n","      <td>[[Como [MASK] elementos em uma pilha ?, enfile...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-441019cb-ad73-4bba-9ea2-7b9b4f67904d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-441019cb-ad73-4bba-9ea2-7b9b4f67904d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-441019cb-ad73-4bba-9ea2-7b9b4f67904d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1411}]},{"cell_type":"code","source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados_pos.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"],"metadata":{"id":"s0aDUbeZT1M8","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1664833389160,"user_tz":180,"elapsed":33,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"8644433f-f6d1-4d65-898c-779e7116d0a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                pos_documento\n","id                                                           \n","1p0_pert_0  [[[Como, colocar, elementos, em, uma, pilha, ?...\n","1p0_pert_1  [[[Como, adicionar, elementos, em, uma, pilha,...\n","1p0_pert_2  [[[Como, organizar, elementos, em, uma, pilha,...\n","1p0_pert_3  [[[Como, identificar, elementos, em, uma, pilh...\n","1p0_pert_4  [[[Como, encontrar, elementos, em, uma, pilha,..."],"text/html":["\n","  <div id=\"df-052ae4d5-2a6d-4ffb-ab97-06fcdca7dfb7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0_pert_0</th>\n","      <td>[[[Como, colocar, elementos, em, uma, pilha, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_1</th>\n","      <td>[[[Como, adicionar, elementos, em, uma, pilha,...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_2</th>\n","      <td>[[[Como, organizar, elementos, em, uma, pilha,...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_3</th>\n","      <td>[[[Como, identificar, elementos, em, uma, pilh...</td>\n","    </tr>\n","    <tr>\n","      <th>1p0_pert_4</th>\n","      <td>[[[Como, encontrar, elementos, em, uma, pilha,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-052ae4d5-2a6d-4ffb-ab97-06fcdca7dfb7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-052ae4d5-2a6d-4ffb-ab97-06fcdca7dfb7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-052ae4d5-2a6d-4ffb-ab97-06fcdca7dfb7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1412}]},{"cell_type":"markdown","source":["### 5.1.5 Agrupar os dados originais e perturbados"],"metadata":{"id":"m-vP_FnPWe0K"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","def agruparDadosOriginaisPerturbados(lista_documentos_originais, lista_documentos_perturbados_indexado):\n","\n","  print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","  lista_documentos_agrupados = []\n","\n","  # Se tem algum id no lista do filtro seleciona os documentos originais\n","  if len(FILTRO_DO) != 0:\n","    lista_filtro = lista_documentos_originais[lista_documentos_originais['id'].isin(FILTRO_DO)]\n","\n","    # Barra de progresso dos documentos\n","    lista_documentos_originais_bar = tqdm_notebook(lista_filtro.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_filtro))\n","  else:\n","    # Barra de progresso dos documentos\n","    lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","  # Percorre os documentos\n","  for i, linha_documento in lista_documentos_originais_bar:\n","      #if i < 2:\n","      #print(\"linha_documento:\",linha_documento)\n","      # Recupera o id do documento\n","      id_documento = linha_documento[0]\n","      #print(\"id_documento:\",id_documento)\n","\n","      # Carrega a lista das sentenças do documento\n","      lista_sentenca_documento = linha_documento[1]\n","      #print(\"\\nlista_sentenca_documento:\",lista_sentenca_documento)\n","      #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","\n","      # Adiciona o original a lista dos dados agrupados, considerando como coerente(1)\n","      lista_documentos_agrupados.append([id_documento, lista_sentenca_documento, linha_documento[2], 1])\n","\n","      # Percorre os documentos perturbados apartir do original\n","      for j in range(0, model_args.documentos_perturbados):\n","\n","        # Id do documento perturbado\n","        id_perturbado = str(id_documento) + \"_pert_\" + str(j)\n","\n","        # localiza o documento perturbado\n","        #documento_perturbado = lista_documentos_perturbados.loc[lista_documentos_perturbados['id']==id_perturbado].values[0]\n","        documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","        # Recupera a sentença do documento perturbado\n","        lista_perturbado = documento_perturbado[0]\n","\n","        # Adiciona o perturbado a lista dos dados agrupados considerando como incoerente(0)\n","        lista_documentos_agrupados.append([id_perturbado, lista_perturbado, documento_perturbado[1], 0])\n","\n","  logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))\n","\n","  # Cria o dataframe da lista\n","  lista_documentos_agrupados = pd.DataFrame(lista_documentos_agrupados, columns = [\"id\",\"sentencas\",\"documento\",\"classe\"])\n","\n","  # Corrige os tipos dos dados da lista agrupada\n","  tipos = {\"id\": str, \"sentencas\": object, \"documento\": str, \"classe\": int}\n","\n","  lista_documentos_agrupados = lista_documentos_agrupados.astype(tipos)\n","\n","  return lista_documentos_agrupados"],"metadata":{"id":"NUJBBHy8We0K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importa das bibliotecas\n","import pandas as pd\n","\n","print(\"Analisando documentos originais e perturbados\")\n","# Concatena as listas de documentos originais e perturbados\n","lista_documentos_agrupados = agruparDadosOriginaisPerturbados(lista_documentos_originais, lista_documentos_perturbados_indexado)\n","lista_documentos_agrupados_pos = pd.concat([lista_documentos_originais_pos, lista_documentos_perturbados_pos])\n","\n","# Corrige o tipo de dado da coluna id da lista\n","tipos = {\"id\": str}\n","lista_documentos_agrupados_pos = lista_documentos_agrupados_pos.astype(tipos)"],"metadata":{"id":"wY3dqPGVdoHp","colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["85aeccb614b74c6983dbb1ee21f6a045","59d9499bd6974ab981e6edf9495d2ebb","429ec1dec6ed49d28056f7179c160086","ca29e82bb519412186157f00420279f2","fac17fbebeb14000b06129839eba9eb4","27e108c119b845f58a9d0f79d007a095","60e17dfdfca44238a359108850eb829a","4eadfb7243044e46a1d35af9a50001f8","848eef1562da4d91b6643ddf9a38e1bf","ca7d7273cc034aadb4ce24e69969a577","d715f4d4814d47e28d16303755f354cd"]},"executionInfo":{"status":"ok","timestamp":1664833389160,"user_tz":180,"elapsed":31,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"d6df8136-f346-44ed-ee82-136151d52f68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Analisando documentos originais e perturbados\n","Processando 20 documentos originais\n"]},{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/1 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85aeccb614b74c6983dbb1ee21f6a045"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO AGRUPAMENTO: 21.\n"]}]},{"cell_type":"code","source":["logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"],"metadata":{"id":"AFvbzDbwdrYx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664833389161,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"344482b1-b0e4-4837-e721-d27f7f9680ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO AGRUPAMENTO: 21.\n"]}]},{"cell_type":"code","source":["lista_documentos_agrupados.sample(1)"],"metadata":{"id":"a5ZV4jzAWe0K","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1664833389161,"user_tz":180,"elapsed":25,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"outputId":"dd18e21a-2fae-44b6-dfd5-b8bd39c2dd14"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              id                                          sentencas  \\\n","18  13p0_pert_17  [O que é uma pilha e como usar um elemento nel...   \n","\n","                                           documento  classe  \n","18  O que é uma pilha e como usar um elemento nela ?       0  "],"text/html":["\n","  <div id=\"df-2f3d5cb6-a360-4bbe-803b-0dd9613e7e54\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>18</th>\n","      <td>13p0_pert_17</td>\n","      <td>[O que é uma pilha e como usar um elemento nel...</td>\n","      <td>O que é uma pilha e como usar um elemento nela ?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f3d5cb6-a360-4bbe-803b-0dd9613e7e54')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2f3d5cb6-a360-4bbe-803b-0dd9613e7e54 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2f3d5cb6-a360-4bbe-803b-0dd9613e7e54');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1416}]},{"cell_type":"code","source":["logging.info(\"TERMINADO AGRUPAMENTO POS: {}.\".format(len(lista_documentos_agrupados_pos)))"],"metadata":{"id":"4mCqTRecWe0L","executionInfo":{"status":"ok","timestamp":1664833389161,"user_tz":180,"elapsed":24,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0d9285cc-fcce-43d8-8b9e-1d465f791e68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:TERMINADO AGRUPAMENTO POS: 420.\n"]}]},{"cell_type":"markdown","source":["#### Criar dados indexados"],"metadata":{"id":"viicg1E7mXLK"}},{"cell_type":"code","source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_indexado = lista_documentos_agrupados.set_index([\"id\"])\n","lista_documentos_agrupados_indexado.head()"],"metadata":{"id":"0YBdkvoPm2vO","executionInfo":{"status":"ok","timestamp":1664833389162,"user_tz":180,"elapsed":19,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"9536bd30-242f-4281-b1a1-be2d4148b038"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     sentencas  \\\n","id                                                               \n","13p0         [O que é uma pilha e como enfileirar um elemen...   \n","13p0_pert_0  [O que é uma pilha e como colocar um elemento ...   \n","13p0_pert_1  [O que é uma pilha e como adicionar um element...   \n","13p0_pert_2  [O que é uma pilha e como ligar um elemento ne...   \n","13p0_pert_3  [O que é uma pilha e como introduzir um elemen...   \n","\n","                                                     documento  classe  \n","id                                                                      \n","13p0         O que é uma pilha e como enfileirar um element...       1  \n","13p0_pert_0  O que é uma pilha e como colocar um elemento n...       0  \n","13p0_pert_1  O que é uma pilha e como adicionar um elemento...       0  \n","13p0_pert_2  O que é uma pilha e como ligar um elemento nela ?       0  \n","13p0_pert_3  O que é uma pilha e como introduzir um element...       0  "],"text/html":["\n","  <div id=\"df-7b8ccc10-eab6-4ff3-ab19-ba0ba81df11b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>13p0</th>\n","      <td>[O que é uma pilha e como enfileirar um elemen...</td>\n","      <td>O que é uma pilha e como enfileirar um element...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13p0_pert_0</th>\n","      <td>[O que é uma pilha e como colocar um elemento ...</td>\n","      <td>O que é uma pilha e como colocar um elemento n...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13p0_pert_1</th>\n","      <td>[O que é uma pilha e como adicionar um element...</td>\n","      <td>O que é uma pilha e como adicionar um elemento...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13p0_pert_2</th>\n","      <td>[O que é uma pilha e como ligar um elemento ne...</td>\n","      <td>O que é uma pilha e como ligar um elemento nela ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13p0_pert_3</th>\n","      <td>[O que é uma pilha e como introduzir um elemen...</td>\n","      <td>O que é uma pilha e como introduzir um element...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b8ccc10-eab6-4ff3-ab19-ba0ba81df11b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7b8ccc10-eab6-4ff3-ab19-ba0ba81df11b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7b8ccc10-eab6-4ff3-ab19-ba0ba81df11b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1418}]},{"cell_type":"code","source":["# Especifica o(s) campo(s) indexado(s) e faz uma cópia da lista indexada\n","lista_documentos_agrupados_pos_indexado = lista_documentos_agrupados_pos.set_index([\"id\"])\n","lista_documentos_agrupados_pos_indexado.head()"],"metadata":{"id":"NQjlOJzOmbsp","executionInfo":{"status":"ok","timestamp":1664833389163,"user_tz":180,"elapsed":19,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"4d54f3eb-78a1-40ad-e3fe-a6fcd5dc4c13"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         pos_documento\n","id                                                    \n","1p0  [[[Como, enfileirar, elementos, em, uma, pilha...\n","2p0  [[[Como, desenfileirar, elementos, em, uma, pi...\n","3p0  [[[Como, empilhar, elementos, em, uma, fila, ?...\n","4p0  [[[Como, empilhar, e, desempilhar, elementos, ...\n","5p0  [[[Como, empilhar, elementos, em, uma, estrutu..."],"text/html":["\n","  <div id=\"df-3e74c3de-74a5-4fe3-8dc6-a9970d015039\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1p0</th>\n","      <td>[[[Como, enfileirar, elementos, em, uma, pilha...</td>\n","    </tr>\n","    <tr>\n","      <th>2p0</th>\n","      <td>[[[Como, desenfileirar, elementos, em, uma, pi...</td>\n","    </tr>\n","    <tr>\n","      <th>3p0</th>\n","      <td>[[[Como, empilhar, elementos, em, uma, fila, ?...</td>\n","    </tr>\n","    <tr>\n","      <th>4p0</th>\n","      <td>[[[Como, empilhar, e, desempilhar, elementos, ...</td>\n","    </tr>\n","    <tr>\n","      <th>5p0</th>\n","      <td>[[[Como, empilhar, elementos, em, uma, estrutu...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e74c3de-74a5-4fe3-8dc6-a9970d015039')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3e74c3de-74a5-4fe3-8dc6-a9970d015039 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3e74c3de-74a5-4fe3-8dc6-a9970d015039');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1419}]},{"cell_type":"markdown","source":["### 5.1.6 Funções auxiliares"],"metadata":{"id":"pnY7O9zb8n8Z"}},{"cell_type":"markdown","source":["#### getIndicePalavraPerturbada\n","\n","Retorna o índice da palavra perturbada em um documento"],"metadata":{"id":"KhhvmLDQbg4z"}},{"cell_type":"code","source":["def getIndicePalavraPerturbada(_id_perturbado):\n","\n","  # print(\"_id_perturbado:\",_id_perturbado)\n","\n","  # localiza os dados do documento perturbado mascarado\n","  reg_documento_perturbado = lista_documentos_perturbados_indexado.loc[_id_perturbado]\n","\n","  # Recupera a lista das sentenças perturbadas\n","  lista_sentencas_mascarada = reg_documento_perturbado[2]\n","\n","  # Índice da sentença perturbada\n","  index_sentenca = -1\n","\n","  # Percorre as sentenças para encontrar a sentença perturbada\n","  for i, linha in enumerate(lista_sentencas_mascarada):\n","\n","    # Identifica a sentença mascarada que foi perturbada\n","    if 'MASK' in linha[0] :\n","      # Recupera a palavra mascarada sentença do documento perturbado\n","      index_sentenca = i\n","      sentenca_mascarada = linha[0]\n","      palavra_mascarada = linha[1]\n","      token_predito = linha[2]\n","      peso_predito = linha[3]\n","\n","\n","  # localiza os dados do documento perturbado pos\n","  reg_documento_perturbado_pos = lista_documentos_perturbados_pos_indexado.loc[_id_perturbado]\n","  # print(\"reg_documento_perturbado_pos:\",reg_documento_perturbado_pos)\n","\n","  # Recupera as POS Tagging do documento perturbado\n","  tokens_perturbado_index_palavra = []\n","\n","  # Recupera os pos das sentenças\n","  pos_documento_perturbado = reg_documento_perturbado_pos['pos_documento']\n","  # print(\"pos_documento_perturbado:\",pos_documento_perturbado)\n","\n","  # Percorre as sentenças do documento\n","  for i, linha1 in enumerate(pos_documento_perturbado):\n","    # print(\"linha1:\", linha1)\n","\n","    # Percorre os tokens da sentença\n","    for j, linha2 in enumerate(linha1[0]):\n","      # print(\"linha2:\", linha2)\n","      # Localiza o indice da palavra perturbada na sentença\n","      if token_predito == linha2:\n","        # Guarda o indice da palavra perturbada\n","        tokens_perturbado_index_palavra.append(j)\n","\n","  # Verifica se encontrou o índice da palavra perturbada\n","  if len(tokens_perturbado_index_palavra) != 0:\n","      # Possui somente uma palavra perturbada\n","      if len(tokens_perturbado_index_palavra) == 1:\n","        return tokens_perturbado_index_palavra[0]\n","      else:\n","        return tokens_perturbado_index_palavra\n","  else:\n","    # Não encontrou o índice da palavra perturbada\n","    return -1"],"metadata":{"id":"509NcnQNUnDN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getIndicePerturbacao(_id_documento):\n","\n","  id_documento_perturbado = \"\"\n","\n","  # Verifica o tipo do documento\n","  #if int(_id_documento)/2 == 1:\n","  if \"_pert_\" in _id_documento:\n","    # Documento perturbado\n","    id_documento_perturbado = _id_documento\n","\n","  else:\n","    # Pega o primeiro documento perturbado para localizar posição\n","    id_documento_perturbado = _id_documento + \"_pert_0\"\n","    #id_documento_perturbado = str(int(_id_documento) + 1)\n","\n","  # Retorna o índice\n","  index_perturbacao = getIndicePalavraPerturbada(id_documento_perturbado)\n","\n","  return index_perturbacao"],"metadata":{"id":"20I7k_2M-rin"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xuM-kq1upR3M"},"source":["## 5.2 Gera os arquivos para o Embedding Projector"]},{"cell_type":"markdown","metadata":{"id":"8FRocbK4_wTk"},"source":["### 5.2.1 Cria o diretório para os arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OaGALkXc_zLl","executionInfo":{"status":"ok","timestamp":1664833389606,"user_tz":180,"elapsed":17,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c79126e8-c6fd-4d84-94e8-f14c6ba162a0"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Diretório já existe: /content/COHQUAD_IN_PTBR/projector\n"]}],"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL + \"projector\"\n","\n","if not os.path.exists(dirbase):\n","    # Cria o diretório\n","    os.makedirs(dirbase)\n","    logging.info(\"Diretório criado: {}\".format(dirbase))\n","else:\n","    logging.info(\"Diretório já existe: {}\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"eFugAWlm1VfN"},"source":["### 5.2.2 Gera os embeddings dos documentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"maBbfHFj1VfN","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["52db2976e12540869081eba2c48b44c1","b13134ae39ee42ea841435693c07a500","15f480af9da24be7b080601dec75b55e","da926fd2a0d54683adb0a00879b4dfe0","b80f33fc3a604d0fb4a35d9dfd070e67","c9e7589c46d540858c5ecd1c352b438e","5d531d053bf7426fb0b9ff84fd4d219d","cfdef08811024a1f86be4804d41958af","c061b1e3a53c477ba66e388b82fb14e3","c49b9b6b16e442a1b0159a3f6a391b08","0fd24aec536d4ffeb0b4d165d0b21112"]},"outputId":"e5b3af63-4d8c-48c6-f940-8e682179c5df"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Documentos:   0%|          | 0/21 [00:00<?, ? documento/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52db2976e12540869081eba2c48b44c1"}},"metadata":{}}],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","lista_embeddings = []\n","lista_embeddings_documento = []\n","lista_documentos = []\n","lista_documentos_tokenizado = []\n","lista_documentos_tokenizado_oov = []\n","lista_documentos_pos = []\n","lista_documentos_classe = []\n","lista_documentos_id = []\n","lista_documentos_origem = []\n","\n","maior_sequencia = 0\n","\n","total_tokens = 0\n","\n","if CLASSE_DOCUMENTO != 2:\n","  documentos = lista_documentos_agrupados.loc[lista_documentos_agrupados['classe'] == CLASSE_DOCUMENTO]\n","else:\n","  documentos = lista_documentos_agrupados\n","\n","# Barra de progresso dos documentos\n","documentos_bar = tqdm_notebook(documentos.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(documentos))\n","\n","# Percorre os documentos\n","for i, linha_documento in documentos_bar:\n","\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    # print(\"id_documento:\",id_documento)\n","    # print(\"linha_documento['documento']:\", linha_documento['documento'])\n","\n","    # Recupera a classe documento (1-original 0-perturbado)\n","    classe = linha_documento['classe']\n","    #print(\"classe:\",classe)\n","\n","    # Localiza a POSTagging do documento agrupado\n","    lista_pos_documento = lista_documentos_agrupados_pos_indexado.loc[id_documento][0]\n","    # print(\"lista_pos_documento:\",lista_pos_documento)\n","    # print(\"len(lista_pos_documento):\",len(lista_pos_documento))\n","\n","    # Troca o documento por uma versão da concatenação das palavras geradas pelo spaCy\n","    # Percorre a lista_pos concatenando a posição 0 dos tokens\n","    documento_concatenado = \" \".join(concatenaListas(lista_pos_documento, pos=0))\n","    # print(\"documento_concatenado:\", documento_concatenado)\n","    documento = documento_concatenado\n","\n","    if CLASSE_DOCUMENTO != 1:\n","      # Recupera a posição do traço no id do arquivo\n","      traco_ix = id_documento.find(\"_\")\n","      if traco_ix != -1:\n","        # Recupera o id da perturbacao até a posição do traço até o fim\n","        id_perturbacao = id_documento[:traco_ix]\n","      else:\n","        id_perturbacao = id_documento\n","\n","    if POOLING_TOKENS == 0:\n","\n","        # Recupera os embeddings\n","        if ESTRATEGIA_EMBEDDING == 1:\n","          # Gera embeddings da última camada do BERT\n","          token_embeddings, documento_tokenizado =  getEmbeddingsUltimaCamada(documento, model, tokenizer)\n","        else:\n","          # Gera embeddings concatenando as 4 últimas camadas do BERT\n","          token_embeddings, documento_tokenizado = getEmbeddingsConcat4UltimasCamadas(documento, model, tokenizer)\n","\n","        # Guarda o maior tamanho de documento\n","        if len(documento_tokenizado) > maior_sequencia:\n","            maior_sequencia =  len(documento_tokenizado)\n","\n","        # Guarda o total de tokens dos documentos\n","        total_tokens = total_tokens + len(documento_tokenizado)\n","\n","        # Guarda os embeddings e o documento tokenizado\n","        lista_embeddings.append(token_embeddings)\n","        # Guarda os embeddings do documento consolidado pela média e removendo os tokens [CLS] e [SEP]\n","        lista_embeddings_documento.append(torch.mean(token_embeddings[1:-1], dim=0))\n","        lista_documentos.append(documento)\n","        lista_documentos_tokenizado.append(documento_tokenizado)\n","        lista_documentos_classe.append(classe)\n","        lista_documentos_id.append(id_documento)\n","        if CLASSE_DOCUMENTO != 1:\n","          lista_documentos_origem.append(id_perturbacao)\n","\n","    else:\n","        # Recupera os embeddings\n","        if ESTRATEGIA_EMBEDDING == 1:\n","          # Gera embeddings da última camada do BERT\n","          token_embeddings, documento_tokenizado =  getEmbeddingsUltimaCamada(documento, model, tokenizer)\n","        else:\n","          # Gera embeddings concatenando as 4 últimas camadas do BERT\n","          token_embeddings, documento_tokenizado = getEmbeddingsConcat4UltimasCamadas(documento, model, tokenizer)\n","\n","        # Combina os embeddings de palavras fora do vocabulário do BERT\n","        listaTokens, listaPOS, lista_tokens_OOV, listaEmbeddingsMEAN, listaEmbeddingsMAX =  getTokensEmbeddingsPOSSentenca(token_embeddings[1:-1],\n","                                                                                                        documento_tokenizado[1:-1],\n","                                                                                                        documento)\n","\n","        # Guarda o maior tamanho de documento\n","        if len(listaTokens) > maior_sequencia:\n","            maior_sequencia =  len(listaTokens)\n","\n","        # Guarda o total de tokens dos documentos\n","        total_tokens = total_tokens + len(listaTokens)\n","\n","        # Guarda os embeddings e os os outros dados do documento\n","        lista_embeddings.append(listaEmbeddingsMEAN)\n","        # Guarda os embeddings do documento consolidado pela média e removendo os tokens [CLS] e [SEP]\n","        lista_embeddings_documento.append(torch.mean(token_embeddings[1:-1], dim=0))\n","        lista_documentos.append(documento)\n","        lista_documentos_tokenizado.append(listaTokens)\n","        lista_documentos_tokenizado_oov.append(lista_tokens_OOV)\n","        lista_documentos_pos.append(listaPOS)\n","        lista_documentos_classe.append(classe)\n","        lista_documentos_id.append(id_documento)\n","        if CLASSE_DOCUMENTO != 1:\n","          lista_documentos_origem.append(id_perturbacao)"]},{"cell_type":"markdown","metadata":{"id":"VOyrUs1d1VfO"},"source":["Mostra um documento processado."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLp3DWq61VfO"},"outputs":[],"source":["print(len(lista_embeddings[0]))\n","print(lista_documentos_tokenizado[0])\n","print(lista_documentos_classe[0])"]},{"cell_type":"markdown","metadata":{"id":"apK3F5W41VfO"},"source":["Quantidade de tokens nos documentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQvbl4XE1VfP"},"outputs":[],"source":["print(\"Quantidade de tokens:\", total_tokens)"]},{"cell_type":"markdown","metadata":{"id":"qvVjozxA1VfP"},"source":["Maior tamanho  de documento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gvZGxIp1VfP"},"outputs":[],"source":["print(\"max_seq_length:\", maior_sequencia)"]},{"cell_type":"markdown","metadata":{"id":"za-9WAYO1VfQ"},"source":["### 5.2.3 Gera os arquivos para o Embedding Projector"]},{"cell_type":"markdown","source":["Gera o sufixo do nome do arquivo"],"metadata":{"id":"R9zqngHokA0-"}},{"cell_type":"code","source":["def getSufixoNomeArquivo():\n","\n","  sufixo_arquivo = \"_\"\n","\n","  # Documento perturbados\n","  if CLASSE_DOCUMENTO == 0:\n","      sufixo_arquivo = sufixo_arquivo + \"PERTDO\" + \"_P\" + str(DOCUMENTOS_PERTURBADOS)\n","  else:\n","    # Documento originais\n","    if CLASSE_DOCUMENTO == 1:\n","      sufixo_arquivo = sufixo_arquivo + \"DO\"\n","    else:\n","      # Documento originais e perturbados\n","      if CLASSE_DOCUMENTO == 2:\n","        sufixo_arquivo = sufixo_arquivo + \"DO_PERTDO\"  + \"_P\" + str(DOCUMENTOS_PERTURBADOS) + \"_CLASSE\"\n","\n","  # Sem pooling dos tokens\n","  if POOLING_TOKENS == 0:\n","    # Tamanho dos embeddings\n","    sufixo_arquivo = sufixo_arquivo + \"_\" + str(lista_embeddings[0].size()[1]) + TAMANHO_BERT\n","\n","    # Não possui o prefixo pooling\n","  else:\n","    # Com pooling dos tokens\n","    if POOLING_TOKENS == 1:\n","      sufixo_arquivo = sufixo_arquivo + \"_\" + str(lista_embeddings[0][0].size()[0]) + TAMANHO_BERT\n","\n","      # Adiciona o prefixo\n","      sufixo_arquivo = sufixo_arquivo + \"_POOL\"\n","\n","  return sufixo_arquivo"],"metadata":{"id":"RNiX8OU7K4-G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCR6vo371VfQ"},"source":["Arquivos com os valores dos embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbILMYpG1VfQ"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","import csv\n","\n","# Recupera o sufixo do nome do arquivo\n","sufixo_arquivo = getSufixoNomeArquivo()\n","#print(\"sufixo_arquivo:\", sufixo_arquivo)\n","\n","NOME_ARQUIVO_RECORD =  DIRETORIO_LOCAL + \"projector/\" + \"DO\" + FILTRO_DO[0] + \"_records_token_sentenca\" + sufixo_arquivo + \".tsv\"\n","\n","# Abre o arquivo\n","with open(NOME_ARQUIVO_RECORD, 'w', encoding='utf8') as tsvfile:\n","  # Cria um arquivo separado por tab\n","    writer = csv.writer(tsvfile, delimiter='\\t')\n","\n","    # Barra de progresso dos embedings\n","    lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","    # Percorre os embeddings\n","    for i, documento_embedding in lista_embeddings_bar:\n","\n","      if POOLING_TOKENS == 0:\n","        # Converte os tensores em numpy array\n","        documento_embedding_np =  documento_embedding.numpy()\n","\n","        # Qtde de tokens do documento\n","        length = len(lista_documentos_tokenizado[i])\n","\n","        # Escreve no arquivo os embeddings das palavras\n","        writer.writerows(documento_embedding_np[:length])\n","\n","      else:\n","        # Converte os tensores em numpy array\n","        documento_embedding_np = []\n","        for linha in documento_embedding:\n","            novo = linha.numpy()\n","            documento_embedding_np.append(novo)\n","\n","        # Qtde de tokens do documento\n","        length = len(lista_documentos_tokenizado[i])\n","\n","        # Escreve no arquivo os embeddings das palavras\n","        writer.writerows(documento_embedding_np[:length])\n","\n","      # Escreve no arquivo os embeddings do documento\n","      writer.writerows([lista_embeddings_documento[i].numpy()])"]},{"cell_type":"markdown","metadata":{"id":"mb580LQT1VfR"},"source":["Arquivo com os metadados dos embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XskFjQ5v1VfR"},"outputs":[],"source":["# Import das bibliotecas.\n","from tqdm.notebook import tqdm as tqdm_notebook\n","import csv\n","\n","# Recupera o sufixo do nome do arquivo\n","sufixo_arquivo = getSufixoNomeArquivo()\n","#print(\"sufixo_arquivo:\", sufixo_arquivo)\n","\n","NOME_ARQUIVO_META =  DIRETORIO_LOCAL + \"projector/\" + \"DO\" + FILTRO_DO[0] + \"_meta_token_sentenca\" + sufixo_arquivo + \".tsv\"\n","\n","# Abre o arquivo\n","with open(NOME_ARQUIVO_META, 'w', encoding='utf8') as tsvfile:\n","    # Define o escritor do arquivo\n","    writer = csv.writer(tsvfile, delimiter='\\t')\n","\n","    # Cabeçalho do arquivo\n","    # Sem pooling\n","    if POOLING_TOKENS == 0:\n","\n","      # Sem classe\n","      if CLASSE_DOCUMENTO != 2:\n","\n","        # Com o link da sequência de tokens da sentença\n","        if LIGACAO_PROXIMO_TOKEN == True:\n","\n","          # Escreve o cabeçalho do arquivo\n","          writer.writerow([\"Token\", \"Id\", \"Origem\", \"Index\", \"__next__\", \"Granularidade\", \"Tipo_Texto\", \"Sentença\"])\n","\n","          # Barra de progresso dos embedings\n","          lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","          # Contador da sequência\n","          conta_proximo = 1\n","\n","          # Percorre os embeddings\n","          for i, documento_embedding in lista_embeddings_bar:\n","\n","              # Qtde de tokens do documento\n","              length = len(lista_documentos_tokenizado[i])\n","\n","              # Escreve a palavra e sua sentença\n","              for j in range(length):\n","\n","                  # Transforma o conta_proximo que é o indicador da sequência em string\n","                  proximo = str(conta_proximo)\n","\n","                  # Incrementa o contador da sequência\n","                  conta_proximo = conta_proximo + 1\n","\n","                  # Monta o registro a ser salvo\n","                  s = [lista_documentos_tokenizado[i][j],\n","                       lista_documentos_id[i],\n","                       lista_documentos_origem[i],\n","                       str(j),\n","                       proximo,\n","                       \"0\",\n","                       lista_documentos_classe[i],\n","                       lista_documentos[i]]\n","\n","                  # Escreve o registro no arquivo\n","                  writer.writerow(s)\n","\n","              # Se chegou no último token da sequência coloca Branco para a próximo palavra\n","              proximo = \"\"\n","\n","              # Escreve o rótulo do documento\n","              # Monta o registro a ser salvo\n","              s = [str(i),\n","                   lista_documentos_id[i],\n","                   lista_documentos_origem[i],\n","                   \"-1\",\n","                   proximo,\n","                   \"1\",\n","                   lista_documentos_classe[i]+2,\n","                   lista_documentos[i]]\n","\n","              # Escreve o registro no arquivo\n","              writer.writerow(s)\n","\n","        else:\n","          # Sem o link de ligação dos tokens da sentença\n","          # Escreve o cabeçalho do arquivo\n","          writer.writerow([\"Token\", \"Id\", \"Origem\", \"Index\", \"Granularidade\", \"Tipo_Texto\", \"Sentença\"])\n","\n","          # Barra de progresso dos embedings\n","          lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","          # Percorre os embeddings\n","          for i, documento_embedding in lista_embeddings_bar:\n","              # Qtde de tokens do documento\n","              length = len(lista_documentos_tokenizado[i])\n","\n","              # Escreve a palavra e sua sentença\n","              for j in range(length):\n","\n","                # Monta o registro a ser salvo\n","                s = [lista_documentos_tokenizado[i][j],\n","                     lista_documentos_id[i],\n","                     lista_documentos_origem[i],\n","                     str(j),\n","                     \"0\",\n","                     lista_documentos_classe[i],\n","                     lista_documentos[i]]\n","\n","                # Escreve o registro no arquivo\n","                writer.writerow(s)\n","\n","          # Escreve o rótulo do documento\n","          # Monta o registro a ser salvo\n","          s = [str(i),\n","               lista_documentos_id[i],\n","               lista_documentos_origem[i],\n","               \"-1\",\n","               \"1\",\n","               lista_documentos_classe[i]+2,\n","               lista_documentos[i]]\n","\n","          # Escreve o registro no arquivo\n","          writer.writerow(s)\n","\n","      else:\n","        # Com classe\n","\n","        # Com o link da sequência de tokens da sentença\n","        if LIGACAO_PROXIMO_TOKEN == True:\n","\n","          # Escreve o cabeçalho do arquivo\n","          writer.writerow([\"Token\", \"Id\", \"Origem\", \"Classe\", \"Perturbada\", \"Index\", \"__next__\", \"Granularidade\", \"Tipo_Texto\", \"Sentença\"])\n","\n","          # Barra de progresso dos embedings\n","          lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","          # Contador da sequência\n","          conta_proximo = 1\n","\n","          # Percorre os embeddings\n","          for i, documento_embedding in lista_embeddings_bar:\n","\n","              # Qtde de tokens do documento\n","              length = len(lista_documentos_tokenizado[i])\n","\n","              # Procura o índice da palavra selecionada para perturbação no documento\n","              indice_palavra_perturbada = getIndicePerturbacao(lista_documentos_id[i])\n","\n","              # Escreve a palavra e sua sentença\n","              for j in range(length):\n","\n","                  # Transforma o conta_proximo que é o indicador da sequência em string\n","                  proximo = str(conta_proximo)\n","\n","                  # Incrementa o contador da sequência\n","                  conta_proximo = conta_proximo + 1\n","\n","                  # Identifica a posição da palavra selecionada para perturbação\n","                  perturbada = \"0\"\n","                  if indice_palavra_perturbada == j:\n","                    perturbada = \"1\"\n","\n","                  # Monta o registro a ser salvo\n","                  s = [lista_documentos_tokenizado[i][j],\n","                       lista_documentos_id[i],\n","                       lista_documentos_origem[i],\n","                       lista_documentos_classe[i],\n","                       perturbada,\n","                       \"-1\",\n","                       proximo,\n","                       \"0\",\n","                       lista_documentos_classe[i],\n","                       lista_documentos[i]\n","                      ]\n","\n","                  # Escreve o registro no arquivo\n","                  writer.writerow(s)\n","\n","              # Escreve o rótulo do documento\n","              # Se chegou no último token da sequência coloca Branco para a próximo palavra\n","              proximo = \"\"\n","\n","              # Incrementa o contador da sequência\n","              conta_proximo = conta_proximo + 1\n","\n","              # Monta o registro a ser salvo\n","              s = [str(i),\n","                   lista_documentos_id[i],\n","                   lista_documentos_origem[i],\n","                   lista_documentos_classe[i],\n","                   \"-1\",\n","                   \"-1\",\n","                   proximo,\n","                   \"1\",\n","                   lista_documentos_classe[i]+2,\n","                   lista_documentos[i]\n","                   ]\n","\n","              # Escreve o registro no arquivo\n","              writer.writerow(s)\n","\n","        else:\n","          # Com Classe\n","          #Sem o link\n","          # Escreve o cabeçalho do arquivo\n","          writer.writerow([\"Token\", \"Id\", \"Origem\", \"Classe\", \"Perturbada\", \"Index\", \"Granularidade\", \"Tipo_Texto\", \"Sentença\"])\n","\n","          # Barra de progresso dos embedings\n","          lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","          # Percorre os embeddings\n","          for i, documento_embedding in lista_embeddings_bar:\n","\n","              # Qtde de tokens do documento\n","              length = len(lista_documentos_tokenizado[i])\n","\n","              # Procura o índice da palavra selecionada para perturbação no documento\n","              indice_palavra_perturbada = getIndicePerturbacao(lista_documentos_id[i])\n","\n","              # Escreve a palavra e sua sentença\n","              for j in range(length):\n","\n","                # Identifica a posição da palavra selecionada para perturbação\n","                perturbada = \"0\"\n","                if indice_palavra_perturbada == j:\n","                  perturbada = \"1\"\n","\n","                # Monta o registro a ser salvo\n","                s = [lista_documentos_tokenizado[i][j],\n","                     lista_documentos_id[i],\n","                     lista_documentos_origem[i],\n","                     lista_documentos_classe[i],\n","                     perturbada,\n","                     str(j),\n","                     \"0\",\n","                     lista_documentos_classe[i],\n","                     lista_documentos[i]]\n","\n","                # Escreve o registro no arquivo\n","                writer.writerow(s)\n","\n","              # Escreve o rótulo do documento\n","              # Monta o registro a ser salvo\n","              s = [str(i),\n","                   lista_documentos_id[i],\n","                   lista_documentos_origem[i],\n","                   lista_documentos_classe[i],\n","                   \"-1\",\n","                   \"-1\",\n","                   \"1\",\n","                   lista_documentos_classe[i]+2,\n","                   lista_documentos[i]]\n","\n","              # Escreve o registro no arquivo\n","              writer.writerow(s)\n","\n","    else:\n","      # Com polling\n","      # Sem classe\n","      if CLASSE_DOCUMENTO != 2:\n","\n","        # Com o link da sequência de tokens da sentença\n","        if LIGACAO_PROXIMO_TOKEN == True:\n","\n","          # Escreve o cabeçalho do arquivo\n","          writer.writerow([\"Token\", \"POS-Tag\", \"OOV\", \"Id\", \"Origem\", \"Index\", \"__next__\", \"Granularidade\", \"Tipo_Texto\", \"Sentença\"])\n","\n","          # Barra de progresso dos embedings\n","          lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","          # Contador da sequência\n","          conta_proximo = 1\n","\n","          # Percorre os embeddings\n","          for i, documento_embedding in lista_embeddings_bar:\n","\n","              # Qtde de tokens do documento\n","              length = len(lista_documentos_tokenizado[i])\n","\n","              # Escreve a palavra e sua sentença\n","              for j in range(length):\n","\n","                # Transforma o conta_proximo que é o indicador da sequência em string\n","                proximo = str(conta_proximo)\n","\n","                # Incrementa o contador da sequência\n","                conta_proximo = conta_proximo + 1\n","\n","                # Monta o registro a ser salvo\n","                s = [lista_documentos_tokenizado[i][j],\n","                     lista_documentos_pos[i][j],\n","                     lista_documentos_tokenizado_oov[i][j],\n","                     lista_documentos_id[i],\n","                     lista_documentos_origem[i],\n","                     str(j),\n","                     proximo,\n","                     \"0\",\n","                     lista_documentos_classe[i],\n","                     lista_documentos[i]]\n","\n","                # Escreve o registro no arquivo\n","                writer.writerow(s)\n","\n","              # Escreve o rótulo do documento\n","              # Se chegou no último token da sequência coloca Branco para a próximo palavra\n","              proximo = \"\"\n","\n","              # Incrementa o contador da sequência\n","              conta_proximo = conta_proximo + 1\n","\n","              # Monta o registro a ser salvo\n","              s = [str(i),\n","                   lista_documentos_pos[i],\n","                   lista_documentos_tokenizado_oov[i],\n","                   lista_documentos_id[i],\n","                   lista_documentos_origem[i],\n","                   \"-1\",\n","                   proximo,\n","                   \"1\",\n","                   lista_documentos_classe[i]+2,\n","                   lista_documentos[i]]\n","\n","              # Escreve o registro no arquivo\n","              writer.writerow(s)\n","\n","        else:\n","            # Sem link de próximo\n","\n","            # Escreve o cabeçalho do arquivo\n","            writer.writerow([\"Token\", \"POS-Tag\", \"OOV\", \"Id\", \"Origem\", \"Index\", \"Granularidade\", \"Tipo_Texto\", \"Sentença\"])\n","\n","            # Barra de progresso dos embedings\n","            lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","            # Contador da sequência\n","            conta_proximo = 1\n","\n","            # Percorre os embeddings\n","            for i, documento_embedding in lista_embeddings_bar:\n","\n","                # Qtde de tokens do documento\n","                length = len(lista_documentos_tokenizado[i])\n","\n","                # Escreve a palavra e sua sentença\n","                for j in range(length):\n","\n","                  # Monta o registro a ser salvo\n","                  s = [lista_documentos_tokenizado[i][j],\n","                       lista_documentos_pos[i][j],\n","                       lista_documentos_tokenizado_oov[i][j],\n","                       lista_documentos_id[i],\n","                       lista_documentos_origem[i],\n","                       str(j),\n","                       \"0\",\n","                       lista_documentos_classe[i],\n","                       lista_documentos[i]\n","                       ]\n","\n","                  # Escreve o registro no arquivo\n","                  writer.writerow(s)\n","\n","            # Escreve o rótulo do documento\n","            # Monta o registro a ser salvo\n","            s = [str(i),\n","                 lista_documentos_pos[i],\n","                 lista_documentos_tokenizado_oov[i],\n","                 lista_documentos_id[i],\n","                 lista_documentos_origem[i],\n","                 str(i),\n","                 \"1\",\n","                 lista_documentos_classe[i]+2,\n","                 lista_documentos[i]\n","                 ]\n","\n","            # Escreve o registro no arquivo\n","            writer.writerow(s)\n","      else:\n","        # Com classe\n","\n","        # Com o link da sequência de tokens da sentença\n","        if LIGACAO_PROXIMO_TOKEN == True:\n","\n","          # Escreve o cabeçalho do arquivo\n","          writer.writerow([\"Token\", \"POS-Tag\", \"OOV\", \"Id\", \"Origem\", \"Classe\", \"Perturbada\", \"Index\", \"__next__\", \"Granularidade\", \"Tipo_Texto\", \"Sentença\"])\n","\n","          # Barra de progresso dos embedings\n","          lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","          # Contador da sequência\n","          conta_proximo = 1\n","\n","          # Percorre os embeddings\n","          for i, documento_embedding in lista_embeddings_bar:\n","\n","              # Qtde de tokens do documento\n","              length = len(lista_documentos_tokenizado[i])\n","\n","              # Procura o índice da palavra selecionada para perturbação no documento\n","              indice_palavra_perturbada = getIndicePerturbacao(lista_documentos_id[i])\n","\n","              # Escreve a palavra e sua sentença\n","              for j in range(length):\n","\n","                # Transforma o conta_proximo que é o indicador da sequência em string\n","                proximo = str(conta_proximo)\n","\n","                # Incrementa o contador da sequência\n","                conta_proximo = conta_proximo + 1\n","\n","                # Identifica a posição da palavra selecionada para perturbação\n","                perturbada = \"0\"\n","                if indice_palavra_perturbada == j:\n","                  perturbada = \"1\"\n","\n","                # Monta o registro a ser salvo\n","                s = [lista_documentos_tokenizado[i][j],\n","                     lista_documentos_pos[i][j],\n","                     lista_documentos_tokenizado_oov[i][j],\n","                     lista_documentos_id[i],\n","                     lista_documentos_origem[i],\n","                     lista_documentos_classe[i],\n","                     perturbada,\n","                     str(j),\n","                     proximo,\n","                     \"0\",\n","                     lista_documentos_classe[i],\n","                     lista_documentos[i]\n","                    ]\n","\n","                # Escreve o registro no arquivo\n","                writer.writerow(s)\n","\n","              # Escreve o rótulo do documento\n","              # Se chegou no último token da sequência coloca Branco para a próximo palavra\n","              proximo = \"\"\n","\n","              # Incrementa o contador da sequência\n","              conta_proximo = conta_proximo + 1\n","\n","              # Monta o registro a ser salvo\n","              s = [str(i),\n","                   lista_documentos_pos[i],\n","                   lista_documentos_tokenizado_oov[i],\n","                   lista_documentos_id[i],\n","                   lista_documentos_origem[i],\n","                   lista_documentos_classe[i],\n","                   \"-1\",\n","                   \"-1\",\n","                   proximo,\n","                   \"1\",\n","                   lista_documentos_classe[i]+2,\n","                   lista_documentos[i]\n","                  ]\n","\n","              # Escreve o registro no arquivo\n","              writer.writerow(s)\n","\n","        else:\n","\n","          # Escreve o cabeçalho do arquivo\n","          writer.writerow([\"Token\", \"POS-Tag\", \"OOV\", \"Id\", \"Origem\", \"Classe\", \"Perturbada\", \"Index\", \"Granularidade\", \"Tipo_Texto\", \"Sentença\" ])\n","\n","          # Barra de progresso dos embedings\n","          lista_embeddings_bar = tqdm_notebook(enumerate(lista_embeddings), desc=f\"Embeddings\", unit=f\" embedding\", total=len(lista_embeddings))\n","\n","          # Percorre os embeddings\n","          for i, documento_embedding in lista_embeddings_bar:\n","\n","              # Qtde de tokens do documento\n","              length = len(lista_documentos_tokenizado[i])\n","\n","              # Procura o índice da palavra selecionada para perturbação no documento\n","              indice_palavra_perturbada = getIndicePerturbacao(lista_documentos_id[i])\n","\n","              # Identifica a posição da palavra selecionada para perturbação\n","              perturbada = \"0\"\n","              if indice_palavra_perturbada == j:\n","                perturbada = \"1\"\n","\n","              # Escreve a palavra e sua sentença\n","              for j in range(length):\n","                # Monta o registro a ser salvo\n","                s = [lista_documentos_tokenizado[i][j],\n","                     lista_documentos_pos[i][j],\n","                     lista_documentos_tokenizado_oov[i][j],\n","                     lista_documentos_id[i],\n","                     lista_documentos_origem[i],\n","                     lista_documentos_classe[i],\n","                     perturbada,\n","                     str(j),\n","                     \"0\",\n","                     lista_documentos_classe[i],\n","                     lista_documentos[i],\n","                    ]\n","\n","                # Escreve o registro no arquivo\n","                writer.writerow(s)\n","\n","              # Escreve o rótulo do documento\n","              # Monta o registro a ser salvo\n","              s = [str(i),\n","                   lista_documentos_pos[i],\n","                   lista_documentos_tokenizado_oov[i],\n","                   lista_documentos_id[i],\n","                   lista_documentos_origem[i],\n","                   lista_documentos_classe[i],\n","                   \"-1\",\n","                   \"-1\",\n","                   \"1\",\n","                   lista_documentos_classe[i]+2,\n","                   lista_documentos[i],\n","                   ]\n","\n","              # Escreve o registro no arquivo\n","              writer.writerow(s)"]},{"cell_type":"markdown","metadata":{"id":"S23zNSjM1VfR"},"source":["Faça o download dos arquivos **records_token_4096.tsv** e **meta_token_4096.tsv** e carregue em https://projector.tensorflow.org/ na opção load.\n","\n","Faça o download dos arquivos gerados pelo notebook clicando na lateral esquerda no ícone \"Arquivos\".\n","\n","Carrega os arquivos na ferramenta através do link \"Load\". Na opção existe um link botão para carregar o arquivo dos embeddings e um outro botão para carregar os metadados.\n","\n","Você também pode utilizar um link a um arquivo de configuração config.json com a referência aos arquivos em algum repositório publico na internet, por exemplo github ou gist\n","\n","Aqui um exemplo.\n","\n","https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/osmarbraz/cohebertv1projecao/main/config.json\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"t56ovS3Kt-W0"},"source":["### 5.3.4 Compacta e copia o arquivo do projetor para uma pasta do GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"MnElyyGbcmlV"},"source":["Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RGK7bu_P2F-m"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_PROJECTOR_COMPACTADO = \"projector.zip\""]},{"cell_type":"markdown","metadata":{"id":"5vZq_1sEtsB0"},"source":["Compacta os arquivos.\n","\n","Usa o zip para compactar:\n","*   `-r` Compacta o diretório\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NunMOJWR2O8H"},"outputs":[],"source":["!zip -r -o -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PROJECTOR_COMPACTADO\" \"$DIRETORIO_LOCAL\"\"/projector/\""]},{"cell_type":"markdown","metadata":{"id":"sw3p4ydkt-W-"},"source":["Copia o arquivo compactado para o GoogleDrive\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5c8sv10t-W_"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","    # Copia o arquivo original\n","    # !cp \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PROJECTOR_COMPACTADO\" \"$DIRETORIO_DRIVE\"\n","\n","    logging.info(\"Terminei a cópia\")"]},{"cell_type":"markdown","metadata":{"id":"NYBu_-xVdHe4"},"source":["## 5.3 Projeção dos embeddings"]},{"cell_type":"markdown","metadata":{"id":"68qT3LkGtRgg"},"source":["### Configuração"]},{"cell_type":"markdown","metadata":{"id":"PHLxY3piwAB-"},"source":["Verifica a versão do tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5A6v8akfdG6j"},"outputs":[],"source":["try:\n","  # %tensorflow_version só existe no Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","%load_ext tensorboard"]},{"cell_type":"markdown","metadata":{"id":"Xh5VnBHxtUS7"},"source":["Importa a biblioteca"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nABca5ukdPE_"},"outputs":[],"source":["# Importa de biblioteca\n","from tensorboard.plugins import projector"]},{"cell_type":"markdown","metadata":{"id":"ix1XJaMqtWqv"},"source":["### Configura o diretório dos logs e arquivos de configuração\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hj1SzSWAfZIJ"},"outputs":[],"source":["# Configure um diretório de logs\n","log_dir =\"/content/projector/\"\n","if not os.path.exists(log_dir):\n","    os.makedirs(log_dir)"]},{"cell_type":"markdown","metadata":{"id":"bI0SITtUsZMx"},"source":["### Cria os arquivos de configuração dos embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U9hYPvidYls"},"outputs":[],"source":["# Configura o projetor\n","config = projector.ProjectorConfig()\n","\n","# Configuração do primeiro conjunto de embeddings sem pooling\n","embedding = config.embeddings.add()\n","# Nome do tensor\n","embedding.tensor_name = \"Cohebert: concat 4 últimas camadas pool BERTimbau large\"\n","# Caminho para os metadados\n","embedding.metadata_path = NOME_ARQUIVO_META\n","# Caminho para os tensores\n","embedding.tensor_path = NOME_ARQUIVO_RECORD\n","# Salva o arquivo de configuração\n","projector.visualize_embeddings(log_dir, config)"]},{"cell_type":"markdown","metadata":{"id":"SkrnWNMLvpCq"},"source":["### Mata o processo\n","\n","Se executar novamente o notebook é necessário matar o processo do tensorprojector."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgTL4Ns2gINB"},"outputs":[],"source":["# Mata o processo do tensorboard\n","#!kill 407"]},{"cell_type":"markdown","metadata":{"id":"xlXJ7-Uytj3f"},"source":["### Visualizando a projeção\n","\n","Na caixa de seleção selecione \"PROJECTOR\" no lugar de \"INACTIVE\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoAAOlWXdf0t"},"outputs":[],"source":["# Agora execute o tensorboard nos dados de log que acabamos de salvar.\n","%tensorboard --logdir /content/projector"]}]}