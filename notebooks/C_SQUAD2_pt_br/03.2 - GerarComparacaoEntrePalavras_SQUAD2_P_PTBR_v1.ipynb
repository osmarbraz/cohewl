{"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# Gerar comparação entre palavras dos documentos originais das sentenças do SQUAD2 P(1,0%) pt-br\n","\n","Gera a comparação entre as palavras das sentenças dos documentos do conjunto de dados SQUAD2 10 pt-br utilizando os arquivos:\n","- `original.zip`\n","- `originalpos.zip`\n","- `perturbado_pX_kY.zip`\n","- `perturbadopos_pX_kY.zip`\n","\n","Nos nomes dos arquivos `perturbado_pX_kY.zip`,`perturbadopos_pX_kY.zip`, X é o número de documentos perturbados e Y o valor de top K predições.\n","\n","Cria o arquivo `comparacao_palavra_pX_kY.zip` com as comparações entre as palavras do documento, onde X é o número de documentos perturbados e Y o valor de top K predições.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YdeJCpYJcIsR"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"hxre__AhcIsS"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhDuOfA0cIsS"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicio_processamento = time.time()"]},{"cell_type":"markdown","metadata":{"id":"1GiKzdwxcIsS"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","metadata":{"id":"OPRnA-mk5-c4"},"source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj5TaAH_5-nB"},"outputs":[],"source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================\n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.\n","    \"\"\"\n","\n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):\n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","\n","    return DIRETORIO_COHEBERT"]},{"cell_type":"markdown","metadata":{"id":"yDCOeh2y5jOH"},"source":["Realiza o download e um arquivo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B1mvfAU5jZf"},"outputs":[],"source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","import os # Biblioteca para manipular arquivos\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"\n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","\n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.\n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","\n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download\n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]\n","\n","    # Define o nome e caminho do arquivo temporário\n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","\n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","\n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:\n","        tamanho_conteudo = data.headers.get(\"Content-Length\")\n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)\n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):\n","            if chunk:\n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","\n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","\n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"guymfKlMcIsU"},"source":["Remove tags de um documento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCuxVFFJcIsU"},"outputs":[],"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","\n","    import re\n","\n","    documento_limpo = re.compile(\"<.*?>\")\n","    return re.sub(documento_limpo, \"\", documento)"]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jirIzIstLea0"},"outputs":[],"source":["def carregar(nomeArquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nomeArquivo, \"r\", encoding= encoding)\n","\n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC9Xppq-_R0w"},"outputs":[],"source":["def carregarLista(nomeArquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.\n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nomeArquivo, \"r\", encoding= encoding)\n","\n","    sentencas = []\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","\n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkVk5LQT_G3f"},"outputs":[],"source":["def salvar(nomeArquivo,texto):\n","    \"\"\"\n","      Salva um texto em arquivo.\n","\n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.\n","    \"\"\"\n","\n","    arquivo = open(nomeArquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"]},{"cell_type":"markdown","metadata":{"id":"aYpeBWk_cIsW"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQqiIUMgcIsW"},"outputs":[],"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempoArredondado = int(round((tempo)))\n","\n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempoArredondado))"]},{"cell_type":"markdown","metadata":{"id":"djVBA8nAcIsX"},"source":["Classe(ModelArguments) de definição dos parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZzZYhBccIsX"},"outputs":[],"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )\n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )\n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )\n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )"]},{"cell_type":"markdown","metadata":{"id":"HIN413rj50EI"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxV4-3Yg50EI"},"outputs":[],"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"VMbijgTCcIsY"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ciuNmOTcIsZ"},"outputs":[],"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\")\n","\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"-4SxfOZ9cIsZ"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ntfwS0amcIsZ"},"outputs":[],"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"]},{"cell_type":"markdown","metadata":{"id":"yuHoA4Dx6K1M"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"0zhAltEP6K1M"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"IxAlgXv66K1M"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cmva6ltA6K1M"},"outputs":[],"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))\n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"]},{"cell_type":"markdown","metadata":{"id":"XrC2SG3x6K1M"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOnQUkWZ6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def getDeviceGPU():\n","    \"\"\"\n","    Retorna um dispositivo de GPU se disponível ou CPU.\n","\n","    Retorno:\n","    `device` - Um device de GPU ou CPU.\n","    \"\"\"\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","\n","        # Diz ao PyTorch para usar GPU.\n","        device = torch.device(\"cuda\")\n","\n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:\n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","\n","    return device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WcMhNxsE6K1N"},"outputs":[],"source":["device = getDeviceGPU()"]},{"cell_type":"markdown","metadata":{"id":"kkdlEouHftcJ"},"source":["Conecta o modelo ao device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-znVDGyfsVx"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def conectaGPU(model, device):\n","    \"\"\"\n","      Conecta um modelo BERT a GPU.\n","\n","      Parâmetros:\n","        `model` - Um modelo BERT carregado.\n","        `device` - Um device de GPU.\n","\n","      Retorno:\n","        `model` - Um objeto model BERT conectado a GPU.\n","    \"\"\"\n","    # Associa a GPU ao modelo.\n","    model.to(device)\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        # Diga ao pytorch para rodar este modelo na GPU.\n","        logging.info(\"Pytorch rodando o modelo na GPU.\")\n","        model.cuda()\n","\n","    else:\n","        logging.info(\"Pytorch rodando sem GPU.\")\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"CRdtvR_J6K1N"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSmGz55H6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"]},{"cell_type":"markdown","metadata":{"id":"PSaUsPWVcIse"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21670,"status":"ok","timestamp":1660729887530,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"DewRGMbdcIsf","outputId":"edb9075a-4ccf-4ce8-f6d4-6770d8b6d281"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Import das bibliotecas.\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"IGyzBEKkcIsf"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"qO2-mx1LcIsf"},"source":["Instalação"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13085,"status":"ok","timestamp":1660729900612,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"cpLi-Uw_cIsg","outputId":"b5e18d2d-43cd-4d12-ec0f-b0fa59349d72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.1-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 55.6 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 55.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 63.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 69.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 68.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 62.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 57.5 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=6bceb1d3444855fe23fd412580623c7697f36bb209120bbabd32aab289c5cd55\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.1\n"]}],"source":["!pip install --upgrade wandb"]},{"cell_type":"markdown","metadata":{"id":"UfB5lrD9cIsg"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"elapsed":18092,"status":"ok","timestamp":1660729918695,"user":{"displayName":"Osmar Oliveira Braz Junior","userId":"03010865824982624199"},"user_tz":180},"id":"dWXrJ-99cIsg","outputId":"c60e7a30-84a3-4df1-a482-cefd7cd5affe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-65.0.2-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\n","Successfully installed pip-22.2.2 setuptools-65.0.2\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{},"output_type":"display_data"}],"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hFvzvhKicIsh","outputId":"612f60bf-7711-4178-931d-115c16d94a29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.64.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.8)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.7)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.10.1)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.7.8)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.4.4)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (65.0.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.3.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.6)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.6.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typing-extensions, pydantic, thinc, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.1.1\n","    Uninstalling typing_extensions-4.1.1:\n","      Successfully uninstalled typing_extensions-4.1.1\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.9.1\n","    Uninstalling pydantic-1.9.1:\n","      Successfully uninstalled pydantic-1.9.1\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.0\n","    Uninstalling thinc-8.1.0:\n","      Successfully uninstalled thinc-8.1.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.1\n","    Uninstalling spacy-3.4.1:\n","      Successfully uninstalled spacy-3.4.1\n"]}],"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"]},{"cell_type":"markdown","metadata":{"id":"OzF4qCTwcIsh"},"source":["## 1.9 Instalação do BERT"]},{"cell_type":"markdown","metadata":{"id":"dLxMA4eScIsh"},"source":["Instala a interface pytorch para o BERT by Hugging Face.\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"s76PzgsJcIsi","outputId":"86f1f59a-c0d4-4b7d-eabb-e5bfdf608e0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2022.6.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=f03d22199f88a00c0a08f7481613f541a0d318717c00308a774c64938861d309\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install -U transformers==4.5.1"]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","metadata":{"id":"ifrYNTwGwKal"},"source":["## Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5uiH9pNpwI6g"},"outputs":[],"source":["# Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 100\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 100"]},{"cell_type":"markdown","metadata":{"id":"mhByVujAwNAU"},"source":["## Específicos"]},{"cell_type":"markdown","metadata":{"id":"Mhkc9sW21zV7"},"source":["Parâmetros do modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oJ15-ylRRRdD"},"outputs":[],"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosMedida(\n","    max_seq_len = 512,\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",\n","    pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","    modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","    versao_modelo_spacy = \"3.2.0\",\n","    sentenciar_documento = False,\n","    do_lower_case = False, # default True\n","    output_attentions = False, # default False\n","    output_hidden_states = True, # default False, se True retorna todas as camadas do modelo para as operações de soma e concatenação\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path.\n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100, 500 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",")"]},{"cell_type":"markdown","metadata":{"id":"WlF4PKP6Iopi"},"source":["## Nome do diretório dos arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"55PNP2s6Iopi"},"outputs":[],"source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"SQUAD2_P\""]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","metadata":{"id":"PWd_9X0nOYnF"},"source":["### Função download modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DjWGu-9D5URZ"},"outputs":[],"source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","metadata":{"id":"XAc1tSwvOc4d"},"source":["### Função descompacta modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Dq9PnXO77bPQ"},"outputs":[],"source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","\n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","\n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivo_tar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")\n","    arquivo_tar.extractall(DIRETORIO_COHEBERT)\n","    arquivo_tar.close()\n","\n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):\n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","metadata":{"id":"3iFBoyWMOgKz"},"source":["### Função carrega modelo spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ePOccj0s8WMg"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","\n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.\n","    \"\"\"\n","\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp"]},{"cell_type":"markdown","metadata":{"id":"cAk5hHx7OnHn"},"source":["### Carrega o modelo spaCy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["8044b6d0e7234c68abc3732ffee7b67c"]},"id":"nbELnrpgA4T1","outputId":"8dc2d22a-ebdc-4b2b-cc46-a0897f128722"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8044b6d0e7234c68abc3732ffee7b67c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/577M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","metadata":{"id":"AEzytjZi5Iw2"},"source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zKg-_XyWoy8o"},"outputs":[],"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","\n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.\n","    \"\"\"\n","\n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords"]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"s1o8jevtoy8p","outputId":"f076c472-f5be-41e5-b32c-0392f5066b4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'pelos', 'quer', 'quero', 'somente', 'sua', 'povo', 'partir', 'aqueles', 'último', 'sabe', 'todos', 'uma', 'bom', 'sexta', 'assim', 'local', 'nuns', 'breve', 'põem', 'dentro', 'cedo', 'cada', 'final', 'ir', 'nos', 'dá', 'nova', 'pelo', 'cima', 'onze', 'te', 'isto', 'à', 'aí', 'tiveram', 'direita', 'coisa', 'corrente', 'perto', 'fazemos', 'seis', 'quinto', 'apoio', 'adeus', 'inicio', 'se', 'dois', 'zero', 'esse', 'cujo', 'estivemos', 'entre', 'que', 'maiorias', 'conhecido', 'sem', 'oito', 'nem', 'meu', 'cinco', 'onde', 'nós', 'és', 'dessa', 'minha', 'com', 'mês', 'certeza', 'fará', 'fazia', 'tais', 'apoia', 'ligado', 'vezes', 'logo', 'tiveste', 'tendes', 'estes', 'eu', 'debaixo', 'vai', 'mas', 'este', 'nas', 'bastante', 'fostes', 'aquela', 'somos', 'deste', 'outra', 'o', 'vens', 'um', 'até', 'contudo', 'porque', 'para', 'foi', 'naquela', 'alguns', 'ambas', 'vosso', 'dos', 'estará', 'próprio', 'nunca', 'qual', 'duas', 'favor', 'terceiro', 'estiveste', 'ponto', 'tivestes', 'quinta', 'tudo', 'tanta', 'pegar', 'acerca', 'vão', 'tivemos', 'mil', 'às', 'irá', 'também', 'custa', 'outras', 'dezanove', 'exemplo', 'iniciar', 'vossa', 'falta', 'portanto', 'pois', 'quinze', 'saber', 'pelas', 'as', 'ora', 'pela', 'apontar', 'faço', 'tua', 'vem', 'nesta', 'após', 'longe', 'tens', 'máximo', 'obrigado', 'parece', 'estiveram', 'num', 'vós', 'daquela', 'só', 'ainda', 'três', 'ademais', 'tanto', 'enquanto', 'ambos', 'baixo', 'ou', 'põe', 'quieto', 'posição', 'algo', 'poder', 'poderá', 'todo', 'é', 'antes', 'através', 'outros', 'segundo', 'todas', 'porquanto', 'quanto', 'no', 'você', 'caminho', 'dezassete', 'estava', 'quieta', 'certamente', 'quarta', 'essa', 'porquê', 'fim', 'por', 'esteve', 'estar', 'grandes', 'mesmo', 'foste', 'estive', 'terceira', 'aos', 'como', 'embora', 'for', 'tentaram', 'relação', 'muitos', 'vez', 'agora', 'lado', 'nove', 'grande', 'vêm', 'posso', 'forma', 'os', 'estás', 'está', 'ela', 'fora', 'querem', 'quatro', 'lhe', 'da', 'me', 'sistema', 'na', 'tarde', 'tão', 'vinda', 'vinte', 'fui', 'então', 'pôde', 'estas', 'tive', 'demais', 'pouca', 'e', 'uns', 'menos', 'deverá', 'desse', 'sob', 'novas', 'dão', 'contra', 'ser', 'das', 'questão', 'tempo', 'pode', 'seria', 'meio', 'foram', 'minhas', 'treze', 'possivelmente', 'são', 'tem', 'quem', 'tuas', 'área', 'nível', 'dar', 'teus', 'vais', 'geral', 'tentar', 'vossas', 'teve', 'dizer', 'novo', 'cá', 'nossos', 'a', 'neste', 'eventual', 'sexto', 'qualquer', 'toda', 'dez', 'mais', 'estou', 'cuja', 'de', 'tu', 'pontos', 'aquilo', 'nessa', 'bem', 'usa', 'nenhuma', 'lá', 'parte', 'tenho', 'conhecida', 'daquele', 'fomos', 'maioria', 'numa', 'temos', 'números', 'novos', 'esses', 'diz', 'conselho', 'valor', 'grupo', 'nossa', 'ele', 'tal', 'muito', 'possível', 'aqui', 'doze', 'dezoito', 'naquele', 'sois', 'ter', 'inclusive', 'disso', 'usar', 'teu', 'ontem', 'puderam', 'apenas', 'elas', 'fazer', 'isso', 'desde', 'boa', 'lugar', 'podem', 'catorze', 'essas', 'momento', 'veja', 'vossos', 'sétima', 'fez', 'eles', 'esta', 'primeiro', 'depois', 'talvez', 'deve', 'próxima', 'nada', 'podia', 'ali', 'tentei', 'próximo', 'obrigada', 'mal', 'comprida', 'menor', 'desta', 'diante', 'cento', 'dizem', 'seus', 'quê', 'vários', 'sete', 'era', 'do', 'nesse', 'maior', 'nosso', 'em', 'quarto', 'sei', 'sempre', 'porém', 'nossas', 'tente', 'quando', 'ver', 'fazes', 'sétimo', 'pouco', 'umas', 'sobre', 'oitava', 'suas', 'meses', 'vindo', 'atrás', 'primeira', 'número', 'estão', 'além', 'devem', 'faz', 'aquele', 'vos', 'des', 'aquelas', 'não', 'comprido', 'fazem', 'oitavo', 'quais', 'fazeis', 'já', 'estado', 'tipo', 'estivestes', 'ao', 'sim', 'dezasseis', 'seu', 'meus', 'algumas', 'segunda', 'vocês', 'têm', 'sou'}\n"]}],"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6hdqVdfxm-_W"},"outputs":[],"source":["# Import das bibliotecas.\n","import spacy\n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ]\n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal\n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ]\n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},\n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar\n","               ]\n","\n","matcherv = Matcher(nlp.vocab)\n","\n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):\n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","\n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","\n","  return lista2"]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novo_dic = dict()\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novo_dic[classe_gramatical] = qtde\n","\n","  return novo_dic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novo_dic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","\n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novo_dic[classe_gramatical] = qtde\n","\n","  return novo_dic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"j9SA61kD6sJY"},"outputs":[],"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","\n","  # Soma os dicionários da lista\n","  novo_dic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n","\n","  return novo_dic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gWxyAo54AOHU"},"outputs":[],"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.text)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:\n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Gvd99wd_pwmt"},"outputs":[],"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy\n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista_tokens = []\n","  lista_post = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:\n","    lista_tokens.append(token.text)\n","    lista_post.append(token.pos_)\n","\n","  return lista_tokens, lista_post"]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tradução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NpCUpOs06sJY"},"outputs":[],"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavra_universal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","\n","#Explica a POS\n","def getPOSPalavraUniversalTraduzido(palavra):\n","  if palavra in palavra_universal_dict.keys():\n","      traduzido = palavra_universal_dict[palavra]\n","  else:\n","      traduzido = \"NA\"\n","  return traduzido"]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rMb0uDWzKZXP"},"outputs":[],"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zxTCYFzcJZD6"},"outputs":[],"source":["def getSentencaSalientePOS(sentenca, pos, tipoSaliente=\"NOUN\"):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especeficado\n","    if pos[i] == tipoSaliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"_xaeX0oTVQ5t"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NIaQ9bzBVQ5t"},"outputs":[],"source":["def removeStopWord(documento, stopwords):\n","\n","  # Remoção das stopwords do documento\n","  documento_sem_stopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documento_limpo = \" \".join(documento_sem_stopwords)\n","\n","  # Retorna o documento\n","  return documento_limpo"]},{"cell_type":"markdown","metadata":{"id":"A7NAe8ogCf1y"},"source":["### retornaRelevante\n","\n","Retorna somente os palavras do documento ou sentença do tipo especificado."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UNNfykypChn-"},"outputs":[],"source":["def retornaRelevante(documento, classe_relevante=\"NOUN\"):\n","\n","  # Corrigir!\n","  # Utilizar o documento já tokenizado pelo spacy!!!!\n","  # Existe uma lista com o documento e a sentença tokenizada pelo spacy\n","\n","  # Realiza o parsing no spacy\n","  doc = nlp(documento)\n","\n","  # Retorna a lista das palavras relevantes\n","  documento_com_substantivos = []\n","  for token in doc:\n","    #print(\"token:\", token.pos_)\n","    if token.pos_ == classe_relevante:\n","      documento_com_substantivos.append(token.text)\n","\n","  # Concatena o documento com os substantivos\n","  documento_concatenado = \" \".join(documento_com_substantivos)\n","\n","  # Retorna o documento\n","  return documento_concatenado"]},{"cell_type":"markdown","metadata":{"id":"IBY7q_uH8JSE"},"source":["# 4 BERT"]},{"cell_type":"markdown","metadata":{"id":"MBGTMy8Ic7GK"},"source":["## 4.1 Modelo Pré-treinado BERT"]},{"cell_type":"markdown","metadata":{"id":"uiuxdXe9t1BX"},"source":["### Funções Auxiliares"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9Huw0x5kt1Le"},"outputs":[],"source":["def getNomeModeloBERT(model_args):\n","    '''\n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","\n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"\n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","        else:\n","            if 'bert' in model_args.pretrained_model_name_or_path:\n","                MODELO_BERT = \"_BERT\"\n","\n","    return MODELO_BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jYJB4ik7t5xe"},"outputs":[],"source":["def getTamanhoBERT(model_args):\n","    '''\n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","\n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","\n","    return TAMANHO_BERT"]},{"cell_type":"markdown","metadata":{"id":"rHt4e5pAcEMd"},"source":["### Função download Modelo Pre-treinado BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"peDUrV2ccEXA"},"outputs":[],"source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","\n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","\n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo!\")\n","            # Apaga o diretório e os arquivos existentes\n","            shutil.rmtree(DIRETORIO_MODELO)\n","\n","        # Realiza o download do arquivo do modelo\n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.\n","        arquivo_zip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivo_zip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.\n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","\n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta!\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada!\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"V74WUpHqcfoI"},"source":["### Copia o modelo do BERT ajustado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iQMpf9yycf8f"},"outputs":[],"source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\"\n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO)\n","\n","    logging.info(\"Modelo BERT ajustado copiado!\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"]},{"cell_type":"markdown","metadata":{"id":"eaneOhAKcO-3"},"source":["### Verifica de onde utilizar o modelo do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TTy1TXz3cPKS"},"outputs":[],"source":["def verificaModelo(model_args):\n","    \"\"\"\n","    Verifica de onde utilizar o modelo.\n","\n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","\n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\"\n","\n","    DIRETORIO_MODELO = None\n","\n","    if model_args.usar_mcl_ajustado == True:\n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","\n","        logging.info(\"Usando modelo BERT ajustado.\")\n","\n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")\n","\n","    return DIRETORIO_MODELO"]},{"cell_type":"markdown","metadata":{"id":"6tKcaIfReqdy"},"source":["## 4.2 Tokenizador BERT"]},{"cell_type":"markdown","metadata":{"id":"e8n7Z5s-QZF8"},"source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mzAuptkwQZR3"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","\n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"]},{"cell_type":"markdown","metadata":{"id":"GYRV9KfHQE6v"},"source":["## 4.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"markdown","metadata":{"id":"-pZZrUKRhR3e"},"source":["### Função carrega modelo BERT medida"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1JUEyjCChUQh"},"outputs":[],"source":["# Import das bibliotecas.\n","from transformers import BertModel # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","\n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.\n","        `model_args` - Objeto com os argumentos do modelo.\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:\n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertModel.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertModel.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"-uFDhRTZe2Js"},"source":["### Função carrega o BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QVtAUbUBe2iS"},"outputs":[],"source":["def carregaBERT(model_args):\n","    \"\"\"\n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","\n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","        `tokenizer` - Um objeto tokenizador BERT carregado.\n","    \"\"\"\n","\n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","\n","    # Variável para conter o modelo\n","    model = None\n","\n","    # Carrega o modelo para cálculo da medida\n","    model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","\n","    # Carrega o tokenizador.\n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","\n","    return model, tokenizer"]},{"cell_type":"markdown","metadata":{"id":"x5NTxBRKfAcT"},"source":["### Carrega o BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["72e54c7e363c44c9be33ac987f1b8d3d","20c65475f97f452dbf0cf45f06cdc905","664210d4267c4259930fdf3e85dd35b5","a3c3e5dd9e754d7caec6c3314cac45fd","dc6f208bb0c346698d440491d8937869","519dd23361314eddb5214c1937693aca"]},"id":"ZYMLJJYSQHY3","outputId":"a111a2e1-fd0f-4f9c-97cb-92323585f8af"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72e54c7e363c44c9be33ac987f1b8d3d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/648 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20c65475f97f452dbf0cf45f06cdc905","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"664210d4267c4259930fdf3e85dd35b5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3c3e5dd9e754d7caec6c3314cac45fd","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc6f208bb0c346698d440491d8937869","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"519dd23361314eddb5214c1937693aca","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/155 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Carrega o modelo e tokenizador do BERT\n","model, tokenizer = carregaBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"d7KprWqyZBQZ"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"D6sPjTQnuQV2"},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"khTFfBVbnsx9"},"source":["## 4.4 Funções auxiliares do BERT"]},{"cell_type":"markdown","metadata":{"id":"lCJzsw8T0I-5"},"source":["### concatenaListas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IpmDZ1mI0JHR"},"outputs":[],"source":["def concatenaListas(lista, pos=1):\n","  lista_concat = []\n","\n","  for x in lista:\n","      lista_concat = lista_concat + x[pos]\n","\n","  return lista_concat"]},{"cell_type":"markdown","metadata":{"id":"s42mgtmSZ8MR"},"source":["### getEmbeddingsCamadas\n","\n","Funções que recuperam os embeddings das camadas:\n","- Primeira camada;\n","- Penúltima camada;\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sgo3EBTRZ9-3"},"outputs":[],"source":["def getEmbeddingPrimeiraCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][0]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingPenultimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-2]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingUltimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado = output[2][-1]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  return resultado\n","\n","def getEmbeddingSoma4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][-4:]\n","  # Saída: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado\n","\n","def getEmbeddingConcat4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Cria uma lista com os tensores a serem concatenados\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Lista com os tensores a serem concatenados\n","  lista_concat = []\n","\n","  # Percorre os 4 últimos\n","  for i in [-1,-2,-3,-4]:\n","      # Concatena da lista\n","      lista_concat.append(output[2][i])\n","\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  # Realiza a concatenação dos embeddings de todos as camadas\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)\n","  resultado = torch.cat(lista_concat, dim=-1)\n","\n","  # Saída: Entrada: (<1(lote)> x <qtde_tokens> x <3072 ou 4096>)\n","  return resultado\n","\n","def getEmbeddingSomaTodasAsCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","\n","  # Retorna todas as camadas descontando a primeira(0)\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  embedding_camadas = output[2][1:]\n","  # Saída: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor\n","  # com a concateção dos tensores dos embeddings.\n","  #Entrada: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)\n","  resultado_stack = torch.stack(embedding_camadas, dim=0)\n","  # Saída: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultado_stack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","\n","  return resultado"]},{"cell_type":"markdown","metadata":{"id":"q7nx_eZ8hSlr"},"source":["### getEmbeddingsVisual\n","\n","Função para gerar as coordenadas de plotagem a partir das sentenças de embeddings.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pLdbOT8-g43V"},"outputs":[],"source":["def getEmbeddingsVisualUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eAf9lJJ2hZbt"},"outputs":[],"source":["def getEmbeddingsVisualSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4XpwSN1ghpnz"},"outputs":[],"source":["def getEmbeddingsVisualConcat4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L3KU1EFrnSPK"},"outputs":[],"source":["def getEmbeddingsVisualSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"Y8MjE0utzlZT"},"source":["### getEmbeddings\n","\n","Função para gerar os embeddings de sentenças.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2QcqOuwS067Q"},"outputs":[],"source":["def getEmbeddingsUltimaCamada(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BK1wDGBl067Y"},"outputs":[],"source":["def getEmbeddingsSoma4UltimasCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Hym19Hxr067Y"},"outputs":[],"source":["def getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer):\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"U-PLZiUR067Z"},"outputs":[],"source":["def getEmbeddingsSomaTodasAsCamadas(documento, modelo, tokenizer):\n","\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário\n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():\n","        # Retorno de model quando ´output_hidden_states=True´ é setado:\n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding\n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"Pyra3_pECsoJ"},"source":["### getEmbeddingsDocumento\n","\n","Recupera os embeddings e tokens do documento sem buffer."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XdDBSRDcCxHp"},"outputs":[],"source":["def getEmbeddingsDocumento(documento, modelo, tokenizer):\n","\n","    return getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"-rLcMuDHC-F5"},"source":["### getEmbeddingsDocumentoBuffer\n","\n","Recupera os embeddings e tokens do documento com buffer."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OogUm0kuC7wK"},"outputs":[],"source":["buffer_token_embeddings = {}\n","\n","def getEmbeddingsDocumentoBuffer(documento, modelo, tokenizer):\n","\n","    # Se documento está no dicionário retorna o embedding e os tokens\n","    if documento in buffer_token_embeddings:\n","        registro_buffer = buffer_token_embeddings.get(documento)\n","        return registro_buffer[0], registro_buffer[1]\n","    else:\n","        # Gera o embedding\n","        token_embeddings, documento_tokenizado = getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer)\n","        buffer_token_embeddings.update({documento: [token_embeddings, documento_tokenizado]})\n","\n","        return  token_embeddings, documento_tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iTRcghhuet76"},"outputs":[],"source":["def limpaBufferEmbedding():\n","    buffer_token_embeddings.clear()"]},{"cell_type":"markdown","metadata":{"id":"zFd1rse11DpZ"},"source":["### getDocumentoTokenizado\n","\n","Retorna o documento tokenizado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gvWIBFTLJ7z9"},"outputs":[],"source":["def getDocumentoTokenizado(documento, tokenizer):\n","    \"\"\"\n","      Retorna o documento tokenizado pelo BERT.\n","\n","      Parâmetros:\n","      `documento` - Documento a ser tokenizado.\n","      `tokenizer` - Tokenizador do BERT.\n","    \"\"\"\n","\n","    # Adiciona os tokens especiais.\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Documento tokenizado\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    del tokenizer\n","\n","    return documento_tokenizado"]},{"cell_type":"markdown","metadata":{"id":"3wvgXwN81RCz"},"source":["### encontrarIndiceSubLista\n","\n","Retorna os índices de início e fim da sublista na lista"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"abS44M4yvFxf"},"outputs":[],"source":["def encontrarIndiceSubLista(lista: List, sublista: List):\n","    \"\"\"\n","    Localiza os índices de início e fim de uma sublista em uma lista.\n","    Baseado no algoritmo de https://codereview.stackexchange.com/questions/19627/finding-sub-list\n","    de  https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n","\n","    Parâmetros:\n","      `lista` - Uma lista.\n","      `sublista` - Uma sublista a ser localizada na lista.\n","\n","    Retorno:\n","      Os índices de início e fim da sublista na lista.\n","    \"\"\"\n","    # Tamanho da lista\n","    h = len(lista)\n","    # Tamanho da sblista\n","    n = len(sublista)\n","    # Cria um dicionário com os saltos descrescentes dos elementos n-1 da sublista\n","    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n","    i = n - 1\n","    # Percorre a lista\n","    while i < h:\n","        # Percorre a sublista\n","        for j in range(n):\n","            # Se elemento da lista diferente da sublista pula a interação\n","            if lista[i - j] != sublista[-j - 1]:\n","              # Passa para o próximo elemento da lista saltando a sublista\n","              i += skip.get(lista[i], n)\n","              # Interrompe o for.\n","              break\n","        else:\n","            #Finalizando a pesquisa depois de executar todo o for(sem break)\n","            indice_inicio = i - n + 1\n","            indice_fim = indice_inicio + len(sublista)-1\n","\n","            # Retorna o início e fim da sublista na lista\n","            return indice_inicio, indice_fim\n","\n","    # Não encontrou a sublista na lista\n","    return -1, -1"]},{"cell_type":"markdown","metadata":{"id":"kGL37G6XFcwp"},"source":["### getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras\n","\n","A partir dos embeddings do documento, localiza o indíce de início e fim de uma sentença no documento e retorna os embeddings da sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uI07Y_M8__HG"},"outputs":[],"source":["# Import das bibliotecas.\n","import numpy as np\n","\n","def getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                           token_BERT_documento,\n","                                                           sentenca,\n","                                                           tokenizer):\n","\n","  # Tokeniza a sentença\n","  sentenca_tokenizada_BERT = getDocumentoTokenizado(sentenca, tokenizer)\n","  #print(sentenca_tokenizada_BERT)\n","\n","  # Remove os tokens de início e fim da sentença\n","  sentenca_tokenizada_BERT.remove(\"[CLS]\")\n","  sentenca_tokenizada_BERT.remove(\"[SEP]\")\n","  #print(len(sentenca_tokenizada_BERT))\n","\n","  # Localiza os índices dos tokens da sentença no documento\n","  inicio, fim = encontrarIndiceSubLista(token_BERT_documento, sentenca_tokenizada_BERT)\n","  #print(inicio,fim)\n","\n","  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do documento\n","  embeddingSentenca = embedding_documento[inicio:fim+1]\n","  #print(\"embeddingSentenca=\", embeddingSentenca.shape)\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del sentenca\n","  del tokenizer\n","\n","  # Retorna o embedding da sentença no documento\n","  return embeddingSentenca, sentenca_tokenizada_BERT"]},{"cell_type":"markdown","metadata":{"id":"THFhXGGmIO_r"},"source":["### getEmbeddingDocumentoComTodasPalavrasMean"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IhW_OiEsIPJI"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento excluindo os tokens\n","    especiais [CLS] do início e [SEP] do fim.\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embedding do documento.\n","  \"\"\"\n","\n","\n","  # Calcula a média dos embeddings para os tokens de embedding_documento, removendo a primeira dimensão.\n","  # Entrada: <qtde_tokens> x <768 ou 1024>\n","  #print(\"embedding_documento1=\", embedding_documento.shape)\n","  media_embedding_documento = torch.mean(embedding_documento[1:-1], dim=0)\n","  # Saída: <768 ou 1024>\n","\n","  del embedding_documento\n","\n","  return media_embedding_documento"]},{"cell_type":"markdown","metadata":{"id":"1Ko_of60YuNd"},"source":["### getEmbeddingDocumentoRelevanteMean"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wDokSSODY0Sf"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                       index_sentenca,\n","                                       embedding_documento,\n","                                       token_BERT_documento,\n","                                       documento,\n","                                       tokenizer,\n","                                       token_documento,\n","                                       pos_documento,\n","                                       filtro):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento considerando tokens do tipo\n","    especificado no filtro\n","    Remove primeira dimensão devido ao cálculo da média.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","\n","  \"\"\"\n","\n","  # Recupera a lista de tokens do documento, a lista dos postagging e a lista dos seus embeddings com um mesmo tamanho\n","  lista_tokens, lista_postagging, lista_embeddings = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                    index_sentenca,\n","                                                                                    embedding_documento,\n","                                                                                    token_BERT_documento,\n","                                                                                    documento,\n","                                                                                    tokenizer,\n","                                                                                    token_documento,\n","                                                                                    pos_documento)\n","\n","  #print(\"len(token_BERT_documento):\", len(token_BERT_documento))\n","  #print(\"token_BERT_documento:\", token_BERT_documento)\n","  #print(\"len(pos_documento):\", len(pos_documento))\n","  #print(\"pos_documento:\", pos_documento)\n","  #print(\"filtro:\", filtro)\n","  #print()\n","\n","  # Lista com os tensores selecionados\n","  lista_tokens_selecionados = []\n","  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word no documento\n","  for i, token_documento in enumerate(lista_tokens):\n","      if (lista_postagging[i] in filtro):\n","          #print(\"Adicionando palavra do embedding:\", lista_tokens[i])\n","          lista_tokens_selecionados.append(lista_embeddings[i])\n","\n","  if  len(lista_tokens_selecionados) != 0:\n","      # Empila os embeddings da lista pela dimensão 0\n","      embedding_relevante = torch.stack(lista_tokens_selecionados, dim=0)\n","      #print(\"embedding_relevante.shape:\",embedding_relevante.shape)\n","\n","      # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n","      # Entrada: <qtde_tokens> x <768 ou 1024>\n","      media_embedding_relevante = torch.mean(embedding_relevante, dim=0)\n","      # Saída: <768 ou 1024>\n","      #print(\"media_embedding_relevante.shape:\", media_embedding_relevante.shape)\n","  else:\n","      media_embedding_relevante = None\n","\n","  del embedding_documento\n","  del token_BERT_documento\n","  del documento\n","  del tokenizer\n","  del token_documento\n","  del pos_documento\n","\n","  return media_embedding_relevante"]},{"cell_type":"markdown","metadata":{"id":"L_vknrk7YSpF"},"source":["### getEmbeddingDocumentoMean\n","\n","Filtros:\n","- ALL - Sentença com todas as palavras\n","- NOUN - Sentença somente com substantivos\n","- VERB - Sentença somente com verbos\n","- VERB,NOUN - Sentença somente com verbos e substantivos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Pd8B76YyYS02"},"outputs":[],"source":["def getEmbeddingDocumentoMean(id_documento,\n","                              index_sentenca,\n","                              embedding_documento,\n","                              token_BERT_documento,\n","                              documento,\n","                              tokenizer,\n","                              token_documento,\n","                              pos_documento,\n","                              filtro=[\"ALL\"]):\n","  \"\"\"\n","    Rediciona o cálculo da média dos embeddings de acordo com o filtro especificado.\n","\n","    Parâmetros:\n","    `embedding_documento` - Embeddings do documento gerados pelo BERT.\n","    `token_BERT_documento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","  \"\"\"\n","\n","  if \"ALL\" in filtro:\n","    return getEmbeddingDocumentoComTodasPalavrasMean(embedding_documento)\n","  else:\n","    return getEmbeddingDocumentoRelevanteMean(id_documento,\n","                                              index_sentenca,\n","                                              embedding_documento,\n","                                              token_BERT_documento,\n","                                              documento,\n","                                              tokenizer,\n","                                              token_documento,\n","                                              pos_documento,\n","                                              filtro)"]},{"cell_type":"markdown","metadata":{"id":"Y7W-7V3QFbpR"},"source":["# 5 Comparar Palavras"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 5.1 Carregamento dos arquivos de dados originais e perturbados"]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["#### 5.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bNgwJRC2uGJb"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_ORIGINAL = \"original.csv\"\n","NOME_ARQUIVO_ORIGINAL_COMPACTADO = \"original.zip\"\n","NOME_ARQUIVO_ORIGINAL_POS = \"originalpos.csv\"\n","NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO = \"originalpos.zip\"\n","\n","NOME_ARQUIVO_PERTURBADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_COMPACTADO = \"perturbado_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\"\n","NOME_ARQUIVO_PERTURBADO_POS = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO = \"perturbadopos_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"CGF4D4B1JY9P"},"source":["### 5.1.2 Cria o diretório local para receber os dados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gFYIHcIHE985"},"outputs":[],"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):\n","    # Cria o diretório\n","    os.makedirs(dirbase)\n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:\n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pviuxToMCxQw"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a cópia.\")"]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens\n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dbHl3d88mouc"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_ORIGINAL_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_PERTURBADO_POS_COMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"]},{"cell_type":"markdown","metadata":{"id":"qzhYJNWJm1z4"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais e pertubados"]},{"cell_type":"markdown","metadata":{"id":"Usr1uRzQeJSb"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QRHlixdHEDTb"},"outputs":[],"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_ORIGINAL_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jJ5STBZPLlie","outputId":"dcfb82e0-f08e-421f-8508-b2459cd6217f"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-62c5d541-9a56-4e98-98ac-dca51fab03a6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>respondivel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1371</th>\n","      <td>57267bc45951b619008f7440</td>\n","      <td>['Qual era o orçamento de publicidade do novo ...</td>\n","      <td>Qual era o orçamento de publicidade do novo ar...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>718</th>\n","      <td>5728c4ee3acd2414000dfdfc</td>\n","      <td>['Qual é a pluviosidade média do Saara?']</td>\n","      <td>Qual é a pluviosidade média do Saara?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>907</th>\n","      <td>5728e91a4b864d1900165077</td>\n","      <td>['Que produto de madeira foi produzido princip...</td>\n","      <td>Que produto de madeira foi produzido principal...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>56f799d2a6d7ea1400e17260</td>\n","      <td>['Quais navios foram atacados em 1852?']</td>\n","      <td>Quais navios foram atacados em 1852?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>223</th>\n","      <td>572409ef0ba9f01400d97b44</td>\n","      <td>['Por que a visão de Victorias estava nublada?']</td>\n","      <td>Por que a visão de Victorias estava nublada?</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62c5d541-9a56-4e98-98ac-dca51fab03a6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-62c5d541-9a56-4e98-98ac-dca51fab03a6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-62c5d541-9a56-4e98-98ac-dca51fab03a6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                            id  \\\n","1371  57267bc45951b619008f7440   \n","718   5728c4ee3acd2414000dfdfc   \n","907   5728e91a4b864d1900165077   \n","11    56f799d2a6d7ea1400e17260   \n","223   572409ef0ba9f01400d97b44   \n","\n","                                              sentencas  \\\n","1371  ['Qual era o orçamento de publicidade do novo ...   \n","718           ['Qual é a pluviosidade média do Saara?']   \n","907   ['Que produto de madeira foi produzido princip...   \n","11             ['Quais navios foram atacados em 1852?']   \n","223    ['Por que a visão de Victorias estava nublada?']   \n","\n","                                              documento  respondivel  \n","1371  Qual era o orçamento de publicidade do novo ar...            1  \n","718               Qual é a pluviosidade média do Saara?            1  \n","907   Que produto de madeira foi produzido principal...            1  \n","11                 Quais navios foram atacados em 1852?            1  \n","223        Por que a visão de Victorias estava nublada?            1  "]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["lista_documentos_originais.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BYddg8UODmdP"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais = lista_documentos_originais.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IbaWPXE2jK26","outputId":"c8749149-cb04-416d-ac29-868ae1dfcaa4"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-9ddf27a6-f79e-407c-abdf-79b09228ef8f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1326</th>\n","      <td>5726bd64dd62a815002e8eea</td>\n","      <td>[[['Qual', 'país', 'é', 'chamado', 'de', \"'\", ...</td>\n","    </tr>\n","    <tr>\n","      <th>853</th>\n","      <td>5727b5944b864d1900163afa</td>\n","      <td>[[['Em', '2012', ',', 'qual', 'foi', 'o', 'ran...</td>\n","    </tr>\n","    <tr>\n","      <th>1119</th>\n","      <td>5725ff8238643c19005acf49</td>\n","      <td>[[['Qual', 'empresa', 'fornece', 'serviço', 'd...</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>572a0ce11d04691400779701</td>\n","      <td>[[['Que', 'proteína', 'Staphylococcus', 'aureu...</td>\n","    </tr>\n","    <tr>\n","      <th>809</th>\n","      <td>571ae8d732177014007e9fd2</td>\n","      <td>[[['Quem', 'veio', 'a', 'Alexandria', 'para', ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ddf27a6-f79e-407c-abdf-79b09228ef8f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9ddf27a6-f79e-407c-abdf-79b09228ef8f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9ddf27a6-f79e-407c-abdf-79b09228ef8f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                            id  \\\n","1326  5726bd64dd62a815002e8eea   \n","853   5727b5944b864d1900163afa   \n","1119  5725ff8238643c19005acf49   \n","113   572a0ce11d04691400779701   \n","809   571ae8d732177014007e9fd2   \n","\n","                                          pos_documento  \n","1326  [[['Qual', 'país', 'é', 'chamado', 'de', \"'\", ...  \n","853   [[['Em', '2012', ',', 'qual', 'foi', 'o', 'ran...  \n","1119  [[['Qual', 'empresa', 'fornece', 'serviço', 'd...  \n","113   [[['Que', 'proteína', 'Staphylococcus', 'aureu...  \n","809   [[['Quem', 'veio', 'a', 'Alexandria', 'para', ...  "]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["lista_documentos_originais_pos.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d96IZl9nDfHf"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_originais_pos = lista_documentos_originais_pos.astype(tipos)"]},{"cell_type":"markdown","metadata":{"id":"-hfUpvKqXoqe"},"source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lj9sJVavMccj"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"]},{"cell_type":"markdown","metadata":{"id":"8yyRt4jnYxsU"},"source":["#### Criando dados indexados originais"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"B9INo4nBS8aQ","outputId":"1fa779be-06da-4eeb-903a-00ed4a0d0ef5"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-74c5e708-96b1-4495-a7cd-cc31d109b8cc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>respondivel</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb</th>\n","      <td>[O formulário Edna do Link é mais rápido do qu...</td>\n","      <td>O formulário Edna do Link é mais rápido do que...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5acfa4e977cf76001a6856da</th>\n","      <td>[Quais dois ministros lutaram pelo poder em An...</td>\n","      <td>Quais dois ministros lutaram pelo poder em Anne?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5ad19f40645df0001a2d213b</th>\n","      <td>[O que Irving Langmuir descobriu que aumentari...</td>\n","      <td>O que Irving Langmuir descobriu que aumentaria...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>56ce66aeaab44d1400b8875a</th>\n","      <td>[Em que ano a célula solar de silício cristali...</td>\n","      <td>Em que ano a célula solar de silício cristalin...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5acdabd307355d001abf48f0</th>\n","      <td>[Desde que ano foi levantada a idéia de um tún...</td>\n","      <td>Desde que ano foi levantada a idéia de um túne...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74c5e708-96b1-4495-a7cd-cc31d109b8cc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-74c5e708-96b1-4495-a7cd-cc31d109b8cc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-74c5e708-96b1-4495-a7cd-cc31d109b8cc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                                  sentencas  \\\n","id                                                                            \n","5a8d89b5df8bba001a0f9afb  [O formulário Edna do Link é mais rápido do qu...   \n","5acfa4e977cf76001a6856da  [Quais dois ministros lutaram pelo poder em An...   \n","5ad19f40645df0001a2d213b  [O que Irving Langmuir descobriu que aumentari...   \n","56ce66aeaab44d1400b8875a  [Em que ano a célula solar de silício cristali...   \n","5acdabd307355d001abf48f0  [Desde que ano foi levantada a idéia de um tún...   \n","\n","                                                                  documento  \\\n","id                                                                            \n","5a8d89b5df8bba001a0f9afb  O formulário Edna do Link é mais rápido do que...   \n","5acfa4e977cf76001a6856da   Quais dois ministros lutaram pelo poder em Anne?   \n","5ad19f40645df0001a2d213b  O que Irving Langmuir descobriu que aumentaria...   \n","56ce66aeaab44d1400b8875a  Em que ano a célula solar de silício cristalin...   \n","5acdabd307355d001abf48f0  Desde que ano foi levantada a idéia de um túne...   \n","\n","                          respondivel  \n","id                                     \n","5a8d89b5df8bba001a0f9afb            0  \n","5acfa4e977cf76001a6856da            0  \n","5ad19f40645df0001a2d213b            0  \n","56ce66aeaab44d1400b8875a            1  \n","5acdabd307355d001abf48f0            0  "]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_originais_indexado = lista_documentos_originais.set_index([\"id\"])\n","lista_documentos_originais_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"j70x_r30T_bx","outputId":"3154545c-5f13-4b66-849f-c58f29e25081"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-440cdfb4-0fde-43e1-9404-5d17428b8acf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb</th>\n","      <td>[[[O, formulário, Edna, do, Link, é, mais, ráp...</td>\n","    </tr>\n","    <tr>\n","      <th>5acfa4e977cf76001a6856da</th>\n","      <td>[[[Quais, dois, ministros, lutaram, pelo, pode...</td>\n","    </tr>\n","    <tr>\n","      <th>5ad19f40645df0001a2d213b</th>\n","      <td>[[[O, que, Irving, Langmuir, descobriu, que, a...</td>\n","    </tr>\n","    <tr>\n","      <th>56ce66aeaab44d1400b8875a</th>\n","      <td>[[[Em, que, ano, a, célula, solar, de, silício...</td>\n","    </tr>\n","    <tr>\n","      <th>5acdabd307355d001abf48f0</th>\n","      <td>[[[Desde, que, ano, foi, levantada, a, idéia, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-440cdfb4-0fde-43e1-9404-5d17428b8acf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-440cdfb4-0fde-43e1-9404-5d17428b8acf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-440cdfb4-0fde-43e1-9404-5d17428b8acf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                              pos_documento\n","id                                                                         \n","5a8d89b5df8bba001a0f9afb  [[[O, formulário, Edna, do, Link, é, mais, ráp...\n","5acfa4e977cf76001a6856da  [[[Quais, dois, ministros, lutaram, pelo, pode...\n","5ad19f40645df0001a2d213b  [[[O, que, Irving, Langmuir, descobriu, que, a...\n","56ce66aeaab44d1400b8875a  [[[Em, que, ano, a, célula, solar, de, silício...\n","5acdabd307355d001abf48f0  [[[Desde, que, ano, foi, levantada, a, idéia, ..."]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_originais_pos_indexado = lista_documentos_originais_pos.set_index([\"id\"])\n","lista_documentos_originais_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"zJXcpioo7Bhn"},"source":["#### Carrega o arquivo dos dados perturbados e POS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gB500dmd7Bho"},"outputs":[],"source":["# Abre o arquivo e retorna o DataFrame\n","lista_documentos_perturbados = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_perturbados_pos = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_PERTURBADO_POS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO PERTURBADOS: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO PERTURBADOS POS: {}.\".format(len(lista_documentos_perturbados_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nQ9cgAz47Bhp","outputId":"e2cdcda4-390c-4c14-aebe-d339b384d980"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-93f399b7-5de1-49af-a612-674e21808797\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documentoPerturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>126983</th>\n","      <td>56db0f17e7c41114004b4ce9_pert_83</td>\n","      <td>['Onde foi publicado o revezamento da tocha na...</td>\n","      <td>Onde foi publicado o revezamento da tocha na c...</td>\n","      <td>[['Onde foi [MASK] o revezamento da tocha na c...</td>\n","    </tr>\n","    <tr>\n","      <th>33994</th>\n","      <td>572813e23acd2414000df3e6_pert_94</td>\n","      <td>['O nível de razão pela qual estimulantes e de...</td>\n","      <td>O nível de razão pela qual estimulantes e depr...</td>\n","      <td>[['O nível de razão pela qual estimulantes e d...</td>\n","    </tr>\n","    <tr>\n","      <th>130344</th>\n","      <td>5a4c43b77a6c4c001a2bbbca_pert_44</td>\n","      <td>['o que está bloqueado usando a superfície de ...</td>\n","      <td>o que está bloqueado usando a superfície de ba...</td>\n","      <td>[['o que está bloqueado [MASK] a superfície de...</td>\n","    </tr>\n","    <tr>\n","      <th>91861</th>\n","      <td>5acfc7b977cf76001a685f26_pert_61</td>\n","      <td>['Desde que anos dominou o baixo cubismo ?']</td>\n","      <td>Desde que anos dominou o baixo cubismo ?</td>\n","      <td>[['Desde que anos [MASK] o baixo cubismo ?', '...</td>\n","    </tr>\n","    <tr>\n","      <th>7490</th>\n","      <td>5ad547945b96ef001a10ac1b_pert_90</td>\n","      <td>['O que todos esses modelos não , em comum ?']</td>\n","      <td>O que todos esses modelos não , em comum ?</td>\n","      <td>[['O que todos esses modelos não [MASK] em com...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93f399b7-5de1-49af-a612-674e21808797')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-93f399b7-5de1-49af-a612-674e21808797 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-93f399b7-5de1-49af-a612-674e21808797');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                      id  \\\n","126983  56db0f17e7c41114004b4ce9_pert_83   \n","33994   572813e23acd2414000df3e6_pert_94   \n","130344  5a4c43b77a6c4c001a2bbbca_pert_44   \n","91861   5acfc7b977cf76001a685f26_pert_61   \n","7490    5ad547945b96ef001a10ac1b_pert_90   \n","\n","                                               perturbado  \\\n","126983  ['Onde foi publicado o revezamento da tocha na...   \n","33994   ['O nível de razão pela qual estimulantes e de...   \n","130344  ['o que está bloqueado usando a superfície de ...   \n","91861        ['Desde que anos dominou o baixo cubismo ?']   \n","7490       ['O que todos esses modelos não , em comum ?']   \n","\n","                                      documentoPerturbado  \\\n","126983  Onde foi publicado o revezamento da tocha na c...   \n","33994   O nível de razão pela qual estimulantes e depr...   \n","130344  o que está bloqueado usando a superfície de ba...   \n","91861            Desde que anos dominou o baixo cubismo ?   \n","7490           O que todos esses modelos não , em comum ?   \n","\n","                                                sentencas  \n","126983  [['Onde foi [MASK] o revezamento da tocha na c...  \n","33994   [['O nível de razão pela qual estimulantes e d...  \n","130344  [['o que está bloqueado [MASK] a superfície de...  \n","91861   [['Desde que anos [MASK] o baixo cubismo ?', '...  \n","7490    [['O que todos esses modelos não [MASK] em com...  "]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["lista_documentos_perturbados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3pXGee7H7Bhp","outputId":"eca40d42-de6d-4648-c9a5-906583bf217c"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-8f8c8ead-152d-43c0-b0bb-1c6e77883fac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>perturbado</th>\n","      <th>documentoPerturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>100393</th>\n","      <td>5acee59732bba1001ae4b8e4_pert_93</td>\n","      <td>['Quais são as quatro capas mais externas de N...</td>\n","      <td>Quais são as quatro capas mais externas de Net...</td>\n","      <td>[['Quais são as quatro [MASK] mais externas de...</td>\n","    </tr>\n","    <tr>\n","      <th>69026</th>\n","      <td>5727e0212ca10214002d9892_pert_26</td>\n","      <td>['Quando foi aceita a Confissão Batista da Fil...</td>\n","      <td>Quando foi aceita a Confissão Batista da Filad...</td>\n","      <td>[['Quando foi [MASK] a Confissão Batista da Fi...</td>\n","    </tr>\n","    <tr>\n","      <th>24277</th>\n","      <td>570c4b09fed7b91900d4584f_pert_77</td>\n","      <td>['Quando Joan Gamper se é presidente do clube ...</td>\n","      <td>Quando Joan Gamper se é presidente do clube de...</td>\n","      <td>[['Quando Joan Gamper se [MASK] presidente do ...</td>\n","    </tr>\n","    <tr>\n","      <th>127681</th>\n","      <td>5727c9d34b864d1900163d20_pert_81</td>\n","      <td>['Por que alguns amantes da música passam o di...</td>\n","      <td>Por que alguns amantes da música passam o diaf...</td>\n","      <td>[['Por que alguns amantes da música [MASK] o d...</td>\n","    </tr>\n","    <tr>\n","      <th>119475</th>\n","      <td>5a3636d5788daf001a5f878f_pert_75</td>\n","      <td>['O que viver em uma parte remota do país ?']</td>\n","      <td>O que viver em uma parte remota do país ?</td>\n","      <td>[['O que [MASK] em uma parte remota do país ?'...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f8c8ead-152d-43c0-b0bb-1c6e77883fac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8f8c8ead-152d-43c0-b0bb-1c6e77883fac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8f8c8ead-152d-43c0-b0bb-1c6e77883fac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                      id  \\\n","100393  5acee59732bba1001ae4b8e4_pert_93   \n","69026   5727e0212ca10214002d9892_pert_26   \n","24277   570c4b09fed7b91900d4584f_pert_77   \n","127681  5727c9d34b864d1900163d20_pert_81   \n","119475  5a3636d5788daf001a5f878f_pert_75   \n","\n","                                               perturbado  \\\n","100393  ['Quais são as quatro capas mais externas de N...   \n","69026   ['Quando foi aceita a Confissão Batista da Fil...   \n","24277   ['Quando Joan Gamper se é presidente do clube ...   \n","127681  ['Por que alguns amantes da música passam o di...   \n","119475      ['O que viver em uma parte remota do país ?']   \n","\n","                                      documentoPerturbado  \\\n","100393  Quais são as quatro capas mais externas de Net...   \n","69026   Quando foi aceita a Confissão Batista da Filad...   \n","24277   Quando Joan Gamper se é presidente do clube de...   \n","127681  Por que alguns amantes da música passam o diaf...   \n","119475          O que viver em uma parte remota do país ?   \n","\n","                                                sentencas  \n","100393  [['Quais são as quatro [MASK] mais externas de...  \n","69026   [['Quando foi [MASK] a Confissão Batista da Fi...  \n","24277   [['Quando Joan Gamper se [MASK] presidente do ...  \n","127681  [['Por que alguns amantes da música [MASK] o d...  \n","119475  [['O que [MASK] em uma parte remota do país ?'...  "]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["lista_documentos_perturbados.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IE1xJdZWkc5I","outputId":"68df7312-ae7e-4f57-c0ed-c540c0bf684d"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-e6b59812-07f1-4408-8914-78f19fc07b19\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>91600</th>\n","      <td>572a0efb3f37b31900478679_pert_0</td>\n","      <td>[[['Que', 'acordo', 'foi', 'assinado', 'em', '...</td>\n","    </tr>\n","    <tr>\n","      <th>53913</th>\n","      <td>57312cffa5e9cc1400cdbcc1_pert_13</td>\n","      <td>[[['O', 'que', 'as', 'civilizações', 'nas', 'A...</td>\n","    </tr>\n","    <tr>\n","      <th>117167</th>\n","      <td>5a5160dace860b001aa3fd71_pert_67</td>\n","      <td>[[['Onde', 'as', 'pessoas', 'se', 'voltam', 'd...</td>\n","    </tr>\n","    <tr>\n","      <th>73100</th>\n","      <td>5ad11ad3645df0001a2d0d93_pert_0</td>\n","      <td>[[['Quantas', 'ogivas', 'nucleares', 'podem', ...</td>\n","    </tr>\n","    <tr>\n","      <th>116496</th>\n","      <td>57302834a23a5019007fcea9_pert_96</td>\n","      <td>[[['Qual', 'é', 'a', 'custo', 'de', 'emprego',...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6b59812-07f1-4408-8914-78f19fc07b19')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e6b59812-07f1-4408-8914-78f19fc07b19 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e6b59812-07f1-4408-8914-78f19fc07b19');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                      id  \\\n","91600    572a0efb3f37b31900478679_pert_0   \n","53913   57312cffa5e9cc1400cdbcc1_pert_13   \n","117167  5a5160dace860b001aa3fd71_pert_67   \n","73100    5ad11ad3645df0001a2d0d93_pert_0   \n","116496  57302834a23a5019007fcea9_pert_96   \n","\n","                                            pos_documento  \n","91600   [[['Que', 'acordo', 'foi', 'assinado', 'em', '...  \n","53913   [[['O', 'que', 'as', 'civilizações', 'nas', 'A...  \n","117167  [[['Onde', 'as', 'pessoas', 'se', 'voltam', 'd...  \n","73100   [[['Quantas', 'ogivas', 'nucleares', 'podem', ...  \n","116496  [[['Qual', 'é', 'a', 'custo', 'de', 'emprego',...  "]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["lista_documentos_perturbados_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"VrfZzjjpsUOU"},"source":["#### Corrigir os tipos de colunas dos dados perturbados e POS\n","\n","Em dados perturbados:\n","- coluna 1 - `perturbado` carregadas do arquivo vem como string e não como lista.\n","- coluna 3 - `sentencas` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados perturbados pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZHf-7dgSsUOU"},"outputs":[],"source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_perturbados[\"perturbado\"] = lista_documentos_perturbados[\"perturbado\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","lista_documentos_perturbados[\"sentencas\"] = lista_documentos_perturbados[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_perturbados_pos[\"pos_documento\"] = lista_documentos_perturbados_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO: {}.\".format(len(lista_documentos_perturbados)))\n","logging.info(\"TERMINADO CORREÇÃO PERTURBADO POS: {}.\".format(len(lista_documentos_perturbados_pos)))"]},{"cell_type":"markdown","metadata":{"id":"Ix-Q5fZXY3HR"},"source":["#### Criando dados indexados perturbados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FqRQnYUtSxzB","outputId":"5b48b3a8-40a2-4d17-e59d-659bf1243f01"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a0e6c941-217d-483d-a9ea-955c9dcda760\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>perturbado</th>\n","      <th>documentoPerturbado</th>\n","      <th>sentencas</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_0</th>\n","      <td>[O form Edna do Link é mais rápido do que outr...</td>\n","      <td>O form Edna do Link é mais rápido do que outro...</td>\n","      <td>[[O [MASK] Edna do Link é mais rápido do que o...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_1</th>\n","      <td>[O Form Edna do Link é mais rápido do que outr...</td>\n","      <td>O Form Edna do Link é mais rápido do que outro...</td>\n","      <td>[[O [MASK] Edna do Link é mais rápido do que o...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_2</th>\n","      <td>[O Can Edna do Link é mais rápido do que outro...</td>\n","      <td>O Can Edna do Link é mais rápido do que outro ...</td>\n","      <td>[[O [MASK] Edna do Link é mais rápido do que o...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_3</th>\n","      <td>[O da Edna do Link é mais rápido do que outro ...</td>\n","      <td>O da Edna do Link é mais rápido do que outro f...</td>\n","      <td>[[O [MASK] Edna do Link é mais rápido do que o...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_4</th>\n","      <td>[O Cada Edna do Link é mais rápido do que outr...</td>\n","      <td>O Cada Edna do Link é mais rápido do que outro...</td>\n","      <td>[[O [MASK] Edna do Link é mais rápido do que o...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0e6c941-217d-483d-a9ea-955c9dcda760')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a0e6c941-217d-483d-a9ea-955c9dcda760 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a0e6c941-217d-483d-a9ea-955c9dcda760');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                                        perturbado  \\\n","id                                                                                   \n","5a8d89b5df8bba001a0f9afb_pert_0  [O form Edna do Link é mais rápido do que outr...   \n","5a8d89b5df8bba001a0f9afb_pert_1  [O Form Edna do Link é mais rápido do que outr...   \n","5a8d89b5df8bba001a0f9afb_pert_2  [O Can Edna do Link é mais rápido do que outro...   \n","5a8d89b5df8bba001a0f9afb_pert_3  [O da Edna do Link é mais rápido do que outro ...   \n","5a8d89b5df8bba001a0f9afb_pert_4  [O Cada Edna do Link é mais rápido do que outr...   \n","\n","                                                               documentoPerturbado  \\\n","id                                                                                   \n","5a8d89b5df8bba001a0f9afb_pert_0  O form Edna do Link é mais rápido do que outro...   \n","5a8d89b5df8bba001a0f9afb_pert_1  O Form Edna do Link é mais rápido do que outro...   \n","5a8d89b5df8bba001a0f9afb_pert_2  O Can Edna do Link é mais rápido do que outro ...   \n","5a8d89b5df8bba001a0f9afb_pert_3  O da Edna do Link é mais rápido do que outro f...   \n","5a8d89b5df8bba001a0f9afb_pert_4  O Cada Edna do Link é mais rápido do que outro...   \n","\n","                                                                         sentencas  \n","id                                                                                  \n","5a8d89b5df8bba001a0f9afb_pert_0  [[O [MASK] Edna do Link é mais rápido do que o...  \n","5a8d89b5df8bba001a0f9afb_pert_1  [[O [MASK] Edna do Link é mais rápido do que o...  \n","5a8d89b5df8bba001a0f9afb_pert_2  [[O [MASK] Edna do Link é mais rápido do que o...  \n","5a8d89b5df8bba001a0f9afb_pert_3  [[O [MASK] Edna do Link é mais rápido do que o...  \n","5a8d89b5df8bba001a0f9afb_pert_4  [[O [MASK] Edna do Link é mais rápido do que o...  "]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_perturbados_indexado = lista_documentos_perturbados.set_index([\"id\"])\n","lista_documentos_perturbados_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"s0aDUbeZT1M8","outputId":"cd20de0b-22f1-4ab5-9d15-2aed2dd818fb"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-fa62658a-27d7-4c21-8e80-eafead04914a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_0</th>\n","      <td>[[[O, form, Edna, do, Link, é, mais, rápido, d...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_1</th>\n","      <td>[[[O, Form, Edna, do, Link, é, mais, rápido, d...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_2</th>\n","      <td>[[[O, Can, Edna, do, Link, é, mais, rápido, do...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_3</th>\n","      <td>[[[O, da, Edna, do, Link, é, mais, rápido, do,...</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_4</th>\n","      <td>[[[O, Cada, Edna, do, Link, é, mais, rápido, d...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa62658a-27d7-4c21-8e80-eafead04914a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fa62658a-27d7-4c21-8e80-eafead04914a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fa62658a-27d7-4c21-8e80-eafead04914a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                                     pos_documento\n","id                                                                                \n","5a8d89b5df8bba001a0f9afb_pert_0  [[[O, form, Edna, do, Link, é, mais, rápido, d...\n","5a8d89b5df8bba001a0f9afb_pert_1  [[[O, Form, Edna, do, Link, é, mais, rápido, d...\n","5a8d89b5df8bba001a0f9afb_pert_2  [[[O, Can, Edna, do, Link, é, mais, rápido, do...\n","5a8d89b5df8bba001a0f9afb_pert_3  [[[O, da, Edna, do, Link, é, mais, rápido, do,...\n","5a8d89b5df8bba001a0f9afb_pert_4  [[[O, Cada, Edna, do, Link, é, mais, rápido, d..."]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_perturbados_pos_indexado = lista_documentos_perturbados_pos.set_index([\"id\"])\n","lista_documentos_perturbados_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"kq0-NGaC76jP"},"source":["### 5.1.5 Agrupar os dados originais e perturbados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["056737efdeed493a9f8c70978477c456"]},"id":"t_HVTlvaxqoM","outputId":"21c09f9a-748b-4090-d955-e2048814f4a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processando 1419 documentos originais\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"056737efdeed493a9f8c70978477c456","version_major":2,"version_minor":0},"text/plain":["Documentos:   0%|          | 0/1419 [00:00<?, ? documento/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Import das bibliotecas.\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","print(\"Processando\",len(lista_documentos_originais),\"documentos originais\")\n","\n","lista_documentos_agrupados = []\n","\n","# Barra de progresso dos documentos\n","lista_documentos_originais_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_originais_bar:\n","  #if i < 2:\n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    #print(\"id_documento:\",id_documento)\n","\n","    # Carrega a lista das sentenças do documento\n","    lista_sentenca_documento = linha_documento[1]\n","    #print(\"\\nlista_sentenca_documento:\",lista_sentenca_documento)\n","    #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","\n","    # Adiciona o original a lista dos dados agrupados, considerando como coerente(1)\n","    lista_documentos_agrupados.append([id_documento, lista_sentenca_documento, linha_documento[2], 1])\n","\n","    # Percorre os documentos perturbados apartir do original\n","    for j in range(0, model_args.documentos_perturbados):\n","\n","      # Id do documento perturbado\n","      id_perturbado = str(id_documento) + \"_pert_\" + str(j)\n","\n","      # localiza o documento perturbado\n","      documento_perturbado = lista_documentos_perturbados_indexado.loc[id_perturbado]\n","      # print(\"documento_perturbado:\", documento_perturbado)\n","      # print(\"len(documento_perturbado):\", len(documento_perturbado))\n","      # Recupera a sentença do documento perturbado\n","      lista_perturbado = documento_perturbado[0]\n","\n","      # Adiciona o perturbado a lista dos dados agrupados considerando como incoerente(0)\n","      lista_documentos_agrupados.append([id_perturbado, lista_perturbado, documento_perturbado[1], 0])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO: {}.\".format(len(lista_documentos_agrupados)))"]},{"cell_type":"markdown","metadata":{"id":"THHBPK6Ov8WV"},"source":["Converte em um dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sWz4b8Fpv8ki"},"outputs":[],"source":["# Cria o dataframe da lista\n","lista_documentos_agrupados = pd.DataFrame(lista_documentos_agrupados, columns = [\"id\",\"sentencas\",\"documento\",\"classe\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AsbAU3pnAjYQ"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str, \"sentencas\": object, \"documento\": str, \"classe\": int}\n","\n","lista_documentos_agrupados = lista_documentos_agrupados.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LExAiKee0nhm","outputId":"e551991a-1392-421f-8ff8-4df053000977"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-3c27df07-a452-4eb8-8cd3-abd0ab2856dc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>53034</th>\n","      <td>5a7d388a70df9f001a875017_pert_8</td>\n","      <td>[Quais foram as causas do cultivo nas primeira...</td>\n","      <td>Quais foram as causas do cultivo nas primeiras...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>107585</th>\n","      <td>57106d2fb654c5140001f8ef_pert_19</td>\n","      <td>[Como foram identificadas coletivamente as cid...</td>\n","      <td>Como foram identificadas coletivamente as cida...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3712</th>\n","      <td>570e5b3b0dc6ce1900204f8b_pert_75</td>\n","      <td>[As áreas de Docklands , St . Kilda Road e Sou...</td>\n","      <td>As áreas de Docklands , St . Kilda Road e Sout...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9812</th>\n","      <td>5acd9b8e07355d001abf4805_pert_14</td>\n","      <td>[Quem foi o republicano da era da metade da re...</td>\n","      <td>Quem foi o republicano da era da metade da rec...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>63956</th>\n","      <td>5aceb92632bba1001ae4b1c2_pert_22</td>\n","      <td>[Quem declarou que Atanásio seria sepultado no...</td>\n","      <td>Quem declarou que Atanásio seria sepultado nov...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>43791</th>\n","      <td>57294a001d0469140077925b_pert_57</td>\n","      <td>[Que evento demonstrou grandes mudanças nas Be...</td>\n","      <td>Que evento demonstrou grandes mudanças nas Ber...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>59885</th>\n","      <td>5726b731dd62a815002e8dca_pert_92</td>\n","      <td>[Onde as perdas são negativas ?]</td>\n","      <td>Onde as perdas são negativas ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6488</th>\n","      <td>57312489497a881900248bad_pert_23</td>\n","      <td>[Por causa do erro de Colombo , as Américas pa...</td>\n","      <td>Por causa do erro de Colombo , as Américas pas...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14134</th>\n","      <td>5725d3e4271a42140099d273_pert_94</td>\n","      <td>[Qual é a principal Superliga de basquete ?]</td>\n","      <td>Qual é a principal Superliga de basquete ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>20230</th>\n","      <td>56f81eceaef2371900625de5_pert_29</td>\n","      <td>[Em que ano Tito viajou para os EUA para acomp...</td>\n","      <td>Em que ano Tito viajou para os EUA para acompa...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c27df07-a452-4eb8-8cd3-abd0ab2856dc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3c27df07-a452-4eb8-8cd3-abd0ab2856dc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3c27df07-a452-4eb8-8cd3-abd0ab2856dc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                      id  \\\n","53034    5a7d388a70df9f001a875017_pert_8   \n","107585  57106d2fb654c5140001f8ef_pert_19   \n","3712    570e5b3b0dc6ce1900204f8b_pert_75   \n","9812    5acd9b8e07355d001abf4805_pert_14   \n","63956   5aceb92632bba1001ae4b1c2_pert_22   \n","43791   57294a001d0469140077925b_pert_57   \n","59885   5726b731dd62a815002e8dca_pert_92   \n","6488    57312489497a881900248bad_pert_23   \n","14134   5725d3e4271a42140099d273_pert_94   \n","20230   56f81eceaef2371900625de5_pert_29   \n","\n","                                                sentencas  \\\n","53034   [Quais foram as causas do cultivo nas primeira...   \n","107585  [Como foram identificadas coletivamente as cid...   \n","3712    [As áreas de Docklands , St . Kilda Road e Sou...   \n","9812    [Quem foi o republicano da era da metade da re...   \n","63956   [Quem declarou que Atanásio seria sepultado no...   \n","43791   [Que evento demonstrou grandes mudanças nas Be...   \n","59885                    [Onde as perdas são negativas ?]   \n","6488    [Por causa do erro de Colombo , as Américas pa...   \n","14134        [Qual é a principal Superliga de basquete ?]   \n","20230   [Em que ano Tito viajou para os EUA para acomp...   \n","\n","                                                documento  classe  \n","53034   Quais foram as causas do cultivo nas primeiras...       0  \n","107585  Como foram identificadas coletivamente as cida...       0  \n","3712    As áreas de Docklands , St . Kilda Road e Sout...       0  \n","9812    Quem foi o republicano da era da metade da rec...       0  \n","63956   Quem declarou que Atanásio seria sepultado nov...       0  \n","43791   Que evento demonstrou grandes mudanças nas Ber...       0  \n","59885                      Onde as perdas são negativas ?       0  \n","6488    Por causa do erro de Colombo , as Américas pas...       0  \n","14134          Qual é a principal Superliga de basquete ?       0  \n","20230   Em que ano Tito viajou para os EUA para acompa...       0  "]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["lista_documentos_agrupados.sample(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"P3qemxYGwHL7","outputId":"46ed6780-7146-4ac6-b694-d7dd00dd3a24"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-908bc4c1-dbb0-4c1d-986e-a58b60f3bb0a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>23437</th>\n","      <td>573360014776f4190066090e_pert_4</td>\n","      <td>[Como são chamados os riscos que apresentam gr...</td>\n","      <td>Como são chamados os riscos que apresentam gra...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4976</th>\n","      <td>56e4b61539bdeb14003479ac_pert_26</td>\n","      <td>[Que tipo de movimento era a arquitetura moder...</td>\n","      <td>Que tipo de movimento era a arquitetura modern...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>40516</th>\n","      <td>57302051947a6a140053d14f_pert_14</td>\n","      <td>[Quem estava ligado no mesmo tipo de aplicação...</td>\n","      <td>Quem estava ligado no mesmo tipo de aplicação ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27543</th>\n","      <td>5a53e21dbdaabd001a3867b6_pert_70</td>\n","      <td>[De que religiões a Igreja Apostólica Armênia ...</td>\n","      <td>De que religiões a Igreja Apostólica Armênia s...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>115703</th>\n","      <td>56ce0f42aab44d1400b8841e_pert_57</td>\n","      <td>[Qual instrumento engloba todas as suas compos...</td>\n","      <td>Qual instrumento engloba todas as suas composi...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>105597</th>\n","      <td>572923981d046914007790b0_pert_51</td>\n","      <td>[Que método é usado para medir janelas ?]</td>\n","      <td>Que método é usado para medir janelas ?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>132982</th>\n","      <td>5ad3dcf2604f3c001a3ff425_pert_65</td>\n","      <td>[Quem é o personagem de Santa Helena represent...</td>\n","      <td>Quem é o personagem de Santa Helena representa...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>915</th>\n","      <td>5a668e55f038b7001ab0bfcc_pert_5</td>\n","      <td>[Sinback trabalha com qual faculdade em um sis...</td>\n","      <td>Sinback trabalha com qual faculdade em um sist...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>87796</th>\n","      <td>5ad171fd645df0001a2d1bd9_pert_26</td>\n","      <td>[O que motiva um aumento nas dificuldades entr...</td>\n","      <td>O que motiva um aumento nas dificuldades entre...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25537</th>\n","      <td>573126ae05b4da19006bcdf4_pert_84</td>\n","      <td>[Que organização é frequentemente lembrado com...</td>\n","      <td>Que organização é frequentemente lembrado como...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-908bc4c1-dbb0-4c1d-986e-a58b60f3bb0a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-908bc4c1-dbb0-4c1d-986e-a58b60f3bb0a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-908bc4c1-dbb0-4c1d-986e-a58b60f3bb0a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                      id  \\\n","23437    573360014776f4190066090e_pert_4   \n","4976    56e4b61539bdeb14003479ac_pert_26   \n","40516   57302051947a6a140053d14f_pert_14   \n","27543   5a53e21dbdaabd001a3867b6_pert_70   \n","115703  56ce0f42aab44d1400b8841e_pert_57   \n","105597  572923981d046914007790b0_pert_51   \n","132982  5ad3dcf2604f3c001a3ff425_pert_65   \n","915      5a668e55f038b7001ab0bfcc_pert_5   \n","87796   5ad171fd645df0001a2d1bd9_pert_26   \n","25537   573126ae05b4da19006bcdf4_pert_84   \n","\n","                                                sentencas  \\\n","23437   [Como são chamados os riscos que apresentam gr...   \n","4976    [Que tipo de movimento era a arquitetura moder...   \n","40516   [Quem estava ligado no mesmo tipo de aplicação...   \n","27543   [De que religiões a Igreja Apostólica Armênia ...   \n","115703  [Qual instrumento engloba todas as suas compos...   \n","105597          [Que método é usado para medir janelas ?]   \n","132982  [Quem é o personagem de Santa Helena represent...   \n","915     [Sinback trabalha com qual faculdade em um sis...   \n","87796   [O que motiva um aumento nas dificuldades entr...   \n","25537   [Que organização é frequentemente lembrado com...   \n","\n","                                                documento  classe  \n","23437   Como são chamados os riscos que apresentam gra...       0  \n","4976    Que tipo de movimento era a arquitetura modern...       0  \n","40516   Quem estava ligado no mesmo tipo de aplicação ...       0  \n","27543   De que religiões a Igreja Apostólica Armênia s...       0  \n","115703  Qual instrumento engloba todas as suas composi...       0  \n","105597            Que método é usado para medir janelas ?       0  \n","132982  Quem é o personagem de Santa Helena representa...       0  \n","915     Sinback trabalha com qual faculdade em um sist...       0  \n","87796   O que motiva um aumento nas dificuldades entre...       0  \n","25537   Que organização é frequentemente lembrado como...       0  "]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["lista_documentos_agrupados.sample(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_TJbwpcYtsN3"},"outputs":[],"source":["# Importa das bibliotecas\n","import pandas as pd\n","\n","# Concatena as listas de documentos originais e perturbados\n","lista_documentos_agrupados_pos = pd.concat([lista_documentos_originais_pos, lista_documentos_perturbados_pos])\n","\n","logging.info(\"TERMINADO AGRUPAMENTO POS: {}.\".format(len(lista_documentos_agrupados_pos)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JvDXTxtRuvrX"},"outputs":[],"source":["# Corrige os tipos dos dados da lista agrupada\n","tipos = {\"id\": str}\n","\n","lista_documentos_agrupados_pos = lista_documentos_agrupados_pos.astype(tipos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDW4pj8vuh2I"},"outputs":[],"source":["lista_documentos_agrupados_pos.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"viicg1E7mXLK"},"source":["#### Criar dados indexados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0YBdkvoPm2vO","outputId":"d0fa71fd-dc48-40fe-ea4e-c11386c13d55"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-ae091883-17ab-4925-9d22-00682fa6355e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb</th>\n","      <td>[O formulário Edna do Link é mais rápido do qu...</td>\n","      <td>O formulário Edna do Link é mais rápido do que...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_0</th>\n","      <td>[O form Edna do Link é mais rápido do que outr...</td>\n","      <td>O form Edna do Link é mais rápido do que outro...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_1</th>\n","      <td>[O Form Edna do Link é mais rápido do que outr...</td>\n","      <td>O Form Edna do Link é mais rápido do que outro...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_2</th>\n","      <td>[O Can Edna do Link é mais rápido do que outro...</td>\n","      <td>O Can Edna do Link é mais rápido do que outro ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb_pert_3</th>\n","      <td>[O da Edna do Link é mais rápido do que outro ...</td>\n","      <td>O da Edna do Link é mais rápido do que outro f...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae091883-17ab-4925-9d22-00682fa6355e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ae091883-17ab-4925-9d22-00682fa6355e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ae091883-17ab-4925-9d22-00682fa6355e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                                         sentencas  \\\n","id                                                                                   \n","5a8d89b5df8bba001a0f9afb         [O formulário Edna do Link é mais rápido do qu...   \n","5a8d89b5df8bba001a0f9afb_pert_0  [O form Edna do Link é mais rápido do que outr...   \n","5a8d89b5df8bba001a0f9afb_pert_1  [O Form Edna do Link é mais rápido do que outr...   \n","5a8d89b5df8bba001a0f9afb_pert_2  [O Can Edna do Link é mais rápido do que outro...   \n","5a8d89b5df8bba001a0f9afb_pert_3  [O da Edna do Link é mais rápido do que outro ...   \n","\n","                                                                         documento  \\\n","id                                                                                   \n","5a8d89b5df8bba001a0f9afb         O formulário Edna do Link é mais rápido do que...   \n","5a8d89b5df8bba001a0f9afb_pert_0  O form Edna do Link é mais rápido do que outro...   \n","5a8d89b5df8bba001a0f9afb_pert_1  O Form Edna do Link é mais rápido do que outro...   \n","5a8d89b5df8bba001a0f9afb_pert_2  O Can Edna do Link é mais rápido do que outro ...   \n","5a8d89b5df8bba001a0f9afb_pert_3  O da Edna do Link é mais rápido do que outro f...   \n","\n","                                 classe  \n","id                                       \n","5a8d89b5df8bba001a0f9afb              1  \n","5a8d89b5df8bba001a0f9afb_pert_0       0  \n","5a8d89b5df8bba001a0f9afb_pert_1       0  \n","5a8d89b5df8bba001a0f9afb_pert_2       0  \n","5a8d89b5df8bba001a0f9afb_pert_3       0  "]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_agrupados_indexado = lista_documentos_agrupados.set_index([\"id\"])\n","lista_documentos_agrupados_indexado.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NQjlOJzOmbsp","outputId":"7870e059-34eb-45bc-c044-8cdffa08bd9e"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-2f491149-de72-4834-ba7a-a5e80ba10e18\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos_documento</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5a8d89b5df8bba001a0f9afb</th>\n","      <td>[[[O, formulário, Edna, do, Link, é, mais, ráp...</td>\n","    </tr>\n","    <tr>\n","      <th>5acfa4e977cf76001a6856da</th>\n","      <td>[[[Quais, dois, ministros, lutaram, pelo, pode...</td>\n","    </tr>\n","    <tr>\n","      <th>5ad19f40645df0001a2d213b</th>\n","      <td>[[[O, que, Irving, Langmuir, descobriu, que, a...</td>\n","    </tr>\n","    <tr>\n","      <th>56ce66aeaab44d1400b8875a</th>\n","      <td>[[[Em, que, ano, a, célula, solar, de, silício...</td>\n","    </tr>\n","    <tr>\n","      <th>5acdabd307355d001abf48f0</th>\n","      <td>[[[Desde, que, ano, foi, levantada, a, idéia, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f491149-de72-4834-ba7a-a5e80ba10e18')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2f491149-de72-4834-ba7a-a5e80ba10e18 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2f491149-de72-4834-ba7a-a5e80ba10e18');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                              pos_documento\n","id                                                                         \n","5a8d89b5df8bba001a0f9afb  [[[O, formulário, Edna, do, Link, é, mais, ráp...\n","5acfa4e977cf76001a6856da  [[[Quais, dois, ministros, lutaram, pelo, pode...\n","5ad19f40645df0001a2d213b  [[[O, que, Irving, Langmuir, descobriu, que, a...\n","56ce66aeaab44d1400b8875a  [[[Em, que, ano, a, célula, solar, de, silício...\n","5acdabd307355d001abf48f0  [[[Desde, que, ano, foi, levantada, a, idéia, ..."]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["# Expecifica o(s) campo(s) indexado(s) e faz uma cópia dda lista inddexada\n","lista_documentos_agrupados_pos_indexado = lista_documentos_agrupados_pos.set_index([\"id\"])\n","lista_documentos_agrupados_pos_indexado.head()"]},{"cell_type":"markdown","metadata":{"id":"d1yGaGzzyEiy"},"source":["## 5.2 Gerando as comparações\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xKaqQPs8VQ5u"},"source":["### 5.2.1 Medidas de similaridade\n"]},{"cell_type":"markdown","metadata":{"id":"jt06PTN5idrg"},"source":["Similaridade do cosseno entre os embeddings.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n","\n","A função spatial.distance.cosine do módulo scipy calcula a distância em vez da similaridade do cosseno, mas para conseguir isso, podemos subtrair o valor da distância de 1.\n","\n","Intervalo de [-1,1]\n","\n","Vetores iguais a distância é igual 1.\n","\n","Vetores diferentes medida próxima de -1."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6vbXj-brOlMF"},"outputs":[],"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cosine\n","\n","def similaridadeCosseno(embeddings1, embeddings2):\n","    \"\"\"\n","      Similaridade do cosseno dos embeddings dos textos.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    similaridade = 1 - cosine(embeddings1, embeddings2)\n","\n","    return similaridade"]},{"cell_type":"markdown","metadata":{"id":"fazAuLMUr_c0"},"source":["### 5.2.2 Medidas de distância"]},{"cell_type":"markdown","metadata":{"id":"_IcrjAbhwake"},"source":["Distância euclidiana entre os embeddings.\n","\n","Possui outros nomes como distância L2 ou norma L2.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mIrTId9jwakh"},"outputs":[],"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import euclidean\n","\n","def distanciaEuclidiana(embeddings1, embeddings2):\n","    \"\"\"\n","      Distância euclidiana entre os embeddings dos textos.\n","      Possui outros nomes como distância L2 ou norma L2.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    distancia = euclidean(embeddings1, embeddings2)\n","\n","    return distancia"]},{"cell_type":"markdown","metadata":{"id":"-uJlqYCSXdVk"},"source":["Distância Manhattan entre os embeddings.\n","\n","Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cityblock.html#scipy.spatial.distance.cityblock"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jFG5UT_SXdVn"},"outputs":[],"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cityblock\n","\n","def distanciaManhattan(embeddings1, embeddings2):\n","    \"\"\"\n","      Distância Manhattan entre os embeddings dos textos\n","      Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","\n","    distancia = cityblock(embeddings1, embeddings2)\n","\n","    return distancia"]},{"cell_type":"markdown","metadata":{"id":"S6A6-Xwg8GJw"},"source":["### 5.2.3 Retorna todas as medidas dos embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qHzQ98zg8GWJ"},"outputs":[],"source":["def getMedidasEmbedding(embedding_wi, embedding_wj):\n","\n","  \"\"\"\n","    Retorna as medidas de similaridade do cosseno(cos), distância Euclidiana(euc) e\n","    distância de Manhattan(man) entre os embeddings.\n","\n","    Parâmetros:\n","    `embeddings_wi` - Um embedding de uma palavra a ser medido.\n","    `embeddings_wj` - Um embedding de uma palavra a ser medido.\n","  \"\"\"\n","\n","  #print(\"embedding_wi=\", embedding_wi.shape)\n","  #print(\"embedding_wj=\", embedding_wj.shape)\n","\n","  # Similaridade do cosseno entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  cos = similaridadeCosseno(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  # Distância euclidiana entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  euc = distanciaEuclidiana(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  # Distância de manhattan entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  man = distanciaManhattan(embedding_wi, embedding_wj)\n","  # Saída: Número real\n","\n","  del embedding_wi\n","  del embedding_wj\n","\n","  # Retorno das medidas das sentenças\n","  return cos, euc, man"]},{"cell_type":"markdown","metadata":{"id":"KEtmDaKqAL-9"},"source":["### 5.2.4 getTokensEmbeddingsPOSSentenca\n","Gera os tokens, POS e embeddings de cada sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MXPWq5JyIoQf"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar mais tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera mais tokens que a tokenização das palavras do spaCy\n","dic_excecao_maior = {\"al-Ḥarrānī\": 3,\n","               \"al-Battānī\": 7,\n","               \"mi.²\":3,\n","               \"nm\":2,\n","               \"550\":2,\n","               \"mg\":1,\n","               \"550nm\":4,\n","               \"q-glass\":5,\n","               \"ômega-6\":3,\n","               str(chr(804)+chr(10217)):1,\n","               \"mm\":1,\n","               \"K\":1,\n","               \"al-qasim\":3,\n","               \"T\":1,\n","               \"ḱlew-\":2,\n","               \"◌\":1,\n","               \"m\":1,\n","               \"TGF-β\":5,\n","               \"56.º\":3,\n","               \"45.º\":3,\n","               \"34.º\":3,\n","               \"nº\":1,\n","               \"200º\":1,\n","               \"1º\":1,\n","               \"g\":1,\n","               \"š\":1,\n","               \"ž\":1,\n","               \"km²\":1,\n","               \"κανὠν\":1,\n","               \"7º\":1,\n","               \"2º\":1,\n","               \"3º\":1,\n","               \"19º\":1,\n","               \"18º\":1,\n","               \"ʱ⟩\":1,\n","               \"ð\":1,\n","               \"θ\":1,\n","               \"Ü-Tsang\":4,\n","               \"p˭\":1,\n","               \"s˭\":1,\n","               \"pʰ\":1,\n","               \"ʰp\":1,\n","               \"sʰ\":1,\n","               \"q\":1,\n","               \"Ṣalībī\":1,\n","               \"ṣalīb\":1,\n","               \"⟨bʰ⟩\":3,\n","               \"Ônibus\":1,\n","               \"2ª\":1,\n","               \"indo-arianas\":4,\n","               \"G\":1,\n","               \"⟨bd\":3,\n","               \"ɡ⟩\":2,\n","               \"tʰ\":1,}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"89oBywgbIxzV"},"outputs":[],"source":["def getExcecaoDicMaior(id, token, dic_excecao_maior):\n","\n","  valor = dic_excecao_maior.get(token)\n","  if valor != None:\n","\n","    if token == \"mg\" and id in [\"572b8803be1ee31400cb8405\",\n","                                \"572b8803be1ee31400cb8406\",\n","                                \"5acfcfd677cf76001a68614c\",\n","                                \"5acfcfd677cf76001a68614d\"]:\n","      return 2\n","    else:\n","      return valor\n","  else:\n","    return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MPODj-AWfhxW"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar menos tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera menos tokens que a tokenização das palavras do spaCy\n","dic_excecao_menor = {\"1°\":1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xy2bzLBWfeqi"},"outputs":[],"source":["def getExcecaoDicMenor(id, token, dic_excecao_menor):\n","\n","  valor = dic_excecao_menor.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"markdown","metadata":{"id":"LLRdNsbo0qxA"},"source":["Função que retorna os embeddings, tokens e POS da sentença com um mesmo tamamnho."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OykQrpVsILpM"},"outputs":[],"source":["# Importa a biblioteca\n","import torch\n","\n","def getTokensEmbeddingsPOSSentenca(id_documento,\n","                                   index_sentenca,\n","                                   embedding_documento,\n","                                   token_BERT_documento,\n","                                   sentenca,\n","                                   tokenizer,\n","                                   sentenca_token = None,\n","                                   sentenca_postagging = None,\n","                                   estrategia_medida = 0):\n","    \"\"\"\n","      Retorna os tokens, as POS-Tagging e os embeddings dos tokens igualando a quantidade de tokens do spaCy com a tokenização do BERT de acordo com a estratégia de pooling para palavras fora do vocabulário do BERT.\n","      Usa a estratégia MEAN para calcular a média dos embeddings dos tokens que formam uma palavra fora do vocabulário do BERT.\n","      Usa a estratégia MAX para calcular o valor máximo dos embeddings dos tokens que formam uma palavra fora do vocabulário do BERT.\n","    \"\"\"\n","\n","    #Guarda os tokens e embeddings\n","    lista_tokens = []\n","    lista_embeddings_mean = []\n","    lista_embeddings_max = []\n","\n","    # Se a sentença não for tokenizada\n","    if sentenca_token == None:\n","      # Gera a tokenização e POS-Tagging da sentença\n","      sentenca_token, sentenca_postagging = getListaTokensPOSSentenca(sentenca)\n","\n","    #print(\"\\nsentenca                :\",sentenca)\n","    #print(\"id_documento                :\",id_documento)\n","    #print(\"index_sentenca              :\",index_sentenca)\n","    #print(\"sentenca_token              :\",sentenca_token)\n","    #print(\"len(sentenca_token)         :\",len(sentenca_token))\n","    #print(\"sentenca_postagging         :\",sentenca_postagging)\n","    #print(\"len(sentenca_postagging)    :\",len(sentenca_postagging))\n","\n","    # Recupera os embeddings da sentença dos embeddings dentro dos embeddings do documento\n","    embedding_sentenca, sentenca_tokenizada_BERT = getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embedding_documento,\n","                                                                                                       token_BERT_documento,\n","                                                                                                       sentenca,\n","                                                                                                       tokenizer)\n","\n","    # embedding <qtde_tokens x 4096>\n","    #print(\"embedding_sentenca          :\",embedding_sentenca.shape)\n","    #print(\"sentenca_tokenizada_BERT     :\",sentenca_tokenizada_BERT)\n","    #print(\"len(sentenca_tokenizada_BERT):\",len(sentenca_tokenizada_BERT))\n","\n","    # Seleciona os pares de palavra a serem avaliadas\n","    pos_wi = 0 # Posição do token da palavra gerado pelo spaCy\n","    pos_wj = pos_wi # Posição do token da palavra gerado pelo BERT\n","    pos2 = -1\n","\n","    # Enquanto o indíce da palavra pos_wj(2a palavra) não chegou ao final da quantidade de tokens do BERT\n","    while pos_wj < len(sentenca_tokenizada_BERT):\n","\n","      # Seleciona os tokens da sentença\n","      wi = sentenca_token[pos_wi] # Recupera o token da palavra gerado pelo spaCy\n","      wi1 = \"\"\n","      pos2 = -1\n","      if pos_wi+1 < len(sentenca_token):\n","        wi1 = sentenca_token[pos_wi+1] # Recupera o próximo token da palavra gerado pelo spaCy\n","\n","        # Localiza o deslocamento da exceção\n","        pos2 = getExcecaoDicMenor(id_documento, wi+wi1, dic_excecao_menor)\n","        #print(\"Exceção pos2:\", pos2)\n","\n","      wj = sentenca_tokenizada_BERT[pos_wj] # Recupera o token da palavra gerado pelo BERT\n","      #print(\"wi[\",pos_wi,\"]=\", wi)\n","      #print(\"wj[\",pos_wj,\"]=\", wj)\n","\n","      # Tratando exceções\n","      # Localiza o deslocamento da exceção\n","      pos = getExcecaoDicMaior(id_documento, wi, dic_excecao_maior)\n","      #print(\"Exceção pos:\", pos)\n","\n","      if pos != -1 or pos2 != -1:\n","        if pos != -1:\n","          #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","          lista_tokens.append(wi)\n","          # Verifica se tem mais de um token\n","          if pos != 1:\n","            indice_token = pos_wj + pos\n","            #print(\"Calcula a média de :\", pos_wj , \"até\", indice_token)\n","            embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","            #print(\"embeddings_tokens_palavra:\",embeddings_tokens_palavra.shape)\n","            # calcular a média dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_mean = torch.mean(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_mean:\",embedding_estrategia_mean.shape)\n","            lista_embeddings_mean.append(embedding_estrategia_mean)\n","\n","            # calcular o máximo dos embeddings dos tokens do BERT da palavra\n","            embedding_estrategia_max, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","            #print(\"embedding_estrategia_max:\",embedding_estrategia_max.shape)\n","            lista_embeddings_max.append(embedding_estrategia_max)\n","          else:\n","            # Adiciona o embedding do token a lista de embeddings\n","            lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","            lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + pos\n","          #print(\"Proxima:\")\n","          #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","          #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","        else:\n","          if pos2 != -1:\n","            #print(\"Adiciona 1 Exceção palavra == wi or palavra = [UNK]:\",wi)\n","            lista_tokens.append(wi+wi1)\n","            # Verifica se tem mais de um token\n","            if pos2 == 1:\n","              # Adiciona o embedding do token a lista de embeddings\n","              lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","              lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","\n","            # Avança para a próxima palavra e token do BERT\n","            pos_wi = pos_wi + 2\n","            pos_wj = pos_wj + pos2\n","            #print(\"Proxima:\")\n","            #print(\"wi[\",pos_wi,\"]=\", sentenca_token[pos_wi])\n","            #print(\"wj[\",pos_wj,\"]=\", sentenca_tokenizada_BERT[pos_wj])\n","      else:\n","        # Tokens iguais adiciona a lista, o token não possui subtoken\n","        if (wi == wj or wj==\"[UNK]\"):\n","          # Adiciona o token a lista de tokens\n","          #print(\"Adiciona 2 wi==wj or wj==[UNK]:\", wi )\n","          lista_tokens.append(wi)\n","          # Adiciona o embedding do token a lista de embeddings\n","          lista_embeddings_mean.append(embedding_sentenca[pos_wj])\n","          lista_embeddings_max.append(embedding_sentenca[pos_wj])\n","          #print(\"embedding1[pos_wj]:\", embedding_sentenca[pos_wj].shape)\n","          # Avança para a próxima palavra e token do BERT\n","          pos_wi = pos_wi + 1\n","          pos_wj = pos_wj + 1\n","\n","        else:\n","          # A palavra foi tokenizada pelo Wordpice com ## ou diferente do spaCy ou desconhecida\n","          # Inicializa a palavra a ser montada\n","          palavra_postagging = wj\n","          indice_token = pos_wj + 1\n","          while  ((palavra_postagging != wi) and indice_token < len(sentenca_tokenizada_BERT)):\n","              if \"##\" in sentenca_tokenizada_BERT[indice_token]:\n","                # Remove os caracteres \"##\" do token\n","                parte = sentenca_tokenizada_BERT[indice_token][2:]\n","              else:\n","                parte = sentenca_tokenizada_BERT[indice_token]\n","\n","              palavra_postagging = palavra_postagging + parte\n","              #print(\"palavra_postagging:\",palavra_postagging)\n","              # Avança para o próximo token do BERT\n","              indice_token = indice_token + 1\n","\n","          #print(\"\\nMontei palavra:\",palavra_postagging)\n","          if (palavra_postagging == wi or palavra_postagging == \"[UNK]\"):\n","              # Adiciona o token a lista\n","              #print(\"Adiciona 3 palavra == wi or palavra_postagging = [UNK]:\",wi)\n","              lista_tokens.append(wi)\n","              # Calcula a média dos tokens da palavra\n","              #print(\"Calcula o máximo :\", pos_wj , \"até\", indice_token)\n","              embeddings_tokens_palavra = embedding_sentenca[pos_wj:indice_token]\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra)\n","              #print(\"embeddings_tokens_palavra2:\",embeddings_tokens_palavra.shape)\n","\n","              # calcular a média dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_mean = torch.mean(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_mean:\",embedding_estrategia_mean)\n","              #print(\"embedding_estrategia_mean.shape:\",embedding_estrategia_mean.shape)\n","              lista_embeddings_mean.append(embedding_estrategia_mean)\n","\n","              # calcular o valor máximo dos embeddings dos tokens do BERT da palavra\n","              embedding_estrategia_max, linha = torch.max(embeddings_tokens_palavra, dim=0)\n","              #print(\"embedding_estrategia_max:\",embedding_estrategia_max)\n","              #print(\"embedding_estrategia_max.shape:\",embedding_estrategia_max.shape)\n","              lista_embeddings_max.append(embedding_estrategia_max)\n","\n","          # Avança para o próximo token do spaCy\n","          pos_wi = pos_wi + 1\n","          # Pula para o próximo token do BERT\n","          pos_wj = indice_token\n","\n","    # Verificação se as listas estão com o mesmo tamanho\n","    #if (len(lista_tokens) != len(sentenca_token)) or (len(lista_embeddings_mean) != len(sentenca_token)):\n","    if (len(lista_tokens) !=  len(lista_embeddings_mean)):\n","       print(\"\\nsentenca                  :\",sentenca)\n","       print(\"id_documento              :\",id_documento)\n","       print(\"index_sentenca            :\",index_sentenca)\n","       print(\"sentenca_postagging       :\",sentenca_postagging)\n","       print(\"sentenca_token            :\",sentenca_token)\n","       print(\"sentenca_tokenizada_BERT  :\",sentenca_tokenizada_BERT)\n","       print(\"lista_tokens              :\",lista_tokens)\n","       print(\"len(lista_tokens)         :\",len(lista_tokens))\n","       print(\"lista_embeddings_mean     :\",lista_embeddings_mean)\n","       print(\"len(lista_embeddings_mean):\",len(lista_embeddings_mean))\n","       print(\"lista_embeddings_max      :\",lista_embeddings_max)\n","       print(\"len(lista_embeddings_max) :\",len(lista_embeddings_max))\n","\n","    del embedding_sentenca\n","    del token_BERT_documento\n","    del tokenizer\n","    del sentenca_tokenizada_BERT\n","    del sentenca_token\n","\n","    return lista_tokens, sentenca_postagging, lista_embeddings_mean, lista_embeddings_max"]},{"cell_type":"markdown","metadata":{"id":"kw0qQ6zoQhkq"},"source":["### 5.2.5 comparaPalavrasSentencaTodas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Of3EOJwpQg-B"},"outputs":[],"source":["def comparaPalavrasSentencaTodas(id_documento,\n","                                 index_documento,\n","                                 index_sentenca,\n","                                 embedding_documento,\n","                                 token_BERT_documento,\n","                                 sentenca,\n","                                 tokenizer,\n","                                 sentenca_token = None,\n","                                 sentenca_postagging = None):\n","\n","  lista_tokens, lista_postagging, lista_embeddings_mean, lista_embeddings_max = getTokensEmbeddingsPOSSentenca(id_documento,\n","                                                                                                  index_sentenca,\n","                                                                                                  embedding_documento,\n","                                                                                                  token_BERT_documento,\n","                                                                                                  sentenca,\n","                                                                                                  tokenizer,\n","                                                                                                  sentenca_token,\n","                                                                                                  sentenca_postagging)\n","  #print(\"\\nSentença   :\",lista_tokens)\n","  #print(\"POS Tagging:\",lista_postagging)\n","  #print(\"Quantidade de palavras:\",len(lista_tokens))\n","\n","  # Quantidade de palavras no documento\n","  n = len(lista_tokens)\n","\n","  # Guarda a comparação da sentença\n","  lista_comparacao = []\n","\n","  # Realiza o combinação das palavras C(n,p)=(n!/(p!(n-p)!))\n","  # n = Número de elementos e p as combinações\n","  # C(5,2) = 10\n","\n","  # Percorre as palavras da sentença\n","  for i in range(0,n-1):\n","\n","    # Seleciona a palavra i da sentença\n","    wi = lista_tokens[i]\n","    pos_i = lista_postagging[i]\n","    #print(\"i:\",i)\n","\n","    # Percorre as palavras da sentença a partir de i + 1\n","    # Para não comparar a palavra com ela mesma\n","    for j in range(i+1,n):\n","\n","        # Seleciona a palavra j da sentença\n","        wj = lista_tokens[j]\n","        pos_j = lista_postagging[j]\n","\n","        # Recupera as medidas dos embeddings das palavras usando as estratégias MEAN e MAX\n","        cos_mean, euc_mean, man_mean = getMedidasEmbedding(lista_embeddings_mean[i], lista_embeddings_mean[j])\n","        cos_max, euc_max, man_max = getMedidasEmbedding(lista_embeddings_max[i], lista_embeddings_max[j])\n","\n","        # Agrupa as medidas\n","        comparacao = [id_documento,   #Id do documento\n","                      index_documento,#Índice do documento no conjunto de dados\n","                      index_sentenca, #[Indice da sentença no documento\n","                      i,              #Índice da palavra i na sentença\n","                      str(wi),        #Palavra i da sentença\n","                      pos_i,          #POS-Tagging da palavra i\n","                      j,              #Índice da palavra j na sentença\n","                      str(wj),        #Palavra j da sentença\n","                      pos_j,          #POS-Tagging da palavra j\n","                      cos_mean,       #Cos de wi e wj usando a média dos embeddings das subpalavras\n","                      euc_mean,       #Euc de wi e wj usando a média dos embeddings das subpalavras\n","                      man_mean,       #Man de wi e wj usando a média dos embeddings das subpalavras\n","                      cos_max,        #Cos de wi e wj usando o máximo dos embeddings das subpalavras\n","                      euc_max,        #Euc de wi e wj usando o máximo dos embeddings das subpalavras\n","                      man_max]        #Man de wi e wj usando o máximo dos embeddings das subpalavras\n","\n","        # Guardas as medidas da comparação na lista\n","        lista_comparacao.append(comparacao)\n","\n","        #print(comparacao)\n","        #print(\"Compara :\", i, \" com \", j)\n","        #print(\"Compara :\", wi, \" com \", wj)\n","        # print(\"     cos_mean:\", cos_mean)\n","        # print(\"     euc_mean:\", euc_mean)\n","        # print(\"     man_mean:\", man_mean)\n","        # print(\"     cos_max:\", cos_max)\n","        # print(\"     euc_max:\", euc_max)\n","        # print(\"     man_max:\", man_max)\n","\n","  del lista_tokens\n","  del lista_postagging\n","  del lista_embeddings_mean\n","  del lista_embeddings_max\n","\n","  return lista_comparacao"]},{"cell_type":"markdown","metadata":{"id":"TXNhBApgbULb"},"source":["### 5.2.6 Realiza a comparação de todas as palavras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfGFsRaPDBMt"},"outputs":[],"source":["# Import das bibliotecas\n","import ast\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","logging.info(\"Processando {} documentos originais e perturbados.\".format(len(lista_documentos_agrupados)))\n","\n","# Guarda a comparacação das sentenças\n","resultado_comparacao = []\n","\n","# Conta sentenças comparadas e não comparadas\n","conta_sentenca = 0\n","\n","# Limpa o buffer antes de realizar a comparação\n","limpaBufferEmbedding()\n","\n","# Barra de progresso dos documentos\n","lista_documentos_bar = tqdm_notebook(lista_documentos_agrupados.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_agrupados))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_bar:\n","  # if i < 2:\n","    # print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]\n","    #print(\"id_documento:\",id_documento)\n","    # Recupera as sentenças do documento\n","    #lista_sentenca_documento = ast.literal_eval(linha_documento[1])\n","    lista_sentenca_documento = linha_documento[1]\n","    # print(\"lista_sentenca_documento:\",lista_sentenca_documento)\n","    # print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","    # Recupera o documento\n","    documento = linha_documento[2]\n","    #print(\"documento:\",documento)\n","    # Recupera a classe documento (1-original 0-perturbado)\n","    #classe = linha_documento[3]\n","    #print(\"classe:\",classe)\n","\n","    # Localiza a POSTagging do documento agrupado\n","    lista_pos_documento = lista_documentos_agrupados_pos_indexado.loc[id_documento][0]\n","    # print(\"lista_pos_documento:\",lista_pos_documento)\n","    # print(\"len(lista_pos_documento):\",len(lista_pos_documento))\n","\n","    # Gera os embeddings do documento utiliza a concatenação das 4 últimas camadas\n","    # Somente para os documentos originais\n","    if \"_pert_\" not in id_documento:\n","      embedding_documento, token_BERT_documento = getEmbeddingsDocumentoBuffer(documento, model, tokenizer)\n","    else:\n","      embedding_documento, token_BERT_documento = getEmbeddingsDocumento(documento, model, tokenizer)\n","    # embedding <qtde_tokens x 4096>\n","    #print(\"embedding_documento:\",embedding_documento.shape)\n","    #print(\"token_BERT_documento:\",token_BERT_documento)\n","    #print(\"len(token_BERT_documento):\",len(token_BERT_documento))\n","\n","    # Percorre as sentenças do documento\n","    for j, sentenca in enumerate(lista_sentenca_documento):\n","      #print(\"id_documento:\",id_documento)\n","      #print(\"sentenca:\",sentenca)\n","\n","      sentenca_token = lista_pos_documento[j][0]\n","      sentenca_postagging = lista_pos_documento[j][1]\n","      #sentenca_verbos = lista_pos_documento[j][2]\n","\n","      #print(\"sentenca_token:\",sentenca_token)\n","      #print(\"len(sentenca_token):\",len(sentenca_token))\n","\n","      #print(\"sentenca_postagging:\",sentenca_postagging)\n","      #print(\"len(sentenca_postagging):\",len(sentenca_postagging))\n","\n","      #print(\"sentenca_verbos:\",sentenca_verbos)\n","      #print(\"len(sentenca_verbos):\",len(sentenca_verbos))\n","\n","      # Conta o número de sentenças com palavras comparadas\n","      conta_sentenca = conta_sentenca + 1\n","\n","      # Recupera as maiores e menores medidas entre as palavras\n","      lista_comparacao = comparaPalavrasSentencaTodas(id_documento,\n","                                                      i,\n","                                                      j,\n","                                                      embedding_documento,\n","                                                      token_BERT_documento,\n","                                                      sentenca,\n","                                                      tokenizer,\n","                                                      sentenca_token,\n","                                                      sentenca_postagging)\n","      #print(len(lista_comparacao))\n","      #print(lista_comparacao)\n","\n","      # Guarda o resultado da comparação\n","      resultado_comparacao = resultado_comparacao + lista_comparacao"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugwTe8C3ebjy"},"outputs":[],"source":["logging.info(\"Número de sentenças com palavras comparadas: {}.\".format(conta_sentenca))\n","logging.info(\"Número de comparações                      : {}.\".format(len(resultado_comparacao)))"]},{"cell_type":"markdown","metadata":{"id":"rTWsTdsrnTr3"},"source":[]},{"cell_type":"markdown","metadata":{"id":"rMg19DZzYjHB"},"source":["## 5.3 Gera arquivo das comparações  "]},{"cell_type":"markdown","metadata":{"id":"waF8KYDlYEH2"},"source":["### 5.3.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kahGlJdWdP8f"},"outputs":[],"source":["# Nome do arquivo\n","NOME_ARQUIVO_COMPARACAO_PALAVRA = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""]},{"cell_type":"markdown","metadata":{"id":"midCJ2AYes2x"},"source":["### 5.3.2 Gera arquivo comparação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vdHTuPLDYjHB"},"outputs":[],"source":["# Cria o dataframe da lista\n","resultado_comparacao = pd.DataFrame(resultado_comparacao, columns = [\"id\",\n","                                                                     \"index_documento\",\n","                                                                     \"index_sentenca\",\n","                                                                     \"index_wi\",\n","                                                                     \"wi\",\n","                                                                     \"pos_i\",\n","                                                                     \"index_wj\",\n","                                                                     \"wj\",\n","                                                                     \"pos_j\",\n","                                                                     \"cos_mean\",\n","                                                                     \"euc_mean\",\n","                                                                     \"man_mean\",\n","                                                                     \"cos_max\",\n","                                                                     \"euc_max\",\n","                                                                     \"man_max\"])\n","\n","# Nome do arquivo original\n","nome_arquivo = DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_PALAVRA\n","\n","# Salva o arquivo original\n","resultado_comparacao.to_csv(nome_arquivo,  sep=\";\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"F9JSH-_lYjHB"},"source":["### 5.3.3 Carrega os dados\n","\n","Carrega os dados das sentencas a partir dos arquivos.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ob-mUkjYjHC"},"outputs":[],"source":["# Importa das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_comparacao_palavra = pd.read_csv(DIRETORIO_LOCAL + NOME_ARQUIVO_COMPARACAO_PALAVRA, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"Quantidade de comparações: {}.\".format(len(lista_comparacao_palavra)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNCI53tPYjHC"},"outputs":[],"source":["lista_comparacao_palavra.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"DFMUo8Oo2CJp"},"source":["### 5.4.4 Compacta e copia o arquivo para uma pasta do GoogleDrive\n","\n","Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"7eb_zukpuHq3"},"source":["Compacta o arquivo.\n","\n","Usa o zip para compactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NunMOJWR2O8H"},"outputs":[],"source":["!zip -o -j -q \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA\""]},{"cell_type":"markdown","metadata":{"id":"49_9c2P2nrOx"},"source":["Copia o arquivo  para o GoogleDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LqDBH5pUnrOx"},"outputs":[],"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","    # Copia o arquivo das comparações para o google drive\n","    !cp \"$DIRETORIO_LOCAL$NOME_ARQUIVO_COMPARACAO_PALAVRA_COMPACTADO\" \"$DIRETORIO_DRIVE\"\n","\n","    logging.info(\"Terminei a cópia do arquivo.\")"]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 5 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Bcjt085lZGUr"},"source":["## 5.1 Tempo final de processamento\n","\n"," 100 = Tempo processamento:  22:20:13 (h:mm:ss)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H50_GKJwpDha"},"outputs":[],"source":["# Pega o tempo atual menos o tempo do início do processamento.\n","final_processamento = time.time()\n","tempo_total_processamento = formataTempo(final_processamento - inicio_processamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempo_total_processamento))"]}],"metadata":{"colab":{"provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}